$ python train.py config/train_openwebtext.py 
Overriding config with config/train_openwebtext.py:
# train on openwebtext dataset
# uses data prepared by data/openwebtext_local/prepare.py

out_dir = 'out-openwebtext'
eval_interval = 500 # evaluate less frequently on larger dataset
eval_iters = 200
log_interval = 100 # don't print too often

# save checkpoint when val improves
always_save_checkpoint = False

wandb_log = False # override via command line if you like
wandb_project = 'openwebtext'
wandb_run_name = 'nano-gpt'

dataset = 'openwebtext_local'
gradient_accumulation_steps = 4 # increase for effective batch size while reducing per-iteration memory
batch_size = 16 # reduced for memory constraints
block_size = 512 # reduced context length for memory

# GPT model for openwebtext (smaller for limited GPU memory)
n_layer = 6
n_head = 6
n_embd = 384
dropout = 0.0

learning_rate = 3e-4 # standard for GPT models
max_iters = 20000
lr_decay_iters = 20000 # make equal to max_iters usually
min_lr = 3e-5 # learning_rate / 10 usually
beta2 = 0.99 # standard for GPT models

warmup_iters = 2000 # more important for larger models

# on macbook also add
# device = 'cpu'  # run on cpu only
# compile = False # do not torch compile the model

tokens per iteration will be: 32,768
Initializing a new model from scratch
defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)
number of parameters: 29.94M
/home/lzw/projects/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))
num decayed parameter tensors: 26, with 30,130,176 parameters
num non-decayed parameter tensors: 13, with 4,992 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
W1116 02:26:15.911000 1188717 torch/_inductor/utils.py:1250] [0/0] Not enough SMs to use max_autotune_gemm mode
step 0: train loss 10.8843, val loss 10.8781
iter 0: loss 10.8865, time 12543.49ms, mfu -100.00%
iter 100: loss 9.8791, time 168.65ms, mfu 12.07%
iter 200: loss 8.8051, time 170.07ms, mfu 12.06%
iter 300: loss 7.8512, time 168.80ms, mfu 12.06%
iter 400: loss 7.3111, time 169.19ms, mfu 12.06%
step 500: train loss 7.1272, val loss 7.0624
saving checkpoint to out-openwebtext
iter 500: loss 7.0877, time 5985.31ms, mfu 10.88%
iter 600: loss 7.0230, time 176.13ms, mfu 10.95%
iter 700: loss 6.5128, time 168.66ms, mfu 11.06%
iter 800: loss 6.6946, time 169.09ms, mfu 11.16%
iter 900: loss 6.1617, time 168.69ms, mfu 11.25%
step 1000: train loss 6.2599, val loss 6.2273
saving checkpoint to out-openwebtext
iter 1000: loss 6.2318, time 5726.97ms, mfu 10.16%
iter 1100: loss 6.1413, time 168.98ms, mfu 10.35%
iter 1200: loss 5.9996, time 170.22ms, mfu 10.51%
iter 1300: loss 5.8912, time 186.07ms, mfu 10.55%
iter 1400: loss 5.7663, time 170.29ms, mfu 10.69%
step 1500: train loss 5.7334, val loss 5.6736
saving checkpoint to out-openwebtext
iter 1500: loss 5.7973, time 6179.80ms, mfu 9.66%
iter 1600: loss 5.7167, time 168.92ms, mfu 9.90%
iter 1700: loss 5.3576, time 168.75ms, mfu 10.11%
iter 1800: loss 5.4523, time 181.16ms, mfu 10.22%
iter 1900: loss 5.2974, time 169.01ms, mfu 10.41%
step 2000: train loss 5.3112, val loss 5.2756
saving checkpoint to out-openwebtext
iter 2000: loss 5.3484, time 5723.40ms, mfu 9.40%
iter 2100: loss 5.3673, time 168.90ms, mfu 9.67%
iter 2200: loss 5.2496, time 168.92ms, mfu 9.90%
iter 2300: loss 5.1582, time 169.21ms, mfu 10.12%
iter 2400: loss 4.9125, time 186.46ms, mfu 10.20%
step 2500: train loss 4.9656, val loss 4.9400
saving checkpoint to out-openwebtext
iter 2500: loss 4.8312, time 6229.08ms, mfu 9.21%
iter 2600: loss 4.8953, time 168.95ms, mfu 9.49%
iter 2700: loss 4.8632, time 169.11ms, mfu 9.75%
iter 2800: loss 4.9114, time 168.85ms, mfu 9.98%
iter 2900: loss 4.7745, time 169.04ms, mfu 10.18%
step 3000: train loss 4.7638, val loss 4.7682
saving checkpoint to out-openwebtext
iter 3000: loss 4.6754, time 5750.81ms, mfu 9.20%
iter 3100: loss 4.7714, time 169.44ms, mfu 9.48%
iter 3200: loss 4.4379, time 169.54ms, mfu 9.73%
iter 3300: loss 4.7479, time 169.34ms, mfu 9.96%
iter 3400: loss 4.7077, time 169.15ms, mfu 10.17%
step 3500: train loss 4.6386, val loss 4.6302
saving checkpoint to out-openwebtext
iter 3500: loss 4.6945, time 5749.50ms, mfu 9.19%
iter 3600: loss 4.4618, time 168.92ms, mfu 9.47%
iter 3700: loss 4.4450, time 168.71ms, mfu 9.73%
iter 3800: loss 4.3306, time 169.35ms, mfu 9.96%
iter 3900: loss 4.7535, time 168.95ms, mfu 10.17%
step 4000: train loss 4.5436, val loss 4.5579
saving checkpoint to out-openwebtext
iter 4000: loss 4.1946, time 5756.89ms, mfu 9.19%
iter 4100: loss 4.2624, time 168.83ms, mfu 9.48%
iter 4200: loss 4.4623, time 169.01ms, mfu 9.73%
iter 4300: loss 4.6044, time 168.97ms, mfu 9.96%
iter 4400: loss 4.3937, time 170.35ms, mfu 10.16%
step 4500: train loss 4.4647, val loss 4.4794
saving checkpoint to out-openwebtext
iter 4500: loss 4.6349, time 5951.10ms, mfu 9.18%
iter 4600: loss 4.3499, time 169.15ms, mfu 9.46%
iter 4700: loss 4.2699, time 187.80ms, mfu 9.60%
iter 4800: loss 4.3857, time 185.54ms, mfu 9.74%
iter 4900: loss 4.3867, time 169.25ms, mfu 9.97%
step 5000: train loss 4.3997, val loss 4.4587
saving checkpoint to out-openwebtext
iter 5000: loss 4.4373, time 5859.69ms, mfu 9.01%
iter 5100: loss 4.2835, time 186.73ms, mfu 9.19%
iter 5200: loss 4.2509, time 169.25ms, mfu 9.48%
iter 5300: loss 4.1811, time 169.31ms, mfu 9.73%
iter 5400: loss 4.4081, time 168.75ms, mfu 9.97%
step 5500: train loss 4.3647, val loss 4.3876
saving checkpoint to out-openwebtext
iter 5500: loss 4.1518, time 5699.80ms, mfu 9.00%
iter 5600: loss 4.5050, time 168.78ms, mfu 9.31%
iter 5700: loss 4.2684, time 187.83ms, mfu 9.46%
iter 5800: loss 4.4142, time 168.78ms, mfu 9.72%
iter 5900: loss 4.3465, time 169.19ms, mfu 9.95%
step 6000: train loss 4.3189, val loss 4.3621
saving checkpoint to out-openwebtext
iter 6000: loss 4.2397, time 5734.57ms, mfu 8.99%
iter 6100: loss 4.2487, time 168.93ms, mfu 9.30%
iter 6200: loss 4.3179, time 185.69ms, mfu 9.46%
iter 6300: loss 4.4935, time 169.15ms, mfu 9.72%
iter 6400: loss 4.3065, time 185.18ms, mfu 9.85%
step 6500: train loss 4.2670, val loss 4.3369
saving checkpoint to out-openwebtext
iter 6500: loss 4.2895, time 5910.00ms, mfu 8.90%
iter 6600: loss 4.4823, time 168.72ms, mfu 9.21%
iter 6700: loss 4.0932, time 168.69ms, mfu 9.50%
iter 6800: loss 4.3355, time 168.71ms, mfu 9.76%
iter 6900: loss 4.2187, time 168.94ms, mfu 9.99%
step 7000: train loss 4.2425, val loss 4.3072
saving checkpoint to out-openwebtext
iter 7000: loss 4.5281, time 5894.46ms, mfu 9.02%
iter 7100: loss 4.3436, time 169.98ms, mfu 9.32%
iter 7200: loss 4.3176, time 169.13ms, mfu 9.59%
iter 7300: loss 4.4420, time 169.80ms, mfu 9.83%
iter 7400: loss 4.1685, time 169.33ms, mfu 10.05%
step 7500: train loss 4.2157, val loss 4.3067
saving checkpoint to out-openwebtext
iter 7500: loss 3.9141, time 5811.76ms, mfu 9.08%
iter 7600: loss 3.9650, time 168.83ms, mfu 9.38%
iter 7700: loss 4.2022, time 180.07ms, mfu 9.57%
iter 7800: loss 4.4252, time 173.79ms, mfu 9.78%
iter 7900: loss 4.1367, time 173.73ms, mfu 9.98%
step 8000: train loss 4.1772, val loss 4.2673
saving checkpoint to out-openwebtext
iter 8000: loss 4.2982, time 5810.37ms, mfu 9.01%
iter 8100: loss 4.2510, time 168.85ms, mfu 9.32%
iter 8200: loss 4.0497, time 169.25ms, mfu 9.59%
iter 8300: loss 3.9729, time 180.65ms, mfu 9.76%
iter 8400: loss 4.1464, time 169.29ms, mfu 9.98%
step 8500: train loss 4.1550, val loss 4.2553
saving checkpoint to out-openwebtext
iter 8500: loss 4.1465, time 5857.29ms, mfu 9.02%
iter 8600: loss 3.9725, time 169.06ms, mfu 9.32%
iter 8700: loss 4.0591, time 169.38ms, mfu 9.59%
iter 8800: loss 3.9263, time 174.96ms, mfu 9.79%
iter 8900: loss 4.1332, time 168.92ms, mfu 10.02%
step 9000: train loss 4.1279, val loss 4.2210
saving checkpoint to out-openwebtext
iter 9000: loss 4.0102, time 6120.26ms, mfu 9.05%
iter 9100: loss 4.1612, time 172.97ms, mfu 9.32%
iter 9200: loss 4.1013, time 172.58ms, mfu 9.57%
iter 9300: loss 4.1252, time 175.13ms, mfu 9.78%
iter 9400: loss 4.0082, time 175.78ms, mfu 9.96%
step 9500: train loss 4.1132, val loss 4.2164
saving checkpoint to out-openwebtext
iter 9500: loss 4.3587, time 6056.24ms, mfu 8.99%
iter 9600: loss 3.9961, time 170.22ms, mfu 9.29%
iter 9700: loss 4.2011, time 175.57ms, mfu 9.52%
iter 9800: loss 4.1253, time 171.79ms, mfu 9.75%
iter 9900: loss 4.0290, time 170.42ms, mfu 9.97%
step 10000: train loss 4.0898, val loss 4.2066
saving checkpoint to out-openwebtext
iter 10000: loss 4.2603, time 6030.52ms, mfu 9.01%
iter 10100: loss 4.2145, time 170.77ms, mfu 9.30%
iter 10200: loss 4.0360, time 171.19ms, mfu 9.56%
iter 10300: loss 4.2156, time 168.74ms, mfu 9.81%
iter 10400: loss 4.1601, time 183.15ms, mfu 9.94%
step 10500: train loss 4.0719, val loss 4.1913
saving checkpoint to out-openwebtext
iter 10500: loss 4.1386, time 5799.57ms, mfu 8.98%
iter 10600: loss 3.9234, time 168.67ms, mfu 9.29%
iter 10700: loss 3.8924, time 187.10ms, mfu 9.45%
iter 10800: loss 4.1522, time 168.98ms, mfu 9.71%
iter 10900: loss 4.1191, time 183.73ms, mfu 9.84%
step 11000: train loss 4.0711, val loss 4.1755
saving checkpoint to out-openwebtext
iter 11000: loss 3.9102, time 5827.40ms, mfu 8.89%
iter 11100: loss 4.1925, time 170.38ms, mfu 9.20%
iter 11200: loss 3.8709, time 169.10ms, mfu 9.48%
iter 11300: loss 4.0975, time 170.55ms, mfu 9.73%
iter 11400: loss 4.1363, time 173.69ms, mfu 9.93%
step 11500: train loss 4.0275, val loss 4.1562
saving checkpoint to out-openwebtext
iter 11500: loss 3.9054, time 5849.48ms, mfu 8.97%
iter 11600: loss 4.0485, time 170.68ms, mfu 9.27%
iter 11700: loss 4.1781, time 185.44ms, mfu 9.44%
iter 11800: loss 3.9339, time 172.56ms, mfu 9.67%
iter 11900: loss 4.0746, time 168.77ms, mfu 9.91%
step 12000: train loss 4.0258, val loss 4.1544
saving checkpoint to out-openwebtext
iter 12000: loss 3.9063, time 5721.62ms, mfu 8.96%
iter 12100: loss 3.9166, time 169.41ms, mfu 9.26%
iter 12200: loss 3.9403, time 169.04ms, mfu 9.54%
iter 12300: loss 3.9443, time 168.97ms, mfu 9.79%
iter 12400: loss 4.0132, time 170.86ms, mfu 10.00%
step 12500: train loss 4.0136, val loss 4.1335
saving checkpoint to out-openwebtext
iter 12500: loss 4.1919, time 5726.01ms, mfu 9.04%
iter 12600: loss 4.0015, time 169.32ms, mfu 9.34%
iter 12700: loss 4.0335, time 169.43ms, mfu 9.60%
iter 12800: loss 4.1352, time 169.47ms, mfu 9.84%
iter 12900: loss 4.0515, time 169.19ms, mfu 10.06%
step 13000: train loss 4.0175, val loss 4.1158
saving checkpoint to out-openwebtext
iter 13000: loss 3.8369, time 5731.38ms, mfu 9.09%
iter 13100: loss 3.7155, time 168.89ms, mfu 9.39%
iter 13200: loss 4.0091, time 168.97ms, mfu 9.65%
iter 13300: loss 4.1370, time 169.73ms, mfu 9.89%
iter 13400: loss 3.9609, time 169.24ms, mfu 10.10%
step 13500: train loss 4.0012, val loss 4.1204
iter 13500: loss 3.5406, time 5314.98ms, mfu 9.13%
iter 13600: loss 3.7778, time 169.11ms, mfu 9.42%
iter 13700: loss 3.8926, time 168.90ms, mfu 9.68%
iter 13800: loss 4.1446, time 168.95ms, mfu 9.92%
iter 13900: loss 4.2612, time 169.80ms, mfu 10.13%
step 14000: train loss 3.9800, val loss 4.1113
saving checkpoint to out-openwebtext
iter 14000: loss 3.9438, time 5721.31ms, mfu 9.15%
iter 14100: loss 3.9920, time 169.20ms, mfu 9.44%
iter 14200: loss 4.0767, time 170.00ms, mfu 9.69%
iter 14300: loss 3.8435, time 169.16ms, mfu 9.92%
iter 14400: loss 3.9228, time 169.34ms, mfu 10.13%
step 14500: train loss 3.9628, val loss 4.0986
saving checkpoint to out-openwebtext
iter 14500: loss 3.9948, time 5749.95ms, mfu 9.16%
iter 14600: loss 3.8432, time 169.26ms, mfu 9.44%
iter 14700: loss 3.8921, time 169.78ms, mfu 9.70%
iter 14800: loss 3.9660, time 169.88ms, mfu 9.93%
iter 14900: loss 3.9016, time 169.20ms, mfu 10.14%
step 15000: train loss 3.9504, val loss 4.0872
saving checkpoint to out-openwebtext
iter 15000: loss 4.0722, time 5750.61ms, mfu 9.16%
iter 15100: loss 3.9283, time 169.24ms, mfu 9.44%
iter 15200: loss 3.6230, time 169.49ms, mfu 9.70%
iter 15300: loss 3.8759, time 169.30ms, mfu 9.93%
iter 15400: loss 4.1464, time 169.79ms, mfu 10.14%
step 15500: train loss 3.9437, val loss 4.0869
saving checkpoint to out-openwebtext
iter 15500: loss 3.9361, time 5743.30ms, mfu 9.16%
iter 15600: loss 3.9583, time 169.49ms, mfu 9.44%
iter 15700: loss 3.9084, time 170.15ms, mfu 9.70%
iter 15800: loss 4.1016, time 169.53ms, mfu 9.93%
iter 15900: loss 4.0565, time 169.41ms, mfu 10.14%
step 16000: train loss 3.9463, val loss 4.0728
saving checkpoint to out-openwebtext
iter 16000: loss 4.0023, time 5772.22ms, mfu 9.16%
iter 16100: loss 3.9726, time 169.00ms, mfu 9.45%
iter 16200: loss 3.7845, time 169.33ms, mfu 9.70%
iter 16300: loss 4.1504, time 170.24ms, mfu 9.93%
iter 16400: loss 3.9404, time 172.46ms, mfu 10.12%
step 16500: train loss 3.9268, val loss 4.0678
saving checkpoint to out-openwebtext
iter 16500: loss 3.9675, time 5762.44ms, mfu 9.14%
iter 16600: loss 3.9906, time 168.91ms, mfu 9.43%
iter 16700: loss 3.8143, time 169.25ms, mfu 9.69%
iter 16800: loss 3.9499, time 169.63ms, mfu 9.92%
iter 16900: loss 3.9879, time 170.49ms, mfu 10.12%
step 17000: train loss 3.8984, val loss 4.0715
iter 17000: loss 3.9936, time 5312.43ms, mfu 9.15%
iter 17100: loss 4.1248, time 170.09ms, mfu 9.43%
iter 17200: loss 3.7568, time 169.15ms, mfu 9.69%
iter 17300: loss 3.9044, time 169.40ms, mfu 9.92%
iter 17400: loss 3.7032, time 169.22ms, mfu 10.13%
step 17500: train loss 3.9235, val loss 4.0704
iter 17500: loss 3.8193, time 5321.48ms, mfu 9.16%
iter 17600: loss 3.7283, time 174.41ms, mfu 9.41%
iter 17700: loss 4.1577, time 168.57ms, mfu 9.68%
iter 17800: loss 3.8104, time 168.66ms, mfu 9.91%
iter 17900: loss 3.7469, time 168.73ms, mfu 10.13%
step 18000: train loss 3.9110, val loss 4.0541
saving checkpoint to out-openwebtext
iter 18000: loss 4.0984, time 5734.01ms, mfu 9.15%
iter 18100: loss 4.0348, time 168.82ms, mfu 9.44%
iter 18200: loss 4.1024, time 168.59ms, mfu 9.71%
iter 18300: loss 4.0035, time 168.62ms, mfu 9.94%
iter 18400: loss 3.9326, time 168.60ms, mfu 10.16%
step 18500: train loss 3.9223, val loss 4.0545
iter 18500: loss 3.7063, time 5304.22ms, mfu 9.18%
iter 18600: loss 4.1207, time 168.59ms, mfu 9.47%
iter 18700: loss 3.8757, time 168.79ms, mfu 9.73%
iter 18800: loss 3.6193, time 168.66ms, mfu 9.96%
iter 18900: loss 3.9650, time 168.60ms, mfu 10.17%
step 19000: train loss 3.8934, val loss 4.0578
iter 19000: loss 4.1044, time 5299.10ms, mfu 9.19%
iter 19100: loss 4.0442, time 168.70ms, mfu 9.48%
iter 19200: loss 3.7855, time 168.60ms, mfu 9.74%
iter 19300: loss 3.9035, time 168.50ms, mfu 9.97%
iter 19400: loss 3.8136, time 168.51ms, mfu 10.18%
step 19500: train loss 3.9118, val loss 4.0556
iter 19500: loss 3.8283, time 5305.05ms, mfu 9.20%
iter 19600: loss 3.8425, time 168.82ms, mfu 9.49%
iter 19700: loss 3.9263, time 168.49ms, mfu 9.75%
iter 19800: loss 3.9136, time 168.43ms, mfu 9.98%
iter 19900: loss 4.0380, time 168.46ms, mfu 10.19%
step 20000: train loss 3.8996, val loss 4.0543
iter 20000: loss 3.8327, time 5302.82ms, mfu 9.21%