---
audio: false
generated: true
image: false
lang: en
layout: post
model: x-ai/grok-4-fast
title: MIT Professor Advances AI Safety
translated: false
---

Aleksander Mądry is a prominent computer scientist and professor at MIT, where he holds the Cadence Design Systems Professorship in the Electrical Engineering and Computer Science (EECS) department. He is also a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL) and serves as the Director of the MIT Center for Deployable Machine Learning. Mądry earned his Ph.D. from MIT in 2011, followed by postdoctoral work at Microsoft Research New England and a faculty position at EPFL before returning to MIT in 2015.

His research primarily focuses on machine learning, optimization, and algorithmic graph theory, with a particular emphasis on developing robust, reliable, and responsible machine learning systems for real-world deployment. He leads the Madry Lab at MIT, which explores tools and techniques to mitigate risks in AI models, such as adversarial robustness and safe decision-making. Notable contributions include foundational work on provably robust neural networks and data attribution methods for large models.

Since May 2023, Mądry has been on leave from MIT to join OpenAI as a Member of Technical Staff. In this role, he heads the AI Preparedness and Reasoning team, which evaluates frontier AI models' potential risks (like catastrophic misuse) and advances reasoning capabilities to make systems more capable, reliable, and aligned with human values. He previously led OpenAI's Preparedness team, focused on safety evaluations, before a 2024 reorganization shifted his emphasis toward reasoning projects. In a recent interview, Mądry predicted that artificial general intelligence (AGI) could emerge by the end of 2026, marking a transition where AI visibly impacts sectors like finance and pharmaceuticals.

He is active on X (formerly Twitter) as @aleks_madry, where he shares updates on his research, including recent work on using smaller "proxy" models to analyze training data effects on large AI systems.

### References
- [Aleksander Mądry Homepage](http://madry.mit.edu/)
- [Madry Lab](https://madrylab.mit.edu/)
- [Aleksander Mądry LinkedIn](https://www.linkedin.com/in/aleksander-madry-61115b233)
- [OpenAI Reassigns Madry to AI Reasoning Role (CNBC, 2024)](https://www.cnbc.com/2024/07/23/openai-removes-ai-safety-executive-aleksander-madry-from-role.html)
- [Mądry on AGI Timeline (Reddit Interview Summary, 2025)](https://www.reddit.com/r/accelerate/comments/1ocgxdl/openais_aleksander_m%C4%85dry_by_the_end_of_2026_well/)
- [Mądry X Profile](https://x.com/aleks_madry)