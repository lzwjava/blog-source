---
audio: false
generated: true
image: false
lang: en
layout: post
model: x-ai/grok-4-fast
title: Training nanochat d32 on RTX 4070
translated: false
type: note
---

The nanochat d32 model (1.9B parameters, same as the one on nanochat.karpathy.ai) was trained on 38 billion tokens on an 8×H100 node in ~33 hours.

A single RTX 4070 (desktop version, 12 GB VRAM) is much slower than one H100, and you’ll also be limited by VRAM, so you can’t run the original batch size / sequence length without heavy quantization or gradient checkpointing.

Here are realistic estimates for training the same d32 model (1.9B, 38B tokens) on **one RTX 4070**:

| Setup on 4070 (12 GB)                  | Approx. TFLOPs (effective) | Estimated total training time | Notes |
|----------------------------------------|----------------------------|--------------------------------|-------|
| FP16 / BF16 (native, no quant)         | ~25–30 TFLOPs              | Impossible                     | Needs ~24–28 GB VRAM → OOM |
| 4-bit quant (QLoRA-style or GPTQ) + gradient checkpointing | ~18–22 TFLOPs | ~35–45 days (~850–1,100 hours) | Most realistic for 12 GB card |
| 3-bit or NF4 + aggressive optimizer (AdamW-8bit) | ~20–24 TFLOPs | ~30–38 days (~750–900 hours) | Slightly faster, still ~1 month |
| 2.5–2.7-bit experimental quant (very recent bitsandbytes) | ~22–26 TFLOPs | ~28–35 days | Cutting-edge, may be unstable |

### Summary for one RTX 4070
- Realistically expect **≈ 4–6 weeks** of continuous 24/7 training if you use modern 3–4 bit quantization and all the memory-saving tricks Karpathy uses in llm.c / nanoGPT (gradient checkpointing, flash-attention, torch.compile, etc.).
- Power consumption will be ~200–250 W the whole time → ~150–200 kWh total → electricity cost roughly $15–40 depending on your local rates (Taiwan electricity is ~NT$3–4/kWh → ~NT$500–800).

If you only have a 4070 Laptop (usually 8 GB or capped lower TDP), add another 50–100% time (so 2–3 months).

### Faster alternatives on one 4070
- Train the smaller d21 model (1.3B params) instead → ~60–65% of the time → 18–25 days
- Train d32 but on fewer tokens (e.g., 15B–20B tokens) → you’ll finish in 12–20 days and still get something quite usable (still beats GPT-2 on many tasks).

So bottom line: yes, you absolutely can train nanochat d32 on a single RTX 4070, but expect roughly **one month** of nonstop running with 3–4 bit quantization.