---
audio: false
generated: false
image: false
lang: en
layout: post
title: AI Tools Tips
translated: false
type: post
---

* Copy example code into Cursor, and use comments to provide context.

* In the Hong Kong region, it is acceptable to use DeepSeek or Mistral services, while it is not acceptable to use ChatGPT, Claude, or Gemini.

* The API policy of a region is approximately the same as its app policy.

* Use Cursor instead of Visual Studio Code.

* There are still cases where you need to use Visual Studio Code, such as for git merge editor scenarios, where I still use `git config --global core.editor "code --wait"`.

* Starting the day from Deepseek V3 release, we don't need to sunbscribe any AI tools.

* Use Gemini or Grok to generate festival celebration images with prompts like "Generate a happy Lunar Snake New Year image with text names included".

* In some cases, even when providing original text to AI models to create a table, a few places in the output may differ from the input. For example, when using the Deepseek V3 model in Cursor to generate a table of pip list, it may include versions like `1.极狐0`. Here, `极狐` refers to the Chinese GitLab platform.

* When using Deepseek or Mistral API to translate titles with prompts like `You are a professional translator. You are translating a markdown file for a Jekyll blog post from English to Chinese. {text}`, it can lead to incorrect translations. Besides the text you provide, the output often includes excessive translation.

* Though sometimes AI models in Cursor give partially correct text, we can accept them, as we can add follow-up instructions that will make the AI models regenerate the correct parts.

* Avoid providing excessive context to large language models if it's unlikely to be helpful. For example, when generating conversational dialog lines, avoid providing 100 points on a topic. Large language models already contain vast amounts of data.

* When providing ample context for tasks like translation or generating dialog lyrics, avoid using chain-of-thought features, as it can be slow and lead to verbose or unhelpful responses.

* One way to test whether a chatbot can follow a user's instructions is to ask it to explain something in English and then continue the input in Chinese, observing whether the chatbot maintains its output in English.

* Instead of providing context to LLMs, finetune a model based on a large dataset of text or code, and then use the finetuned model.

* Use AI chatbots in turns for a week so you can understand their differences. Don't stick to one AI tool or the best tool if you want to learn more.

* It is enjoyable to open Grok, Gemini, ChatGPT, DeepSeek, Mistral, Perplexity and Claude together, open many tabs with them, read their answers, and then ask questions. We can compare the answers or continue asking questions based on our interests.

* If the task is summarizing YouTube videos, use Gemini first; if it involves information from X, use Grok first.

* Books are becoming less and less useful. Use AI chatbots to read a book; they can provide you with Chapter 1 or Chapter 2, a summary, or an introduction of a book.

* Instead of using deep thinking or Chain of Thought (CoT) to solve hard problems, you can sometimes simplify problems to let standard models solve them.

* Language matters when chatting with AI, especially when it involves specific regions or areas. Using relevant local knowledge can help you find more accurate information—for example, on how to get an identity card or register a vehicle.

* When working with the latest information—such as newly released libraries, code, or documentation—it is better to check with several AI chatbots, as their knowledge cutoffs and responses may differ in subtle ways.

* After writing an essay, we can use AI chatbots to fix grammar and Git to view the differences.

* A powerful way to use AI is to write down your ideas on a topic and then have Grok analyze them and provide a comprehensive guide and suggestions.

* It's better to split a large Python script into smaller ones that are under 100 lines of code, as this uses fewer tokens and allows large language models to handle them more effectively.

* For LLMs, it’s easy to make mistakes when generating Chinese holidays due to lunar calendar rules. These holidays vary each year, requiring LLMs to perform calculations and verify results.

* If a repository contains code and blog posts with code, AI often fails to process them correctly and may garble them.

* File name information in LLM context is often overlooked. However, this information is important in certain cases.

* [AI-Powered Git Commit Messages](./gitmessageai-en)

* [Conversation Audio Generation](./conversation-style-en)

* [Google Cloud Transcription](./speech-to-text-en)

* [Trying llama.cpp](./llama-cpp-en)

* [A Case Using Search in ChatGPT](./ai-search-en)

* [Deepseek, Mistral and Anthropic](./dma-en)