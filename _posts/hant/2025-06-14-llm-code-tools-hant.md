---
audio: false
generated: true
image: false
lang: hant
layout: post
model: openai/gpt-5
title: 大型語言模型、代碼推理與工具使用
translated: true
type: note
---

很好的問題！你實際上是在詢問像 **Anthropic 的 Claude（以及類似的 LLMs）** 內部是如何處理以下事項的：

1. **程式碼執行或與程式碼相關的推理**
2. **JSON 結構檢查/結構化輸出驗證**
3. **工具使用及在工具之間的路由選擇**

讓我詳細分解說明。

---

### 1. 程式碼推理與執行
Claude（以及其他前沿的 LLMs）並不會直接在模型內部*執行*程式碼——它們是通過預測程式碼或邏輯步驟的 token 來**模擬程式碼推理**。

- 在**一般文字模式**下，Claude 可以通過延續模式來「撰寫」程式碼，但不會在內部執行它。
- 當與**後端系統（如 Anthropic 的 Workbench 或 OpenAI 的 Code Interpreter）** 一起使用時，系統可以捕捉這些程式碼片段，然後在沙盒環境中實際*執行*它們。
- 執行結果隨後可以作為上下文回傳給模型，因此它可以進行鏈式推理，例如：
  → 生成程式碼 → 外部執行 → 接收輸出 → 決定下一步。

所以，智能體現在這個循環中：LLM 生成 → 外部執行器執行 → LLM 解讀結果。

---

### 2. JSON 結構檢查
許多 API（Claude、OpenAI 等）現在支援**結構化輸出模式**，你可以附加一個 JSON 結構定義。以下是其內部運作方式：

- 你在請求中傳遞一個 **JSON 結構定義**。
- LLM 被引導只輸出符合該結構的**有效 JSON**。
- 如果它試圖輸出無效的 JSON，系統會檢測到（使用如 [jsonschema](https://pypi.org/project/jsonschema/) 這樣的驗證器），並要求模型「修復」輸出。
- 在底層，這通常是一種**受限解碼**或**基於文法的解碼**機制——基本上是限制 token 的生成，只允許生成「在結構中有效的下一個 token」。

這確保了輸出是語法和語義上都正確的 JSON，這對於工具使用的自動化至關重要。

---

### 3. 工具使用與路由
工具使用是通過一個位於 LLM 和工具執行環境之間的**路由層**來處理的：

- **路由邏輯**：模型被提示以*決定要呼叫哪個工具*（或直接回應）。
- **結構強制執行**：每個工具都有一個輸入結構。LLM 需要為該工具產生有效的 JSON。
- **執行適配器**：協調層（在模型外部）接收 LLM 產生的 JSON，根據結構進行驗證，執行工具，然後將結果作為上下文回傳。
- **鏈式推理（ReAct 風格）**：LLM「自言自語地思考」（可能會產生對用戶隱藏的推理步驟），然後在必要時發出工具呼叫，逐步得出最終答案。

例如：
```json
{
  "tool": "web_search",
  "query": "latest research on quantum error correction"
}
```
→ 路由器看到 `"tool": "web_search"`，驗證結構，執行網絡搜索，將結果放回模型的上下文中，然後模型繼續推理。

Anthropic 的 Claude、OpenAI 的 GPTs、LangChain 以及其他系統都支援這種模式。

---

### 🔑 總結
- **Claude 與程式碼**：不在內部執行程式碼；生成程式碼 → 沙盒執行 → 回傳結果 → 迭代推理。
- **JSON 結構檢查**：使用受限解碼 / 結構驗證來確保有效的結構化輸出。
- **工具使用路由**：LLM 以 JSON 格式選擇工具呼叫，協調引擎驗證並執行它們，並在循環中將結果回傳。

---

👉 你希望我**繪製一個流程圖**（LLM ↔ 工具路由器 ↔ 結構驗證器 ↔ 執行引擎）以便更清晰地視覺化展示嗎？