---
audio: false
generated: true
image: false
lang: hant
layout: post
model: x-ai/grok-4-fast
title: 計算驅動人工智能未來
translated: true
type: note
---

在史丹佛大學的CS25課程（關於Transformer架構的課程）中，OpenAI研究科學家Hyung Won Chung以客座講師身份發表了題為「塑造AI未來」的演講（屬於V4系列的一部分）。他闡述了在任何領域中，識別重大變革背後的「主導驅動力」對於有效預測其未來發展軌跡的重要性。

### 討論重點摘要
- **筆墜類比**：Chung透過一個簡單的物理學例子來說明：當你鬆手讓筆掉落時，其軌跡是可預測的，因為我們理解**主導力量**——重力——壓倒了空氣阻力等次要因素。透過聚焦於這種主導力量，我們能簡化複雜系統並做出可靠的預測。他主張我們應將同樣的視角應用於AI領域。

- **AI領域的主導力量**：對AI研究而言，主導驅動力是**運算成本呈指數級下降**（即更廉價且更充裕的計算能力）。這一直是推動快速進步的關鍵因素，使模型能透過更多數據和參數進行擴展。Chung強調，理解這種力量能將焦點轉向建立可擴展的通用方法，而非過度設計、偏見重重的方案。

- **與「苦澀教訓」的關聯**：他引用了Rich Sutton的《苦澀教訓》一文，該文主張AI的進步來自於運用更多運算資源與數據，並採用更簡潔的基於學習的方法（如Transformer），而非依賴人為設計的歸納偏見。當運算能力成為主導力量時，架構設計應優先考慮可擴展性——例如，相較於更複雜的編碼器-解碼器配置，更傾向使用僅解碼器的Transformer架構，因為在資源充沛的情況下，額外的結構已無必要。

- **更廣泛的影響**：Chung展示了運算能力增長與AI性能表現的歷史數據圖表，指出過去趨勢（如摩爾定律）表明持續的規模擴展將驅動未來的突破。他的建議是：「當我們談論未來發展時，獲取建議的最佳途徑是回顧歷史。」

此框架有助於解釋為何近期的AI模型（例如OpenAI的模型）強調大規模擴展而非微調優化。

[史丹佛CS25：V4 - 與Hyung Won Chung共同塑造AI未來](https://www.linkedin.com/pulse/stanford-cs25-v4-shaping-future-ai-hyung-won-chung-tarazona-md-lf9pe)  
[完整講座影片（YouTube）](https://www.youtube.com/watch?v=orDKvo8h71o)