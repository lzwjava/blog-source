---
audio: true
lang: hant
layout: post
title: MMLU 基准测试
translated: true
---

## 前言

本文使用MMLU（大規模多任務語言理解）基準來評估一個語言模型。

MMLU基準是一個全面的測試，旨在評估模型在廣泛學科中執行各種任務的能力。它包含多項選擇題，涵蓋數學、歷史、法律和醫學等不同領域。

**數據集鏈接：**

*   [Papers with Code](https://paperswithcode.com/dataset/mmlu)
*   [Hugging Face Datasets](https://huggingface.co/datasets/cais/mmlu)

## llama-server

要運行llama-server：

```bash
build/bin/llama-server -m models/7B/mistral-7b-instruct-v0.2.Q4_K_M.gguf --port 8080
```

## MMLU基準

此腳本使用三種不同的後端來評估MMLU基準：`ollama`、`llama-server`和`deepseek`。

要運行MMLU基準代碼：

```python
import torch
from datasets import load_dataset
import requests
import json
from tqdm import tqdm
import argparse
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# 設置參數解析
parser = argparse.ArgumentParser(description="使用不同後端評估MMLU數據集。")
parser.add_argument("--type", type=str, default="ollama", choices=["ollama", "llama", "deepseek"], help="後端類型：ollama、llama或deepseek")
args = parser.parse_args()

# 加載MMLU數據集
subject = "college_computer_science"  # 選擇你的科目
dataset = load_dataset("cais/mmlu", subject, split="test", cache_dir="./.cache")

# 格式化提示，不包含少樣本示例
def format_mmlu_prompt(example):
    prompt = "以下是關於{}的多項選擇題".format(subject.replace("_", " "))
    prompt += "。請僅回答正確選項的字母（A、B、C或D）。"
    prompt += " 僅回答字母。不需要解釋。"
    
    # 添加當前問題
    prompt += f"問題：{example['question']}\n"
    prompt += "選項：\nA. {}\nB. {}\nC. {}\nD. {}\n".format(*example['choices'])
    return prompt

# 評估循環
correct = 0
total = 0

# 如果需要，初始化DeepSeek客戶端
if args.type == "deepseek":
    api_key = os.environ.get("DEEPSEEK_API_KEY")
    if not api_key:
        print("錯誤：未設置DEEPSEEK_API_KEY環境變量。")
        exit()
    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")


for i, example in tqdm(enumerate(dataset), total=len(dataset), desc="評估中"):
    prompt = format_mmlu_prompt(example)
    
    # 向後端發送請求
    if args.type == "ollama":
        url = "http://localhost:11434/v1/chat/completions"
        data = {
            "messages": [{"role": "user", "content": prompt}],
            "model": "mistral:7b"
        }
        headers = {"Content-Type": "application/json"}
        print(f"API輸入：{data}")
        response = requests.post(url, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            output_text = response.json()["choices"][0]["message"]["content"]
            predicted_answer = output_text.strip()[0] if len(output_text.strip()) > 0 else ""
            print(f"API輸出：{output_text}")
        else:
            predicted_answer = ""
            print(f"錯誤：{response.status_code} - {response.text}")
    elif args.type == "llama":
        url = "http://localhost:8080/v1/chat/completions"
        data = {
            "messages": [{"role": "user", "content": prompt}]
        }
        headers = {"Content-Type": "application/json"}
        print(f"API輸入：{data}")
        response = requests.post(url, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            output_text = response.json()["choices"][0]["message"]["content"]
            predicted_answer = output_text.strip()[0] if len(output_text.strip()) > 0 else ""
            print(f"API輸出：{output_text}")
        else:
            predicted_answer = ""
            print(f"錯誤：{response.status_code} - {response.text}")
    elif args.type == "deepseek":
        try:
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=100
            )
            if response and response.choices:
                output_text = response.choices[0].message.content.strip()
                predicted_answer = output_text.strip()[0] if len(output_text.strip()) > 0 else ""
                print(f"API輸出：{output_text}")
            else:
                predicted_answer = ""
                print("錯誤：API無響應。")
        except Exception as e:
            predicted_answer = ""
            print(f"API調用錯誤：{e}")
    else:
        raise ValueError("無效的後端類型")
    
    # 與真實答案比較
    
    answer_map = {0: "A", 1: "B", 2: "C", 3: "D"}
    ground_truth_answer = answer_map.get(example["answer"], "")
    is_correct = predicted_answer.upper() == ground_truth_answer
    if is_correct:
        correct += 1
    total += 1
    
    print(f"問題：{example['question']}")
    print(f"選項：A. {example['choices'][0]}, B. {example['choices'][1]}, C. {example['choices'][2]}, D. {example['choices'][3]}")
    print(f"預測答案：{predicted_answer}, 真實答案：{ground_truth_answer}, 正確：{is_correct}")
    print("-" * 30)

    if (i+1) % 10 == 0:
        accuracy = correct / total
        print(f"已處理 {i+1}/{len(dataset)}。當前準確率：{accuracy:.2%} ({correct}/{total})")


# 計算準確率
accuracy = correct / total
print(f"科目：{subject}")
print(f"準確率：{accuracy:.2%} ({correct}/{total})")
```

## 結果

### 零樣本評估

| 模型                     | 方式                      | 科目                        | 準確率   |
|---------------------------|--------------------------|--------------------------------|------------|
| mistral-7b-instruct-v0.2, Q4_K_M | macOS m2, 16GB, llama-server | MMLU college_computer_science | 40.00% (40/100) |
| Mistral-7B-Instruct-v0.3, Q4_0  | macOS m2, 16GB, ollama      | MMLU college_computer_science | 40.00% (40/100) |
| deepseek v3               | API, 2025.1.25           | MMLU college_computer_science | 78.00% (78/100) |
| gemini-1.5-flash          | API, 2025.1.25           | MMLU college_computer_science | 78.00% (78/100) |