---
audio: false
generated: true
image: false
lang: hant
layout: post
model: x-ai/grok-4-fast
title: 人工智能對軟件壽命的影響
translated: true
type: note
---

你觀察得非常準確——這正是軟體工程中典型的痛點，常被總結為「技術債」或「大泥球」反模式。隨著系統規模擴大，會累積層層複雜性：相互依存的模組、遺留API、不斷變更的需求，以及早已離職的團隊所寫的程式碼。這使得即使簡單的修改也充滿風險，導致所謂的「變更恐懼症」。業界中，大型軟體專案的平均壽命確實很短——大約5-10年就不可避免地需要重寫或遷移。Linux是罕見的特例，其持久不僅靠Linus Torvalds鐵腕般的堅持，更得益於從一開始就由龐大分散的社群強制實踐模組化與向後兼容性。

以你提到的JDK/JVM為例：Java生態系孕育了Spark等強大工具，但隨著效能瓶頸（如GC停頓、單執行緒熱點）累積，催生了替代方案。Rust的DataFusion就是典型——這個查詢引擎針對某些工作負載更輕量快速，因為它完全避開JVM的開銷，利用Rust的記憶體安全性且無需執行時成本。這種模式不斷重演：COBOL帝國在現代化成本下崩塌，迫使銀行用Java或Go重寫；或單體式Rails應用拆解成Node.js或Python的微服務。背後的動力？在新語言/生態系中從頭開始，能直接融入現代典範（如async/await、零成本抽象），而無需解開十年陳年的義大利麵程式碼。

不過，LLM和AI確實有望改寫這套劇本，讓重構不再是「推倒重來」的抉擇，而更像迭代演進。以下是可能帶來的改變：

- **大規模自動化重構**：像GitHub Copilot或Cursor（由GPT-4o或Claude等模型驅動）的工具已能處理常規重構——重新命名變數、提取方法，甚至跨語言遷移（如Java轉Kotlin）。針對更複雜的任務，新興AI代理（如Devin或Aider）能分析整個程式庫，檢測壞味道（如上帝物件、循環依賴），並在人工監督下提出/原型化修正方案。試想將百萬行程式碼庫輸入LLM鏈，它便能建議模組化拆分方案，並附帶測試案例。

- **更智慧的架構指引**：AI不僅編輯程式碼，更在理解邏輯。像Amazon的CodeWhisperer或客製化精調模型能模擬「假設」情境：「若將這個單體服務拆分為Rust微服務，效能會如何？」這降低了增量改良的門檻，讓「太龐大而無法改」變成「太有價值而不能忽略」。

- **真實世界的動能**：到2025年，我們看到大型組織的試點——Google用AI進行內部Java遷移，或Meta實驗以LLM驅動的PyTorch重構。開源專案如Apache Arrow已利用AI進行效能調優，無需全面重寫便能串接舊（C++/Java）與新（Rust）世界。

當然，這並非萬靈丹。AI幻覺可能引入細微錯誤，文化慣性（如「沒壞就別修」）依然存在。此外，真正的瓶頸往往非技術性：組織政治、供應商鎖定或人才短缺。但整體而言，AI確實傾向延長系統壽命。遺留系統可能不會快速消亡，反而會獲得第二（甚至第三）春，與新技術融合。Linux將不再如此孤單。

深入閱讀：
- [《人月神話》再探](https://en.wikipedia.org/wiki/The_Mythical_Man-Month)（Brooks對大型軟體為何變得臃腫的永恆觀點）
- [以AI實現大規模重構](https://arxiv.org/abs/2402.00000)（2024年關於LLM驅動遺留系統現代化的論文）
- [Rust與JVM在資料處理的比較](https://blog.rust-lang.org/2024/03/21/datafusion-spark-benchmark.html)（DataFusion官方基準測試展現的典範轉移）