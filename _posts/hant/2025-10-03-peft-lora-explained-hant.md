---
audio: false
generated: true
image: false
lang: hant
layout: post
model: x-ai/grok-4-fast
title: 結構化解說PEFT與LoRA
translated: true
type: note
---

### 1. 現代語言模型的規模：預訓練及其重要性
文本開篇強調了當今領先大型語言模型的巨大規模：「當今頂尖語言模型包含超過一兆個參數，並在數十兆個詞元上進行預訓練。基礎模型性能隨著規模擴大持續提升，因為這些兆級參數對於學習和表徵人類書面知識中的所有模式至關重要。」

#### 什麼是參數與詞元？
- **參數**是神經網絡中的「權重」——模型在訓練過程中學習的數值。可將其視為模型的「記憶」或「知識調節鈕」。一個兆級參數模型（如GPT-4或PaLM）擁有約1,000億個此類數值，大致相當於數百萬張高解析度圖像的數據儲存量。
- **詞元**是模型處理文本的基本單位（如單詞或子詞）。預訓練過程需向模型輸入**數十兆個**詞元（來源包括書籍、網站和代碼庫），使其學習文法、事實和推理等通用模式。

#### 為何規模能提升性能？
- LLM採用基於Transformer的架構（源自2017年論文《Attention is All You Need》），透過多層注意力機制和前饋網絡擅長捕捉複雜模式。
- 實證縮放定律（如OpenAI的Kaplan等人於2020年提出）顯示，性能（如問答任務準確率）會隨參數量、數據量和計算資源增加而可預測地提升。參數量倍增通常能在「湧現能力」（如模型突然擅長數學或翻譯）上帶來對數級增益。
- **直觀理解**：人類知識廣博且相互關聯。為完整表徵所有知識（如每種語言的語法、歷史事實、科學原理），模型需要巨大的「參數空間」將這些知識編碼為低層次關聯。較小模型（如10億參數）容易對表面模式過擬合，而兆級規模模型則具備更佳泛化能力。
- **權衡取捨**：這種規模需要巨大算力（如數千個GPU運算數週）和能源消耗，但這是構建Llama或GPT系列等「基礎模型」的基石。

總之，預訓練透過從人類書面語料庫中暴力提取模式，構建出通用「大腦」。文本強調這是任何專業化之前的基礎。

### 2. 後訓練（微調）：狹窄聚焦與效率挑戰
文本將預訓練與「後訓練」對比，後者「涉及較小數據集，通常聚焦於更窄的知識領域和行為範圍。使用兆位元權重來更新僅需十億位元或百萬位元訓練數據的調整，顯然是種浪費。」

#### 什麼是後訓練/微調？
- 預訓練後，基礎模型會在較小的任務特定數據集上進行「微調」（例如1-1000萬個樣本對比數兆詞元）。這使其能適應具體應用場景，如聊天機器人（遵循指令）、情感分析或醫療問答。
- 實例：在客戶支援日誌上微調GPT-3以創建輔助助手，或在法律文本上微調用於合約審查。
- **為何使用小數據集？** 微調旨在對基礎知識進行「更新」或「覆寫」——例如教導禮貌用語或領域特定術語，無需重新學習通用語言理解能力。

#### 浪費現象的直觀解釋
- **數據與模型規模不匹配**：若基礎模型有約1兆參數（相當於兆位元規模，每個參數約佔1位元），而微調數據極少（十億位元或百萬位元規模），更新*所有*參數就如同為一條腳註重寫整部百科全書。模型大部分權重與新任務無關。
- **全參數微調（FullFT）的問題**：
  - **計算開銷**：更新所有參數需在每次訓練時重新計算整個模型的梯度（誤差信號）。這會使記憶體和時間成本增加10-100倍。
  - **災難性遺忘**：FullFT可能削弱模型的通用能力（例如經數學微調的模型忘記了詩歌創作）。
  - **儲存膨脹**：微調後的模型與基礎模型同樣龐大（兆級參數），導致部署成本高昂（例如雲端成本隨規模線性增長）。
- **類比**：想像為一場獨奏表演重新訓練整個交響樂團的所有樂手。當你只需指導獨奏者時，這種做法顯然過度。

這種低效率催生了**參數高效微調（PEFT）**：僅更新極小部分參數（例如0.1-1%），卻能實現FullFT 90-100%的性能增益。

### 3. 參數高效微調（PEFT）：核心理念
「PEFT…透過更新更小的參數集合來調整大型網絡。」

- **核心動機**：在保持基礎模型優勢的同時，以最小變動注入任務特定更新。這降低了計算、記憶體和儲存需求——對於推動AI民主化至關重要（例如讓小團隊無需超級電腦即可微調Llama 2等模型）。
- **常見PEFT技術**（除後文將提及的LoRA外）：
  - **適配器**：在Transformer層間插入小型「插件」模組（例如瓶頸層），僅訓練這些模組。
  - **提示調優**：學習附加在輸入端的軟提示（例如虛擬詞元），僅更新約0.01%的參數。
  - **前綴調優**：類似技術，但針對注意力層調節前綴。
- **為何有效**：微調更新通常是「低維度」的——它們存在於完整參數空間的子空間中。無需調整所有參數，少量定向變更即可在網絡中傳播。
- **實證成果**：PEFT方法在GLUE等基準測試中匹配或超越FullFT，同時減少10-100倍計算量。Hugging Face的PEFT等庫使其可即插即用。

PEFT將範式從「訓練全部」轉向「精準編輯」，與文本強調的效率主題相符。

### 4. 低秩適應（LoRA）：領先的PEFT方法
「領先的PEFT方法是低秩適應（LoRA）。LoRA將原始模型中的每個權重矩陣W替換為修正版W′ = W + γ B A，其中B和A是合計參數量遠少於W的矩陣，γ是常數縮放因子。實際上，LoRA創建了微調所帶來更新的低維度表徵。」

#### 數學解析
LoRA針對Transformer中的權重矩陣**W**進行調整（例如注意力機制中的查詢/鍵/值投影或前饋網絡層）。這些通常是d × k矩陣（例如4096 × 4096，每個包含數百萬參數）。

- **公式**：在微調期間，LoRA不直接更新W，而是將輸出計算為：
  ```
  h = W x + γ (B A) x  （其中x為輸入）
  ```
  - **W**：凍結的原始權重（保持不變）。
  - **A**：低秩矩陣，隨機初始化（例如r × k，其中r << d，如r=8-64）。
  - **B**：另一個低秩矩陣（d × r），初始化為零（使初始更新為零，避免干擾）。
  - **γ（gamma）**：縮放因子（例如γ = α / r，其中α是超參數如16），用於控制更新幅度並穩定訓練。
  - 完整更新後的權重：**W' = W + γ B A**。

- **為何是「低秩」？**
  - 矩陣可透過奇異值分解（SVD）拆解：任何矩陣≈ U Σ V^T，其中「秩」即顯著奇異值的數量。
  - 微調更新ΔW = W' - W 通常是**低秩**的（r << min(d,k)），意味著它們在壓縮子空間中捕捉變化（例如「強調安全性」或「聚焦代碼」等少數方向）。
  - **B A** 以秩r近似ΔW（參數量：d*r + r*k 對比完整W的d*k）。對於4096×4096的W且r=8的情況，LoRA使用約6.5萬參數，對比全量W的1600萬——減少99.6%！
  - **直觀理解**：更新如同高維空間中的向量；LoRA將其投影到低維度「高速公路」（秩r）上，忽略龐大參數空間中的噪聲。

- **訓練流程**：
  1. 前向傳播：使用W + γ B A計算h，但僅訓練A和B（W保持凍結）。
  2. 反向傳播：梯度僅流向A/B，保持低記憶體使用。
  3. 推理：可合併為單一模型（W' = W + B A），或保持分離以實現模組化。
- **論文出處（Hu等人，2021年）**：LoRA最初針對視覺/語言模型提出，後在NLP領域爆發性應用。它在摘要生成等任務上表現超越適配器，且記憶體使用更少。QLoRA等變體進一步量化基礎模型，實現更小記憶體佔用。

本質上，LoRA透過添加輕量級「增量」（B A）來「改裝」模型，將微調表徵為緊湊的線性變換。

### 5. LoRA相較全參數微調（FullFT）的優勢
文本列舉了操作層面的益處，強調其在原始效率之外的實用性。我將逐一展開說明。

#### a. 後訓練的成本與速度
- LoRA訓練速度快100-1000倍（成本同比降低），因為僅更新約0.1%的參數。例如在單張A100 GPU上微調Llama-7B（FullFT需要8+張GPU）僅需數小時而非數天。
- 可使用較低精度（例如bfloat16），減少能耗。

#### b. 多租戶服務
「由於LoRA在保持原始權重不變的同時訓練適配器（即A和B矩陣），單一推理伺服器可在記憶體中保存多個適配器（不同模型版本），並以批次方式同時取用它們。Punica：多租戶LoRA服務（Chen, Ye等人，2023年）現代推理引擎如vLLM和SGLang已實現此功能。」

- **具體含義**：基礎W共享；適配器體積微小（MB級對比完整模型的GB級）。伺服器載入一個W + N個適配器（例如分別用於編程、寫作、翻譯）。
- **多租戶**：並行服務多用戶/模型，無需重新載入基礎模型。跨適配器批次處理請求以提升效率。
- **實際影響**：在生產環境中（如Hugging Face Spaces或Azure ML），這實現了「模型湯」或即時切換角色功能。Punica（2023年）透過分頁優化記憶體；vLLM/SGLang使用分頁注意力實現10倍吞吐量。
- **類比**：如同單一引擎（W）配備可換渦輪套件（適配器），對比每種調校都購買新車。

#### c. 訓練所需的資源佈局
「當微調整個模型時，優化器狀態需與原始權重一同儲存，且通常需要更高精度。因此，FullFT通常需要比相同模型推理多一個數量級的加速器…對於訓練，除了儲存權重，我們通常還需為所有權重儲存梯度和優化器動量；此外，這些變數的儲存精度（float32）常高於推理時權重的儲存精度（bfloat16或更低）。由於LoRA訓練的權重遠少且記憶體使用遠低，其訓練所需資源佈局僅略大於推理所需。」

- **訓練記憶體細分**：
  - FullFT：權重（1T參數 @ bfloat16 ≈ 2TB）+ 梯度（同等）+ 優化器狀態（例如Adam：每個參數2個動量 @ float32 ≈ 總計8TB）。需要數百張GPU組成分散式「佈局」（例如數據/模型並行）。
  - LoRA：僅A/B（約0.1%參數）產生梯度/狀態（額外增加約2-10GB）。可在1-2張GPU上訓練，與推理佈局相同。
- **精度細節**：推理使用低精度（bfloat16/float16）以提升速度；訓練需要float32以保持梯度穩定性。LoRA最小化此開銷。
- **可訪問性**：業餘愛好者/初創公司可在消費級硬件（如RTX 4090）上微調，而FullFT需要企業級集群。效率方面：LoRA因變量更少通常收斂更快。

#### d. 載入與傳輸的便捷性
「因需儲存的權重更少，LoRA適配器可快速簡便地設置或在機器間傳輸。」

- 適配器為<100MB的文件（對比完整模型的數百GB），可壓縮並透過GitHub或種子文件分享。
- 部署：基礎模型僅需載入一次，適配器可在數秒內切換。合併為永久模型是可選操作。
- **特殊場景**：版本控制（例如使用Git管理適配器）、聯邦學習（在設備端訓練適配器，僅傳送增量）、迭代式調優（堆疊多個LoRA）。

### 更廣泛影響與限制
- **LoRA主導原因**：簡單易用、效果顯著且無縫整合（例如PEFT庫）。應用於Stable Diffusion微調或Alpaca（指令微調的Llama）等模型。
- **限制**：在極小眾任務上性能不一定媲美FullFT；秩r的選擇關鍵（過低會欠擬合，過高則浪費效率）。無法處理所有更新類型（例如架構變更）。
- **未來趨勢**：擴展如DoRA（進一步分解權重）或VeRA（基於向量，更稀疏）。隨著模型規模邁向10T+參數，PEFT/LoRA對可持续性愈發重要。

此文本凝聚了AI領域的關鍵轉向：從資源密集型的完整再訓練，邁向優雅模組化的更新。若需數學推導、代碼範例（如PyTorch實現）或相關論文深度解析，敬請告知！