---
audio: false
generated: true
lang: hant
layout: post
title: 深度學習、機器學習與GPT發展進程（2010-2025）
translated: true
type: note
---

以下是深度學習、機器學習及GPT領域從2010年至2024年10月知識截止期間的重大突破時間軸：

## 2010年代初期：奠基時期

- **2012年：AlexNet** - Krizhevsky、Sutskever與Hinton的卷積神經網絡架構贏得ImageNet競賽，將錯誤率從26%降至15.3%，引爆電腦視覺領域的深度學習革命

- **2013年：Word2Vec** - Mikolov提出詞嵌入技術，透過上下文將詞語表示為向量，實現語義理解

- **2014年：GANs（生成對抗網絡）** - Goodfellow提出生成器與判別器網絡相互競爭的框架，實現逼真圖像生成

- **2014年：序列到序列模型** - Sutskever、Vinyals與Le開發出能將輸入序列映射到輸出序列的機器翻譯模型

## 2010年代中期：基礎模型浮現

- **2015年：ResNet** - 何愷明等人提出殘差連接，使訓練更深層網絡（152+層）成為可能，並以3.57%錯誤率贏得ImageNet

- **2015年：批量歸一化** - Ioffe與Szegedy提出穩定並加速神經網絡訓練的技術

- **2015年：注意力機制** - Bahdanau將注意力機制引入神經機器翻譯，使模型能專注於輸入序列的相關部分

- **2016年：AlphaGo** - DeepMind系統結合深度強化學習與蒙地卡羅樹搜索，擊敗圍棋世界冠軍李世石

## 2010年代後期：Transformer革命

- **2017年：Transformer架構** - Vaswani等人發表《Attention is All You Need》論文，以自注意力機制取代循環神經網絡

- **2018年：BERT** - 谷歌的雙向編碼器表示轉換器在自然語言理解任務中達到最先進成果

- **2018年：GPT-1** - OpenAI發布首個生成式預訓練轉換器，具備1.17億參數，基於BookCorpus訓練

- **2019年：GPT-2** - OpenAI將模型規模擴展至15億參數，展現驚人的零樣本能力，但因濫用疑慮最初未完全公開

## 2020年代初期：規模化與多模態發展

- **2020年：GPT-3** - OpenAI發布1750億參數模型，在無需微調的情況下展現卓越的少樣本學習能力

- **2021年：DALL-E** - OpenAI展示轉換器能根據文字描述生成圖像

- **2021年：Codex** - OpenAI的代碼生成模型驅動GitHub Copilot，展現編程能力

- **2021年：擴散模型** - GLIDE、DALL-E 2與Stable Diffusion帶來更優質的圖像生成效果

- **2022年：ChatGPT** - OpenAI基於GPT模型的對話介面獲得空前公眾採用（兩個月內達1億用戶）

- **2022年：PaLM** - 谷歌的5400億參數模型展現推理能力

- **2022年：Chinchilla** - DeepMind提出最佳化擴展定律，顯示更多數據訓練的較小模型可勝過較大模型

## 2023-2024年：多模態LLM與推理進化

- **2023年：GPT-4** - OpenAI的多模態模型具備改進的推理能力、安全性與圖像理解功能

- **2023年：Claude** - Anthropic發布基於憲法AI的模型，專注於有益性、無害性與誠實性

- **2023年：LLaMA** - Meta發布開放權重的大型語言模型，推動開源創新

- **2023年：專家混合模型（MoE）** - 如Mixtral 8x7B等模型透過僅激活每個輸入的相關網絡部分，實現效率提升

- **2023-2024年：多模態模型** - GPT-4V、Gemini、Claude 3等模型在視覺、音頻與語言領域獲得新能力

- **2024年：Sora** - OpenAI的文字轉視頻模型能生成複雜場景的逼真影片

- **2024年：推理增強** - 模型獲得改進的思維鏈能力，並出現專用於數學、編程與科學推理的特化模型

- **2024年：智能體框架** - 結合規劃、工具使用與記憶功能的系統，使模型能完成複雜多步驟任務

## 關鍵發展趨勢：

1. **擴展定律**：透過增加模型規模、數據集規模與計算量，持續提升性能

2. **湧現能力**：如上下文學習等能力在特定規模閾值意外出現

3. **多模態整合**：文字、圖像、音頻與視頻在統一模型中的融合

4. **人類反饋強化學習（RLHF）**：使模型與人類偏好對齊

5. **技術民主化**：開源模型與易用框架的增長，降低機器學習開發門檻

這段時期可能是人類歷史上任何技術領域中最快速的進步歷程，將機器學習從專業學術學科轉變為具有全球影響力的通用技術。