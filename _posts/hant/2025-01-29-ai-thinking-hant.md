---
audio: false
generated: false
lang: hant
layout: post
title: 人工智慧思考
translated: true
---

- 薩迪亞·納德拉提到傑夫森悖論。值得學習。

- 王隱：人工智慧中沒有所謂的「智慧」，神經網絡中沒有所謂的「神經」，機器學習中沒有所謂的「學習」，深度學習中沒有所謂的「深度」。所有真正在這個領域中有效的，都應該叫做「微積分」。因此，我更喜歡把這個領域稱為「可微分計算」，而模型建設的過程稱為「可微分編程」。

- 王隱：機器學習確實很有用，甚至可以說是美麗的理論，因為它只是微積分的改裝！它是牛頓、列布尼茲那位老伯爵的古老而偉大的理論，以簡單、優雅且強大的形式重新塑造。機器學習基本上是使用微積分來導出和適合某些函數，而深度學習則是適合更複雜的函數。

- 目前，大型語言模型無法按文件語言（如YAML或Python）進行篩選。然而，現實世界中的大量信息都是這樣組織的。這意味著我們可以使用文件來訓練大型語言模型。

- 在訓練大型語言模型時，我們可以開發一個系統來找到精確匹配。也許我們可以將KMP（Knuth-Morris-Pratt）搜尋算法與transformer架構結合，以增強搜尋能力。