---
audio: false
generated: true
image: false
lang: hant
layout: post
model: x-ai/grok-4-fast
title: 優化多服務水平目標的大型語言模型服務
translated: true
type: note
---

### 概述
論文《SLOs-Serve：優化多服務等級目標大型語言模型的服務》介紹了 SLOs-Serve，這是一個專為高效服務大型語言模型而設計的系統，適用於多階段應用場景。在這些場景中，每個階段（例如用於輸入處理的預填充階段、用於令牌生成的解碼階段）和每個應用（例如聊天機器人、編程助手）都有特定的服務等級目標。這些 SLO 確保面向用戶的方面具有低延遲，例如預填充階段的首次令牌時間和解碼階段的每輸出時間令牌數。傳統的服務系統如 vLLM 或 Sarathi-Serve 優先考慮吞吐量，但在共享資源下（特別是在流量突發或混合工作負載時）經常違反這些細粒度的 SLO。

### 關鍵挑戰與貢獻
作者指出了多 SLO 服務中的挑戰：
- **多階段請求**：如推理型 LLM（在「思考」階段有嚴格 SLO）或工具調用代理（具有嚴格預填充/解碼的循環）等應用需要階段特定的保證。
- **資源競爭**：共享 GPU 導致在共置或分離式設置中出現 SLO 違規。
- **突發流量**：突然的流量高峰使調度器不堪重負。

SLOs-Serve 的貢獻包括：
- 一個基於動態規劃的調度器，優化令牌分配（預填充預算、批次大小）以滿足 SLO，同時最大化吞吐量。
- 支持分塊預填充、SLO 自適應推測解碼（根據 SLO 層級自定義推測長度）以及軟性准入控制（保證已接受請求的 SLO，推遲其他請求）。
- 一個分佈式架構，具有多副本路由和突發恢復能力，基於 vLLM 進行批次處理並使用 Ray 進行協調。

| 應用場景 | 預填充 SLO | 解碼 SLO | 範例 |
|-------------|-------------|------------|---------|
| 摘要生成 | 嚴格（例如，最大延遲 3 倍） | 寬鬆（100ms TPOT） | 文件處理 |
| 編程 | 寬鬆 | 嚴格（50ms TPOT） | 代碼生成 |
| 聊天機器人 | 寬鬆 | 寬鬆 | 互動式查詢 |
| 工具調用 | 嚴格（循環中） | 嚴格（循環中）、寬鬆（最終） | 代理工作流 |
| 推理 | 嚴格（思考中） | 嚴格（思考中）、寬鬆（回應） | 思維鏈 |

### 系統設計
- **調度器（算法 1）**：使用動態規劃來接受請求並規劃批次，通過受 Roofline 啟發的預測器（R² > 0.8 準確度）建模執行時間。狀態跟踪記憶體、預填充預算和已接受請求；轉換優先考慮早期截止時間和 SLO 達成。
- **批次形成**：基於最嚴格的 TPOT 進行動態大小調整（最多 512+ 令牌），實現更大批次以提高吞吐量而不違反 SLO。
- **推測解碼**：根據 SLO 層級調整推測長度（例如 1-10 個令牌）以提升預填充預算，通過枚舉求解以實現最佳預填充/解碼平衡。
- **多副本與突發處理**：集中式控制器主動路由請求；無法達成的請求進入盡力而為隊列，必要時可被搶佔。

該設計探討了權衡，例如更大批次提高吞吐量但增加延遲風險（在顯示 SLO 可行區域的圖表中可視化）。

### 評估
使用真實追踪數據（Azure LLM 工作負載）和數據集（ShareGPT、HumanEval 等）在 6 種場景（聊天機器人、編程、摘要生成、混合、工具調用、推理）上進行測試。模型：OPT-7B/13B/30B、ToolLlama-7B。硬件：4×A100 GPU（主要），最多 8×H100。

- **容量增益**：相比 vLLM/Sarathi-Serve/DistServe，平均提升 2.2 倍（跨場景幾何平均）。例如，推理場景提升 2.4 倍，突發編程場景提升 2.1 倍。
- **擴展性**：通過路由實現與副本數的超線性擴展（工具調用場景在突發下最高達 6.2 倍）。
- **消融研究**：推測解碼貢獻 1.66 倍，路由貢獻 1.19 倍，突發處理貢獻 1.34 倍。
- 開銷：每次調度調用 <10ms。

圖表顯示 SLOs-Serve 在流量高峰期間保持 p99 延遲接近目標，而基線系統性能下降。

### 結論
SLOs-Serve 通過在多樣化、突發的環境中保證多 SLO，推進了 LLM 服務，釋放了 2 倍以上的效率增益。未來工作可擴展到未知解碼長度或更多階段。該系統證明，針對 SLO 定制的調度是生產級 LLM 部署的關鍵。

[SLOs-Serve: Optimized Serving of Multi-SLO LLMs](https://arxiv.org/abs/2504.08784)