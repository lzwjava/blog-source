---
audio: false
generated: true
lang: hant
layout: post
title: Mistral NeMo：強大的120億參數大型語言模型
translated: true
type: note
---

**Mistral NeMo** 是由 **Mistral AI 與 NVIDIA 合作** 開發的強大 120 億參數大型語言模型（LLM）。該模型旨在提供最先進的自然語言處理能力，尤其在其規模級別中，於推理能力、世界知識和編碼準確性方面表現卓越。

以下是 Mistral NeMo 的主要特點和面向：

* **120 億參數：** 這使其成為相對緊湊但仍具備高度能力的模型，在效能與效率之間取得平衡。
* **大型上下文窗口：** 擁有高達 128k tokens 的上下文窗口，使其能更有效地處理和理解更長的文本、複雜文件及多輪對話。
* **最先進的效能：** Mistral NeMo 為其規模級別的模型設立了新標準，在推理、通用世界知識和程式碼生成相關任務中展現出強大效能。
* **多語言支援：** 為全球應用而設計，精通多種語言，包括英語、法語、德語、西班牙語、意大利語、葡萄牙語、中文、日語、韓語、阿拉伯語和印地語。
* **Tekken Tokenizer：** 使用名為 Tekken（基於 Tiktoken）的新型分詞器，在壓縮超過 100 種語言的自然語言文本和原始碼方面，比先前的分詞器更有效率。
* **函數呼叫：** 該模型針對函數呼叫進行訓練，增強了其根據自然語言輸入與特定程式函數互動及執行的能力。
* **量化感知：** 透過量化感知訓練，使其能夠在不影響效能的情況下進行 FP8 推理，這對於高效能部署至關重要。
* **開源許可：** Mistral NeMo 以 Apache 2.0 許可證發布，促進研究人員和企業的廣泛採用、自訂和整合。
* **易於整合：** 其標準架構使其易於作為已使用 Mistral 7B 的系統的直接替代品。
* **與 NVIDIA 合作：** 該模型在 NVIDIA DGX Cloud AI 平台上進行訓練，並利用 NVIDIA 優化的硬體和軟體生態系統，包括用於加速推理效能的 TensorRT-LLM，以及用於構建自訂生成式 AI 模型的 NeMo 開發平台。它也可作為 NVIDIA NIM 推理微服務使用。

本質上，Mistral NeMo 旨在提供一個多功能、高效能且效率卓越的 LLM，能夠在單一 GPU 上運行，使先進的 AI 能力更易於應用於各種企業應用，如聊天機器人、摘要、語言翻譯和程式碼生成。