---
audio: false
generated: true
lang: hant
layout: post
title: 多模態大型語言模型
translated: true
type: note
---

讓我們逐步拆解，說明多模態實作在大型語言模型（LLM）中的運作原理，並解答你關於圖像與文字轉換為向量的疑問。

### 多模態 LLM 的運作原理
多模態 LLM 的設計旨在處理並基於多種類型數據（如文字、圖像、音頻，甚至結構化數據如表格）生成回應。與僅處理文字的傳統 LLM 不同，多模態模型將這些不同的「模態」整合到統一框架中。以下是典型的實作方式：

1. **各模態的獨立編碼器**：
   - **文字**：使用分詞器（例如將文字拆分為單詞或子詞）處理文字，然後透過詞彙表或預訓練的嵌入層轉換為稱為嵌入（向量）的數值表示。這在 BERT 或 GPT 等模型中很常見。
   - **圖像**：使用視覺模型（如卷積神經網絡 CNN 或 Vision Transformer ViT）處理圖像。這些模型從圖像中提取特徵（如邊緣、形狀或物體），並將其轉換為高維空間中的向量表示。
   - 其他模態（如音頻）也遵循類似過程，使用專門的編碼器（例如將聲波轉換為頻譜圖再轉為向量）。

2. **統一表示**：
   - 每個模態被編碼為向量後，模型會對齊這些表示，使它們能夠「互相溝通」。這可能涉及將它們投影到共享的嵌入空間中，讓文字向量和圖像向量能夠相容。借用自 Transformer 的跨注意力機制等技術，有助於模型理解模態之間的關係——例如將文字中的「貓」與貓的圖像連結起來。

3. **訓練**：
   - 模型在配對多模態的數據集上訓練（例如帶有標題的圖像），從而學會將文字描述與視覺特徵關聯起來。這可能涉及對比學習（如 CLIP）或聯合訓練，讓模型從圖像預測文字或反之。

4. **輸出生成**：
   - 生成回應時，模型使用其解碼器（或統一的 Transformer 架構）來產生文字、圖像或兩者，具體取決於任務。例如，它可能為圖像生成標題，或回答關於圖片的問題。

### 圖像也會轉換為向量嗎？
是的，完全正確！就像文字一樣，圖像在多模態 LLM 中也被轉換為向量：
- **運作原理**：圖像被輸入到視覺編碼器（例如預訓練的 ResNet 或 ViT）。該編碼器處理原始像素數據，並輸出固定大小的向量（或一系列向量），捕捉圖像的語義內容——如物體、顏色或圖案。
- **範例**：一張狗的照片可能被轉換為 512 維的向量，編碼了「狗類」特徵。這個向量在我們看來不像圖像，但包含模型可以使用的數值資訊。
- **與文字的區別**：文字向量來自詞彙表（例如「狗」或「貓」的詞嵌入），而圖像向量則來自視覺模型提取的空間和視覺特徵。兩者最終都成為向量空間中的數值。

### 文字轉向量：建構詞彙表
你提到文字透過建構詞彙表轉換為向量——以下是具體過程：
- **分詞**：文字被拆分為較小單位（詞元），如單詞或子詞（例如在 BERT 等模型中，「playing」可能拆分為「play」和「##ing」）。
- **詞彙表**：預定義的詞彙表將每個詞元映射到唯一的 ID。例如，「狗」的 ID 可能是 250，「貓」的 ID 可能是 300。
- **嵌入層**：每個詞元 ID 使用嵌入矩陣轉換為密集向量（例如 768 維向量）。這些向量在訓練過程中學習捕捉語義含義——含義相似的詞（如「狗」和「小狗」）最終會有相似的向量。
- **上下文化**：在現代 LLM 中，Transformer 會根據上下文精煉這些向量（例如「河岸」中的「bank」與「銀行」中的「bank」會得到不同的向量）。

### 文字與圖像的關鍵相似點
文字和圖像最終都表示為高維空間中的向量。多模態模型的魔力在於對齊這些空間，使模型能夠跨模態推理。例如：
- 狗的圖像和「狗」一詞可能被映射到共享空間中相鄰的點。
- 模型隨後可以透過橋接圖像向量與文字向量，回答「這張圖片中有什麼？」等問題。

### 多模態實作的挑戰
- **對齊**：確保文字和圖像向量有意義地相關聯是困難的，需要大量配對數據集。
- **計算**：與純文字模型相比，同時處理圖像和文字需要更多計算資源。
- **解讀**：模型需要根據輸入「理解」何時優先處理某一模態。

這樣解釋是否更清晰？如果你希望我更深入探討任何部分——例如視覺編碼器的運作原理或向量空間的樣貌——請告訴我！