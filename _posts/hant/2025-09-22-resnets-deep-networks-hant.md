---
audio: false
generated: true
image: false
lang: hant
layout: post
model: x-ai/grok-4-fast:free
title: 殘差網絡革新深度網絡訓練
translated: true
type: note
---

### 為何我們使用 ResNet？

ResNet（殘差網路）是由微軟研究員於 2015 年提出的深度神經網路架構系列（發表於論文《Deep Residual Learning for Image Recognition》）。它廣泛應用於電腦視覺任務，例如影像分類、物件偵測和語義分割。以下我將解釋其廣受歡迎與採用的關鍵原因。

#### 1. **解決深度網路中的梯度消失問題**
   - 在傳統的深度神經網路（例如 VGG 等普通 CNN）中，增加更多層數通常會導致**效能下降**。這是因為在反向傳播過程中，梯度變得非常小（消失），使得訓練超過約 20-30 層的深度網路變得困難。
   - ResNet 引入了**跳躍連接**（也稱為殘差區塊或捷徑連接）。這些連接允許將層的輸入直接加到其輸出上，從而有效學習**殘差函數**（即學習該對輸入添加什麼，而不是從頭學習整個轉換）。
     - 數學上：若 \\( H(x) \\) 是期望輸出，ResNet 學習 \\( F(x) = H(x) - x \\)，因此 \\( H(x) = F(x) + x \\)。
   - 這使得**梯度流動**能夠更輕易地在網路中傳播，從而能夠訓練極深的模型（例如 ResNet-50、ResNet-101，甚至具有 152 層的 ResNet-152），且準確率不會下降。

#### 2. **更佳的優化與訓練效率**
   - 跳躍連接充當**恆等映射**，這對於優化器（如 SGD 或 Adam）來說更容易學習。如果某層不需要太多改變，它可以直接傳遞輸入，減輕優化負擔。
   - 這導致訓練過程中**收斂速度更快**，並在 ImageNet 等基準測試中獲得更高準確率（ResNet 在 2015 年贏得了 ImageNet 大規模視覺識別挑戰賽）。
   - 實證證據：ResNet-152 在參數效率更高的同時，其表現顯著優於較淺層的網路（如 VGG-19）。

#### 3. **在複雜任務上的卓越表現**
   - ResNet 在許多現代架構中作為**強大的骨幹網路**：
     - **影像分類**：在 ImageNet 上達到約 78% 的 top-1 準確率。
     - **物件偵測**：用於 Faster R-CNN、Mask R-CNN 和 YOLO 變體等框架。
     - **遷移學習**：預訓練的 ResNet 模型（例如來自 PyTorch 或 TensorFlow 的模型）易於取得，並可針對資料有限的客製化任務進行微調。
   - 它們能良好泛化到其他領域，例如醫學影像、自動駕駛，以及自然語言處理（透過受 ResNet 啟發的視覺 transformer）。

#### 4. **實務優勢**
   - **模組化**：殘差區塊易於堆疊，使得調整深度變得簡單（例如，輕量級應用使用 ResNet-18，高準確率需求使用 ResNet-152）。
   - **效率**：儘管深度較深，但其參數量少於某些替代方案（例如，ResNet-50 約有 2500 萬參數，而 VGG-16 有 1.38 億）。
   - **對現代架構的影響**：ResNet 的概念啟發了 EfficientNet、DenseNet，甚至 transformer（在注意力層中使用殘差連接）。

總而言之，我們使用 ResNet 是因為它透過使**極深層網路可訓練且有效**，徹底改變了深度學習領域，從而以最少的額外複雜度實現了最先進的成果。如果您要實作它，像 PyTorch（`torchvision.models.resnet50()`）或 Keras 這樣的函式庫讓這變得簡單直接。如需更多細節，請查閱原始論文或特定使用案例！如果您有具體情境（例如專案需求），我可以進一步深入探討。