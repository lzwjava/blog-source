---
audio: false
generated: false
lang: hant
layout: post
title: 機器學習、深度學習與生成式預訓練模型
translated: true
type: note
---

1. 機器學習（ML）是計算機科學的一個領域，使系統能夠從數據中學習並在無需明確編程的情況下提升效能。

2. 深度學習（DL）是機器學習的一個子領域，利用多層神經網絡來建模數據中的複雜模式。

3. 神經網絡是受人類大腦啟發的計算模型，由相互連接的節點（神經元）組成，以分層方式處理信息。

4. 訓練數據是用於教導機器學習模型執行任務的標記或未標記數據集。

5. 監督學習涉及在標記數據上訓練模型，其中每個示例都有輸入及對應的正確輸出。

6. 無監督學習使用未標記數據，讓模型在無明確指導的情況下發現隱藏模式或分組。

7. 強化學習（RL）通過獎勵期望行為和懲罰不良行為來訓練智能體做出決策。

8. 生成模型學習產生與其訓練示例相似的新數據（例如文本、圖像）。

9. 判別模型專注於將輸入分類到不同類別或預測特定結果。

10. 遷移學習允許在一個任務上訓練的模型在相關任務上重複使用或微調。

11. GPT（生成式預訓練轉換器）是由 OpenAI 開發的大型語言模型系列，能夠生成類人文本。

12. ChatGPT 是 GPT 的互動式變體，專為對話和遵循指令任務而微調。

13. 轉換器架構在論文《Attention Is All You Need》中提出，通過依賴注意力機制徹底改變了自然語言處理。

14. 自注意力機制讓模型在構建輸出表示時權衡輸入序列的不同部分。

15. 轉換器中的位置編碼幫助模型識別序列中標記的順序。

16. 預訓練是初始階段，模型在針對特定任務微調之前從大規模數據中學習通用特徵。

17. 微調是採用預訓練模型並使用較小的任務特定數據集使其適應更狹窄任務的過程。

18. 語言建模是預測序列中下一個標記（單詞或子詞）的任務，是 GPT 類模型的基礎。

19. 零樣本學習允許模型在無明確訓練示例的情況下處理任務，依賴於學習到的通用知識。

20. 少樣本學習利用有限數量的任務特定示例來指導模型的預測或行為。

21. RLHF（基於人類反饋的強化學習）用於使模型輸出與人類偏好和價值觀對齊。

22. 人類反饋可以包括排名或標籤，引導模型的生成朝向更期望的回應。

23. 提示工程是設計輸入查詢或指令以有效引導大型語言模型的藝術。

24. 上下文窗口是指模型一次能處理的最大文本量；GPT 模型具有有限的上下文長度。

25. 推理是訓練後的模型在給定新輸入時進行預測或生成輸出的階段。

26. 參數數量是模型能力的關鍵因素；更大的模型能捕捉更複雜的模式但需要更多計算。

27. 模型壓縮技術（例如剪枝、量化）減小模型尺寸並加速推理，同時最小化準確性損失。

28. 轉換器中的注意力頭並行處理輸入的不同方面，提高表示能力。

29. 掩碼語言建模（例如在 BERT 中）涉及預測句子中缺失的標記，幫助模型學習上下文。

30. 因果語言建模（例如在 GPT 中）涉及基於所有先前標記預測下一個標記。

31. 編碼器-解碼器架構（例如 T5）使用一個網絡編碼輸入，另一個網絡將其解碼為目標序列。

32. 卷積神經網絡（CNN）通過卷積層擅長處理網格狀數據（例如圖像）。

33. 循環神經網絡（RNN）通過沿時間步傳遞隱藏狀態來處理序列數據，但可能難以處理長期依賴。

34. 長短期記憶（LSTM）和 GRU 是 RNN 的變體，旨在更好地捕捉長程依賴。

35. 批次歸一化通過歸一化中間層輸出來穩定訓練。

36. Dropout 是一種正則化技術，在訓練期間隨機“丟棄”神經元以防止過度擬合。

37. 優化器算法如隨機梯度下降（SGD）、Adam 和 RMSProp 基於梯度更新模型參數。

38. 學習率是一個超參數，決定訓練期間權重更新的幅度。

39. 超參數（例如批次大小、層數）是在訓練前選擇的配置設置，用於控制學習過程。

40. 模型過度擬合發生在模型過於擬合訓練數據，無法泛化到新數據時。

41. 正則化技術（例如 L2 權重衰減、dropout）有助於減少過度擬合並改善泛化。

42. 驗證集用於調整超參數，而測試集評估模型的最終性能。

43. 交叉驗證將數據分成多個子集，系統地進行訓練和驗證以獲得更穩健的性能估計。

44. 梯度爆炸和消失問題出現在深度網絡中，導致訓練不穩定或無效。

45. 殘差連接（跳躍連接）在如 ResNet 等網絡中通過捷徑數據路徑幫助緩解梯度消失。

46. 縮放定律表明增加模型尺寸和數據通常會帶來更好的性能。

47. 計算效率至關重要；訓練大型模型需要優化的硬件（GPU、TPU）和算法。

48. 倫理考量包括偏見、公平性和潛在危害——必須仔細測試和監控 ML 模型。

49. 數據增強人為擴展訓練數據集以提高模型魯棒性（特別是在圖像和語音任務中）。

50. 數據預處理（例如標記化、歸一化）對於有效的模型訓練至關重要。

51. 標記化將文本分割成標記（單詞或子詞），這是語言模型處理的基本單位。

52. 向量嵌入將標記或概念表示為數值向量，保留語義關係。

53. 位置嵌入添加關於每個標記位置的信息，幫助轉換器理解序列順序。

54. 注意力權重揭示模型如何在不同輸入部分分配注意力。

55. 束搜索是語言模型中的一種解碼策略，在每一步保留多個候選輸出以找到最佳整體序列。

56. 貪婪搜索在每一步選擇最可能的標記，但可能導致次優的最終輸出。

57. 採樣中的溫度調整語言生成的創造性：較高溫度 = 更多隨機性。

58. Top-k 和 Top-p（核）採樣方法將候選標記限制為前 k 個最可能或累積概率 p，平衡多樣性和連貫性。

59. 困惑度衡量概率模型預測樣本的好壞；較低的困惑度表示更好的預測性能。

60. 精確率和召回率是分類任務的指標，分別關注正確性和完整性。

61. F1 分數是精確率和召回率的調和平均數，將兩個指標平衡為單一值。

62. 準確率是正確預測的比例，但在不平衡數據集中可能具有誤導性。

63. ROC 曲線下面積（AUC）衡量分類器在不同閾值下的性能。

64. 混淆矩陣顯示真陽性、假陽性、假陰性和真陰性的計數。

65. 不確定性估計方法（例如蒙特卡羅 Dropout）評估模型對其預測的信心程度。

66. 主動學習涉及查詢模型最不確定的新數據示例，提高數據效率。

67. 在線學習在新數據到達時逐步更新模型，而不是從頭重新訓練。

68. 進化算法和遺傳算法使用受生物啟發的變異和選擇來優化模型或超參數。

69. 貝葉斯方法結合先驗知識並用新數據更新信念，對於不確定性量化很有用。

70. 集成方法（例如隨機森林、梯度提升）結合多個模型以提高性能和穩定性。

71. 袋裝法（自助聚合）在不同數據子集上訓練多個模型，然後平均它們的預測。

72. 提升法迭代訓練新模型以糾正先前訓練模型所犯的錯誤。

73. 梯度提升決策樹（GBDT）對於結構化數據非常強大，通常勝過簡單的神經網絡。

74. 自回歸模型基於序列中先前的輸出預測下一個值（或標記）。

75. 自編碼器是一種神經網絡，設計用於將數據編碼為潛在表示然後解碼回原始形式，學習壓縮的數據表示。

76. 變分自編碼器（VAE）引入概率轉折以生成與訓練集相似的新數據。

77. 生成對抗網絡（GAN）讓生成器與判別器對抗，產生逼真的圖像、文本或其他數據。

78. 自監督學習通過創建人工訓練任務（例如預測缺失部分）來利用大量未標記數據。

79. 基礎模型是大型預訓練模型，可以適應廣泛的下游任務。

80. 多模態學習整合來自多個來源的數據（例如文本、圖像、音頻）以創建更豐富的表示。

81. 數據標記通常是 ML 中最耗時的部分，需要仔細註釋以確保準確性。

82. 邊緣計算將 ML 推理更靠近數據源，減少延遲和帶寬使用。

83. 聯邦學習在持有本地數據樣本的分散式設備或服務器上訓練模型，無需交換數據。

84. 隱私保護 ML 包括差分隱私和同態加密等技術以保護敏感數據。

85. 可解釋人工智能（XAI）旨在使複雜模型的決策對人類更可解釋。

86. ML 中的偏見和公平性需要仔細監督，因為模型可能無意中學習並放大社會偏見。

87. 概念漂移發生在目標變量的統計屬性隨時間變化時，影響模型性能。

88. AB 測試比較兩個或多個模型版本，以查看哪個在真實環境中表現更好。

89. GPU 加速利用圖形卡上的並行計算大幅加速 ML 訓練。

90. TPU（張量處理單元）是 Google 專門用於高效深度學習工作負載的硬件加速器。

91. 開源框架（例如 TensorFlow、PyTorch）提供 ML 模型開發的構建模塊和工具。

92. 模型服務是部署訓練後模型的實踐，使其能夠處理實時或批量預測。

93. 可擴展性對於處理大型數據集或高流量至關重要，需要分散式訓練和推理策略。

94. MLOps 將 ML 開發與運維實踐相結合，專注於可重現性、測試和持續集成。

95. 數據和模型的版本控制確保一致的實驗跟踪和協作。

96. 部署策略（例如容器、微服務）組織模型的打包和大規模服務方式。

97. 監控在部署後跟踪模型性能，觀察性能下降或異常。

98. 重新訓練和模型更新在新數據和變化條件出現時保持模型的最新狀態。

99. 時間複雜度（O 表示法）衡量算法運行時間隨輸入大小的縮放方式；O(1) 表示常數時間。

100. ML 的未來承諾越來越複雜和通用的模型，但必須解決倫理、社會和環境考量。