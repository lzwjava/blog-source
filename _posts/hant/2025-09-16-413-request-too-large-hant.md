---
audio: false
generated: true
image: false
lang: hant
layout: post
model: openai/gpt-oss-120b
title: 解決請求過大錯誤 413
translated: true
type: note
---

## 錯誤訊息的含義

- **413 請求過大** 是一個 HTTP 狀態碼，表示伺服器因負載超過允許大小而拒絕處理請求。在 OpenAI 推論服務的上下文中，「負載」是指單一請求中發送的總令牌數（輸入 + 輸出）。 [1]

- **每分鐘令牌數 (TPM) 限制**：`openai/gpt‑oss‑120b` 模型在隨選服務層級配置的最高限制為 **8,000 TPM**。您發送的請求包含 **13,701 個令牌**，這比限制超出了 **5,701 個令牌**。 [1]

- **發生的原因**：
  1. **提示過大** – 輸入文字（包括系統指令、用戶訊息和任何附加資料）可能非常長。
  2. **過高的 `max_tokens` 設定** – 如果請求要求模型生成較長的回覆，則預期的輸出令牌數會加到輸入計數中。
  3. **快速連續呼叫** – 如果在短時間內發出大量請求，即使每個單獨的請求都低於限制，當前一分鐘內的累積令牌數也可能超過 TPM 配額。

## 如何解決

| 選項 | 操作方式 | 效果 |
|--------|------------|--------|
| **精簡提示** | 移除不必要的文字、使用簡潔的指令，或在發送前壓縮資料（例如總結大段文字）。 | 降低輸入令牌數。 |
| **減少 `max_tokens`** | 請求較短的回覆（例如，將 `max_tokens` 設為 500 而不是 2000）。 | 減少預期的輸出令牌數。 |
| **拆分請求** | 將龐大的文件拆分為多個較小的區塊，並依序呼叫模型，最後將結果拼接起來。 | 使每次呼叫都保持在 TPM 限制內。 |
| **升級服務層級** | 移至容量更高的服務層級（例如開發者層級），該層級的 TPM 限制更大或無限制。 | 允許更大的單次請求負載而不會出錯。 |
| **限制呼叫頻率** | 在請求之間添加短暫延遲，或實施速率限制，使每分鐘總令牌數 ≤ 8,000。 | 防止累積 TPM 超限。 |

## 發送請求前的快速檢查清單

1. **計算令牌數** – 使用 OpenAI 的令牌化工具（或 `tiktoken`）估算總令牌數（提示 + 最大令牌數）。
2. **保持在 ≤ 8,000 TPM** 以內（適用於隨選層級）。
3. **如果接近限制**，請考慮上述其中一項緩解措施。

透過確保請求保持在每分鐘 8,000 個令牌的配額內，即可避免 413 「請求過大」的錯誤。 [1]

引用文獻：
[1] https://www.reddit.com/r/OpenAI/comments/1nbtl2p/wow_weve_been_burning_money_for_6_months/