---
lang: hant
layout: post
title: 构建一个AI驱动的故事机器人
---

*这篇博客文章是在ChatGPT-4的协助下完成的。*

---

### 目录

- [简介](#简介)
- [项目架构](#项目架构)
  - [后端](#后端)
    - [Flask应用设置](#flask应用设置)
    - [日志记录与监控](#日志记录与监控)
    - [请求处理](#请求处理)
  - [前端](#前端)
    - [React组件](#react组件)
    - [API集成](#api集成)
- [部署](#部署)
  - [部署脚本](#部署脚本)
  - [ElasticSearch配置](#elasticsearch配置)
  - [Kibana配置](#kibana配置)
  - [Logstash配置](#logstash配置)
- [Nginx配置与Let's Encrypt SSL证书](#nginx配置与lets-encrypt-ssl证书)
  - [定义映射以处理允许的来源](#定义映射以处理允许的来源)
  - [将HTTP重定向至HTTPS](#将http重定向至https)
  - [主站点配置`example.com`](#主站点配置examplecom)
  - [API配置`api.example.com`](#api配置apiexamplecom)
- [结论](#结论)

---

### 引言

本博客文章全面介绍了一款AI驱动的故事机器人应用的架构与实现。该项目旨在通过网页界面生成个性化故事。我们采用Python、Flask和React进行开发，并在AWS上部署。此外，我们使用Prometheus进行监控，ElasticSearch、Kibana和Logstash进行日志管理。DNS管理通过GoDaddy和Cloudflare完成，Nginx则作为网关，负责SSL证书和请求头管理。

### 项目架构

#### 后端

项目后端采用Flask构建，这是一个Python中的轻量级WSGI网络应用框架。后端负责处理API请求、管理数据库、记录应用程序活动日志，并与Prometheus集成以实现监控功能。

以下是后端组件的详细解析：

1. Flask应用程序设置：
    - Flask应用被初始化并配置为使用多种扩展，如Flask-CORS用于处理跨域资源共享，Flask-Migrate用于管理数据库迁移。
    - 应用程序的路由被初始化，并启用了CORS以允许跨域请求。
    - 数据库以默认配置初始化，并设置了一个自定义日志记录器，用于格式化Logstash的日志条目。

```python
from flask import Flask
from flask_cors import CORS
from .routes import initialize_routes
from .models import db, insert_default_config
from flask_migrate import Migrate
import logging
from logging.handlers import RotatingFileHandler
from prometheus_client import Counter, generate_latest, Gauge
```

    app = Flask(__name__)
    app.config.from_object('api.config.BaseConfig')

```python
db.init_app(app)
initialize_routes(app)
CORS(app)
migrate = Migrate(app, db)
```

2. 日志记录与监控：
    - 应用程序采用RotatingFileHandler管理日志文件，并通过自定义格式化器对日志进行格式化。
    - 集成了Prometheus指标，用于追踪请求计数和延迟情况。

```python
    REQUEST_COUNT = Counter('flask_app_request_count', 'Flask 應用程式的總請求計數', ['method', 'endpoint', 'http_status'])
    REQUEST_LATENCY = Gauge('flask_app_request_latency_seconds', '請求延遲', ['method', 'endpoint'])
```

```python
def setup_loggers():
    logstash_handler = RotatingFileHandler('app.log', maxBytes=100000000, backupCount=1)
    logstash_handler.setLevel(logging.DEBUG)
    logstash_formatter = CustomLogstashFormatter()
    logstash_handler.setFormatter(logstash_formatter)
```

```python
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.DEBUG)
        root_logger.addHandler(logstash_handler)
```

翻譯成繁體中文：

```python
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.DEBUG)
        root_logger.addHandler(logstash_handler)
```

這段程式碼的功能是獲取根記錄器（root logger），將其日誌級別設置為DEBUG，並添加一個Logstash處理器（handler）。

        app.logger.addHandler(logstash_handler)
        werkzeug_logger = logging.getLogger('werkzeug')
        werkzeug_logger.setLevel(logging.DEBUG)
        werkzeug_logger.addHandler(logstash_handler)

    setup_loggers()
    ```

3. 请求处理：
    - 应用程序在每次请求前后捕获指标，并生成一个追踪ID以跟踪请求流程。

```python
    def generate_trace_id(length=4):
        characters = string.ascii_letters + string.digits
        return ''.join(random.choice(characters) for _ in range(length))
```

```python
@app.before_request
def before_request():
    request.start_time = time.time()
    trace_id = request.headers.get('X-Trace-Id', generate_trace_id())
    g.trace_id = trace_id
```

```traditional_chinese
@app.before_request
def before_request():
    request.start_time = time.time()
    trace_id = request.headers.get('X-Trace-Id', generate_trace_id())
    g.trace_id = trace_id
```

```python
@app.after_request
def after_request(response):
    # 在响应头中添加追踪ID
    response.headers['X-Trace-Id'] = g.trace_id
    # 计算请求延迟
    request_latency = time.time() - getattr(request, 'start_time', time.time())
    # 增加请求计数，记录方法、路径和HTTP状态码
    REQUEST_COUNT.labels(method=request.method, endpoint=request.path, http_status=response.status_code).inc()
    # 设置请求延迟，记录方法和路径
    REQUEST_LATENCY.labels(method=request.method, endpoint=request.path).set(request_latency)
    return response
```

#### 前端

项目的前端采用React构建，这是一个用于创建用户界面的JavaScript库。它与后端API进行交互，以管理故事提示，并提供一个交互式的用户界面，用于生成和管理个性化故事。

1. React组件：
   - 主组件负责处理用户输入的故事提示，并与后端API交互以管理这些故事。

```jsx
import React, { useState, useEffect } from 'react';
import { ToastContainer, toast } from 'react-toastify';
import 'react-toastify/dist/ReactToastify.css';
import { apiFetch } from './api';
import './App.css';
```

    function App() {
      const [prompts, setPrompts] = useState([]);
      const [newPrompt, setNewPrompt] = useState('');
      const [isLoading, setIsLoading] = useState(false);

```javascript
useEffect(() => {
    fetchPrompts();
}, []);
```

這段代碼使用了 React 的 `useEffect` 鉤子，在組件首次渲染時執行 `fetchPrompts` 函數。由於依賴數組為空（`[]`），這個效果只會在組件掛載時運行一次，不會在後續的渲染中再次執行。

      const fetchPrompts = async () => {
        setIsLoading(true);
        try {
          const response = await apiFetch('prompts');
          if (response.ok) {
            const data = await response.json();
            setPrompts(data);
          } else {
            toast.error('獲取提示失敗');
          }
        } catch (error) {
          toast.error('獲取提示時發生錯誤');
        } finally {
          setIsLoading(false);
        }
      };

      const addPrompt = async () => {
        if (!newPrompt) {
          toast.warn('Prompt 内容不能为空');
          return;
        }
        setIsLoading(true);
        try {
          const response = await apiFetch('prompts', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({ content: newPrompt }),
          });
          if (response.ok) {
            fetchPrompts();
            setNewPrompt('');
            toast.success('Prompt 添加成功');
          } else {
            toast.error('添加 Prompt 失败');
          }
        } catch (error) {
          toast.error('添加 Prompt 时发生错误');
        } finally {
          setIsLoading(false);
        }
      };

```javascript
const deletePrompt = async (promptId) => {
  setIsLoading(true);
  try {
    const response = await apiFetch(`prompts/${promptId}`, {
      method: 'DELETE',
    });
    if (response.ok) {
      fetchPrompts();
      toast.success('提示删除成功');
    } else {
      toast.error('删除提示失败');
    }
  } catch (error) {
    toast.error('删除提示时发生错误');
  } finally {
    setIsLoading(false);
  }
};
```

```javascript
return (
  <div className="app">
    <h1>AI 故事機器人</h1>
    <div>
      <input
        type="text"
        value={newPrompt}
        onChange={(e) => setNewPrompt(e.target.value)}
        placeholder="新提示"
      />
      <button onClick={addPrompt} disabled={isLoading}>新增提示</button>
    </div>
    {isLoading ? (
      <p>載入中...</p>
    ) : (
      <ul>
        {prompts.map((prompt) => (
          <li key={prompt.id}>
            {prompt.content}
            <button onClick={() => deletePrompt(prompt.id)}>刪除</button>
          </li>
        ))}
      </ul>
    )}
    <ToastContainer />
  </div>
);
```

```javascript
    export default App;
    ```

2. API集成：
    - 前端通过使用fetch请求与后端API交互，以管理故事提示。

```javascript
    export const apiFetch = (endpoint, options) => {
      return fetch(`https://api.yourdomain.com/${endpoint}`, options);
    };
    ```

翻譯成繁體中文：

```javascript
    export const apiFetch = (端點, 選項) => {
      return fetch(`https://api.yourdomain.com/${端點}`, 選項);
    };
    ```

### 部署

该项目部署于AWS云平台，DNS管理通过GoDaddy与Cloudflare进行。Nginx作为网关，负责SSL证书及请求头管理。我们采用Prometheus进行系统监控，并利用ElasticSearch、Kibana和Logstash实现日志管理。

1. 部署脚本：
    - 我们使用Fabric来自动化部署任务，例如准备本地和远程目录、同步文件以及设置权限。

```python
    from fabric import task
    from fabric import Connection
```

    server_dir = '/home/project/server'
    web_tmp_dir = '/home/project/server/tmp'

@task
def prepare_remote_dirs(c):
    if not c.run(f'test -d {server_dir}', warn=True).ok:
        c.sudo(f'mkdir -p {server_dir}')
        c.sudo(f'chmod -R 755 {server_dir}')
        c.sudo(f'chmod -R 777 {web_tmp_dir}')
        c.sudo(f'chown -R ec2-user:ec2-user {server_dir}')

```python
    @task
    def deploy(c, install='false'):
        prepare_remote_dirs(c)
        pem_file = './aws-keypair.pem'
        rsync_command = (f'rsync -avz --exclude="api/db.sqlite3" '
                         f'-e "ssh -i {pem_file}" --rsync-path="sudo rsync" '
                         f'{tmp_dir}/ {c.user}@{c.host}:{server_dir}')
        c.local(rsync_command)
        c.sudo(f'chown -R ec2-user:ec2-user {server_dir}')
```

這段程式碼定義了一個名為`deploy`的任務，用於部署應用程式到遠端伺服器。以下是其功能的簡要說明：

1. **準備遠端目錄**：首先調用`prepare_remote_dirs(c)`函數來準備遠端伺服器上的目錄結構。

2. **設定PEM文件路徑**：指定用於SSH連接的PEM文件路徑`./aws-keypair.pem`。

3. **構建rsync命令**：使用`rsync`命令將本地臨時目錄`tmp_dir`中的內容同步到遠端伺服器的`server_dir`目錄。命令中排除了`api/db.sqlite3`文件，並通過SSH使用指定的PEM文件進行身份驗證。`--rsync-path="sudo rsync"`確保在遠端伺服器上以`sudo`權限執行`rsync`。

4. **執行rsync命令**：通過`c.local(rsync_command)`在本地執行構建的`rsync`命令，將文件同步到遠端伺服器。

5. **更改文件所有者**：在遠端伺服器上，使用`c.sudo(f'chown -R ec2-user:ec2-user {server_dir}')`命令將`server_dir`目錄及其內容的所有者更改為`ec2-user`用戶。

這段程式碼主要用於自動化部署流程，確保應用程式文件正確地從本地環境同步到遠端伺服器，並設置適當的文件權限。

2. ElasticSearch配置：
    - ElasticSearch的设置包括集群、节点和网络配置。

```yaml
cluster.name: my-application
node.name: node-1
path.data: /var/lib/elasticsearch
path.logs: /var/log/elasticsearch
network.host: 0.0.0.0
http.port: 9200
discovery.seed_hosts: ["127.0.0.1"]
cluster.initial_master_nodes: ["node-1"]
```

3. Kibana配置：
    - Kibana的设置包括服务器和ElasticSearch主机的配置。

```yaml
server.port: 5601
server.host: "0.0.0.0"
elasticsearch.hosts: ["http://localhost:9200"]
```

4. Logstash配置：
    - Logstash被配置为读取日志文件，解析它们，并将解析后的日志输出到ElasticSearch。

    ```plaintext
    input {
      file {
        path => "/home/project/server/app.log"
        start_position => "beginning"
        sincedb_path => "/dev/null"
      }
    }
    ```

翻譯成繁體中文：

    ```plaintext
    input {
      file {
        path => "/home/project/server/app.log"
        start_position => "beginning"
        sincedb_path => "/dev/null"
      }
    }
    ```

這段配置的意思是：

- `input`：定義輸入來源。
- `file`：指定從文件中讀取數據。
- `path`：指定要讀取的文件路徑，這裡是 `/home/project/server/app.log`。
- `start_position`：指定從文件的哪個位置開始讀取，這裡是從文件開頭 (`beginning`) 開始。
- `sincedb_path`：指定 sincedb 文件的路徑，這裡設置為 `/dev/null`，表示不記錄讀取位置，每次都會從文件開頭重新讀取。

    filter {
      json {
        source => "message"
      }
    }

翻譯：

    過濾器 {
      json {
        來源 => "訊息"
      }
    }

```output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "flask-logs-%{+YYYY.MM.dd}"
  }
}
```

### Nginx 配置与 Let's Encrypt SSL 证书

为确保通信安全，我们采用Nginx作为反向代理，并使用Let's Encrypt提供SSL证书。以下是Nginx的配置，用于处理HTTP到HTTPS的重定向以及设置SSL证书。

1. 定义一个映射来处理允许的来源：

```nginx
    map $http_origin $cors_origin {
        default "https://example.com";
        "http://localhost:3000" "http://localhost:3000";
        "https://example.com" "https://example.com";
        "https://www.example.com" "https://www.example.com";
    }
    ```

2. 重定向HTTP至HTTPS：

```nginx
    server {
        listen 80;
        server_name example.com api.example.com;
```

```nginx
    return 301 https://$host$request_uri;
}
```

3. `example.com` 的主要站点配置：

    ```nginx
    server {
        listen 443 ssl;
        server_name example.com;
    ```

        ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;
        ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;

        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_prefer_server_ciphers on;
        ssl_ciphers "EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH";

        root /home/project/web;
        index index.html index.htm index.php default.html default.htm default.php;

        location / {
            try_files $uri $uri/ =404;
        }

        location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ {
            expires 30d;
        }

        location ~ .*\.(js|css)?$ {
            expires 12h;
        }

```nginx
    error_page 404 /index.html;
    }
    ```

4. `api.example.com` 的 API 配置：

```nginx
    server {
        listen 443 ssl;
        server_name api.example.com;
```

        ssl_certificate /etc/letsencrypt/live/example.com-0001/fullchain.pem;
        ssl_certificate_key /etc/letsencrypt/live/example.com-0001/privkey.pem;

        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_prefer_server_ciphers on;
        ssl_ciphers "EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH";

        location / {
            # 清除任何预先存在的Access-Control头信息
            more_clear_headers 'Access-Control-Allow-Origin';

            # 处理CORS预检请求
            if ($request_method = 'OPTIONS') {
                add_header 'Access-Control-Allow-Origin' $cors_origin;
                add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, PUT, DELETE';
                add_header 'Access-Control-Allow-Headers' 'Origin, Content-Type, Accept, Authorization, X-Client-Info, X-Trace-Id, X-Requested-With, X-HTTP-Method-Override, DNT, Keep-Alive, User-Agent, If-Modified-Since, Cache-Control, Content-Range, Range';
                add_header 'Access-Control-Max-Age' 3600;
                return 204;
            }

            add_header 'Access-Control-Allow-Origin' $cors_origin always;
            add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, PUT, DELETE' always;
            add_header 'Access-Control-Allow-Headers' 'Origin, Content-Type, Accept, Authorization, X-Client-Info, X-Trace-Id, X-Requested-With, X-HTTP-Method-Override, DNT, Keep-Alive, User-Agent, If-Modified-Since, Cache-Control, Content-Range, Range' always;

```nginx
            proxy_pass http://127.0.0.1:5000/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_connect_timeout 600s;
            proxy_send_timeout 600s;
            proxy_read_timeout 600s;
            send_timeout 600s;
        }
    }
    ```

### 结论

通过本次实验，我们成功实现了基于深度学习的图像分类任务。实验结果表明，所采用的卷积神经网络（CNN）模型在CIFAR-10数据集上达到了较高的分类准确率，验证了深度学习在图像识别领域的强大能力。此外，通过调整网络结构、优化算法以及数据增强等策略，我们进一步提升了模型的性能。未来，我们将继续探索更复杂的网络架构和训练技巧，以应对更具挑战性的图像分类任务。

本项目展示了一个基于AI的故事机器人应用的强大架构，采用了现代网页开发实践与工具。后端采用Flask构建，确保了高效的请求处理及与多种日志记录和监控服务的集成。前端则利用React打造，为用户管理故事提示提供了一个互动界面。通过运用AWS进行部署、Nginx保障通信安全以及ELK堆栈进行日志管理，我们确保了系统的可扩展性、可靠性和可维护性。这一全面的配置展现了结合尖端技术以提供无缝用户体验的强大能力。