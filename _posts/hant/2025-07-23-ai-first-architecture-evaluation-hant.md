---
audio: false
generated: true
lang: hant
layout: post
title: 人工智能優先架構於現代開發
translated: true
type: note
---

這篇文章是在 Grok 的協助下完成撰寫，但其中的觀點均為原創。

---

### 對您觀點的評估

我將逐一分析您的觀點，並根據當前軟體工程趨勢、AI/LLM 整合（例如 GitHub Copilot、Cursor 或自訂 LLM 代理等工具）以及實際應用影響進行評估。您觸及了一個關鍵洞察：隨著 AI 成為開發工作流程中不可或缺的一部分，系統架構必須在注重以人為本的設計之餘，同時優先考慮對 AI 的友好性。然而，並非所有想法都普遍適用——情境至關重要，在簡潔性與可擴展性之間取得平衡是必要的。我將概述同意、不同意之處以及關鍵的細微差別。

#### 1. 傳統銀行架構有其優點，但新項目應優先考慮 AI/LLM 優化：聚焦於情境工程、清晰分離及 AI 優先設計
理論上您的觀點是正確的。傳統架構（例如銀行業中假設指的是單體式或分層企業系統）在可靠性、安全性和人類可維護性方面表現出色。然而，隨著 AI/LLM 代理驅動程式碼生成、除錯和重構，「AI 優先」的思維模式越來越重要。這涉及為 LLM 的限制（例如 GPT-4o 中 128k token 的有限上下文視窗）進行設計，透過模組化程式碼以確保關鍵細節能適應這些限制。

- **優勢**：清晰的關注點分離（例如不同的資料流、提示詞或 API 邊界）使 AI 能夠更有效地進行推理。例如，像 LangChain 或自訂代理這樣的 AI 工具在具有明確定義、隔離的情境下表現更佳，而非糾結的邏輯。
- **細微差別**：以人為本的設計仍然至關重要——在像金融這樣監管合規性和安全性至關重要的複雜領域，AI 仍然需要人類監督。混合模式可能最為理想：重複性任務進行 AI 優化，關鍵邏輯則進行人類優化。
- **整體評估**：大致同意；這一趨勢在 AI 驅動的微服務和無伺服器架構中顯而易見。

#### 2. Spring 提供強大的抽象，但對 AI/LLM 的理解構成挑戰
您在這點上是正確的。Spring（以及類似 Java 框架如 Micronaut）非常適合企業環境，具有依賴注入、AOP 和分層抽象（例如控制器 -> 服務 -> 儲存庫）等功能。雖然這些對於人類管理的大型團隊非常出色，但由於間接性和樣板程式碼，它們可能會讓 LLM 不堪重負。

- **優勢**：LLM 通常難以處理深層呼叫堆疊或隱含行為（例如 @Autowired 註解），導致產生幻覺或不完整分析。關於 AI 程式碼生成的研究表明，在過度抽象的程式碼庫中錯誤率更高。
- **細微差別**：並非所有抽象都是有害的——例如，介面增強了可測試性，間接幫助了 AI 執行像模擬生成這樣的任務。然而，過多的分層會膨脹上下文，使 LLM 的邏輯追蹤複雜化。
- **整體評估**：強烈同意；正朝著更輕量級的框架（例如 Quarkus）或最小化框架方法轉變，以提高 AI 相容性。

#### 3. 偏好扁平化結構，類似扁平化組織：限制在 2 個層級，第一層級呼叫第二層級，避免具有 50 個層級的深堆疊
這是一個對於簡潔性來說引人注目的想法，但並非普遍理想。扁平化結構（例如，頂層協調器呼叫多個小函數）減少了嵌套，有助於 LLM 避免在複雜呼叫堆疊上出現推理錯誤。這反映了在 Python 腳本中常見的直觀函數鏈接。

- **優勢**：扁平化程式碼降低了 AI 的認知負荷——LLM 在線性或平行推理上表現優於深層遞歸。「扁平化組織」的類比成立：如同新創公司，扁平化程式碼更適合 AI 修改。
- **細微差別**：從單一點呼叫大量函數，若沒有嚴格的組織（例如清晰的命名或模組化），可能導致「義大利麵條式」程式碼。在較大系統中，最少層級（3-4 層）可防止混亂。雖然像 Devin 這樣的 AI 代理能很好地處理扁平結構，但若沒有適當的協調，可能會出現效能問題。
- **整體評估**：部分同意；在可行的情况下扁平化是有益的，但必須測試可擴展性。這與 AI 驅動開發中的函數式程式設計趨勢一致。

#### 4. AI/LLM 難以處理複雜的嵌套結構，擅長小函數（100-200 行）；Python 的呼叫和導入系統支援這一點
關於 LLM 能力這點，您說得很對。當前模型（例如 Claude 3.5、GPT-4）擅長專注、封閉的任務，但在處理複雜性時會失誤——由於 token 限制和注意力分散，在超過約 500 行上下文後錯誤率會上升。

- **優勢**：小函數（100-200 行）對 AI 是最佳的：易於提示、生成或重構。Python 的導入系統（例如 `from module import func`）促進了模組化，使其比 Java 以類別為中心的結構更對 AI 友好。
- **細微差別**：雖然 LLM 在不斷進步（例如透過思維鏈提示），但嵌套邏輯仍然是一個挑戰。Python 的靈活性有所幫助，但靜態類型（例如 TypeScript）也可以透過提供明確的線索來協助 AI。
- **整體評估**：強烈同意；這解釋了為什麼 ML/AI 生態系統（例如 Hugging Face 函式庫）通常採用 Python 的模組化風格。

#### 5. 將 Java 大檔案拆分為更多函數的較小檔案，以便於測試/驗證；Java 項目應模仿 Python 的結構
這是一個實用的方向。龐大、單體的 Java 類別（例如 1000+ 行）對人類和 AI 都具有挑戰性，而拆分為較小的檔案/函數則提高了粒度。

- **優勢**：較小的單元簡化了單元測試（例如使用 JUnit）和驗證（AI 可以一次專注於一個函數），反映了 Python 的每個功能一個模組的方法。像 Maven/Gradle 這樣的建置工具可以無縫適應這一點。
- **細微差別**：Java 的套件系統已經支援這一點，但需要從 OOP 單體的文化轉變。並非所有 Java 項目都應該模仿 Python——效能關鍵型應用程式可能受益於某些整合。
- **整體評估**：同意；現代 Java（例如 Java 21+ 中的紀錄和密封類別）正朝著這個方向發展。

#### 6. 在 AI/LLM 時代，程序式程式設計可能勝過 OOP
這是一個大膽但在特定情境下有效的觀點。程序式（或函數式）方法強調直觀的流程和純函數，符合 LLM 的優勢——生成線性程式碼比處理 OOP 的狀態、繼承和多型更簡單。

- **優勢**：像深層繼承這樣的 OOP 抽象常常混淆 LLM，導致生成的程式碼出錯。程序式程式碼更可預測，適合 AI 的模式匹配特性。像 Rust（具有程序式特徵）和 Go（強調簡潔性）這樣的語言反映了這一趨勢。
- **細微差別**：OOP 並未過時——它在建模複雜領域（例如金融實體）方面仍然有效。混合方法（程序式核心與 OOP 包裝器）可能最為理想。透過量身訂製的提示，LLM 可以管理 OOP，但程序式減少了摩擦。
- **整體評估**：部分同意；程序式/函數式風格在 AI 工作流程中越來越受歡迎，但 OOP 在大型系統的長期可維護性方面仍具有價值。

#### 7. 像 VSCode 或 IntelliJ IDEA 這樣的 IDE 應提供用於 AI 輔助函數/方法編輯的快捷方式
您說得對，這將簡化工作流程。雖然當前的 IDE 提供部分支援（例如 VSCode 的「Go to Definition」或 Copilot 的內嵌建議），但專用的 AI 編輯快捷方式正變得越來越普遍。

- **優勢**：選擇一個函數/方法並提示 AI（例如「重構這個」）將提高效率。像 Cursor（基於 VSCode 構建）這樣的工具已經實現了區域特定的 AI 編輯。
- **細微差別**：IntelliJ IDEA 提供「Extract Method」和 AI 助手（透過 JetBrains AI），而 VSCode 擴充功能如 GitHub Copilot Chat 支援基於選擇的查詢。然而，原生的「AI-edit this function」快捷方式將是一個有價值的補充——很可能在未來的更新中出現。
- **整體評估**：同意；這與日益增長的 AI 優先工具趨勢一致。

### 總結
您的見解大部分是準確的：採用 AI 優化架構（扁平、模組化、小單元）解決了真實的 LLM 限制，並可以加速開發。然而，極端做法如完全程序式或過度扁平的設計可能會損害長期可維護性——平衡至關重要。在金融等領域，安全性和合規性可能需要某些抽象。您的觀點與 AI 輔助編碼中新興的最佳實踐一致，其中簡潔性對人類和機器都有益。

如果您有具體的程式碼範例或想探索 AI 優先的重新設計，請隨時提問！