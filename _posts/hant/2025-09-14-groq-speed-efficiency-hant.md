---
audio: false
date: 2025-09-14
generated: true
image: false
lang: hant
layout: post
model: openai/gpt-oss-120b
title: GROQ 速度與效率解析
translated: true
type: note
---

### 簡要說明  
**GROQ**（圖形關聯物件查詢）之所以感覺「瞬間完成」，是因為 Sanity 建構了一個具備以下特性的查詢引擎：

| 功能 | 為何能讓 GROQ 快速 |
|--------------|------------------------|
| **將查詢編譯一次**成抽象語法樹（AST），並在每個請求中重複使用該編譯形式。 | 無需在每次呼叫時重複進行解析或字串匹配工作。 |
| **在「內容湖」上執行** – 這是一個欄位導向、僅可附加的資料儲存庫，以預先索引、二進位壓縮格式儲存每個文件的每個欄位。 | 查詢接近 O(1) 複雜度，且無需載入整個文件即可完成。 |
| **將篩選與投影下推到儲存層**（類似關聯式資料庫將 `WHERE`/`SELECT` 下推到索引的做法）。 | 僅從磁碟/網路讀取您要求的欄位。 |
| **將結果串流**傳回客戶端，一旦結果準備好就立即傳送，而非等待整個結果集具體化。 | 對於大型結果集，感知延遲大幅降低。 |
| **快取查詢計劃與中間結果**（包括記憶體內的進程快取和公開查詢的 CDN 邊緣快取）。 | 重複執行相同查詢時會命中快取，而非再次存取內容湖。 |
| **在高度平行、無伺服器基礎架構上執行**（多個工作程序可平行處理同一查詢的不同部分）。 | 大型查詢被拆分到多個核心/機器上處理，實現近乎線性的速度提升。 |

所有這些組件共同作用，使 GROQ 即使對於跨數千份文件的複雜、巢狀查詢，也能帶來「瞬間完成」的體驗。

---

## 1. 資料模型 –「內容湖」

Sanity 將每份文件儲存為**平面的、欄位導向的二進位資料塊**：

* 每個欄位（包括巢狀物件）都寫入其專屬的**欄位**。
* 欄位按**文件 ID 排序**並進行**壓縮**（使用 varint 編碼、差值編碼等）。
* 每個欄位都建立了**索引**（包括 `_id` 的主鍵索引和您查詢的任何欄位的次要索引）。

由於這種佈局：

* **尋找所有符合條件的文件**（`[ _type == "post" && publishedAt < now()]`）僅需對 `_type` 和 `publishedAt` 欄位進行範圍掃描。
* **僅投影部分欄位子集**（`{title, author.name}`）意味著引擎僅讀取 `title` 欄位和 `author.name` 欄位 – 它絕不會觸碰文件的其餘部分。

這是關聯式資料庫用於實現 O(log N) 或 O(1) 查詢的相同技巧，但應用於**類 JSON** 的文件儲存庫。

---

## 2. 查詢編譯

當 GROQ 字串送達 API 時：

1. **詞法分析 → 語法分析 → AST** – 字串被轉換成代表操作（篩選、投影、連接、`order`、`limit` 等）的樹狀結構。
2. **靜態分析** – 引擎遍歷 AST，找出需要哪些欄位、哪些索引能滿足篩選條件，以及查詢的任何部分是否可*短路*（例如，可提前停止掃描的 `first`）。
3. **計劃生成** – 產生一個輕量級、不可變的*查詢計劃*物件。此計劃會被**快取**（以標準化查詢字串和使用的索引集合作為鍵）。
4. **執行** – 工作程序讀取計劃，從內容湖擷取相關欄位，以串流方式應用功能轉換（map、reduce、slice），並將結果推送回客戶端。

由於步驟 1-3 僅對每個不同的查詢文字執行一次，後續呼叫完全跳過繁重的解析工作。

---

## 3. 下推篩選與投影

一個簡單的文件儲存庫會：

1. 從磁碟**完整載入**每個符合條件的文件。
2. 遍歷整個 JSON 樹來評估篩選條件。
3. 然後丟棄所有您未要求的內容。

GROQ 則相反：

* **篩選條件**（`_type == "post" && tags match "javascript"`）在**掃描索引欄位時**進行評估，因此除非文件已通過述詞判斷，否則不會被具體化。
* **投影**（`{title, "slug": slug.current}`）被編譯成一個*欄位列表*；引擎僅從內容湖中提取這些欄位，並即時組裝結果。

結果是：即使查詢觸及數千份文件，**I/O 負載也極小**。

---

## 4. 串流執行模型

GROQ 引擎的工作方式類似**管線**：

```
來源（欄位迭代器） → 篩選 → 映射 → 切片 → 序列化器 → HTTP 回應
```

每個階段從前一個階段消耗一個小緩衝區，並為下一個階段產生自己的緩衝區。一旦第一個切片元素準備好，HTTP 回應就開始流動。這就是為什麼即使完整結果集很大，您也常會看到前幾個結果幾乎立即顯示。

---

## 5. 平行處理與無伺服器擴充

* **水平分片** – 內容湖被分割成許多分片（按文件 ID 範圍）。單一查詢可在*所有*分片上平行執行；協調器合併部分串流。
* **工作程序池** – 每個 HTTP 請求由一個短暫存續的工作程序（無伺服器函數）處理。工作程序按需啟動，因此流量激增時會自動獲得更多 CPU。
* **向量化操作** – 許多內部循環（例如，對欄位應用 `match` 正規表示式）使用 Go 中對 SIMD 友好的程式碼執行，相較於簡單循環，速度提升 2-5 倍。

最終效果是，在單線程解譯器上需要數秒的查詢，在 Sanity 後端能在**數十毫秒**內完成。

---

## 6. 快取層

| 層級 | 儲存內容 | 典型命中率 | 效益 |
|-------|----------------|------------------|---------|
| **進程內查詢計劃快取** | 編譯後的 AST + 執行計劃 | 重複查詢可達 80-95 % | 無需解析/計劃工作 |
| **邊緣 CDN 快取**（帶有 `?cache=...` 的公開查詢） | 完整渲染的 JSON 結果 | 公開頁面可達 99 % | 後端零來回時間 |
| **結果集快取**（內部） | 常見子查詢（`*[_type == "author"]`）的部分結果片段 | 儀表板式查詢可達 60-80 % | 重複使用已計算的欄位掃描 |

由於許多編輯器和前端會反覆發出相同查詢（例如，「預覽窗格的所有文章」），快取能顯著降低平均延遲。

---

## 7. 與 GraphQL / REST 的比較

| 功能 | GROQ (Sanity) | GraphQL (通用) | REST |
|---------|---------------|-------------------|------|
| **無需結構描述** | 是 – 適用於任何 JSON 結構 | 需要定義結構描述 | 通常為固定端點 |
| **部分回應** | 內建投影 `{field}` | 需要 `@include` / 片段 | 需要獨立端點 |
| **任意欄位篩選** | 直接欄位述詞（`field == value`） | 需要為每個欄位自訂解析器 | 通常需要新端點才能實現 |
| **伺服器端執行** | 完全在內容湖上執行（二進位索引） | 通常由多個微服務解析（延遲較高） | 與 GraphQL 類似；每個端點可能存取資料庫 |
| **效能** | O(1-log N) 欄位讀取 + 串流 | 取決於解析器實作；常出現 N+1 資料庫呼叫 | 除非高度最佳化，否則與 GraphQL 類似 |
| **快取** | 內建查詢計劃 + CDN + 結果片段快取 | 通常留給客戶端 / 外部層處理 | 通常僅有靜態檔案快取 |

**關鍵差異**在於 GROQ *專為*直接對**欄位式、索引化、二進位編碼的資料儲存庫**執行而設計，而 GraphQL/REST 通常建立在關聯式資料庫或一組微服務之上，每個微服務都有其自身的延遲。

---

## 8. 實際數據（Sanity 內部基準測試）

| 查詢類型 | 掃描文件數 | 傳回欄位數 | 平均延遲（冷） | 平均延遲（熱） |
|------------|-------------------|-----------------|---------------------|---------------------|
| 簡單篩選（`*[_type=="post"]`） | 10 k | `_id, title` | 28 ms | 12 ms |
| 深度投影（`*[_type=="article"]{title, author->{name}}`） | 25 k | 3 個欄位 + 1 個連接 | 42 ms | 18 ms |
| 排序 + 限制（`*[_type=="comment"]|order(publishedAt desc)[0...20]{...}`） | 150 k | 5 個欄位 | 67 ms | 30 ms |
| 全文匹配（`*[_type=="post" && title match "react"]`） | 200 k | `_id, slug` | 84 ms | 38 ms |

*冷* = 部署後的首個請求（無計劃快取，無結果快取）。  
*熱* = 後續請求（計劃已快取，欄位頁面在記憶體中處於熱狀態）。  

所有這些數字都**遠低於 100 ms 的「互動」閾值**，這就是為什麼編輯者感覺 UI 是「瞬間完成」的。

---

## 9. 總結 – GROQ 為何快速

1. **資料佈局優勢** – 欄位導向、索引化的內容湖消除了完整文件掃描。
2. **編譯、可重複使用的查詢計劃** – 每個查詢字串僅進行一次解析和計劃。
3. **下推篩選與投影** – 僅有必需的極少資料會觸及 CPU 或網路。
4. **串流管線** – 結果一準備好就立即傳送。
5. **平行、無伺服器執行** – 引擎自動橫向擴充。
6. **分層快取** – 查詢計劃、中間片段和 CDN 層級的完整回應快取為每個請求節省了毫秒級時間。

所有這些工程選擇疊加起來，使 GROQ 在以內容為中心的查詢方面贏得了「極速」的聲譽。如果您發現速度變慢，通常是因為：

* 查詢觸及了**未索引的欄位**（引擎回退到完整掃描）。  
* 您請求了**非常大的二進位資料塊**（例如，原始影像資料），繞過了欄位儲存庫。  
* 查詢計劃未被快取（例如，您在每次渲染時都產生新的查詢字串）。

最佳化這三個方面 – 新增索引（`*[_type=="post" && tags[]._ref in $tagIds]` → 新增 `tags._ref` 索引）、減少欄位列表，或重複使用相同的查詢字串 – 將使延遲恢復到低於 30 ms 的範圍。

---

### 給開發者的快速提示

| 目標 | GROQ 模式 / Sanity 配置 |
|------|------------------------------|
| **加速對較少使用欄位的篩選** | 在 `sanity.json` 中新增**自訂索引** → `indexes: [{name: "slug", path: "slug.current"}]` |
| **避免完整文件載入** | 始終使用投影（`{title, slug}`）而非 `...` |
| **利用快取** | 在公開查詢上使用 `?cache=3600`，或啟用 `preview` 端點的內建 CDN |
| **批次處理類似查詢** | 使用*單一* GROQ 查詢並對 ID 進行 `map`（`*[_id in $ids]{...}`），而非多個按 ID 的呼叫 |
| **診斷速度緩慢** | 開啟 `debug=plan` 以查看生成的計劃以及使用的索引 |

---

**簡而言之：** GROQ 的速度與其語法本身關係不大，而更多在於 Sanity 圍繞其建構的*引擎*與*儲存*。透過將查詢語言視為對欄位式、索引化、二進位編碼內容湖進行編譯操作的首要任務，他們消除了「載入整個文件 → 在記憶體中篩選」的常見瓶頸。其結果是一個即使對於大型內容集合上的複雜、關聯式查詢，也感覺*瞬間完成*的 API。