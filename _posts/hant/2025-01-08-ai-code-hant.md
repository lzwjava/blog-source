---
audio: true
lang: hant
layout: post
title: AI代码编辑器的未来方向
---

最近，我正在致力于为GitHub Actions添加一个`xelatex`编译流程。

我在GitHub流程中遇到了`fontawesome5`包的问题。4o-mini提供的解决方案（安装TeX Live 2021并使用`tlmgr install fontawesome5`）对我无效。不过，4o提出了一个更好的方法：升级到TeX Live 2023，并继续使用`tlmgr`来安装`fontawesome5`。虽然这并未彻底解决问题，但切换到TeX Live 2023后，情况有了显著改善。

我利用ChatGPT来帮助解决这个问题。欲了解更多详情，请查看[ChatGPT O1能做什么而4o-mini不能](./o1-en)。

此时，我并未使用诸如Cursor或Windsurf这类编辑器，尽管在另一个项目中我确实尝试过它们。这些代码编辑器的问题在于，它们仅能捕获本地测试输出，这在云环境中极大地限制了它们的功能性。

在GitHub Actions、Jenkins作业或任何代码部署及测试流程中，代码编辑器需实现更深度的集成。它们应提供与云端及CI/CD流程的无缝交互体验。

这种整合同样适用于其他内容创作工具——无论是文本、图像、音频还是视频。这些工具应与A/B测试系统相结合。AI工具负责生成内容，而A/B测试工具则提供反馈。这一机制类似于基于人类反馈的强化学习（RLHF），即AI模型根据现实世界的反馈不断优化。

将RLHF（基于人类反馈的强化学习）的应用范围从模型输出扩展到现实世界的测试与部署环境，这一理念似乎为代码编辑器和AI驱动的内容创作工具的改进指明了一个充满希望的方向。

测试可以是即时或长期的，也可以是自动化或人工辅助的。如果测试是自动化的，比如针对AI工具的用户A/B测试，虽然仍涉及人类反馈，但过程是自动化的。例如，我们可以让计算机根据A/B测试结果每天或每小时检查结果，以改进创作过程。同样地，对于Jenkins或GitHub Actions的任务，我们可以在它们完成任务后让计算机进行检查。

如果涉及到人工协助，机器就无法完全理解反馈，而且反馈往往有些模糊。例如，当人工智能工具创建图像或视频等内容时，人类可能会指出内容不够有趣，或者应该改进某个细节。机器在使一切变得完美方面还有很长的路要走，而某些东西是否"完美"往往是主观的，取决于个人品味。正是人类的反馈帮助把事情做得更好。

理论上，所有人为定义的规则都可以写成提示词。有用户提示词和系统提示词。我们应该专注于改进提示词，而不是每次都去修正输出。