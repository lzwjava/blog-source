---
lang: hant
layout: post
title: äº‘è®¡ç®—ä¸å¤§æ•°æ®å…¥é—¨
---

é€™ç¯€èª²åŒ…å«ä»¥ä¸‹è©±é¡Œï¼š

* Spark
* Hadoop
* Kubernetes
* Docker
* Flink
* MongoDB

è¯´èµ·äº‘è®¡ç®—ï¼Œä¼¼ä¹ç¦»ä¸å¼€ä¼—å¤šçš„å·¥å…·ï¼Œå¦‚Hadoopã€Hiveã€Hbaseã€ZooKeeperã€Dockerã€Kubernetesã€Sparkã€Kafkaã€MongoDBã€Flinkã€Druidã€Prestoã€Kylinã€Elastic Searchã€‚è¿™äº›å·¥å…·ä½ éƒ½æœ‰æ‰€è€³é—»å—ï¼Ÿå…¶ä¸­ä¸€äº›æ˜¯æˆ‘ä»`å¤§æ•°æ®å·¥ç¨‹å¸ˆ`å’Œ`åˆ†å¸ƒå¼åç«¯å·¥ç¨‹å¸ˆ`çš„èŒä½æè¿°ä¸­å‘ç°çš„ã€‚è¿™äº›éƒ½æ˜¯é«˜è–ªèŒä½ã€‚æˆ‘ä»¬ä¸å¦¨å°è¯•å°†å®ƒä»¬ä¸€ä¸€å®‰è£…ï¼Œç¨ä½œæ¢ç´¢ã€‚
## åˆæ¢ Spark

å®˜ç½‘ä»‹ç»ï¼Œ`Spark` æ˜¯ä¸€ä¸ªç”¨äºå¤§è§„æ¨¡æ•°æ®åˆ†æçš„å¼•æ“ã€‚`Spark` å®é™…ä¸Šæ˜¯ä¸€å¥—åº“ï¼Œå®ƒä¸åƒ `Redis` é‚£æ ·åˆ†ä¸ºæœåŠ¡ç«¯å’Œå®¢æˆ·ç«¯ã€‚`Spark` ä¸»è¦æ˜¯åœ¨å®¢æˆ·ç«¯ä½¿ç”¨çš„ã€‚ä»å®˜ç½‘ä¸‹è½½äº†æœ€æ–°ç‰ˆæœ¬ï¼Œæ–‡ä»¶åä¸º `spark-3.1.1-bin-hadoop3.2.tar`ã€‚

```shell
$ tree . -L 1
.
â”œâ”€â”€ LICENSE
â”œâ”€â”€ NOTICE
â”œâ”€â”€ R
â”œâ”€â”€ README.md
â”œâ”€â”€ RELEASE
â”œâ”€â”€ bin
â”œâ”€â”€ conf
â”œâ”€â”€ data
â”œâ”€â”€ examples
â”œâ”€â”€ jars
â”œâ”€â”€ kubernetes
â”œâ”€â”€ licenses
â”œâ”€â”€ python
â”œâ”€â”€ sbin
â””â”€â”€ yarn
```

11å€‹ç›®éŒ„ï¼Œ4å€‹æ–‡ä»¶
```

ä¼¼ä¹å°±æ˜¯å„ç§è¯­è¨€ç¼–å†™çš„ä¸€äº›åˆ†æåº“ã€‚

åŒæ—¶ï¼Œå®˜ç½‘æåˆ°å¯ä»¥ç›´æ¥åœ¨Pythonä¸Šå®‰è£…ä¾èµ–åº“ã€‚ä½¿ç”¨å‘½ä»¤ `pip install pyspark` å³å¯å®Œæˆå®‰è£…ã€‚

```shell
$ pip install pyspark
æ­£åœ¨æ”¶é›† pyspark
  ä¸‹è¼‰ pyspark-3.1.1.tar.gz (212.3 MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212.3 MB 14 kB/s
æ­£åœ¨æ”¶é›† py4j==0.10.9
  ä¸‹è¼‰ py4j-0.10.9-py2.py3-none-any.whl (198 kB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198 kB 145 kB/s
æ­£åœ¨ç‚ºæ”¶é›†çš„å¥—ä»¶æ§‹å»ºè¼ªå­ï¼špyspark
  æ­£åœ¨ç‚º pyspark æ§‹å»ºè¼ªå­ (setup.py) ... å®Œæˆ
  å·²ç‚º pyspark å‰µå»ºè¼ªå­ï¼šæª”æ¡ˆå=pyspark-3.1.1-py2.py3-none-any.whl å¤§å°=212767604 sha256=0b8079e82f3a5bcadad99179902d8c8ff9f8eccad928a469c11b97abdc960b72
  å„²å­˜æ–¼ç›®éŒ„ï¼š/Users/lzw/Library/Caches/pip/wheels/23/bf/e9/9f3500437422e2ab82246f25a51ee480a44d4efc6c27e50d33
æˆåŠŸæ§‹å»º pyspark
æ­£åœ¨å®‰è£æ”¶é›†çš„å¥—ä»¶ï¼špy4j, pyspark
æˆåŠŸå®‰è£ py4j-0.10.9 pyspark-3.1.1
```

è£…ä¸Šäº†ã€‚

ç°åœ¨è®¿é—®å®˜ç½‘ï¼ŒæŸ¥çœ‹ä¸€äº›ç¤ºä¾‹ã€‚

```shell
./bin/run-example SparkPi 10
``` 

é€™è¡Œå‘½ä»¤çš„æ„æ€æ˜¯åŸ·è¡Œ Spark æä¾›çš„ç¯„ä¾‹ç¨‹å¼ `SparkPi`ï¼Œä¸¦å°‡åƒæ•¸ `10` å‚³éçµ¦å®ƒã€‚é€™å€‹ç¯„ä¾‹ç¨‹å¼é€šå¸¸ç”¨æ–¼è¨ˆç®—åœ“å‘¨ç‡ Ï€ çš„è¿‘ä¼¼å€¼ï¼Œè€Œåƒæ•¸ `10` å¯èƒ½ä»£è¡¨è¨ˆç®—çš„è¿­ä»£æ¬¡æ•¸æˆ–ç²¾åº¦ç­‰ç´šã€‚åŸ·è¡Œæ­¤å‘½ä»¤å¾Œï¼ŒSpark æœƒé‹è¡Œè©²ç¯„ä¾‹ä¸¦è¼¸å‡ºè¨ˆç®—çµæœã€‚

å“¦ï¼ŒåŸä¾†å¯ä»¥é‹è¡Œå‰›å‰›ä¸‹è¼‰çš„å®‰è£åŒ…è£¡çš„ç¨‹å¼ã€‚ä½†å‡ºéŒ¯äº†ã€‚

```shell
$ ./bin/run-example SparkPi 10
21/03/11 00:06:15 WARN NativeCodeLoader: ç„¡æ³•ç‚ºæ‚¨çš„å¹³å°åŠ è¼‰åŸç”ŸHadoopåº«...åœ¨é©ç”¨çš„æƒ…æ³ä¸‹ä½¿ç”¨å…§å»ºçš„Javaé¡
21/03/11 00:06:16 INFO ResourceUtils: æœªç‚ºspark.driveré…ç½®è‡ªå®šç¾©è³‡æºã€‚
21/03/11 00:06:16 WARN Utils: æœå‹™ 'sparkDriver' ç„¡æ³•ç¶å®šåˆ°éš¨æ©Ÿç©ºé–’ç«¯å£ã€‚æ‚¨å¯èƒ½éœ€è¦æª¢æŸ¥æ˜¯å¦é…ç½®äº†é©ç•¶çš„ç¶å®šåœ°å€ã€‚
```

> Spark æ˜¯ä¸€ä¸ªå¿«é€Ÿä¸”é€šç”¨çš„å¤„ç†å¼•æ“ï¼Œå…¼å®¹ Hadoop æ•°æ®ã€‚å®ƒå¯ä»¥é€šè¿‡ YARN æˆ– Spark çš„ç‹¬ç«‹æ¨¡å¼åœ¨ Hadoop é›†ç¾¤ä¸­è¿è¡Œï¼Œå¹¶ä¸”èƒ½å¤Ÿå¤„ç† HDFSã€HBaseã€Cassandraã€Hive ä»¥åŠä»»ä½• Hadoop InputFormat ä¸­çš„æ•°æ®ã€‚Spark è®¾è®¡ç”¨äºæ‰§è¡Œæ‰¹å¤„ç†ï¼ˆç±»ä¼¼äº MapReduceï¼‰ä»¥åŠæ–°çš„å·¥ä½œè´Ÿè½½ï¼Œå¦‚æµå¤„ç†ã€äº¤äº’å¼æŸ¥è¯¢å’Œæœºå™¨å­¦ä¹ ã€‚

å‡ºç°äº†å¥½å‡ æ¬¡`hadoop`ã€‚åœ¨è°·æ­Œæœç´¢`spark depends hadoop`ä¹‹åï¼Œæ‰¾åˆ°äº†è¿™æ ·ä¸€æ®µè¯ã€‚çœ‹æ¥è¿™ä¾èµ–äº`Hadoop`æ ¼å¼çš„æ•°æ®ã€‚è®©æˆ‘ä»¬å…ˆç ”ç©¶ä¸€ä¸‹`Hadoop`ã€‚

## Hadoop

ç®€å•æµè§ˆäº†å®˜ç½‘åï¼Œç°åœ¨æ¥å®‰è£…ä¸€ä¸‹ã€‚

```shell
brew install hadoop
```

åœ¨å®‰è£…çš„è¿‡ç¨‹ä¸­ï¼Œè®©æˆ‘ä»¬æ¥äº†è§£ä¸€ä¸‹ã€‚

> Apache Hadoop è½¯ä»¶åº“æ˜¯ä¸€ä¸ªæ¡†æ¶ï¼Œå®ƒå…è®¸ä½¿ç”¨ç®€å•çš„ç¼–ç¨‹æ¨¡å‹åœ¨è®¡ç®—æœºé›†ç¾¤ä¸Šåˆ†å¸ƒå¼å¤„ç†å¤§å‹æ•°æ®é›†ã€‚å®ƒæ—¨åœ¨ä»å•ä¸€æœåŠ¡å™¨æ‰©å±•åˆ°æ•°åƒå°æœºå™¨ï¼Œæ¯å°æœºå™¨éƒ½æä¾›æœ¬åœ°è®¡ç®—å’Œå­˜å‚¨ã€‚è¯¥åº“æœ¬èº«å¹¶ä¸ä¾èµ–ç¡¬ä»¶æ¥æä¾›é«˜å¯ç”¨æ€§ï¼Œè€Œæ˜¯è®¾è®¡ç”¨äºåœ¨åº”ç”¨å±‚æ£€æµ‹å’Œå¤„ç†æ•…éšœï¼Œä»è€Œåœ¨è®¡ç®—æœºé›†ç¾¤ä¹‹ä¸Šæä¾›é«˜å¯ç”¨æ€§æœåŠ¡ï¼Œå°½ç®¡é›†ç¾¤ä¸­çš„æ¯å°è®¡ç®—æœºéƒ½å¯èƒ½å‡ºç°æ•…éšœã€‚

ç®€è€Œè¨€ä¹‹ï¼ŒHadoop æ˜¯ä¸€å¥—ç”¨äºå¤„ç†åˆ†å¸ƒå¼æ•°æ®é›†çš„æ¡†æ¶ã€‚è¿™äº›æ•°æ®é›†å¯èƒ½åˆ†å¸ƒåœ¨ä¼—å¤šè®¡ç®—æœºä¸Šï¼Œé€šè¿‡æå…¶ç®€æ´çš„ç¼–ç¨‹æ¨¡å‹è¿›è¡Œå¤„ç†ã€‚Hadoop çš„è®¾è®¡åˆè¡·æ˜¯ä»å•ä¸€æœåŠ¡å™¨æ‰©å±•è‡³æˆåƒä¸Šä¸‡å°æœºå™¨ã€‚ä¸åŒäºä¾èµ–ç¡¬ä»¶çš„é«˜å¯ç”¨æ€§ï¼Œè¯¥åº“æ—¨åœ¨åº”ç”¨å±‚é¢å°±èƒ½æ£€æµ‹å¹¶å¤„ç†é”™è¯¯ã€‚å› æ­¤ï¼Œå³ä¾¿é›†ç¾¤ä¸­çš„æ¯å°è®¡ç®—æœºéƒ½å¯èƒ½å‡ºç°æ•…éšœï¼Œé«˜å¯ç”¨æœåŠ¡ä¾ç„¶èƒ½å¤Ÿéƒ¨ç½²äºæ•´ä¸ªé›†ç¾¤ä¹‹ä¸­ã€‚

```shell
$ brew install hadoop
é”™è¯¯ï¼š
  homebrew-core æ˜¯ä¸€ä¸ªæµ…å…‹éš†ã€‚
  homebrew-cask æ˜¯ä¸€ä¸ªæµ…å…‹éš†ã€‚
è¦æ‰§è¡Œ `brew update`ï¼Œé¦–å…ˆè¿è¡Œï¼š
  git -C /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core fetch --unshallow
  git -C /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask fetch --unshallow
è¿™äº›å‘½ä»¤å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ‰èƒ½è¿è¡Œï¼Œå› ä¸ºä»“åº“çš„å¤§å°è¾ƒå¤§ã€‚
ç”±äº Homebrew/homebrew-core å’Œ Homebrew/homebrew-cask çš„æ ‘å½¢ç»“æ„å’Œæµé‡ï¼Œæ›´æ–°æµ…å…‹éš†æ˜¯ä¸€é¡¹æå…¶æ˜‚è´µçš„æ“ä½œï¼Œå› æ­¤ GitHub æå‡ºäº†è¿™ä¸€é™åˆ¶ã€‚æˆ‘ä»¬æ²¡æœ‰è‡ªåŠ¨ä¸ºæ‚¨æ‰§è¡Œæ­¤æ“ä½œï¼Œä»¥é¿å…åœ¨ CI ç³»ç»Ÿä¸­é‡å¤æ‰§è¡Œæ˜‚è´µçš„éæµ…å…‹éš†æ“ä½œï¼ˆè¿™äº›ç³»ç»Ÿåº”ä¿®å¤ä¸ºä¸ä½¿ç”¨æµ…å…‹éš†ï¼‰ã€‚å¯¹æ­¤å¸¦æ¥çš„ä¸ä¾¿ï¼Œæˆ‘ä»¬æ·±è¡¨æ­‰æ„ï¼
==> æ­£åœ¨ä¸‹è½½ https://homebrew.bintray.com/bottles/openjdk-15.0.1.big_sur.bottle.tar.gz
å·²ä¸‹è½½ï¼š/Users/lzw/Library/Caches/Homebrew/downloads/d1e3ece4af1d225bc2607eaa4ce85a873d2c6d43757ae4415d195751bc431962--openjdk-15.0.1.big_sur.bottle.tar.gz
==> æ­£åœ¨ä¸‹è½½ https://www.apache.org/dyn/closer.lua?path=hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
å·²ä¸‹è½½ï¼š/Users/lzw/Library/Caches/Homebrew/downloads/764c6a0ea7352bb8bb505989feee1b36dc628c2dcd6b93fef1ca829d191b4e1e--hadoop-3.3.0.tar.gz
==> æ­£åœ¨å®‰è£… hadoop çš„ä¾èµ–é¡¹ï¼šopenjdk
==> æ­£åœ¨å®‰è£… hadoop ä¾èµ–é¡¹ï¼šopenjdk
==> æ­£åœ¨è§£å‹ openjdk-15.0.1.big_sur.bottle.tar.gz
==> æ³¨æ„äº‹é¡¹
ä¸ºäº†è®©ç³»ç»Ÿ Java åŒ…è£…å™¨æ‰¾åˆ°æ­¤ JDKï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åˆ›å»ºç¬¦å·é“¾æ¥ï¼š
  sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk
```

openjdk æ˜¯ keg-only çš„ï¼Œè¿™æ„å‘³ç€å®ƒæ²¡æœ‰è¢«ç¬¦å·é“¾æ¥åˆ° /usr/local ä¸­ï¼Œ
å› ä¸ºå®ƒä¼šé®è”½ macOS çš„ `java` åŒ…è£…å™¨ã€‚

å¦‚æœæ‚¨éœ€è¦å°† openjdk æ”¾åœ¨ PATH çš„é¦–ä½ï¼Œè¯·è¿è¡Œï¼š
  echo 'export PATH="/usr/local/opt/openjdk/bin:$PATH"' >> /Users/lzw/.bash_profile

ä¸ºäº†è®©ç¼–è¯‘å™¨æ‰¾åˆ° openjdkï¼Œæ‚¨å¯èƒ½éœ€è¦è®¾ç½®ï¼š
  export CPPFLAGS="-I/usr/local/opt/openjdk/include"

==> æ‘˜è¦
ğŸº  /usr/local/Cellar/openjdk/15.0.1: 614 ä¸ªæ–‡ä»¶ï¼Œ324.9MB
==> æ­£åœ¨å®‰è£… hadoop
ğŸº  /usr/local/Cellar/hadoop/3.3.0: 21,819 ä¸ªæ–‡ä»¶ï¼Œ954.7MBï¼Œæ„å»ºç”¨æ—¶ 2 åˆ†é’Ÿ 15 ç§’
==> å‡çº§ 1 ä¸ªä¾èµ–é¡¹ï¼š
maven 3.3.3 -> 3.6.3_1
==> æ­£åœ¨å‡çº§ maven 3.3.3 -> 3.6.3_1
==> æ­£åœ¨ä¸‹è½½ https://www.apache.org/dyn/closer.lua?path=maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
==> æ­£åœ¨ä» https://mirror.olnevhost.net/pub/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz ä¸‹è½½
######################################################################## 100.0%
é”™è¯¯ï¼š`brew link` æ­¥éª¤æœªæˆåŠŸå®Œæˆ
è¯¥å…¬å¼å·²æ„å»ºï¼Œä½†æœªç¬¦å·é“¾æ¥åˆ° /usr/local
æ— æ³•ç¬¦å·é“¾æ¥ bin/mvn
ç›®æ ‡ /usr/local/bin/mvn
æ˜¯å±äº maven çš„ç¬¦å·é“¾æ¥ã€‚æ‚¨å¯ä»¥å–æ¶ˆé“¾æ¥å®ƒï¼š
  brew unlink maven

è¦å¼ºåˆ¶é“¾æ¥å¹¶è¦†ç›–æ‰€æœ‰å†²çªçš„æ–‡ä»¶ï¼š
  brew link --overwrite maven

è¦åˆ—å‡ºæ‰€æœ‰å°†è¢«åˆ é™¤çš„æ–‡ä»¶ï¼š
  brew link --overwrite --dry-run maven

å¯èƒ½äº§ç”Ÿå†²çªçš„æ–‡ä»¶æœ‰ï¼š
/usr/local/bin/mvn -> /usr/local/Cellar/maven/3.3.3/bin/mvn
/usr/local/bin/mvnDebug -> /usr/local/Cellar/maven/3.3.3/bin/mvnDebug
/usr/local/bin/mvnyjp -> /usr/local/Cellar/maven/3.3.3/bin/mvnyjp
==> æ‘˜è¦
ğŸº  /usr/local/Cellar/maven/3.6.3_1: 87ä¸ªæ–‡ä»¶ï¼Œ10.7MBï¼Œ7ç§’å†…æ„å»ºå®Œæˆ
æ­£åœ¨ç§»é™¤ï¼š/usr/local/Cellar/maven/3.3.3...ï¼ˆ92ä¸ªæ–‡ä»¶ï¼Œ9MBï¼‰
==> æ£€æŸ¥å‡çº§å…¬å¼çš„ä¾èµ–é¡¹...
==> æœªå‘ç°æŸåçš„ä¾èµ–é¡¹ï¼
==> æ³¨æ„äº‹é¡¹
==> openjdk
ä¸ºäº†è®©ç³»ç»ŸJavaåŒ…è£…å™¨æ‰¾åˆ°è¿™ä¸ªJDKï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åˆ›å»ºç¬¦å·é“¾æ¥ï¼š
  sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk

openjdk æ˜¯ keg-only çš„ï¼Œè¿™æ„å‘³ç€å®ƒæ²¡æœ‰è¢«ç¬¦å·é“¾æ¥åˆ° /usr/local ä¸­ï¼Œ
å› ä¸ºå®ƒä¼šé®è”½ macOS çš„ `java` åŒ…è£…å™¨ã€‚

å¦‚æœæ‚¨éœ€è¦å°† openjdk ç½®äº PATH çš„é¦–ä½ï¼Œè¯·è¿è¡Œï¼š
  echo 'export PATH="/usr/local/opt/openjdk/bin:$PATH"' >> /Users/lzw/.bash_profile

ä¸ºäº†è®©ç¼–è¯‘å™¨æ‰¾åˆ°openjdkï¼Œæ‚¨å¯èƒ½éœ€è¦è®¾ç½®ï¼š
  export CPPFLAGS="-I/usr/local/opt/openjdk/include"
```

æ³¨æ„åˆ°`brew`çš„è¼¸å‡ºæ—¥èªŒä¸­`maven`æ²’æœ‰å¾ˆå¥½åœ°è¢«é€£çµã€‚æ¥ä¸‹ä¾†ï¼Œé€²è¡Œå¼·åˆ¶é€£çµåˆ°`3.6.3_1`ç‰ˆæœ¬ã€‚

```shell
  brew link --overwrite maven
```

ç¿»è­¯ç‚ºï¼š

```shell
  brew å¼·åˆ¶é€£çµä¸¦è¦†è“‹ maven
```

`Hadoop` å·²æˆåŠŸå®‰è£ã€‚

> ## æ¨¡å—
>
> è¯¥é¡¹ç›®åŒ…å«ä»¥ä¸‹æ¨¡å—ï¼š
>
> - **Hadoop Common**ï¼šæ”¯æŒå…¶ä»–Hadoopæ¨¡å—çš„é€šç”¨å·¥å…·é›†ã€‚
> - **Hadoopåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼ˆHDFSâ„¢ï¼‰**ï¼šä¸€ç§åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼Œä¸ºåº”ç”¨ç¨‹åºæ•°æ®æä¾›é«˜ååé‡çš„è®¿é—®ã€‚
> - **Hadoop YARN**ï¼šä¸€ä¸ªç”¨äºä½œä¸šè°ƒåº¦å’Œé›†ç¾¤èµ„æºç®¡ç†çš„æ¡†æ¶ã€‚
> - **Hadoop MapReduce**ï¼šåŸºäºYARNçš„ç³»ç»Ÿï¼Œç”¨äºå¤§è§„æ¨¡æ•°æ®é›†çš„å¹¶è¡Œå¤„ç†ã€‚
> - **Hadoop Ozone**ï¼šHadoopçš„å¯¹è±¡å­˜å‚¨ç³»ç»Ÿã€‚

è¯´æœ‰è¿™äº›æ¨¡å—ã€‚è¿™ä¼šæ•²å…¥`hadoop`å‡ºç°äº†ï¼š

```shell
$ hadoop
ç”¨æ³•ï¼šhadoop [é¸é …] å­å‘½ä»¤ [å­å‘½ä»¤é¸é …]
 æˆ–    hadoop [é¸é …] é¡å [é¡åé¸é …]
  å…¶ä¸­ï¼Œé¡åæ˜¯ç”¨æˆ¶æä¾›çš„Javaé¡
```

OPTIONS ç‚ºç©ºæˆ–åŒ…å«ä»¥ä¸‹ä»»æ„é¸é …ï¼š

--config dir                     Hadoop é…ç½®ç›®éŒ„
--debug                          é–‹å•Ÿ shell è…³æœ¬èª¿è©¦æ¨¡å¼
--help                           ä½¿ç”¨ä¿¡æ¯
buildpaths                       å˜—è©¦å¾æ§‹å»ºæ¨¹ä¸­æ·»åŠ é¡æ–‡ä»¶
hostnames list[,of,host,names]   åœ¨å¾å±¬æ¨¡å¼ä¸‹ä½¿ç”¨çš„ä¸»æ©Ÿååˆ—è¡¨
hosts filename                   åœ¨å¾å±¬æ¨¡å¼ä¸‹ä½¿ç”¨çš„ä¸»æ©Ÿåˆ—è¡¨æ–‡ä»¶
loglevel level                   è¨­ç½®æ­¤å‘½ä»¤çš„ log4j æ—¥èªŒç´šåˆ¥
workers                          é–‹å•Ÿå·¥ä½œæ¨¡å¼

 å­å‘½ä»¤æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š
    ç®¡ç†å‘½ä»¤ï¼š

daemonlog     è·å–/è®¾ç½®æ¯ä¸ªå®ˆæŠ¤è¿›ç¨‹çš„æ—¥å¿—çº§åˆ«

å®¢æˆ·ç«¯å‘½ä»¤ï¼š

archive       åˆ›å»ºHadoopå½’æ¡£æ–‡ä»¶
checknative   æ£€æŸ¥HadoopåŸç”Ÿåº“åŠå‹ç¼©åº“çš„å¯ç”¨æ€§
classpath     æ‰“å°è·å–Hadoop jaråŠæ‰€éœ€åº“çš„ç±»è·¯å¾„
conftest      éªŒè¯é…ç½®XMLæ–‡ä»¶
credential    ä¸å‡­è¯æä¾›è€…äº¤äº’
distch        åˆ†å¸ƒå¼å…ƒæ•°æ®æ›´æ”¹å™¨
distcp        é€’å½’å¤åˆ¶æ–‡ä»¶æˆ–ç›®å½•
dtutil        ä¸å§”æ‰˜ä»¤ç‰Œç›¸å…³çš„æ“ä½œ
envvars       æ˜¾ç¤ºè®¡ç®—å‡ºçš„Hadoopç¯å¢ƒå˜é‡
fs            è¿è¡Œé€šç”¨æ–‡ä»¶ç³»ç»Ÿç”¨æˆ·å®¢æˆ·ç«¯
gridmix       æäº¤æ··åˆçš„åˆæˆä½œä¸šï¼Œæ¨¡æ‹Ÿç”Ÿäº§è´Ÿè½½çš„é…ç½®æ–‡ä»¶
jar <jar>     è¿è¡Œjaræ–‡ä»¶ã€‚æ³¨æ„ï¼šè¯·ä½¿ç”¨"yarn jar"æ¥å¯åŠ¨YARNåº”ç”¨ç¨‹åºï¼Œè€Œéæ­¤å‘½ä»¤ã€‚
jnipath       æ‰“å°java.library.path
kdiag         è¯Šæ–­Kerberosé—®é¢˜
kerbname      æ˜¾ç¤ºauth_to_localä¸»ä½“è½¬æ¢
key           é€šè¿‡KeyProviderç®¡ç†å¯†é’¥
rumenfolder   ç¼©æ”¾rumenè¾“å…¥è·Ÿè¸ª
rumentrace    å°†æ—¥å¿—è½¬æ¢ä¸ºrumenè·Ÿè¸ª
s3guard       ç®¡ç†S3ä¸Šçš„å…ƒæ•°æ®
trace         æŸ¥çœ‹å’Œä¿®æ”¹Hadoopè·Ÿè¸ªè®¾ç½®
version       æ‰“å°ç‰ˆæœ¬ä¿¡æ¯

å®ˆæŠ¤è¿›ç¨‹å‘½ä»¤ï¼š

kms           è¿è¡ŒKMSï¼Œå³å¯†é’¥ç®¡ç†æœåŠ¡å™¨
registrydns   è¿è¡Œæ³¨å†Œè¡¨DNSæœåŠ¡å™¨

å­å‘½ä»¤åœ¨è°ƒç”¨æ—¶ä¸å¸¦å‚æ•°æˆ–ä½¿ç”¨`-h`æ—¶ï¼Œå¯èƒ½ä¼šæ‰“å°å¸®åŠ©ä¿¡æ¯ã€‚

å®˜ç½‘ä¸Šæä¾›äº†ä¸€äº›ç¤ºä¾‹ã€‚

```shell
  $ mkdir input
  $ cp etc/hadoop/*.xml input
  $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'
  $ cat output/*
```

æ³¨æ„åˆ°æœ‰`share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar`ã€‚é€™æ„å‘³è‘—å¯èƒ½æœ‰äº›æ¨£ä¾‹æ–‡ä»¶æˆ‘å€‘æ²’æœ‰å¾—åˆ°ã€‚çŒœæ¸¬ç”¨`Homebrew`å®‰è£æœƒæ²’æœ‰é€™äº›æ–‡ä»¶ã€‚æˆ‘å€‘å¾å®˜ç¶²ä¸‹è¼‰äº†å®‰è£æ–‡ä»¶åŒ…ã€‚

```shell
$ tree . -L 1
.
â”œâ”€â”€ LICENSE-binary
â”œâ”€â”€ LICENSE.txt
â”œâ”€â”€ NOTICE-binary
â”œâ”€â”€ NOTICE.txt
â”œâ”€â”€ README.txt
â”œâ”€â”€ bin
â”œâ”€â”€ etc
â”œâ”€â”€ include
â”œâ”€â”€ lib
â”œâ”€â”€ libexec
â”œâ”€â”€ licenses-binary
â”œâ”€â”€ sbin
â””â”€â”€ share
```

å‡ºç¾äº†`share`ç›®éŒ„ã€‚ç„¶è€Œ`Homebrew`çœŸçš„æ²’æœ‰é™„åŠ çš„é€™äº›æ–‡ä»¶å—ï¼Ÿæ‰¾åˆ°`Homebrew`å®‰è£çš„ç›®éŒ„ã€‚

```shell
$ type hadoop
hadoop æ˜¯ /usr/local/bin/hadoop
$ ls -alrt /usr/local/bin/hadoop
lrwxr-xr-x  1 lzw  admin  33 3æœˆ 11 00:48 /usr/local/bin/hadoop -> ../Cellar/hadoop/3.3.0/bin/hadoop
$ cd /usr/local/Cellar/hadoop/3.3.0
```

è¿™æ˜¯åœ¨`/usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop`ä¸‹æ‰“å°çš„ç›®å½•æ ‘

```shell
$ tree . -L 2
.
â”œâ”€â”€ client
â”‚   â”œâ”€â”€ hadoop-client-api-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-client-minicluster-3.3.0.jar
â”‚   â””â”€â”€ hadoop-client-runtime-3.3.0.jar
â”œâ”€â”€ common
â”‚   â”œâ”€â”€ hadoop-common-3.3.0-tests.jar
â”‚   â”œâ”€â”€ hadoop-common-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-kms-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-nfs-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-registry-3.3.0.jar
â”‚   â”œâ”€â”€ jdiff
â”‚   â”œâ”€â”€ lib
â”‚   â”œâ”€â”€ sources
â”‚   â””â”€â”€ webapps
â”œâ”€â”€ hdfs
â”‚   â”œâ”€â”€ hadoop-hdfs-3.3.0-tests.jar
â”‚   â”œâ”€â”€ hadoop-hdfs-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-hdfs-client-3.3.0-tests.jar
â”‚   â”œâ”€â”€ hadoop-hdfs-client-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-hdfs-httpfs-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-hdfs-native-client-3.3.0-tests.jar
â”‚   â”œâ”€â”€ hadoop-hdfs-native-client-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-hdfs-nfs-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-hdfs-rbf-3.3.0-tests.jar
â”‚   â”œâ”€â”€ hadoop-hdfs-rbf-3.3.0.jar
â”‚   â”œâ”€â”€ jdiff
â”‚   â”œâ”€â”€ lib
â”‚   â”œâ”€â”€ sources
â”‚   â””â”€â”€ webapps
â”œâ”€â”€ mapreduce
â”‚   â”œâ”€â”€ hadoop-mapreduce-client-app-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-mapreduce-client-common-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-mapreduce-client-core-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-mapreduce-client-hs-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-mapreduce-client-hs-plugins-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-mapreduce-client-jobclient-3.3.0-tests.jar
â”‚   â”œâ”€â”€ hadoop-mapreduce-client-jobclient-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-mapreduce-client-nativetask-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-mapreduce-client-shuffle-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-mapreduce-client-uploader-3.3.0.jar
â”‚   â”œâ”€â”€ hadoop-mapreduce-examples-3.3.0.jar
â”‚   â”œâ”€â”€ jdiff
â”‚   â”œâ”€â”€ lib-examples
â”‚   â””â”€â”€ sources
â”œâ”€â”€ tools
â”‚   â”œâ”€â”€ dynamometer
â”‚   â”œâ”€â”€ lib
â”‚   â”œâ”€â”€ resourceestimator
â”‚   â”œâ”€â”€ sls
â”‚   â””â”€â”€ sources
â””â”€â”€ yarn
    â”œâ”€â”€ csi
    â”œâ”€â”€ hadoop-yarn-api-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-catalog-webapp-3.3.0.war
    â”œâ”€â”€ hadoop-yarn-applications-distributedshell-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-mawo-core-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-client-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-common-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-registry-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-applicationhistoryservice-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-common-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-nodemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-resourcemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-router-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-sharedcachemanager-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-tests-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-timeline-pluginstorage-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-server-web-proxy-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-services-api-3.3.0.jar
    â”œâ”€â”€ hadoop-yarn-services-core-3.3.0.jar
    â”œâ”€â”€ lib
    â”œâ”€â”€ sources
    â”œâ”€â”€ test
    â”œâ”€â”€ timelineservice
    â”œâ”€â”€ webapps
    â””â”€â”€ yarn-service-examples
```

å¯ä»¥çœ‹åˆ°æœ‰å¾ˆå¤šçš„`jar`åŒ…ã€‚

```shell
$ mkdir input
$ ls
bin			hadoop-config.sh	hdfs-config.sh		libexec			sbin			yarn-config.sh
etc			hadoop-functions.sh	input			mapred-config.sh	share
$ cp etc/hadoop/*.xml input
$ cd input/
$ ls
capacity-scheduler.xml	hadoop-policy.xml	hdfs-site.xml		kms-acls.xml		mapred-site.xml
core-site.xml		hdfs-rbf-site.xml	httpfs-site.xml		kms-site.xml		yarn-site.xml
$ cd ..
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'
JAR æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯æ™®é€šæ–‡ä»¶: /usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar
$
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar grep input output 'dfs[a-z.]+'
2021-03-11 01:54:30,791 WARN util.NativeCodeLoader: æ— æ³•ä¸ºæ‚¨çš„å¹³å°åŠ è½½åŸç”Ÿ hadoop åº“... åœ¨é€‚ç”¨çš„æƒ…å†µä¸‹ä½¿ç”¨å†…ç½®çš„ Java ç±»
2021-03-11 01:54:31,115 INFO impl.MetricsConfig: ä» hadoop-metrics2.properties åŠ è½½å±æ€§
2021-03-11 01:54:31,232 INFO impl.MetricsSystemImpl: è®¡åˆ’æ¯ 10 ç§’è¿›è¡Œä¸€æ¬¡æŒ‡æ ‡å¿«ç…§ã€‚
...
```

æŒ‰ç…§å®˜ç½‘çš„ä¾‹å­æ“ä½œã€‚æ³¨æ„åˆ°`bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input`ï¼Œè¿™é‡Œçš„`jar`åŒ…å‰å¸¦æœ‰ç‰ˆæœ¬å·ã€‚å› æ­¤éœ€è¦å°†å…¶æ›¿æ¢ä¸ºæˆ‘ä»¬ä½¿ç”¨çš„`3.3.0`ç‰ˆæœ¬ã€‚

æ—¥å¿—çš„ç»“å°¾ï¼š

```shell
2021-03-11 01:54:35,374 INFO mapreduce.Job:  map 100% reduce 100%
2021-03-11 01:54:35,374 INFO mapreduce.Job: ä½œæ¥­ job_local2087514596_0002 æˆåŠŸå®Œæˆ
2021-03-11 01:54:35,377 INFO mapreduce.Job: è¨ˆæ•¸å™¨: 30
	æª”æ¡ˆç³»çµ±è¨ˆæ•¸å™¨
		FILE: è®€å–çš„å­—ç¯€æ•¸=1204316
		FILE: å¯«å…¥çš„å­—ç¯€æ•¸=3565480
		FILE: è®€å–æ“ä½œæ¬¡æ•¸=0
		FILE: å¤§å‹è®€å–æ“ä½œæ¬¡æ•¸=0
		FILE: å¯«å…¥æ“ä½œæ¬¡æ•¸=0
	Map-Reduce æ¡†æ¶
		Map è¼¸å…¥è¨˜éŒ„=1
		Map è¼¸å‡ºè¨˜éŒ„=1
		Map è¼¸å‡ºå­—ç¯€=17
		Map è¼¸å‡ºå¯¦é«”åŒ–å­—ç¯€=25
		è¼¸å…¥åˆ†å‰²å­—ç¯€=141
		åˆä½µè¼¸å…¥è¨˜éŒ„=0
		åˆä½µè¼¸å‡ºè¨˜éŒ„=0
		Reduce è¼¸å…¥çµ„=1
		Reduce æ··æ´—å­—ç¯€=25
		Reduce è¼¸å…¥è¨˜éŒ„=1
		Reduce è¼¸å‡ºè¨˜éŒ„=1
		æº¢å‡ºè¨˜éŒ„=2
		æ··æ´—çš„ Map æ•¸é‡=1
		å¤±æ•—çš„æ··æ´—=0
		åˆä½µçš„ Map è¼¸å‡º=1
		GC æ™‚é–“è€—æ™‚ (æ¯«ç§’)=57
		ç¸½æäº¤çš„å †ä½¿ç”¨é‡ (å­—ç¯€)=772800512
	æ··æ´—éŒ¯èª¤
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	æª”æ¡ˆè¼¸å…¥æ ¼å¼è¨ˆæ•¸å™¨
		è®€å–çš„å­—ç¯€=123
	æª”æ¡ˆè¼¸å‡ºæ ¼å¼è¨ˆæ•¸å™¨
		å¯«å…¥çš„å­—ç¯€=23
```

ç»§ç»­æŸ¥çœ‹ã€‚

```shell
$ cat output/*
1	dfsadmin
```

ç¿»è­¯æˆç¹é«”ä¸­æ–‡ç‚ºï¼š

```shell
$ cat output/*
1	dfsadmin
```

ï¼ˆæ³¨ï¼šæ­¤è™•çš„å…§å®¹æ˜¯å‘½ä»¤å’Œå…¶è¼¸å‡ºçµæœï¼Œå±¬æ–¼ä»£ç¢¼ç¯„ç–‡ï¼Œç„¡éœ€ç¿»è­¯ï¼Œä¿æŒåŸæ¨£å³å¯ã€‚ï¼‰

è¿™åˆ°åº•æ˜¯ä»€ä¹ˆæ„æ€å‘¢ï¼Ÿä¸è¦ç´§ï¼Œæ€»ä¹‹æˆ‘ä»¬æŠŠ`Hadoop`æˆåŠŸå¯åŠ¨äº†ï¼Œå¹¶ä¸”è¿è¡Œäº†ç¬¬ä¸€ä¸ªå•æœºç‰ˆçš„è®¡ç®—ç¤ºä¾‹ã€‚

## æ˜Ÿç«

å›åˆ° Spark ä¸Šã€‚æ¥çœ‹ä¸€ä¸ªä¾‹å­ã€‚

```python
text_file = sc.textFile("hdfs://...")
counts = text_file.flatMap(lambda line: line.split(" ")) \
             .map(lambda word: (word, 1)) \
             .reduceByKey(lambda a, b: a + b)
counts.saveAsTextFile("hdfs://...")
```

è¿™é‡Œå‡ºç°äº†`hdfs`æ–‡ä»¶ã€‚æŸ¥é˜…å¾Œï¼Œå¾—çŸ¥å¯ä»¥é€™æ¨£å‰µå»º`hdfs`æ–‡ä»¶ï¼š

```shell
hdfs dfs -mkdir /test
``` 

é€™è¡ŒæŒ‡ä»¤åœ¨Hadoopåˆ†å¸ƒå¼æ–‡ä»¶ç³»çµ±ï¼ˆHDFSï¼‰ä¸­å‰µå»ºä¸€å€‹åç‚º`/test`çš„ç›®éŒ„ã€‚ç¿»è­¯æˆç¹é«”ä¸­æ–‡ç‚ºï¼š

```shell
hdfs dfs -mkdir /æ¸¬è©¦
``` 

è«‹æ³¨æ„ï¼Œé›–ç„¶è·¯å¾‘åç¨±å¯ä»¥ç¿»è­¯ï¼Œä½†åœ¨å¯¦éš›æ“ä½œä¸­ï¼Œè·¯å¾‘åç¨±é€šå¸¸ä¿æŒè‹±æ–‡ä»¥é¿å…å…¼å®¹æ€§å•é¡Œã€‚å› æ­¤ï¼Œå³ä½¿ç¿»è­¯æˆâ€œ/æ¸¬è©¦â€ï¼Œåœ¨å¯¦éš›ä½¿ç”¨æ™‚ä»å»ºè­°ä½¿ç”¨â€œ/testâ€ã€‚

æ¥çœ‹çœ‹`hdfs`å‘½ä»¤ã€‚

```shell
$ hdfs
ç”¨æ³•ï¼šhdfs [é¸é …] å­å‘½ä»¤ [å­å‘½ä»¤é¸é …]
```

OPTIONS ç‚ºç©ºæˆ–åŒ…å«ä»¥ä¸‹ä»»æ„é¸é …ï¼š

--buildpaths                       å°è¯•ä»æ„å»ºæ ‘ä¸­æ·»åŠ ç±»æ–‡ä»¶
--config dir                       Hadoop é…ç½®ç›®å½•
--daemon (start|status|stop)       å¯¹å®ˆæŠ¤è¿›ç¨‹è¿›è¡Œæ“ä½œ
--debug                            å¼€å¯ shell è„šæœ¬è°ƒè¯•æ¨¡å¼
--help                             ä½¿ç”¨ä¿¡æ¯
--hostnames list[,of,host,names]   åœ¨ worker æ¨¡å¼ä¸‹ä½¿ç”¨çš„ä¸»æœºååˆ—è¡¨
--hosts filename                   åœ¨ worker æ¨¡å¼ä¸‹ä½¿ç”¨çš„ä¸»æœºåˆ—è¡¨æ–‡ä»¶
--loglevel level                   è®¾ç½®æ­¤å‘½ä»¤çš„ log4j æ—¥å¿—çº§åˆ«
--workers                          å¼€å¯ worker æ¨¡å¼

 å­å‘½ä»¤ï¼ˆSUBCOMMANDï¼‰æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š
    ç®¡ç†å‘˜å‘½ä»¤ï¼š

cacheadmin           é…ç½®HDFSç¼“å­˜
crypto               é…ç½®HDFSåŠ å¯†åŒºåŸŸ
debug                è¿è¡Œè°ƒè¯•ç®¡ç†å‘˜ä»¥æ‰§è¡ŒHDFSè°ƒè¯•å‘½ä»¤
dfsadmin             è¿è¡ŒDFSç®¡ç†å®¢æˆ·ç«¯
dfsrouteradmin       ç®¡ç†åŸºäºè·¯ç”±å™¨çš„è”é‚¦
ec                   è¿è¡ŒHDFSçº åˆ ç¼–ç å‘½ä»¤è¡Œç•Œé¢
fsck                 è¿è¡ŒDFSæ–‡ä»¶ç³»ç»Ÿæ£€æŸ¥å·¥å…·
haadmin              è¿è¡ŒDFSé«˜å¯ç”¨æ€§ç®¡ç†å®¢æˆ·ç«¯
jmxget               ä»NameNodeæˆ–DataNodeè·å–JMXå¯¼å‡ºå€¼
oev                  å°†ç¦»çº¿ç¼–è¾‘æŸ¥çœ‹å™¨åº”ç”¨äºç¼–è¾‘æ–‡ä»¶
oiv                  å°†ç¦»çº¿fsimageæŸ¥çœ‹å™¨åº”ç”¨äºfsimage
oiv_legacy           å°†ç¦»çº¿fsimageæŸ¥çœ‹å™¨åº”ç”¨äºæ—§ç‰ˆfsimage
storagepolicies      åˆ—å‡º/è·å–/è®¾ç½®/æ»¡è¶³å—å­˜å‚¨ç­–ç•¥

å®¢æˆ·ç«¯å‘½ä»¤ï¼š

classpath            æ‰“å°è·å–Hadoop jaråŠæ‰€éœ€åº“çš„ç±»è·¯å¾„
dfs                  åœ¨æ–‡ä»¶ç³»ç»Ÿä¸Šè¿è¡Œæ–‡ä»¶ç³»ç»Ÿå‘½ä»¤
envvars              æ˜¾ç¤ºè®¡ç®—å‡ºçš„Hadoopç¯å¢ƒå˜é‡
fetchdt              ä»NameNodeè·å–å§”æ‰˜ä»¤ç‰Œ
getconf              ä»é…ç½®ä¸­è·å–é…ç½®å€¼
groups               è·å–ç”¨æˆ·æ‰€å±çš„ç»„
lsSnapshottableDir   åˆ—å‡ºå½“å‰ç”¨æˆ·æ‹¥æœ‰çš„æ‰€æœ‰å¯å¿«ç…§ç›®å½•
snapshotDiff         æ¯”è¾ƒç›®å½•çš„ä¸¤ä¸ªå¿«ç…§æˆ–æ¯”è¾ƒå½“å‰ç›®å½•å†…å®¹ä¸å¿«ç…§
version              æ‰“å°ç‰ˆæœ¬ä¿¡æ¯

å®ˆæŠ¤è¿›ç¨‹å‘½ä»¤ï¼š

balancer             è¿è¡Œé›†ç¾¤å¹³è¡¡å·¥å…·
datanode             è¿è¡ŒDFSæ•°æ®èŠ‚ç‚¹
dfsrouter            è¿è¡ŒDFSè·¯ç”±å™¨
diskbalancer         åœ¨ç»™å®šèŠ‚ç‚¹ä¸Šçš„ç£ç›˜é—´å‡åŒ€åˆ†å¸ƒæ•°æ®
httpfs               è¿è¡ŒHttpFSæœåŠ¡å™¨ï¼Œå³HDFS HTTPç½‘å…³
journalnode          è¿è¡ŒDFSæ—¥å¿—èŠ‚ç‚¹
mover                è¿è¡Œå·¥å…·ä»¥è·¨å­˜å‚¨ç±»å‹ç§»åŠ¨å—å‰¯æœ¬
namenode             è¿è¡ŒDFSåç§°èŠ‚ç‚¹
nfs3                 è¿è¡ŒNFSç‰ˆæœ¬3ç½‘å…³
portmap              è¿è¡Œç«¯å£æ˜ å°„æœåŠ¡
secondarynamenode    è¿è¡ŒDFSè¾…åŠ©åç§°èŠ‚ç‚¹
sps                  è¿è¡Œå¤–éƒ¨å­˜å‚¨ç­–ç•¥æ»¡è¶³å™¨
zkfc                 è¿è¡ŒZKæ•…éšœè½¬ç§»æ§åˆ¶å™¨å®ˆæŠ¤è¿›ç¨‹

å­å‘½ä»¤åœ¨è°ƒç”¨æ—¶è‹¥ä¸å¸¦å‚æ•°æˆ–ä½¿ç”¨ -h å‚æ•°ï¼Œå¯èƒ½ä¼šæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ã€‚

ç»§ç»­ä¿®æ”¹ä»£ç ã€‚

```python
from pyspark.sql import SparkSession
```

spark = SparkSession.builder.master("local[*]")\
           .config('spark.driver.bindAddress', '127.0.0.1')\
           .getOrCreate()
sc = spark.sparkContext

ç¿»è¯‘ä¸ºï¼š

spark = SparkSession.builder.master("local[*]")\
           .config('spark.driver.bindAddress', '127.0.0.1')\
           .getOrCreate()
sc = spark.sparkContext

è¿™æ®µä»£ç åˆ›å»ºäº†ä¸€ä¸ªSparkä¼šè¯ï¼Œå¹¶è®¾ç½®äº†é©±åŠ¨ç¨‹åºçš„ç»‘å®šåœ°å€ä¸ºæœ¬åœ°å›ç¯åœ°å€ï¼ˆ127.0.0.1ï¼‰ï¼Œç„¶åè·å–æˆ–åˆ›å»ºäº†ä¸€ä¸ªSparkä¸Šä¸‹æ–‡ï¼ˆscï¼‰ã€‚åœ¨ä¸­æ–‡ç¯å¢ƒä¸­ï¼Œè¿™æ®µä»£ç çš„åŠŸèƒ½å’Œç»“æ„ä¿æŒä¸å˜ï¼Œå› æ­¤ç¿»è¯‘åçš„ä»£ç ä¸åŸæ–‡ç›¸åŒã€‚

```python
text_file = sc.textFile("a.txt")
counts = text_file.flatMap(lambda line: line.split(" ")) \
             .map(lambda word: (word, 1)) \
             .reduceByKey(lambda a, b: a + b)
counts.saveAsTextFile("b.txt")
```

æ³¨æ„åˆ°`.config('spark.driver.bindAddress', '127.0.0.1')`éå¸¸é‡è¦ã€‚å¦åˆ™ï¼Œå¯èƒ½ä¼šé‡åˆ°é”™è¯¯æç¤º`Service 'sparkDriver' could not bind on a random free port. You may check whether configuring an appropriate binding address`ã€‚

ç„¶è€Œï¼Œé€™æ™‚åˆå‡ºç¾äº†éŒ¯èª¤ã€‚

```shell
åŸå› ï¼šorg.apache.spark.api.python.PythonException: å›æº¯ï¼ˆæœ€è¿‘ä¸€æ¬¡è°ƒç”¨æœ€åï¼‰ï¼š
  æ–‡ä»¶ "/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py"ï¼Œç¬¬ 473 è¡Œï¼Œåœ¨ main å‡½æ•°ä¸­
    æŠ›å‡ºå¼‚å¸¸(("å·¥ä½œèŠ‚ç‚¹ä¸­çš„ Python ç‰ˆæœ¬ %s ä¸é©±åŠ¨ç¨‹åºä¸­çš„ç‰ˆæœ¬ä¸åŒ " +
å¼‚å¸¸ï¼šå·¥ä½œèŠ‚ç‚¹ä¸­çš„ Python ç‰ˆæœ¬ä¸º 3.8ï¼Œè€Œé©±åŠ¨ç¨‹åºä¸­çš„ç‰ˆæœ¬ä¸º 3.9ï¼ŒPySpark æ— æ³•åœ¨ä¸åŒçš„æ¬¡è¦ç‰ˆæœ¬ä¸‹è¿è¡Œã€‚è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ PYSPARK_PYTHON å’Œ PYSPARK_DRIVER_PYTHON æ˜¯å¦æ­£ç¡®è®¾ç½®ã€‚
```

è¡¨ç¤ºé‹è¡Œäº†ä¸åŒç‰ˆæœ¬çš„`Python`ã€‚

ä¿®æ”¹ `.bash_profile` æ–‡ä»¶é€šå¸¸æ˜¯ä¸ºäº†è‡ªå®šä¹‰ä½ çš„ shell ç¯å¢ƒï¼Œæ¯”å¦‚è®¾ç½®ç¯å¢ƒå˜é‡ã€åˆ«åã€è·¯å¾„ç­‰ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„ä¿®æ”¹æ­¥éª¤ï¼š

### 1. æ‰“å¼€ `.bash_profile` æ–‡ä»¶
ä½ å¯ä»¥ä½¿ç”¨ä»»ä½•æ–‡æœ¬ç¼–è¾‘å™¨æ¥æ‰“å¼€ `.bash_profile` æ–‡ä»¶ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ `nano` ç¼–è¾‘å™¨ï¼š

```bash
nano ~/.bash_profile
```

### 2. æ·»åŠ æˆ–ä¿®æ”¹å†…å®¹
åœ¨ `.bash_profile` æ–‡ä»¶ä¸­ï¼Œä½ å¯ä»¥æ·»åŠ æˆ–ä¿®æ”¹ä»¥ä¸‹å†…å®¹ï¼š

#### è®¾ç½®ç¯å¢ƒå˜é‡
```bash
export PATH="$HOME/bin:$PATH"
export JAVA_HOME="/usr/lib/jvm/java-11-openjdk"
```

#### è®¾ç½®åˆ«å
```bash
alias ll='ls -la'
alias gs='git status'
```

#### è®¾ç½®æç¤ºç¬¦ (PS1)
```bash
export PS1="\u@\h:\w\$ "
```

#### åŠ è½½å…¶ä»–é…ç½®æ–‡ä»¶
```bash
if [ -f ~/.bashrc ]; then
    . ~/.bashrc
fi
```

### 3. ä¿å­˜å¹¶é€€å‡º
åœ¨ `nano` ç¼–è¾‘å™¨ä¸­ï¼ŒæŒ‰ `Ctrl + X` é€€å‡ºï¼Œç„¶åæŒ‰ `Y` ç¡®è®¤ä¿å­˜ï¼Œæœ€åæŒ‰ `Enter` ç¡®è®¤æ–‡ä»¶åã€‚

### 4. ä½¿æ›´æ”¹ç”Ÿæ•ˆ
ä¸ºäº†ä½¿æ›´æ”¹ç«‹å³ç”Ÿæ•ˆï¼Œä½ å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
source ~/.bash_profile
```

æˆ–è€…ä½ ä¹Ÿå¯ä»¥é‡æ–°å¯åŠ¨ç»ˆç«¯ã€‚

### 5. æ£€æŸ¥æ›´æ”¹
ä½ å¯ä»¥é€šè¿‡è¿è¡Œ `echo $PATH` æˆ– `alias` ç­‰å‘½ä»¤æ¥æ£€æŸ¥ä½ çš„æ›´æ”¹æ˜¯å¦ç”Ÿæ•ˆã€‚

### æ³¨æ„äº‹é¡¹
- å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ `zsh`ï¼Œä½ å¯èƒ½éœ€è¦ä¿®æ”¹ `.zshrc` æˆ– `.zprofile` æ–‡ä»¶ã€‚
- å¦‚æœä½ ä¸ç¡®å®šæŸä¸ªè®¾ç½®çš„ä½œç”¨ï¼Œå»ºè®®å…ˆå¤‡ä»½ `.bash_profile` æ–‡ä»¶ã€‚

```bash
cp ~/.bash_profile ~/.bash_profile.bak
```

è¿™æ ·ï¼Œå³ä½¿ä¿®æ”¹å‡ºé”™ï¼Œä½ ä¹Ÿå¯ä»¥æ¢å¤åˆ°ä¹‹å‰çš„çŠ¶æ€ã€‚

```shell
PYSPARK_PYTHON=/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
PYSPARK_DRIVER_PYTHON=/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
```

ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼š

```shell
PYSPARK_PYTHON=/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
PYSPARK_DRIVER_PYTHON=/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
```

é€™æ®µä»£ç¢¼æ˜¯è¨­ç½®ç’°å¢ƒè®Šé‡ï¼ŒæŒ‡å®š PySpark ä½¿ç”¨çš„ Python è§£é‡‹å™¨è·¯å¾‘ã€‚åœ¨ç¹é«”ä¸­æ–‡ç’°å¢ƒä¸‹ï¼Œé€™æ®µä»£ç¢¼ä¿æŒä¸è®Šï¼Œå› ç‚ºå®ƒä¸»è¦æ˜¯è·¯å¾‘å’Œè®Šé‡åç¨±ï¼Œä¸éœ€è¦ç¿»è­¯ã€‚

ç„¶è€Œè¿˜æ˜¯æŠ¥åŒæ ·çš„é”™ã€‚äº†è§£ä¸€ç•ªåï¼Œå¯èƒ½æ˜¯å› ä¸º`spark`è¿è¡Œçš„æ—¶å€™ï¼Œæ²¡æœ‰è½½å…¥è¿™ä¸ªç¯å¢ƒå˜é‡ï¼Œæ²¡æœ‰ä½¿ç”¨ç»ˆç«¯é»˜è®¤çš„ç¯å¢ƒå˜é‡ã€‚

éœ€è¦åœ¨ä»£ç ä¸­è®¾ç½®ï¼š

```python
import os
```

# è®¾ç½® Spark ç¯å¢ƒ
os.environ['PYSPARK_PYTHON'] = '/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'
os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'
```

é€™æœƒé‹è¡Œã€‚

```shell
$ python sc.py
21/03/11 02:54:52 è­¦å‘Š NativeCodeLoader: ç„¡æ³•ç‚ºæ‚¨çš„å¹³å°åŠ è¼‰åŸç”ŸHadoopåº«...åœ¨é©ç”¨çš„åœ°æ–¹ä½¿ç”¨å…§å»ºçš„Javaé¡
ä½¿ç”¨Sparkçš„é»˜èªlog4jé…ç½®æ–‡ä»¶ï¼šorg/apache/spark/log4j-defaults.properties
å°‡é»˜èªæ—¥èªŒç´šåˆ¥è¨­ç½®ç‚ºâ€œWARNâ€ã€‚
è¦èª¿æ•´æ—¥èªŒç´šåˆ¥ï¼Œè«‹ä½¿ç”¨sc.setLogLevel(newLevel)ã€‚å°æ–¼SparkRï¼Œè«‹ä½¿ç”¨setLogLevel(newLevel)ã€‚
PythonRDD[6] ä½æ–¼ PythonRDD.scala:53 çš„ RDD
```

é€™æ™‚ç”Ÿæˆäº†`b.txt`ã€‚

```shell
â”œâ”€â”€ b.txt
â”‚   â”œâ”€â”€ _SUCCESS
â”‚   â”œâ”€â”€ part-00000
â”‚   â””â”€â”€ part-00001
```

æ‰“é–‹ä¸€ä¸‹ã€‚

```shell
$ cat b.txt/part-00000
('college', 1)
('two', 1)
('things', 2)
('worked', 1)
('on,', 1)
('of', 8)
('school,', 2)
('writing', 2)
('programming.', 1)
("didn't", 4)
('then,', 1)
('probably', 1)
('are:', 1)
('short', 1)
('awful.', 1)
('They', 1)
('plot,', 1)
('just', 1)
('characters', 1)
('them', 2)
...
```

æˆåŠŸäº†ï¼è¿™åœºæ™¯æ˜¯ä¸æ˜¯å¾ˆç†Ÿæ‚‰ï¼Ÿå°±åƒåœ¨`Hadoop`ç¤ºä¾‹ä¸­ä¸€æ ·ã€‚

```shell
$ cat output/*
1	dfsç®¡ç†å“¡
```

é€™äº›æ–‡ä»¶å°±å«åš`HDFS`ã€‚å¯è¦‹é€™è£¡ä½¿ç”¨`Spark`ä¾†çµ±è¨ˆå–®è©ã€‚çŸ­çŸ­å¹¾å¥ï¼Œæ“ä½œèµ·ä¾†éå¸¸æ–¹ä¾¿çš„æ¨£å­ã€‚

## Kubernetes

æ¥ä¸‹æ¥æˆ‘ä»¬æ¥æ¢è®¨ä¸€ä¸‹`Kubernetes`ï¼Œä¹Ÿè¢«ç§°ä¸º`k8s`ï¼Œå…¶ä¸­é—´çš„8ä¸ªå­—æ¯è¢«ç®€åŒ–ä¸º8ã€‚è¿™æ˜¯ä¸€å¥—å¼€æºç³»ç»Ÿï¼Œç”¨äºè‡ªåŠ¨åŒ–éƒ¨ç½²ã€æ‰©å±•å’Œç®¡ç†å®¹å™¨åŒ–åº”ç”¨ç¨‹åºã€‚

`kubectl` å‘½ä»¤è¡Œå·¥å…·æ˜¯ç”¨ä¾†åŸ·è¡Œä¸€äº›æ“ä½œ Kubernetes (k8s) é›†ç¾¤çš„å‘½ä»¤ã€‚å¯ä»¥ç”¨å®ƒä¾†éƒ¨ç½²æ‡‰ç”¨ç¨‹å¼ã€æŸ¥çœ‹å’Œç®¡ç†é›†ç¾¤è³‡æºï¼Œä»¥åŠæŸ¥çœ‹æ—¥èªŒã€‚

åŒæ ·å¯ä»¥ä½¿ç”¨Homebrewæ¥å®‰è£…ã€‚

```shell
brew install kubectl
``` 

ç¿»è­¯æˆç¹é«”ä¸­æ–‡ç‚ºï¼š

```shell
ä½¿ç”¨ brew å®‰è£ kubectl
``` 

é€™è£¡çš„ `brew` æ˜¯ macOS ä¸Šçš„ä¸€å€‹å¥—ä»¶ç®¡ç†å·¥å…·ï¼Œ`kubectl` æ˜¯ç”¨ä¾†èˆ‡ Kubernetes å¢é›†é€²è¡Œäº’å‹•çš„å‘½ä»¤åˆ—å·¥å…·ã€‚

è¼¸å‡ºæ—¥èªŒï¼š

```shell
==> æ­£åœ¨ä¸‹è¼‰ https://homebrew.bintray.com/bottles/kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
==> å¾ https://d29vzk4ow07wi7.cloudfront.net/0b4f08bd1d47cb913d7cd4571e3394c6747dfbad7ff114c5589c8396c1085ecf?response-content-disposition=a ä¸‹è¼‰
######################################################################## 100.0%
==> æ­£åœ¨è§£å£“ kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
==> æ³¨æ„äº‹é …
Bash è‡ªå‹•è£œå…¨åŠŸèƒ½å·²å®‰è£è‡³ï¼š
  /usr/local/etc/bash_completion.d
==> ç¸½çµ
ğŸº  /usr/local/Cellar/kubernetes-cli/1.20.1: 246 å€‹æ–‡ä»¶ï¼Œå…± 46.1MB
```

è£å¥½äº†ã€‚

```shell
$ kubectl version --client
å®¢æˆ¶ç«¯ç‰ˆæœ¬ï¼šversion.Info{Major:"1", Minor:"20", GitVersion:"v1.20.1", GitCommit:"c4d752765b3bbac2237bf87cf0b1c2e307844666", GitTreeState:"clean", BuildDate:"2020-12-19T08:38:20Z", GoVersion:"go1.15.5", Compiler:"gc", Platform:"darwin/amd64"}
```

```shell
$ kubectl
kubectl æ§åˆ¶ Kubernetes é›†ç¾¤ç®¡ç†å™¨ã€‚
```

æ¬²äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—®ï¼šhttps://kubernetes.io/docs/reference/kubectl/overview/

åŸºæœ¬å‘½ä»¤ï¼ˆåˆå­¦è€…ï¼‰ï¼š
  create        ä»æ–‡ä»¶æˆ–æ ‡å‡†è¾“å…¥åˆ›å»ºèµ„æºã€‚
  expose        å°†å¤åˆ¶æ§åˆ¶å™¨ã€æœåŠ¡ã€éƒ¨ç½²æˆ–Podæš´éœ²ä¸ºæ–°çš„KubernetesæœåŠ¡ã€‚
  run           åœ¨é›†ç¾¤ä¸Šè¿è¡Œç‰¹å®šçš„é•œåƒã€‚
  set           è®¾ç½®å¯¹è±¡ä¸Šçš„ç‰¹å®šåŠŸèƒ½ã€‚

åŸºæœ¬å‘½ä»¤ï¼ˆä¸­çº§ï¼‰ï¼š
  explain       æŸ¥çœ‹èµ„æºçš„æ–‡æ¡£è¯´æ˜
  get           æ˜¾ç¤ºä¸€ä¸ªæˆ–å¤šä¸ªèµ„æº
  edit          åœ¨æœåŠ¡å™¨ä¸Šç¼–è¾‘èµ„æº
  delete        é€šè¿‡æ–‡ä»¶åã€æ ‡å‡†è¾“å…¥ã€èµ„æºåŠåç§°ï¼Œæˆ–èµ„æºåŠæ ‡ç­¾é€‰æ‹©å™¨åˆ é™¤èµ„æº

éƒ¨ç½²å‘½ä»¤ï¼š
  rollout       ç®¡ç†èµ„æºçš„éƒ¨ç½²è¿‡ç¨‹
  scale         ä¸º Deploymentã€ReplicaSet æˆ– Replication Controller è®¾ç½®æ–°çš„è§„æ¨¡
  autoscale     è‡ªåŠ¨è°ƒæ•´ Deploymentã€ReplicaSet æˆ– ReplicationController çš„è§„æ¨¡

é›†ç¾¤ç®¡ç†å‘½ä»¤ï¼š
  certificate   ä¿®æ”¹è¯ä¹¦èµ„æºã€‚
  cluster-info  æ˜¾ç¤ºé›†ç¾¤ä¿¡æ¯ã€‚
  top           æ˜¾ç¤ºèµ„æºï¼ˆCPU/å†…å­˜/å­˜å‚¨ï¼‰ä½¿ç”¨æƒ…å†µã€‚
  cordon        å°†èŠ‚ç‚¹æ ‡è®°ä¸ºä¸å¯è°ƒåº¦ã€‚
  uncordon      å°†èŠ‚ç‚¹æ ‡è®°ä¸ºå¯è°ƒåº¦ã€‚
  drain         æ’ç©ºèŠ‚ç‚¹ä»¥å‡†å¤‡ç»´æŠ¤ã€‚
  taint         æ›´æ–°ä¸€ä¸ªæˆ–å¤šä¸ªèŠ‚ç‚¹çš„æ±¡ç‚¹ã€‚

æ•…éšœæ’æŸ¥ä¸è°ƒè¯•å‘½ä»¤ï¼š
  describe      æ˜¾ç¤ºç‰¹å®šèµ„æºæˆ–èµ„æºç»„çš„è¯¦ç»†ä¿¡æ¯
  logs          æ‰“å° Pod ä¸­å®¹å™¨çš„æ—¥å¿—
  attach        è¿æ¥åˆ°æ­£åœ¨è¿è¡Œçš„å®¹å™¨
  exec          åœ¨å®¹å™¨å†…æ‰§è¡Œå‘½ä»¤
  port-forward  å°†ä¸€ä¸ªæˆ–å¤šä¸ªæœ¬åœ°ç«¯å£è½¬å‘åˆ° Pod
  proxy         è¿è¡Œä¸€ä¸ªæŒ‡å‘ Kubernetes API æœåŠ¡å™¨çš„ä»£ç†
  cp            åœ¨å®¹å™¨ä¹‹é—´å¤åˆ¶æ–‡ä»¶å’Œç›®å½•
  auth          æ£€æŸ¥æˆæƒä¿¡æ¯
  debug         ä¸ºå·¥ä½œè´Ÿè½½å’ŒèŠ‚ç‚¹åˆ›å»ºè°ƒè¯•ä¼šè¯ä»¥è¿›è¡Œæ•…éšœæ’æŸ¥

é«˜çº§å‘½ä»¤ï¼š
  diff          å¯¹æ¯”å½“å‰ç‰ˆæœ¬ä¸å³å°†åº”ç”¨çš„ç‰ˆæœ¬
  apply         é€šè¿‡æ–‡ä»¶åæˆ–æ ‡å‡†è¾“å…¥å°†é…ç½®åº”ç”¨åˆ°èµ„æº
  patch         æ›´æ–°èµ„æºçš„å­—æ®µ
  replace       é€šè¿‡æ–‡ä»¶åæˆ–æ ‡å‡†è¾“å…¥æ›¿æ¢èµ„æº
  wait          å®éªŒæ€§åŠŸèƒ½ï¼šç­‰å¾…ä¸€ä¸ªæˆ–å¤šä¸ªèµ„æºè¾¾åˆ°ç‰¹å®šæ¡ä»¶
  kustomize     ä»ç›®å½•æˆ–è¿œç¨‹URLæ„å»ºkustomizationç›®æ ‡

è®¾ç½®å‘½ä»¤ï¼š
  label         æ›´æ–°èµ„æºçš„æ ‡ç­¾
  annotate      æ›´æ–°èµ„æºçš„æ³¨è§£
  completion    è¾“å‡ºæŒ‡å®š shellï¼ˆbash æˆ– zshï¼‰çš„ shell è¡¥å…¨ä»£ç 

å…¶ä»–å‘½ä»¤ï¼š
  api-resources æ‰“å°æœåŠ¡å™¨ä¸Šæ”¯æŒçš„APIèµ„æº
  api-versions  æ‰“å°æœåŠ¡å™¨ä¸Šæ”¯æŒçš„APIç‰ˆæœ¬ï¼Œæ ¼å¼ä¸ºâ€œç»„/ç‰ˆæœ¬â€
  config        ä¿®æ”¹kubeconfigæ–‡ä»¶
  plugin        æä¾›ä¸æ’ä»¶äº¤äº’çš„å®ç”¨å·¥å…·
  version       æ‰“å°å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨çš„ç‰ˆæœ¬ä¿¡æ¯

ç”¨æ³•ï¼š
  kubectl [æ ‡å¿—] [é€‰é¡¹]

ä½¿ç”¨ "kubectl <å‘½ä»¤> --help" è·å–æœ‰å…³ç‰¹å®šå‘½ä»¤çš„æ›´å¤šä¿¡æ¯ã€‚
ä½¿ç”¨ "kubectl options" æŸ¥çœ‹å…¨å±€å‘½ä»¤è¡Œé€‰é¡¹åˆ—è¡¨ï¼ˆé€‚ç”¨äºæ‰€æœ‰å‘½ä»¤ï¼‰ã€‚
```

ä¾†å‰µå»ºä¸€å€‹é…ç½®æ–‡ä»¶ã€‚

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  minReadySeconds: 5
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

```
```

```shell
$ kubectl apply -f simple_deployment.yaml
é€£æ¥åˆ°ä¼ºæœå™¨ localhost:8080 è¢«æ‹’çµ• - æ‚¨æ˜¯å¦æŒ‡å®šäº†æ­£ç¢ºçš„ä¸»æ©Ÿæˆ–ç«¯å£ï¼Ÿ
```

```shell
$ kubectl é›†ç¾¤ä¿¡æ¯
```

è¦è¿›ä¸€æ­¥è°ƒè¯•å’Œè¯Šæ–­é›†ç¾¤é—®é¢˜ï¼Œè¯·ä½¿ç”¨ 'kubectl cluster-info dump'ã€‚
è¿æ¥æœåŠ¡å™¨ localhost:8080 è¢«æ‹’ç»â€”â€”æ‚¨æ˜¯å¦æŒ‡å®šäº†æ­£ç¡®çš„ä¸»æœºæˆ–ç«¯å£ï¼Ÿ
```

ç•¶ç”¨å®˜ç¶²çš„çµ‚ç«¯è©¦è‘—é‹è¡Œä¸‹ã€‚

```shell
$ start.sh
æ­£åœ¨å¯åŠ¨ Kubernetes...minikube ç‰ˆæœ¬ï¼šv1.8.1
æäº¤ï¼šcbda04cf6bbe65e987ae52bb393c10099ab62014
* minikube v1.8.1 è¿è¡Œäº Ubuntu 18.04
* æ ¹æ®ç”¨æˆ·é…ç½®ä½¿ç”¨ none é©±åŠ¨
* åœ¨ localhost ä¸Šè¿è¡Œï¼ˆCPU=2ï¼Œå†…å­˜=2460MBï¼Œç£ç›˜=145651MBï¼‰...
* æ“ä½œç³»ç»Ÿç‰ˆæœ¬ä¸º Ubuntu 18.04.4 LTS
```

* æ­£åœ¨Docker 19.03.6ä¸Šå‡†å¤‡Kubernetes v1.17.3...
  - kubelet.resolv-conf=/run/systemd/resolve/resolv.conf
* å¯åŠ¨Kubernetesä¸­...
* å¯ç”¨é™„åŠ ç»„ä»¶ï¼šdefault-storageclass, storage-provisioner
* é…ç½®æœ¬åœ°ä¸»æœºç¯å¢ƒ...
* å®Œæˆï¼kubectlç°å·²é…ç½®ä¸ºä½¿ç”¨"minikube"
* 'dashboard'é™„åŠ ç»„ä»¶å·²å¯ç”¨
Kuberneteså·²å¯åŠ¨
```

ç»§ç»­å›åˆ°æˆ‘ä»¬çš„ç»ˆç«¯ã€‚

```shell
$ kubectl version --client
å®¢æˆ¶ç«¯ç‰ˆæœ¬ï¼šversion.Info{Major:"1", Minor:"20", GitVersion:"v1.20.1", GitCommit:"c4d752765b3bbac2237bf87cf0b1c2e307844666", GitTreeState:"clean", BuildDate:"2020-12-19T08:38:20Z", GoVersion:"go1.15.5", Compiler:"gc", Platform:"darwin/amd64"}
$ kubectl version
å®¢æˆ¶ç«¯ç‰ˆæœ¬ï¼šversion.Info{Major:"1", Minor:"20", GitVersion:"v1.20.1", GitCommit:"c4d752765b3bbac2237bf87cf0b1c2e307844666", GitTreeState:"clean", BuildDate:"2020-12-19T08:38:20Z", GoVersion:"go1.15.5", Compiler:"gc", Platform:"darwin/amd64"}
é€£æ¥åˆ°ä¼ºæœå™¨ localhost:8080 è¢«æ‹’çµ• - æ‚¨æ˜¯å¦æŒ‡å®šäº†æ­£ç¢ºçš„ä¸»æ©Ÿæˆ–ç«¯å£ï¼Ÿ
```

æœ‰è¶£çš„æ˜¯ï¼ŒåŠ ä¸Š `--client` é€‰é¡¹å¹¶æ²¡æœ‰å¼•å‘é”™è¯¯ã€‚

æ–‡æ¡£æŒ‡å‡ºï¼Œéœ€è¦å…ˆå®‰è£…`Minikube`ã€‚

```shell
$ brew install minikube
==> æ­£åœ¨ä¸‹è¼‰ https://homebrew.bintray.com/bottles/minikube-1.16.0.big_sur.bottle.tar.gz
==> å¾ https://d29vzk4ow07wi7.cloudfront.net/1b6d7d1b97b11b6b07e4fa531c2dc21770da290da9b2816f360fd923e00c85fc?response-content-disposition=a ä¸‹è¼‰
######################################################################## 100.0%
==> æ­£åœ¨è§£å£“ minikube-1.16.0.big_sur.bottle.tar.gz
==> æ³¨æ„äº‹é …
Bash è‡ªå‹•è£œå…¨åŠŸèƒ½å·²å®‰è£è‡³ï¼š
  /usr/local/etc/bash_completion.d
==> ç¸½çµ
ğŸº  /usr/local/Cellar/minikube/1.16.0: 8 å€‹æ–‡ä»¶ï¼Œå…± 64.6MB
```

```shell
$ minikube start
ğŸ˜„  minikube v1.16.0 åœ¨ Darwin 11.2.2 ä¸Šè¿è¡Œ
ğŸ‰  minikube 1.18.1 å·²å‘å¸ƒï¼ä¸‹è½½åœ°å€ï¼šhttps://github.com/kubernetes/minikube/releases/tag/v1.18.1
ğŸ’¡  è¦ç¦ç”¨æ­¤é€šçŸ¥ï¼Œè¯·è¿è¡Œï¼š'minikube config set WantUpdateNotification false'
```

âœ¨ è‡ªå‹•é¸æ“‡äº† virtualbox é©…å‹•ç¨‹åº
ğŸ’¿ æ­£åœ¨ä¸‹è¼‰è™›æ“¬æ©Ÿå•Ÿå‹•é¡åƒ...
    > minikube-v1.16.0.iso.sha256: 65 B / 65 B [-------------] 100.00% ? p/s 0s
    > minikube-v1.16.0.iso: 212.62 MiB / 212.62 MiB [] 100.00% 5.32 MiB p/s 40s
ğŸ‘ æ­£åœ¨é›†ç¾¤ minikube ä¸­å•Ÿå‹•æ§åˆ¶å¹³é¢ç¯€é» minikube
ğŸ’¾ æ­£åœ¨ä¸‹è¼‰ Kubernetes v1.20.0 é åŠ è¼‰...
    > preloaded-images-k8s-v8-v1....: 491.00 MiB / 491.00 MiB  100.00% 7.52 MiB
ğŸ”¥ æ­£åœ¨å‰µå»º virtualbox è™›æ“¬æ©Ÿï¼ˆCPU=2ï¼Œå…§å­˜=4000MBï¼Œç£ç›¤=20000MBï¼‰...
â— æ­¤è™›æ“¬æ©Ÿåœ¨è¨ªå• https://k8s.gcr.io æ™‚é‡åˆ°å•é¡Œ
ğŸ’¡ è¦æ‹‰å–æ–°çš„å¤–éƒ¨é¡åƒï¼Œæ‚¨å¯èƒ½éœ€è¦é…ç½®ä»£ç†ï¼šhttps://minikube.sigs.k8s.io/docs/reference/networking/proxy/
ğŸ³ æ­£åœ¨ Docker 20.10.0 ä¸Šæº–å‚™ Kubernetes v1.20.0 ...
    â–ª ç”Ÿæˆè­‰æ›¸å’Œå¯†é‘°...
    â–ª å•Ÿå‹•æ§åˆ¶å¹³é¢...
    â–ª é…ç½® RBAC è¦å‰‡...
ğŸ” æ­£åœ¨é©—è­‰ Kubernetes çµ„ä»¶...
ğŸŒŸ å·²å•Ÿç”¨æ’ä»¶ï¼šstorage-provisioner, default-storageclass
ğŸ„ å®Œæˆï¼kubectl ç¾åœ¨å·²é…ç½®ç‚ºé»˜èªä½¿ç”¨ "minikube" é›†ç¾¤å’Œ "default" å‘½åç©ºé–“
```

æ¥è‘—ä¾†è¨ªå•é€™å€‹é›†ç¾¤ã€‚

```shell
$ kubectl get po -A
å‘½åç©ºé–“      åç¨±                                å°±ç·’   ç‹€æ…‹     é‡å•Ÿæ¬¡æ•¸  å¹´é½¡
kube-system   coredns-74ff55c5b-ndbcr            1/1    é‹è¡Œä¸­    0          60ç§’
kube-system   etcd-minikube                      0/1    é‹è¡Œä¸­    0          74ç§’
kube-system   kube-apiserver-minikube            1/1    é‹è¡Œä¸­    0          74ç§’
kube-system   kube-controller-manager-minikube   1/1    é‹è¡Œä¸­    0          74ç§’
kube-system   kube-proxy-g2296                   1/1    é‹è¡Œä¸­    0          60ç§’
kube-system   kube-scheduler-minikube            0/1    é‹è¡Œä¸­    0          74ç§’
kube-system   storage-provisioner                1/1    é‹è¡Œä¸­    1          74ç§’
```

ä¾†æ‰“é–‹`minikube`çš„æ§åˆ¶é¢æ¿ã€‚

```shell
$ minikube dashboard
ğŸ”Œ  æ­£åœ¨å•Ÿç”¨å„€è¡¨æ¿ ...
ğŸ¤”  æ­£åœ¨é©—è­‰å„€è¡¨æ¿å¥åº·ç‹€æ…‹ ...
ğŸš€  æ­£åœ¨å•Ÿå‹•ä»£ç† ...
ğŸ¤”  æ­£åœ¨é©—è­‰ä»£ç†å¥åº·ç‹€æ…‹ ...
ğŸ‰  æ­£åœ¨æ‚¨çš„é è¨­ç€è¦½å™¨ä¸­é–‹å•Ÿ http://127.0.0.1:50030/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ ...
```

![k8s](assets/images/distributed/k8s.png)

å¦‚ä½•é—œæ‰å‘¢ã€‚

```shell
$ minikube
minikube æä¾›ä¸¦ç®¡ç†å°ˆç‚ºé–‹ç™¼å·¥ä½œæµç¨‹å„ªåŒ–çš„æœ¬åœ° Kubernetes é›†ç¾¤ã€‚
```

åŸºæœ¬å‘½ä»¤ï¼š
  start          å¯åŠ¨æœ¬åœ° Kubernetes é›†ç¾¤
  status         è·å–æœ¬åœ° Kubernetes é›†ç¾¤çš„çŠ¶æ€
  stop           åœæ­¢æ­£åœ¨è¿è¡Œçš„æœ¬åœ° Kubernetes é›†ç¾¤
  delete         åˆ é™¤æœ¬åœ° Kubernetes é›†ç¾¤
  dashboard      è®¿é—®åœ¨ minikube é›†ç¾¤å†…è¿è¡Œçš„ Kubernetes ä»ªè¡¨æ¿
  pause          æš‚åœ Kubernetes
  unpause        æ¢å¤å·²æš‚åœçš„ Kubernetes

é•œåƒå‘½ä»¤ï¼š
  docker-env     é…ç½®ç¯å¢ƒä»¥ä½¿ç”¨ minikube çš„ Docker å®ˆæŠ¤è¿›ç¨‹
  podman-env     é…ç½®ç¯å¢ƒä»¥ä½¿ç”¨ minikube çš„ Podman æœåŠ¡
  cache          æ·»åŠ ã€åˆ é™¤æˆ–å°†æœ¬åœ°é•œåƒæ¨é€åˆ° minikube

é…ç½®ä¸ç®¡ç†å‘½ä»¤ï¼š
  addons         å¯ç”¨æˆ–ç¦ç”¨ minikube çš„é™„åŠ ç»„ä»¶
  config         ä¿®æ”¹æŒä¹…åŒ–çš„é…ç½®å€¼
  profile        è·å–æˆ–åˆ—å‡ºå½“å‰é…ç½®ï¼ˆé›†ç¾¤ï¼‰
  update-context åœ¨ IP æˆ–ç«¯å£å˜æ›´æ—¶æ›´æ–° kubeconfig

ç½‘ç»œä¸è¿æ¥å‘½ä»¤ï¼š
  service        è¿”å›ç”¨äºè¿æ¥æœåŠ¡çš„URL
  tunnel         è¿æ¥åˆ°LoadBalanceræœåŠ¡

é«˜çº§å‘½ä»¤ï¼š
  mount          å°†æŒ‡å®šç›®å½•æŒ‚è½½åˆ°minikubeä¸­
  ssh            ç™»å½•åˆ°minikubeç¯å¢ƒï¼ˆç”¨äºè°ƒè¯•ï¼‰
  kubectl        è¿è¡Œä¸é›†ç¾¤ç‰ˆæœ¬åŒ¹é…çš„kubectläºŒè¿›åˆ¶æ–‡ä»¶
  node           æ·»åŠ ã€åˆ é™¤æˆ–åˆ—å‡ºé¢å¤–èŠ‚ç‚¹

æ•…éšœæ’é™¤å‘½ä»¤ï¼š
  ssh-key        è·å–æŒ‡å®šèŠ‚ç‚¹çš„SSHèº«ä»½å¯†é’¥è·¯å¾„
  ssh-host       è·å–æŒ‡å®šèŠ‚ç‚¹çš„SSHä¸»æœºå¯†é’¥
  ip             è·å–æŒ‡å®šèŠ‚ç‚¹çš„IPåœ°å€
  logs           è¿”å›ç”¨äºè°ƒè¯•æœ¬åœ°Kubernetesé›†ç¾¤çš„æ—¥å¿—
  update-check   æ‰“å°å½“å‰åŠæœ€æ–°ç‰ˆæœ¬å·
  version        æ‰“å°minikubeçš„ç‰ˆæœ¬ä¿¡æ¯

å…¶ä»–å‘½ä»¤ï¼š
  completion     ä¸º shell ç”Ÿæˆå‘½ä»¤è¡¥å…¨è„šæœ¬

ä½¿ç”¨ "minikube <å‘½ä»¤> --help" è·å–æœ‰å…³ç‰¹å®šå‘½ä»¤çš„æ›´å¤šä¿¡æ¯ã€‚
```

å¯è§æ˜¯`minikube stop`ã€‚

å›åˆ°`kubernetes`ï¼Œç¾åœ¨å·¥ä½œæ­£å¸¸äº†ã€‚

```shell
$ kubectl cluster-info
Kubernetes æ§åˆ¶å¹³é¢æ­£åœ¨ https://192.168.99.100:8443 ä¸Šé‹è¡Œ
KubeDNS æ­£åœ¨ https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy ä¸Šé‹è¡Œ
```

è¦è¿›ä¸€æ­¥è°ƒè¯•å’Œè¯Šæ–­é›†ç¾¤é—®é¢˜ï¼Œè¯·ä½¿ç”¨ `kubectl cluster-info dump`ã€‚
```

å½“æˆ‘ä»¬æ‰“å¼€`https://192.168.99.100:8443`æ—¶ï¼Œæµè§ˆå™¨æ˜¾ç¤ºï¼š

```json
{
  "kind": "ç‹€æ…‹",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "å¤±æ•—",
  "message": "ç¦æ­¢ï¼šç”¨æˆ¶ \"system:anonymous\" ç„¡æ³•è¨ªå•è·¯å¾‘ \"/\"",
  "reason": "ç¦æ­¢",
  "details": {
    
  },
  "code": 403
}
```

è®¿é—®`https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy`ï¼š

```json
{
  "kind": "ç‹€æ…‹",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "å¤±æ•—",
  "message": "æœå‹™ \"kube-dns:dns\" è¢«ç¦æ­¢ï¼šç”¨æˆ¶ \"system:anonymous\" ç„¡æ³•åœ¨å‘½åç©ºé–“ \"kube-system\" ä¸­ç²å– API ç¾¤çµ„ \"\" ä¸­çš„è³‡æº \"services/proxy\"",
  "reason": "ç¦æ­¢",
  "details": {
    "name": "kube-dns:dns",
    "kind": "æœå‹™"
  },
  "code": 403
}
```

æ¥è¯•è¯•åˆšæ‰é‚£ä¸ªé…ç½®ã€‚

```shell
$ kubectl apply -f simple_deployment.yaml
deployment.apps/nginx-deployment å·²å‰µå»º
```

æœ‰ç‚¹é—®é¢˜ã€‚ä¸è¿‡åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬å·²ç»æˆåŠŸå¯åŠ¨äº†`Kubernetes`ã€‚å…ˆå‘Šä¸€æ®µè½ï¼Œåç»­å†ç»§ç»­æ¢ç´¢ã€‚

```shell
$ minikube stop
âœ‹  æ­£åœ¨åœæ­¢ç¯€é» "minikube"  ...
ğŸ›‘  1 å€‹ç¯€é»å·²åœæ­¢ã€‚
```

æª¢æŸ¥æ˜¯å¦çµæŸã€‚

```shell
w$ minikube dashboard
ğŸ¤·  æ§åˆ¶å¹³é¢ç¯€é»å¿…é ˆé‹è¡Œæ‰èƒ½åŸ·è¡Œæ­¤å‘½ä»¤
ğŸ‘‰  è¦å•Ÿå‹•é›†ç¾¤ï¼Œè«‹é‹è¡Œï¼š"minikube start"
```

## Docker

`Docker` ä¹Ÿæ˜¯ä¸€ç§å®¹å™¨å¹³å°ï¼Œæ—¨åœ¨å¸®åŠ©åŠ é€Ÿåˆ›å»ºã€åˆ†äº«å’Œè¿è¡Œç°ä»£åº”ç”¨ç¨‹åºã€‚æ‚¨å¯ä»¥ä»å®˜ç½‘ä¸‹è½½åº”ç”¨ç¨‹åºã€‚

![docker](assets/images/distributed/docker.png)

ä½¿ç”¨å®¢æˆ·ç«¯æœ‰ç‚¹å¡é¡¿ã€‚è®©æˆ‘ä»¬æ”¹ç”¨å‘½ä»¤è¡Œå§ã€‚

```docker
$ docker
```

ç”¨æ³•ï¼šdocker [é€‰é¡¹] å‘½ä»¤

è‡ªç»™è‡ªè¶³çš„å®¹å™¨è¿è¡Œæ—¶

é€‰é¡¹ï¼š
      --config string      å®¢æˆ·ç«¯é…ç½®æ–‡ä»¶çš„ä½ç½®ï¼ˆé»˜è®¤ä¸º "/Users/lzw/.docker"ï¼‰
  -c, --context string     ç”¨äºè¿æ¥åˆ°å®ˆæŠ¤è¿›ç¨‹çš„ä¸Šä¸‹æ–‡åç§°ï¼ˆè¦†ç›– DOCKER_HOST ç¯å¢ƒå˜é‡å’Œä½¿ç”¨ "docker context use" è®¾ç½®çš„é»˜è®¤ä¸Šä¸‹æ–‡ï¼‰
  -D, --debug              å¯ç”¨è°ƒè¯•æ¨¡å¼
  -H, --host list          è¦è¿æ¥çš„å®ˆæŠ¤è¿›ç¨‹å¥—æ¥å­—åˆ—è¡¨
  -l, --log-level string   è®¾ç½®æ—¥å¿—çº§åˆ«ï¼ˆ"debug"|"info"|"warn"|"error"|"fatal"ï¼‰ï¼ˆé»˜è®¤ä¸º "info"ï¼‰
      --tls                ä½¿ç”¨ TLSï¼›--tlsverify éšå«æ­¤é€‰é¡¹
      --tlscacert string   ä»…ä¿¡ä»»ç”±æ­¤ CA ç­¾åçš„è¯ä¹¦ï¼ˆé»˜è®¤ä¸º "/Users/lzw/.docker/ca.pem"ï¼‰
      --tlscert string     TLS è¯ä¹¦æ–‡ä»¶çš„è·¯å¾„ï¼ˆé»˜è®¤ä¸º "/Users/lzw/.docker/cert.pem"ï¼‰
      --tlskey string      TLS å¯†é’¥æ–‡ä»¶çš„è·¯å¾„ï¼ˆé»˜è®¤ä¸º "/Users/lzw/.docker/key.pem"ï¼‰
      --tlsverify          ä½¿ç”¨ TLS å¹¶éªŒè¯è¿œç¨‹
  -v, --version            æ‰“å°ç‰ˆæœ¬ä¿¡æ¯å¹¶é€€å‡º

ç®¡ç†å‘½ä»¤ï¼š
  app*        Docker åº”ç”¨ç¨‹åºï¼ˆDocker Inc.ï¼Œç‰ˆæœ¬ v0.9.1-beta3ï¼‰
  builder     ç®¡ç†æ„å»º
  buildx*     ä½¿ç”¨ BuildKit æ„å»ºï¼ˆDocker Inc.ï¼Œç‰ˆæœ¬ v0.5.1-dockerï¼‰
  config      ç®¡ç† Docker é…ç½®
  container   ç®¡ç†å®¹å™¨
  context     ç®¡ç†ä¸Šä¸‹æ–‡
  image       ç®¡ç†é•œåƒ
  manifest    ç®¡ç† Docker é•œåƒæ¸…å•å’Œæ¸…å•åˆ—è¡¨
  network     ç®¡ç†ç½‘ç»œ
  node        ç®¡ç† Swarm èŠ‚ç‚¹
  plugin      ç®¡ç†æ’ä»¶
  scan*       Docker æ‰«æï¼ˆDocker Inc.ï¼Œç‰ˆæœ¬ v0.5.0ï¼‰
  secret      ç®¡ç† Docker å¯†é’¥
  service     ç®¡ç†æœåŠ¡
  stack       ç®¡ç† Docker å †æ ˆ
  swarm       ç®¡ç† Swarm
  system      ç®¡ç† Docker
  trust       ç®¡ç† Docker é•œåƒçš„ä¿¡ä»»
  volume      ç®¡ç†å·

å‘½ä»¤ï¼š
  attach      å°‡æœ¬åœ°æ¨™æº–è¼¸å…¥ã€è¼¸å‡ºå’ŒéŒ¯èª¤æµé™„åŠ åˆ°æ­£åœ¨é‹è¡Œçš„å®¹å™¨
  build       å¾Dockerfileæ§‹å»ºé¡åƒ
  commit      æ ¹æ“šå®¹å™¨çš„æ›´æ”¹å‰µå»ºæ–°é¡åƒ
  cp          åœ¨å®¹å™¨å’Œæœ¬åœ°æ–‡ä»¶ç³»çµ±ä¹‹é–“è¤‡è£½æ–‡ä»¶/æ–‡ä»¶å¤¾
  create      å‰µå»ºæ–°å®¹å™¨
  diff        æª¢æŸ¥å®¹å™¨æ–‡ä»¶ç³»çµ±ä¸Šæ–‡ä»¶æˆ–ç›®éŒ„çš„æ›´æ”¹
  events      å¾æœå‹™å™¨ç²å–å¯¦æ™‚äº‹ä»¶
  exec        åœ¨é‹è¡Œä¸­çš„å®¹å™¨å…§åŸ·è¡Œå‘½ä»¤
  export      å°‡å®¹å™¨çš„æ–‡ä»¶ç³»çµ±å°å‡ºç‚ºtarå­˜æª”
  history     é¡¯ç¤ºé¡åƒçš„æ­·å²è¨˜éŒ„
  images      åˆ—å‡ºé¡åƒ
  import      å¾tarballå°å…¥å…§å®¹ä»¥å‰µå»ºæ–‡ä»¶ç³»çµ±é¡åƒ
  info        é¡¯ç¤ºç³»çµ±ç¯„åœçš„ä¿¡æ¯
  inspect     è¿”å›Dockerå°è±¡çš„ä½ç´šä¿¡æ¯
  kill        çµ‚æ­¢ä¸€å€‹æˆ–å¤šå€‹é‹è¡Œä¸­çš„å®¹å™¨
  load        å¾tarå­˜æª”æˆ–STDINåŠ è¼‰é¡åƒ
  login       ç™»éŒ„åˆ°Dockerè¨»å†Šè¡¨
  logout      å¾Dockerè¨»å†Šè¡¨ç™»å‡º
  logs        ç²å–å®¹å™¨çš„æ—¥èªŒ
  pause       æš«åœä¸€å€‹æˆ–å¤šå€‹å®¹å™¨å…§çš„æ‰€æœ‰é€²ç¨‹
  port        åˆ—å‡ºç«¯å£æ˜ å°„æˆ–å®¹å™¨çš„ç‰¹å®šæ˜ å°„
  ps          åˆ—å‡ºå®¹å™¨
  pull        å¾è¨»å†Šè¡¨æ‹‰å–é¡åƒæˆ–å€‰åº«
  push        æ¨é€é¡åƒæˆ–å€‰åº«åˆ°è¨»å†Šè¡¨
  rename      é‡å‘½åå®¹å™¨
  restart     é‡å•Ÿä¸€å€‹æˆ–å¤šå€‹å®¹å™¨
  rm          ç§»é™¤ä¸€å€‹æˆ–å¤šå€‹å®¹å™¨
  rmi         ç§»é™¤ä¸€å€‹æˆ–å¤šå€‹é¡åƒ
  run         åœ¨æ–°å®¹å™¨ä¸­é‹è¡Œå‘½ä»¤
  save        å°‡ä¸€å€‹æˆ–å¤šå€‹é¡åƒä¿å­˜åˆ°tarå­˜æª”ï¼ˆé»˜èªæµå¼å‚³è¼¸åˆ°STDOUTï¼‰
  search      åœ¨Docker Hubä¸­æœç´¢é¡åƒ
  start       å•Ÿå‹•ä¸€å€‹æˆ–å¤šå€‹å·²åœæ­¢çš„å®¹å™¨
  stats       é¡¯ç¤ºå®¹å™¨è³‡æºä½¿ç”¨çµ±è¨ˆçš„å¯¦æ™‚æµ
  stop        åœæ­¢ä¸€å€‹æˆ–å¤šå€‹é‹è¡Œä¸­çš„å®¹å™¨
  tag         å‰µå»ºå¼•ç”¨SOURCE_IMAGEçš„TARGET_IMAGEæ¨™ç±¤
  top         é¡¯ç¤ºå®¹å™¨çš„é‹è¡Œé€²ç¨‹
  unpause     æ¢å¾©ä¸€å€‹æˆ–å¤šå€‹å®¹å™¨å…§çš„æ‰€æœ‰é€²ç¨‹
  update      æ›´æ–°ä¸€å€‹æˆ–å¤šå€‹å®¹å™¨çš„é…ç½®
  version     é¡¯ç¤ºDockerç‰ˆæœ¬ä¿¡æ¯
  wait        é˜»å¡ç›´åˆ°ä¸€å€‹æˆ–å¤šå€‹å®¹å™¨åœæ­¢ï¼Œç„¶å¾Œæ‰“å°å®ƒå€‘çš„é€€å‡ºä»£ç¢¼

è¿è¡Œ 'docker å‘½ä»¤ --help' å¯è·å–æœ‰å…³æŸä¸ªå‘½ä»¤çš„æ›´å¤šä¿¡æ¯ã€‚

è¦è·å–æ›´å¤šå…³äº Docker çš„å¸®åŠ©ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„æŒ‡å—ï¼šhttps://docs.docker.com/go/guides/
```

æŒ‰ç…§æ•™ç¨‹æ¥è¯•è¯•çœ‹ã€‚

```shell
$ docker run -d -p 80:80 docker/getting-started
ç„¡æ³•åœ¨æœ¬åœ°æ‰¾åˆ° 'docker/getting-started:latest' çš„æ˜ åƒ
latest: æ­£åœ¨å¾ docker/getting-started æ‹‰å–
aad63a933944: æ‹‰å–å®Œæˆ
b14da7a62044: æ‹‰å–å®Œæˆ
343784d40d66: æ‹‰å–å®Œæˆ
6f617e610986: æ‹‰å–å®Œæˆ
æ‘˜è¦: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
ç‹€æ…‹: å·²ä¸‹è¼‰è¼ƒæ–°çš„æ˜ åƒ docker/getting-started:latest
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: ä¾†è‡ªå®ˆè­·ç¨‹åºçš„éŒ¯èª¤éŸ¿æ‡‰: ç«¯å£ä¸å¯ç”¨: ç›£è½ tcp 0.0.0.0:80: ç¶å®š: åœ°å€å·²åœ¨ä½¿ç”¨ä¸­ã€‚
```

æ›´æ”¹ç«¯å£ã€‚

```shell
$ docker run -d -p 8080:80 docker/getting-started
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
```

![docker_run](assets/images/distributed/docker_run.png)

æ‰“é–‹ç€è¦½å™¨ï¼Œèªªæ˜æˆ‘å€‘å·²ç¶“æˆåŠŸå•Ÿå‹•äº†`docker`ã€‚

![æµè§ˆå™¨](assets/images/distributed/browser.png)

åœæ­¢å®¹å™¨ã€‚ä½¿ç”¨å‰›å‰›è¿”å›çš„`ID`ã€‚

```shell
$ docker stop 45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
```

è¿™æ—¶å·²ç»æ— æ³•æ‰“å¼€ç½‘å€äº†ã€‚

è¿™è¯´æ˜`docker`ç±»ä¼¼äºè™šæ‹Ÿæœºã€‚

## Flink

æ‰“å¼€å®˜ç¶²ã€‚

![flink-home-graphic](assets/images/distributed/flink-home-graphic.png)

`Flink` æ˜¯ä¸€ç§ç”¨äºæ•°æ®æµçš„ `Stateful` è®¡ç®—æ¡†æ¶ã€‚`Stateful` æŒ‡çš„æ˜¯ä»€ä¹ˆï¼Ÿæš‚æ—¶è¿˜ä¸æ˜ç™½ã€‚ä¸è¿‡ï¼Œä¸Šé¢è¿™ä¸ªå›¾çœ‹èµ·æ¥å¾ˆæœ‰è¶£ã€‚æ¥è¯•è¯•çœ‹å§ã€‚

è¯´æ˜¯éœ€è¦Javaç¯å¢ƒã€‚

```shell
$ java -version
java ç‰ˆæœ¬ "1.8.0_151"
Java(TM) SE é‹è¡Œç’°å¢ƒ (build 1.8.0_151-b12)
Java HotSpot(TM) 64 ä½å…ƒä¼ºæœå™¨è™›æ“¬æ©Ÿ (build 25.151-b12, æ··åˆæ¨¡å¼)
```

ä»å®˜ç½‘ä¸‹è½½æœ€æ–°ç‰ˆæœ¬çš„ `flink-1.12.2-bin-scala_2.11.tar`ã€‚

```shell
$ ./bin/start-cluster.sh
æ­£åœ¨å•Ÿå‹•é›†ç¾¤ã€‚
åœ¨ä¸»æ©Ÿ lzwjava ä¸Šå•Ÿå‹• standalonesession å®ˆè­·ç¨‹åºã€‚
åœ¨ä¸»æ©Ÿ lzwjava ä¸Šå•Ÿå‹• taskexecutor å®ˆè­·ç¨‹åºã€‚
```

```shell
$ ./bin/flink run examples/streaming/WordCount.jar
æ­£åœ¨ä½¿ç”¨é»˜èªè¼¸å…¥æ•¸æ“šé›†åŸ·è¡Œ WordCount ç¤ºä¾‹ã€‚
ä½¿ç”¨ --input ä¾†æŒ‡å®šæ–‡ä»¶è¼¸å…¥ã€‚
å°‡çµæœæ‰“å°åˆ°æ¨™æº–è¼¸å‡ºã€‚ä½¿ç”¨ --output ä¾†æŒ‡å®šè¼¸å‡ºè·¯å¾‘ã€‚
ä½œæ¥­å·²æäº¤ï¼Œä½œæ¥­IDç‚º 60f37647c20c2a6654359bd34edab807
ç¨‹åºåŸ·è¡Œå®Œç•¢
ä½œæ¥­IDç‚º 60f37647c20c2a6654359bd34edab807 çš„ä½œæ¥­å·²å®Œæˆã€‚
ä½œæ¥­é‹è¡Œæ™‚é–“ï¼š757 æ¯«ç§’
```

```shell
$ tail log/flink-*-taskexecutor-*.out
(ä»™å¥³,1)
(åœ¨,3)
(ä½ çš„,1)
(ç¥ˆç¥·,1)
(æ˜¯,4)
(æ‰€æœ‰,2)
(æˆ‘çš„,1)
(ç½ªè¿‡,1)
(è®°ä½,1)
(d,4)
```

```shell
$ ./bin/stop-cluster.sh
æ­£åœ¨åœæ­¢ taskexecutor å®ˆæŠ¤è¿›ç¨‹ï¼ˆè¿›ç¨‹IDï¼š41812ï¼‰åœ¨ä¸»æœº lzwjava ä¸Šã€‚
```

å—¯ï¼Œä¸Šæ‰‹æˆåŠŸã€‚å¯è§é€™è·Ÿ`Spark`å¾ˆåƒã€‚

## éº’éºŸ

å‰å¾€é–‹å•Ÿå®˜ç¶²ã€‚

> Apache Kylinâ„¢ æ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼åˆ†ææ•°æ®ä»“åº“ï¼Œä¸“ä¸ºå¤§æ•°æ®æ—¶ä»£æä¾›åœ¨çº¿åˆ†æå¤„ç†ï¼ˆOLAPï¼‰èƒ½åŠ›è€Œè®¾è®¡ã€‚é€šè¿‡åœ¨Hadoopå’ŒSparkä¸Šé©æ–°å¤šç»´ç«‹æ–¹ä½“åŠé¢„è®¡ç®—æŠ€æœ¯ï¼ŒKylinèƒ½å¤Ÿå®ç°å‡ ä¹æ’å®šçš„æŸ¥è¯¢é€Ÿåº¦ï¼Œä¸å—æ•°æ®é‡æŒç»­å¢é•¿çš„å½±å“ã€‚å®ƒå°†æŸ¥è¯¢å»¶è¿Ÿä»åˆ†é’Ÿçº§é™è‡³äºšç§’çº§ï¼Œè®©åœ¨çº¿åˆ†æé‡å›å¤§æ•°æ®é¢†åŸŸã€‚

> Apache Kylinâ„¢ è®©æ‚¨é€šè¿‡ä¸‰ä¸ªæ­¥éª¤å®ç°äºšç§’çº§å»¶è¿ŸæŸ¥è¯¢æ•°åäº¿è¡Œæ•°æ®ã€‚
>
> 1. åœ¨Hadoopä¸Šè¯†åˆ«æ˜Ÿå‹æˆ–é›ªèŠ±å‹æ¶æ„ã€‚
> 2. æ ¹æ®è¯†åˆ«å‡ºçš„è¡¨æ„å»ºCubeã€‚
> 3. ä½¿ç”¨ANSI-SQLè¿›è¡ŒæŸ¥è¯¢ï¼Œå¹¶é€šè¿‡ODBCã€JDBCæˆ–RESTful APIåœ¨äºšç§’çº§å†…è·å–ç»“æœã€‚

![éº’éºŸæ¶æ„å›¾](assets/images/distributed/kylin_diagram.png)

å¤§è‡´ä¸Šï¼Œå®ƒæ˜¯å¤„ç†å¤§æ•°æ®çš„ä¸€ä¸ªå±‚çº§ã€‚é€šè¿‡å®ƒï¼ŒæŸ¥è¯¢é€Ÿåº¦å¯ä»¥éå¸¸å¿«ã€‚å®ƒå……å½“äº†æ¡¥æ¢çš„è§’è‰²ã€‚

å¯æƒœå½“å‰åªèƒ½åœ¨`Linux`ç¯å¢ƒä¸‹ä½¿ç”¨ã€‚å›å¤´å†æ¥æŠ˜è…¾ã€‚

## MongoDB

é€™ä¹Ÿæ˜¯ä¸€ç¨®æ•¸æ“šåº«ã€‚è©¦è©¦å®‰è£ã€‚

```shell
$ brew tap mongodb/brew
==> æ­£åœ¨æ·»åŠ  mongodb/brew æº
æ­£åœ¨å…‹éš†åˆ° '/usr/local/Homebrew/Library/Taps/mongodb/homebrew-brew'...
remote: æšä¸¾å¯¹è±¡: 63, å®Œæˆã€‚
remote: è®¡æ•°å¯¹è±¡: 100% (63/63), å®Œæˆã€‚
remote: å‹ç¼©å¯¹è±¡: 100% (62/62), å®Œæˆã€‚
remote: æ€»è®¡ 566 (å·®å¼‚ 21), å¤ç”¨ 6 (å·®å¼‚ 1), åŒ…å¤ç”¨ 503
æ¥æ”¶å¯¹è±¡: 100% (566/566), 121.78 KiB | 335.00 KiB/s, å®Œæˆã€‚
å¤„ç†å·®å¼‚: 100% (259/259), å®Œæˆã€‚
å·²æ·»åŠ  11 ä¸ªå…¬å¼ (39 ä¸ªæ–‡ä»¶, 196.2KB)ã€‚
```

```shell
$ brew install mongodb-community@4.4
==> æ­£åœ¨ä» mongodb/brew å®‰è£… mongodb-community
==> ä¸‹è½½ https://fastdl.mongodb.org/tools/db/mongodb-database-tools-macos-x86_64-100.3.0.zip
######################################################################## 100.0%
==> ä¸‹è½½ https://fastdl.mongodb.org/osx/mongodb-macos-x86_64-4.4.3.tgz
######################################################################## 100.0%
==> æ­£åœ¨å®‰è£… mongodb/brew/mongodb-community çš„ä¾èµ–é¡¹ï¼šmongodb-database-tools
==> æ­£åœ¨å®‰è£… mongodb/brew/mongodb-community çš„ä¾èµ–é¡¹ï¼šmongodb-database-tools
é”™è¯¯ï¼š`brew link` æ­¥éª¤æœªæˆåŠŸå®Œæˆ
è¯¥å…¬å¼å·²æ„å»ºï¼Œä½†æœªç¬¦å·é“¾æ¥åˆ° /usr/local
æ— æ³•ç¬¦å·é“¾æ¥ bin/bsondump
ç›®æ ‡ /usr/local/bin/bsondump
æ˜¯ä¸€ä¸ªå±äº mongodb çš„ç¬¦å·é“¾æ¥ã€‚æ‚¨å¯ä»¥å–æ¶ˆé“¾æ¥ï¼š
  brew unlink mongodb
```

è¦å¼ºåˆ¶é“¾æ¥å¹¶è¦†ç›–æ‰€æœ‰å†²çªçš„æ–‡ä»¶ï¼š
  brew link --overwrite mongodb-database-tools

è¦åˆ—å‡ºæ‰€æœ‰å°†è¢«åˆ é™¤çš„æ–‡ä»¶ï¼š
  brew link --overwrite --dry-run mongodb-database-tools

å¯èƒ½äº§ç”Ÿå†²çªçš„æ–‡ä»¶æœ‰ï¼š
/usr/local/bin/bsondump -> /usr/local/Cellar/mongodb/3.0.7/bin/bsondump
/usr/local/bin/mongodump -> /usr/local/Cellar/mongodb/3.0.7/bin/mongodump
/usr/local/bin/mongoexport -> /usr/local/Cellar/mongodb/3.0.7/bin/mongoexport
/usr/local/bin/mongofiles -> /usr/local/Cellar/mongodb/3.0.7/bin/mongofiles
/usr/local/bin/mongoimport -> /usr/local/Cellar/mongodb/3.0.7/bin/mongoimport
/usr/local/bin/mongorestore -> /usr/local/Cellar/mongodb/3.0.7/bin/mongorestore
/usr/local/bin/mongostat -> /usr/local/Cellar/mongodb/3.0.7/bin/mongostat
/usr/local/bin/mongotop -> /usr/local/Cellar/mongodb/3.0.7/bin/mongotop
==> æ‘˜è¦
ğŸº  /usr/local/Cellar/mongodb-database-tools/100.3.0: 13ä¸ªæ–‡ä»¶ï¼Œ154MBï¼Œ11ç§’å†…æ„å»ºå®Œæˆ
==> æ­£åœ¨å®‰è£… mongodb/brew/mongodb-community
é”™è¯¯ï¼š`brew link` æ­¥éª¤æœªæˆåŠŸå®Œæˆ
è¯¥å…¬å¼å·²æ„å»ºï¼Œä½†æœªç¬¦å·é“¾æ¥åˆ° /usr/local
æ— æ³•ç¬¦å·é“¾æ¥ bin/mongo
ç›®æ ‡ /usr/local/bin/mongo
æ˜¯å±äº mongodb çš„ç¬¦å·é“¾æ¥ã€‚æ‚¨å¯ä»¥å–æ¶ˆé“¾æ¥ï¼š
  brew unlink mongodb

è¦å¼ºåˆ¶é“¾æ¥å¹¶è¦†ç›–æ‰€æœ‰å†²çªçš„æ–‡ä»¶ï¼š
  brew link --overwrite mongodb-community

è¦åˆ—å‡ºæ‰€æœ‰å°†è¢«åˆ é™¤çš„æ–‡ä»¶ï¼š
  brew link --overwrite --dry-run mongodb-community

å¯èƒ½ç”¢ç”Ÿè¡çªçš„æ–‡ä»¶æœ‰ï¼š
/usr/local/bin/mongo -> /usr/local/Cellar/mongodb/3.0.7/bin/mongo
/usr/local/bin/mongod -> /usr/local/Cellar/mongodb/3.0.7/bin/mongod
/usr/local/bin/mongos -> /usr/local/Cellar/mongodb/3.0.7/bin/mongos
==> æ³¨æ„äº‹é …
è¦è®“ launchd ç¾åœ¨å•Ÿå‹• mongodb/brew/mongodb-community ä¸¦åœ¨ç™»éŒ„æ™‚é‡å•Ÿï¼š
  brew services start mongodb/brew/mongodb-community
æˆ–è€…ï¼Œå¦‚æœæ‚¨ä¸éœ€è¦/æƒ³è¦å¾Œå°æœå‹™ï¼Œå¯ä»¥ç›´æ¥é‹è¡Œï¼š
  mongod --config /usr/local/etc/mongod.conf
==> ç¸½çµ
ğŸº  /usr/local/Cellar/mongodb-community/4.4.3: 11 å€‹æ–‡ä»¶ï¼Œ156.8MBï¼Œ10 ç§’å…§æ§‹å»ºå®Œæˆ
==> æ³¨æ„äº‹é …
==> mongodb-community
è¦è®“ launchd ç¾åœ¨å•Ÿå‹• mongodb/brew/mongodb-community ä¸¦åœ¨ç™»éŒ„æ™‚é‡å•Ÿï¼š
  brew services start mongodb/brew/mongodb-community
æˆ–è€…ï¼Œå¦‚æœæ‚¨ä¸éœ€è¦/æƒ³è¦å¾Œå°æœå‹™ï¼Œå¯ä»¥ç›´æ¥é‹è¡Œï¼š
  mongod --config /usr/local/etc/mongod.conf
```

ä¹‹å‰æˆ‘å®‰è£…äº†ä¸€ä¸ªæ—§ç‰ˆæœ¬ã€‚è§£é™¤ä¸€ä¸‹é“¾æ¥ã€‚

```shell
$ brew unlink mongodb
å–æ¶ˆé“¾æ¥ /usr/local/Cellar/mongodb/3.0.7... å·²ç§»é™¤ 11 ä¸ªç¬¦å·é“¾æ¥
```

```shell
$ mongod --version
db ç‰ˆæœ¬ v4.4.3
æ§‹å»ºä¿¡æ¯: {
    "ç‰ˆæœ¬": "4.4.3",
    "gitç‰ˆæœ¬": "913d6b62acfbb344dde1b116f4161360acd8fd13",
    "æ¨¡å¡Š": [],
    "åˆ†é…å™¨": "ç³»çµ±",
    "ç’°å¢ƒ": {
        "åˆ†ç™¼æ¶æ§‹": "x86_64",
        "ç›®æ¨™æ¶æ§‹": "x86_64"
    }
}
```

æ¥ç€è¿è¡Œ`mongod`å¯åŠ¨MongoDBæ•°æ®åº“æœåŠ¡å™¨ã€‚ç„¶è€Œï¼Œç¬¬ä¸€æ¬¡å¯åŠ¨æ—¶æç¤º`/data/db`ç›®å½•ä¸å­˜åœ¨ã€‚äºæ˜¯ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªç›®å½•`~/mongodb`ï¼Œç”¨äºå­˜æ”¾æ•°æ®åº“æ–‡ä»¶ã€‚

```shell
$ mongod --dbpath ~/mongodb
```

ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼š

```shell
$ mongod --dbpath ~/mongodb
```

é€™æ®µå‘½ä»¤çš„æ„æ€æ˜¯å•Ÿå‹• MongoDB æ•¸æ“šåº«æœå‹™ï¼Œä¸¦æŒ‡å®šæ•¸æ“šåº«å­˜å„²è·¯å¾‘ç‚ºç”¨æˆ¶ç›®éŒ„ä¸‹çš„ `mongodb` æ–‡ä»¶å¤¾ã€‚

è¾“å‡ºä¸ºï¼š

```json
{"t":{"$date":"2021-03-11T18:17:32.838+08:00"},"s":"I",  "c":"CONTROL",  "id":23285,   "ctx":"main","msg":"è‡ªå‹•ç¦ç”¨ TLS 1.0ï¼Œè‹¥è¦å¼·åˆ¶å•Ÿç”¨ TLS 1.0ï¼Œè«‹æŒ‡å®š --sslDisabledProtocols 'none'"}
{"t":{"$date":"2021-03-11T18:17:32.842+08:00"},"s":"W",  "c":"ASIO",     "id":22601,   "ctx":"main","msg":"åœ¨ NetworkInterface å•Ÿå‹•æœŸé–“æœªé…ç½® TransportLayer"}
{"t":{"$date":"2021-03-11T18:17:32.842+08:00"},"s":"I",  "c":"NETWORK",  "id":4648602, "ctx":"main","msg":"éš±å¼ä½¿ç”¨ TCP FastOpenã€‚"}
{"t":{"$date":"2021-03-11T18:17:32.842+08:00"},"s":"I",  "c":"STORAGE",  "id":4615611, "ctx":"initandlisten","msg":"MongoDB æ­£åœ¨å•Ÿå‹•","attr":{"pid":46256,"port":27017,"dbPath":"/Users/lzw/mongodb","architecture":"64-bit","host":"lzwjava"}}
{"t":{"$date":"2021-03-11T18:17:32.842+08:00"},"s":"I",  "c":"CONTROL",  "id":23403,   "ctx":"initandlisten","msg":"æ§‹å»ºä¿¡æ¯","attr":{"buildInfo":{"version":"4.4.3","gitVersion":"913d6b62acfbb344dde1b116f4161360acd8fd13","modules":[],"allocator":"system","environment":{"distarch":"x86_64","target_arch":"x86_64"}}}}
{"t":{"$date":"2021-03-11T18:17:32.843+08:00"},"s":"I",  "c":"CONTROL",  "id":51765,   "ctx":"initandlisten","msg":"æ“ä½œç³»çµ±","attr":{"os":{"name":"Mac OS X","version":"20.3.0"}}}
...
```

å¯è§éƒ½æ˜¯`JSON`æ ¼å¼ã€‚MongoDBå°±æ˜¯å°†æ‰€æœ‰æ•°æ®æ–‡ä»¶éƒ½ç”¨`JSON`æ ¼å¼æ¥ä¿å­˜çš„ã€‚æ¥ç€ï¼Œæ‰“å¼€å¦ä¸€ä¸ªç»ˆç«¯æ ‡ç­¾ã€‚

```shell
$ mongo
MongoDB shell ç‰ˆæœ¬ v4.4.3
æ­£åœ¨è¿æ¥åˆ°ï¼šmongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb
éšå¼ä¼šè¯ï¼šä¼šè¯ { "id" : UUID("4f55c561-70d3-4289-938d-4b90a284891f") }
MongoDB æœåŠ¡å™¨ç‰ˆæœ¬ï¼š4.4.3
---
æœåŠ¡å™¨å¯åŠ¨æ—¶ç”Ÿæˆäº†ä»¥ä¸‹è­¦å‘Šï¼š
        2021-03-11T18:17:33.743+08:00: æ•°æ®åº“æœªå¯ç”¨è®¿é—®æ§åˆ¶ã€‚æ•°æ®å’Œé…ç½®çš„è¯»å†™è®¿é—®ä¸å—é™åˆ¶
        2021-03-11T18:17:33.743+08:00: æ­¤æœåŠ¡å™¨ç»‘å®šåˆ° localhostã€‚è¿œç¨‹ç³»ç»Ÿå°†æ— æ³•è¿æ¥åˆ°æ­¤æœåŠ¡å™¨ã€‚å¯åŠ¨æœåŠ¡å™¨æ—¶ä½¿ç”¨ --bind_ip <åœ°å€> æŒ‡å®šåº”å“åº”è¯·æ±‚çš„ IP åœ°å€ï¼Œæˆ–ä½¿ç”¨ --bind_ip_all ç»‘å®šåˆ°æ‰€æœ‰æ¥å£ã€‚å¦‚æœè¿™æ˜¯é¢„æœŸçš„è¡Œä¸ºï¼Œè¯·ä½¿ç”¨ --bind_ip 127.0.0.1 å¯åŠ¨æœåŠ¡å™¨ä»¥ç¦ç”¨æ­¤è­¦å‘Š
        2021-03-11T18:17:33.743+08:00: è½¯èµ„æºé™åˆ¶è¿‡ä½
        2021-03-11T18:17:33.743+08:00:        å½“å‰å€¼ï¼š4864
        2021-03-11T18:17:33.743+08:00:        æ¨èæœ€å°å€¼ï¼š64000
---
---
        å¯ç”¨ MongoDB çš„å…è´¹åŸºäºäº‘çš„ç›‘æ§æœåŠ¡ï¼Œè¯¥æœåŠ¡å°†æ¥æ”¶å¹¶æ˜¾ç¤ºæœ‰å…³æ‚¨çš„éƒ¨ç½²çš„æŒ‡æ ‡ï¼ˆç£ç›˜åˆ©ç”¨ç‡ã€CPUã€æ“ä½œç»Ÿè®¡ä¿¡æ¯ç­‰ï¼‰ã€‚
```

ç›‘æ§æ•°æ®å°†å‘å¸ƒåœ¨ä¸€ä¸ªMongoDBç½‘ç«™ä¸Šï¼Œè¯¥ç½‘ç«™æ‹¥æœ‰ä¸€ä¸ªç‹¬ç‰¹çš„URLï¼Œæ‚¨åŠæ‚¨åˆ†äº«è¯¥URLçš„ä»»ä½•äººçš†å¯è®¿é—®ã€‚MongoDBå¯èƒ½ä¼šåˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥æ”¹è¿›äº§å“ï¼Œå¹¶å‘æ‚¨æ¨èMongoDBçš„äº§å“åŠéƒ¨ç½²æ–¹æ¡ˆã€‚

è¦å•Ÿç”¨å…è²»ç›£æ§ï¼Œè«‹é‹è¡Œä»¥ä¸‹å‘½ä»¤ï¼šdb.enableFreeMonitoring()
è‹¥è¦æ°¸ä¹…åœç”¨æ­¤æé†’ï¼Œè«‹é‹è¡Œä»¥ä¸‹å‘½ä»¤ï¼šdb.disableFreeMonitoring()
```

æ¥ç€å¯ä»¥å°è¯•æ’å…¥æ•°æ®ã€æŸ¥è¯¢æ•°æ®ã€‚

```shell
> db.inventory.insertOne(
...    { item: "canvas", qty: 100, tags: ["cotton"], size: { h: 28, w: 35.5, uom: "cm" } }
... )
{
	"acknowledged" : true,
	"insertedId" : ObjectId("6049ef91b653541cf355facb")
}
>
> db.inventory.find()
{ "_id" : ObjectId("6049ef91b653541cf355facb"), "item" : "canvas", "qty" : 100, "tags" : [ "cotton" ], "size" : { "h" : 28, "w" : 35.5, "uom" : "cm" } }
```

ç¿»è­¯å¦‚ä¸‹ï¼š

```shell
> db.inventory.insertOne(
...    { ç‰©å“: "ç•«å¸ƒ", æ•¸é‡: 100, æ¨™ç±¤: ["æ£‰"], å°ºå¯¸: { é«˜: 28, å¯¬: 35.5, å–®ä½: "å…¬åˆ†" } }
... )
{
	"å·²ç¢ºèª" : true,
	"æ’å…¥çš„ID" : ObjectId("6049ef91b653541cf355facb")
}
>
> db.inventory.find()
{ "_id" : ObjectId("6049ef91b653541cf355facb"), "ç‰©å“" : "ç•«å¸ƒ", "æ•¸é‡" : 100, "æ¨™ç±¤" : [ "æ£‰" ], "å°ºå¯¸" : { "é«˜" : 28, "å¯¬" : 35.5, "å–®ä½" : "å…¬åˆ†" } }
```

## æœ€å

å…ˆåˆ°è¿™é‡Œã€‚æ¥ä¸‹æ¥æˆ‘ä»¬ä¼šæ¥è§¦å…¶ä»–å·¥å…·ã€‚æˆ‘ä»¬åšè¿™äº›çš„æ„ä¹‰ä½•åœ¨ï¼Ÿå¤§æ¦‚æ˜¯ä¸ºäº†å…ˆç†æ¸…æ€è·¯ã€‚ä¸‡äº‹å¼€å¤´éš¾ï¼Œè€Œæˆ‘ä»¬ä¸€å¼€å§‹å°±æŠŠè¿™äº›å…¨éƒ½å°è¯•äº†ä¸€éã€‚è¿™ç»™äº†æˆ‘ä»¬ä¿¡å¿ƒï¼Œæ¥ä¸‹æ¥ï¼Œå°±æ˜¯æ›´å¤šåœ°æ¢ç´¢è¿™äº›è½¯ä»¶äº†ã€‚

## ç»ƒä¹ 

* å­¦ç”Ÿåƒä¸Šé¢ä¸€æ ·ç±»ä¼¼æ¢ç´¢ä¸€éã€‚