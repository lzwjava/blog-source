---
audio: false
generated: true
image: false
lang: hant
layout: post
title: 人工智能速度與現實世界實用性相遇
translated: true
type: note
---

以下是論文的**重點摘要**：

---

### 核心概念

* **傳統 AI 基準測試** 主要關注準確性/品質，但忽略了**處理速度**，這在現實世界對時間敏感的應用中（例如自動駕駛、客戶服務）至關重要。
* 現有的速度指標（TTFT、TPS）是**以 token 為中心**的，不足以應對多模態 AI 的未來。
* **提議的新指標**：**智能頻寬** — AI 在單位時間內能產生的有用資訊量。

---

### 智能頻寬的近似估算方法

1. **單位時間的基準測試得分**

   * 使用標準化的基準測試性能除以所花費的時間。
   * 對於實際任務而言，比 tokens/秒 更具參考價值。

2. **資訊理論方法**

   * 透過機率分佈來衡量輸出資訊的內容。
   * 由於資訊 ≠ 實用性，且需要存取機率向量，因此有其局限性。

3. **原始輸出位元/秒**

   * 最簡單、與模態無關的方法。
   * 衡量 AI 輸出（文字、圖像、影片）的位元/秒。
   * 不能直接衡量實用性，但若僅應用於頂尖性能模型則有效。

---

### 歷史背景

* 過去忽略速度的原因是：

  1. AI 尚未先進到需要考慮速度。
  2. 應用範圍狹窄且針對特定任務。
* 隨著 **LLMs** 和**多模態 AI** 的出現，**統一的速度指標**已變得必要。

---

### 對人機互動的啟示

* 類似於**摩爾定律**和**尼爾森定律**，此指標可以揭示成長趨勢。
* **臨界點概念**：一旦 AI 輸出速度超越人類感知速度（例如閱讀或聆聽），即時互動就成為可能。
* AI 已經超越人類的閱讀和聆聽速度；下一個前沿是**即時圖像與影片整合**。
* 未來：AI 可能支援**即時視覺推理、白板式設計和沉浸式虛擬環境**。

---

### 實驗與數據

* 使用**原始輸出位元/秒**對歷史上的 LLMs、圖像和影片生成器進行測量。
* **觀察結果**：

  * LLMs：0–3 KB/秒。
  * 圖像生成器：呈指數級成長。
  * 影片生成器：目前落後但預計將加速。
  * **Gemini 2.5 Flash** 是一個特例（針對低延遲進行了優化）。

---

### Jin's Law

* **表述**：*最佳公開可用託管 AI 模型的智能頻寬每年翻倍。*
* 目前由**圖像生成器**領先；隨著服務改進，預計影片將後來居上。
* **預測**：

  1. **圖像整合至 AI 對話**將在 1 年內成為標準。
  2. **即時影片互動**預計在約 3 年內可行（需要約 8 倍的速度提升）。

---

### 局限性

* 如何定義**「有用資訊」** 仍未解決。
* 目前數據稀疏，因此「一年翻倍」的估算存在不確定性。
* 成長可能受能源/經濟限制，而不僅僅是技術進步。

---

### 總結

* AI 評估必須同時考量**正確性和速度**，這與人類智能的評估方式相似。
* **智能頻寬**為 AI 的未來提供了一個預測框架，特別是對於**即時、多模態互動**而言。

---

您是否希望我也建立一個 **Jin's Law 預測的可視化時間軸**（文字 → 圖像 → 影片 → 沉浸式環境），以便一目了然？