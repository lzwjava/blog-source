---
audio: false
generated: true
image: false
lang: hant
layout: post
model: x-ai/grok-4-fast
title: 2025年ImageNet分類新進展
translated: true
type: note
---

自2012年後出現顯著進步以來，ImageNet上的頂尖技術（具體指ImageNet-1K圖像分類驗證集）持續穩步發展。截至2025年11月，領先模型的top-1準確率約達91%，對應top-1錯誤率約為9%。Top-5準確率更高，通常超過99%，使top-5錯誤率低於1%。

### 關鍵頂尖模型（取自Papers With Code排行榜前五名）
以下為當前頂尖模型（基於ImageNet-1K微調）的top-1準確率概覽。對於這些高性能模型，top-5準確率未必會明確重新報告（因其已接近完美水平），但參照近期類似架構可知所有模型top-5錯誤率均低於1%：

| 排名 | 模型 | Top-1準確率 | 預估Top-5準確率 | 參數量 | 備註 |
|------|--------|----------------|---------------------|------------|-------|
| 1 | CoCa（微調版） | 91.0%（錯誤率9.0%） | ~99.5%（錯誤率<0.5%） | 2.1B | 多模態圖像-文本模型；在零樣本（top-1達86.3%）與凍結編碼器設定（top-1達90.6%）表現卓越 |
| 2 | Model Soups（BASIC-L） | 90.98%（錯誤率9.02%） | ~99.4%（錯誤率<0.6%） | ~1B | 透過集成微調模型平均值提升魯棒性 |
| 3 | Model Soups（ViT-G/14） | 90.94%（錯誤率9.06%） | ~99.4%（錯誤率<0.6%） | 1.8B | 基於ViT架構；對分佈外數據具強泛化能力 |
| 4 | DaViT-Giant | 90.4%（錯誤率9.6%） | ~99.3%（錯誤率<0.7%） | 1.4B | 雙注意力ViT；使用15億圖像-文本對訓練 |
| 5 | ConvNeXt V2-Huge | 88.9%（錯誤率11.1%） | ~99.0%（錯誤率~1.0%） | 660M | 結合掩碼自編碼器預訓練的CNN革新架構；適合邊緣設備高效運算 |

### 關於「當今<3%」的說明
- 此指標指**top-5錯誤率**而非top-1。2012年前的基準模型（如SVM）top-5錯誤率約為25%。至2017年（SENet）已降至約2.3%。當代頂尖模型更將其壓縮至1%以下，使top-5預測在多數實際應用中已具可靠性。
- Top-1錯誤率仍維持較高水準（約9%），因其要求*完全匹配*最高概率預測結果，對於模糊圖像等邊緣案例的判斷更為嚴苛。

近年因數據集飽和現象，進展速度放緩——當前提升主要來自大規模預訓練（如使用ImageNet-21K或網絡級數據）及模型集成與蒸餾等技術。人類專家在此基準的表現約為5% top-1錯誤率（top-5錯誤率依研究不同落在2-12%），意味著AI在此基準測試已超越人類水平。

[ImageNet基準測試（Papers With Code）](https://paperswithcode.com/sota/image-classification-on-imagenet)  
[2025年圖像分類頂尖模型綜述（HiringNet）](https://hiringnet.com/image-classification-state-of-the-art-models-in-2025)  
[CoCa：對比式描述模型作為圖像-文本基礎模型（arXiv）](https://arxiv.org/abs/2205.01917)