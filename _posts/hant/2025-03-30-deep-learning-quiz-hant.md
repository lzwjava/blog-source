---
audio: false
generated: true
lang: hant
layout: post
title: 深度學習測驗
translated: true
type: note
---

以下係根據你提供嘅內容設計嘅測驗：

### 機器學習與深度學習測驗

#### **選擇題 (MCQ)：**

1. **以下哪項最準確定義機器學習 (ML)？**
   - A) 一門專注於手動編程演算法嘅電腦科學領域
   - B) 一門讓系統能從數據中學習並提升表現嘅電腦科學領域
   - C) 專注於假設檢定嘅統計學分支
   - D) 一種數據可視化技術

2. **深度學習 (DL) 與傳統機器學習 (ML) 嘅主要區別係咩？**
   - A) DL 唔需要任何數據預處理
   - B) DL 使用多層神經網絡來建模複雜模式
   - C) ML 始終使用無監督學習
   - D) DL 無法處理圖像相關任務

3. **在監督式學習中，用咩嚟訓練模型？**
   - A) 未標記數據
   - B) 包含輸入及對應正確輸出嘅數據
   - C) 強化信號
   - D) 從其他任務預訓練嘅模型

4. **Transformer 架構主要依賴咩技術處理自然語言？**
   - A) 卷積層
   - B) 循環層
   - C) 注意力機制
   - D) 決策樹

5. **Positional Encoding 在 Transformer 中嘅主要功能係咩？**
   - A) 決定序列中每個詞嘅重要性
   - B) 幫助模型理解序列中詞元嘅順序
   - C) 壓縮輸入數據
   - D) 防止模型過度擬合

6. **你會使用哪種模型來生成類似圖像或文本嘅新數據？**
   - A) 生成對抗網絡 (GAN)
   - B) 卷積神經網絡 (CNN)
   - C) 決策樹
   - D) K-最近鄰居 (KNN)

7. **「Zero-shot Learning」一詞係咩意思？**
   - A) 僅從一個標記樣本中學習
   - B) 模型無需明確訓練樣本即可處理任務
   - C) 模型使用完整標記數據執行任務
   - D) 模型無需任何數據即可學習

8. **哪種方法用於在大型數據集預訓練後，針對特定任務微調模型？**
   - A) 強化學習
   - B) 微調
   - C) 遷移學習
   - D) 數據增強

9. **F1 Score 在分類任務中平衡咩指標？**
   - A) 精確率與召回率
   - B) 準確率與精確率
   - C) 召回率與特異性
   - D) 敏感度與特異性

10. **哪種係神經網絡中避免過度擬合嘅常用技術？**
    - A) 梯度下降
    - B) 正則化（例如 L2 權重衰減）
    - C) 數據標準化
    - D) 數據增強

#### **是非題：**

11. **生成式模型學習將數據分類到預定義類別中。**
   - 正確  
   - 錯誤

12. **在循環神經網絡 (RNN) 中，模型嘅隱藏狀態會隨時間步傳遞。**
   - 正確  
   - 錯誤

13. **Dropout 係一種用於鼓勵過度擬合嘅技術。**
   - 正確  
   - 錯誤

14. **Transformer 中的 Attention Heads 讓模型能並行處理輸入，提升表示能力。**
   - 正確  
   - 錯誤

15. **Self-Attention 機制讓模型在預測時能考慮整個序列。**
   - 正確  
   - 錯誤

#### **簡答題：**

16. **用一句話解釋「強化學習」係咩。**

17. **描述「生成式」與「判別式」模型嘅區別。**

18. **在機器學習中使用「遷移學習」嘅目的係咩？**

19. **點解「交叉驗證」在評估模型表現時咁重要？**

20. **神經網絡中「Batch Normalization」與「Dropout」有咩區別？**

---

此測驗涵蓋所提供內容嘅關鍵概念！

---

以下係更多擴展測驗嘅題目：

### **附加選擇題 (MCQ)：**

21. **以下哪項係 GPT 模型嘅關鍵特徵？**
   - A) 使用循環層進行文本生成
   - B) 使用監督學習訓練序列數據
   - C) 使用 Transformer 架構並生成類人文本
   - D) 使用卷積層處理輸入數據

22. **哪種學習方法讓模型能根據人類偏好嘅反饋改進？**
   - A) 人類反饋強化學習 (RLHF)
   - B) 監督學習
   - C) 無監督學習
   - D) 自監督學習

23. **「Tokenization」在自然語言處理 (NLP) 中指咩？**
   - A) 將文本拆分為文法部分
   - B) 將文本轉換為固定大小向量
   - C) 將文本拆分為模型處理嘅單詞或子詞
   - D) 加密敏感文本數據

24. **「數據增強」嘅主要目的係咩？**
   - A) 減少訓練所用數據量
   - B) 人工擴展訓練數據集並提升魯棒性
   - C) 提升模型推理速度
   - D) 清除數據集中嘅異常值

25. **以下哪項唔係用於序列數據嘅神經網絡類型？**
   - A) 循環神經網絡 (RNN)
   - B) 長短期記憶 (LSTM)
   - C) 卷積神經網絡 (CNN)
   - D) 門控循環單元 (GRU)

26. **「學習率」超參數在訓練神經網絡中嘅作用係咩？**
   - A) 決定模型預測新輸出嘅速度
   - B) 控制模型架構嘅大小
   - C) 影響訓練期間權重更新嘅幅度
   - D) 影響訓練模型所需嘅周期數

27. **以下哪項係通過隨機丟棄神經元來減少過度擬合嘅正則化技術？**
   - A) 批量標準化
   - B) Dropout
   - C) 隨機梯度下降
   - D) 權重衰減

28. **在「混淆矩陣」中，「True Positive」代表咩？**
   - A) 正確預測負例嘅數量
   - B) 正確預測正例嘅數量
   - C) 錯誤預測負例嘅數量
   - D) 錯誤預測正例嘅數量

29. **以下哪項係衡量模型預測序列中下一個詞元能力嘅指標？**
   - A) 精確率
   - B) 困惑度
   - C) 準確率
   - D) 召回率

30. **機器學習中哪種技術旨在結合多個模型以提升表現同穩定性？**
   - A) 集成方法
   - B) 遷移學習
   - C) 數據預處理
   - D) 數據增強

---

### **附加是非題：**

31. **生成對抗網絡 (GAN) 由相互競爭嘅生成器同判別器組成。**
   - 正確  
   - 錯誤

32. **在「因果語言建模」中，模型根據序列中所有先前詞元預測下一個詞元。**
   - 正確  
   - 錯誤

33. **精確率係真陽性預測與所有預測（包括假陽性）嘅比率。**
   - 正確  
   - 錯誤

34. **Batch Normalization 通過標準化層輸出幫助穩定深度網絡嘅訓練。**
   - 正確  
   - 錯誤

35. **Transformer 中「Positional Encoding」嘅目的係防止模型學習任何序列信息。**
   - 正確  
   - 錯誤

36. **神經網絡中嘅殘差連接通過讓梯度更易流動，有助緩解梯度消失問題。**
   - 正確  
   - 錯誤

37. **當模型在訓練數據上表現不佳但在新數據上表現良好時，就會發生模型過度擬合。**
   - 正確  
   - 錯誤

38. **聯邦學習在唔交換本地數據嘅情況下，跨分散式設備訓練模型。**
   - 正確  
   - 錯誤

---

### **附加簡答題：**

39. **「監督式學習」與「無監督式學習」有咩區別？**

40. **Transformer 模型中「Context Window」嘅作用係咩？**

41. **「遷移學習」應用於新任務時對模型有咩益處？**

42. **在「強化學習」中，獎勵函數在訓練智能體時扮演咩角色？**

43. **解釋「注意力機制」如何幫助提升像 GPT 這類語言模型嘅表現。**

44. **Transformer 中「Encoder-Decoder」架構與「因果語言建模」有咩區別？**

45. **NLP 任務中「向量嵌入」嘅功能係咩？**

46. **評估不平衡數據集時，「F1 Score」嘅重要性係咩？**

47. **「可解釋人工智能 (XAI)」在機器學習模型中旨在實現咩目標？**

48. **對數據有限嘅任務使用「Few-shot Learning」有咩優勢？**

---

這些附加題目將有助進一步評估使用者對機器學習、深度學習同 GPT 模型嘅理解！