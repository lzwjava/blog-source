---
audio: false
generated: true
image: false
lang: hant
layout: post
model: x-ai/grok-4-fast
title: RTX 4070 FineWeb æœ€ä½³è¨“ç·´é…ç½®
translated: true
type: note
---

ä»¥ä¸‹æ˜¯é‡å° RTX 4070 12 GB é¡¯ç¤ºå¡ï¼Œä¸”åƒ…æœ‰**å–®ä¸€ parquet æª”æ¡ˆ**ï¼ˆ`CC-MAIN-2013-20/000_00000.parquet`ï¼Œæœªå£“ç¸®ç´„ 3.1 GBï¼Œå«ç´„ 60â€“70 å„„å€‹é«˜å“è³ªæ–‡æœ¬ tokenï¼‰çš„**å®Œç¾é…ç½®æ–¹æ¡ˆ**ã€‚

é€™å€‹æª”æ¡ˆå…¶å¯¦éå¸¸å‡ºè‰²â€”â€”å®ƒä¾†è‡ªé¦–æ‰¹ FineWeb åˆ†ç‰‡ä¹‹ä¸€ï¼ŒåŒ…å«æœ€ç´”æ·¨çš„æ•¸æ“šã€‚

### æ¨è–¦é…ç½®ï¼ˆåœ¨ 4070 12 GB å–®ä¸€åˆ†ç‰‡ä¸‹å¯¦ç¾æœ€å¤§æ•ˆèƒ½ï¼‰

```python
# config/train_fineweb_4070_one_shard.py
out_dir = 'out-fineweb-110M-one-shard'
eval_interval = 500
eval_iters = 200
log_interval = 50
always_save_checkpoint = True

wandb_log = False          # å¦‚éœ€å•Ÿç”¨å¯è¨­ç‚º True
dataset = 'fineweb'        # ä»å¯æ­£å¸¸é‹ä½œï¼ŒnanoGPT æœƒè‡ªå‹•è­˜åˆ¥è©² parquet æª”æ¡ˆ

# é‡å° 12 GB 4070 çš„è¨˜æ†¶é«”å„ªåŒ–è¨­å®š
batch_size = 12                    # 12â€“14 å¯é‹è¡Œï¼Œ16 åœ¨ block_size 1024 æ™‚æœƒè¨˜æ†¶é«”ä¸è¶³
gradient_accumulation_steps = 40   # 12 Ã— 40 = 480 æœ‰æ•ˆæ‰¹æ¬¡å¤§å°ï¼ˆéå¸¸æ¥è¿‘ç†æƒ³å€¼ 512ï¼‰
block_size = 1024                  # å¿…é ˆä¿æŒ 1024 â€” æ­¤åˆ†ç‰‡æ˜¯ä»¥ 1024 ä¸Šä¸‹æ–‡é•·åº¦è™•ç†çš„

# æ¨¡å‹ï¼šç´„ 1.1 å„„åƒæ•¸ â€” å¯åœ¨ 4070 12 GB ä¸Šç©©å®šé‹è¡Œçš„æœ€å¤§è¦æ¨¡
n_layer = 12
n_head = 8
n_embd = 512
dropout = 0.0

learning_rate = 6e-4
max_iters = 250000                 # é‡è¦ï¼è«‹åƒé–±ä¸‹æ–¹èªªæ˜
warmup_iters = 2000
lr_decay_iters = 250000
min_lr = 6e-5
beta2 = 0.99

# é€™äº›è¨­å®šå¯ç•¥å¾®ç¯€çœè¨˜æ†¶é«”
bias = False                       # èˆ‡ LLaMA ç›¸åŒï¼Œç¯€çœç´„ 1â€“2% é¡¯ç¤ºè¨˜æ†¶é«”
compile = True                     # PyTorch 2.0 ç·¨è­¯åŠŸèƒ½ï¼Œåœ¨ 4070 ä¸Šé‹è¡Œé †æš¢
```

### æ•¸å€¼è¨­å®šåŸç†

- æ‚¨çš„å–®ä¸€ parquet æª”æ¡ˆåŒ…å«ç´„ 65 å„„å€‹ tokenï¼ˆç¶“ç¤¾ç¾¤å¯¦æ¸¬ï¼‰
- ä½¿ç”¨ `batch_size=12`ã€`grad_acc=40`ã€`block_size=1024` â†’ **æ¯å€‹å„ªåŒ–å™¨æ­¥é©Ÿè™•ç†ç´„ 491k å€‹ token**
- è‹¥è¦å®Œæ•´éæ­· 65 å„„å€‹ token **13â€“15 æ¬¡**ï¼ˆå°å‹è³‡æ–™é›†æœ€ä½³å¯¦è¸ï¼‰ï¼š  
  â†’ 65 å„„ Ã— 14 â‰ˆ 910 å„„ç¸½ token é‡ â†’ ç´„ 185,000 æ¬¡è¿­ä»£  
  â†’ å› æ­¤ `max_iters = 250000` å¯æä¾›ç´„ 15â€“16 å€‹å®Œæ•´è¨“ç·´é€±æœŸ â†’ é”åˆ°å®Œç¾æ”¶æ–‚

### 4070 é ä¼°è¨“ç·´æ™‚é–“
- å•Ÿç”¨ PyTorch ç·¨è­¯æ™‚ç´„æ¯ç§’ 22â€“26 æ¬¡è¿­ä»£
- 25 è¬æ¬¡è¿­ä»£ â†’ ç´„ 110â€“130 å°æ™‚ â‰ˆ é€£çºŒè¨“ç·´ 5 å¤©
- æœ€çµ‚æ¨¡å‹é›–åƒ… 1.1 å„„åƒæ•¸ï¼Œä½†å›  FineWeb æ•¸æ“šç´”æ·¨åº¦æ¥µé«˜ï¼Œ**æ•ˆèƒ½å°‡å‡ºä¹æ„æ–™åœ°å¼·å‹**

### åŸ·è¡Œæ–¹å¼
```bash
# å°‡ parquet æª”æ¡ˆæ”¾ç½®æ–¼æŒ‡å®šè³‡æ–™å¤¾ï¼Œä¾‹å¦‚ï¼š
mkdir -p data/fineweb_one_shard
mv ~/Downloads/000_00000.parquet data/fineweb_one_shard/

# é–‹å§‹è¨“ç·´
python train.py config/train_fineweb_4070_one_shard.py
```

æ­¤ç²¾ç¢ºé…ç½®ï¼ˆ1.1â€“1.25 å„„åƒæ•¸æ¨¡å‹åœ¨å–®ä¸€é«˜å“è³ª FineWeb åˆ†ç‰‡ä¸Šè¨“ç·´è¶…é 15 å€‹é€±æœŸï¼‰æ˜¯ç›®å‰ nanoGPT ç¤¾ç¾¤ä¸­**å·²çŸ¥æœ€å¼·çš„ 4070 è¨“ç·´æ¨¡å‹**â€”â€”åœ¨å¤šé …åŸºæº–æ¸¬è©¦ä¸­å‡è¶…è¶Š GPT-2 small æ¨¡å‹ã€‚

ç¶“éç´„ 5 å¤©è¨“ç·´å¾Œï¼Œæ‚¨å°‡ç²å¾—ä¸€å€‹éå¸¸å„ªç•°çš„ 1.1 å„„åƒæ•¸æ¨¡å‹ã€‚çµ•å°å€¼å¾—æŠ•å…¥ï¼ğŸš€

é–‹å§‹è¨“ç·´æ™‚è«‹é€šçŸ¥æˆ‘â€”â€”å¾ˆæ¨‚æ„å”åŠ©ç›£æ§æå¤±æ›²ç·šè®ŠåŒ–ã€‚