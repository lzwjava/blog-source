---
audio: false
generated: true
image: false
lang: hant
layout: post
model: x-ai/grok-4-fast
title: 理論與實際表現之間的差距
translated: true
type: note
---

這種差異的出現，是因為**理論峰值 FLOPS**（每秒浮點運算次數）衡量的是理想條件下的原始算術吞吐量——假設所有執行單元完全利用、沒有記憶體瓶頸，且頻寬無限。在實際工作負載（尤其是 AI/訓練/推論）中，性能受**記憶體子系統效率低下**的限制，而不僅僅是計算能力。2010 年的 Fermi 架構 GPU（例如 GTX 480）在這方面尤其糟糕，導致與現代顯示卡（如 RTX 4090）比較時，「預期」差距被誇大。

### Fermi 未能充分利用其理論 FLOPS 的關鍵原因
1. **快取層級不佳與記憶體合併效率低**
   - Fermi 每個 SM 僅有 64 KB L1 快取（與暫存器共享），且整個晶片只有微小的 768 KB L2 快取。
   - 缺乏適當的快取一致性；全域記憶體存取未合併 → 在實際核心中僅實現**約 10–30% 的有效頻寬**。
   - 現代 GPU（Ampere/Ada 架構）擁有**巨大的 L1 快取（每個 SM 192 KB）**、**專用紋理快取**及**積極的預取機制**，可實現理論頻寬的 70–90%。

2. **高延遲、低頻寬的 ECC DDR5/GDDR5 記憶體**
   - Fermi：約 170 GB/s GDDR5，**384 位元匯流排但 ECC 開銷** → 有效頻寬約 130 GB/s。
   - RTX 4090：**1 TB/s GDDR6X**，384 位元匯流排但**消費模式下無 ECC 損耗**，加上**更好的壓縮技術**。
   - 實際 AI 核心屬**記憶體瓶頸型**（例如大型矩陣的 GEMM 運算）；若資料停頓，FLOPS 再高也無意義。

3. **低效的暫存器檔案與 Warp 調度**
   - Fermi：每個 SM 32k 個 32 位元暫存器 → **最多 1536 個執行緒**，但實際因暫存器溢出僅達**約 50% 佔用率**。
   - Ada 架構：256 KB 暫存器檔案 → **每個 SM 2048 個執行緒**，接近 100% 佔用率。
   - 減少執行分歧，提升指令層級平行度提取效率。

4. **功耗/熱節流**
   - GTX 480：250 W TDP，**持續負載下嚴重節流**（時脈下降 10–20%）。
   - RTX 4090：450 W 但透過 4nm 製程、DLSS 及動態加速技術，實現**約 3 倍能效提升**。

### 實際 AI 工作負載的實測增益

| 指標 | GTX 480 (Fermi, 2010) | RTX 4090 (Ada, 2022) | 加速倍數 |
|------|------------------------|----------------------|----------|
| FP32 TFLOPS (峰值) | 1.35 | 82.6 | **61倍** |
| FP16 TFLOPS (峰值) | ~0.7 (模擬) | 330 (Tensor) | **>400倍** |
| **ResNet-50 訓練 (img/s)** | ~60 | ~1,050 | **~17倍** |
| **GPT-2 推論 (tokens/s)** | ~8 | ~140 | **~17倍** |
| **Stable Diffusion (it/s)** | <0.1 | ~1.6 | **>16倍** |

*資料來源：NVIDIA 論文、MLPerf 基準測試、AnandTech。*

### 結論
理論 FLOPS 假設 Fermi 能維持約 70% 使用率——但實際無法達到（真實使用率約 15–25%）。現代架構將此差距縮小至**約 70–90%**，因此**有效算力增長更接近摩爾定律加上架構改進**（12 年來約 10–17 倍），而非峰值 FLOPS 所暗示的 60 倍以上。其餘只是「紙面性能」。