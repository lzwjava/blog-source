---
audio: false
generated: true
lang: hant
layout: post
title: 線性代數附加筆記
translated: true
type: note
---

在線性代數中，兩個方陣 \\( A \\) 和 \\( B \\) 被稱為相似矩陣，若存在一個可逆矩陣 \\( P \\) 使得：

\\[ B = P^{-1}AP \\]

這種關係稱為相似變換。矩陣 \\( P \\) 稱為基變換矩陣，它將矩陣 \\( A \\) 轉換為矩陣 \\( B \\)。

### 相似矩陣的關鍵性質：
1. **相同特徵值**：相似矩陣具有相同的特徵值，因為特徵值在相似變換下保持不變。
2. **相同行列式**：相似矩陣的行列式相同，因為 \\(\det(P^{-1}AP) = \det(A)\\)。
3. **相同跡**：相似矩陣的跡（對角線元素之和）相同，因為 \\(\text{tr}(P^{-1}AP) = \text{tr}(A)\\)。
4. **相同秩**：相似矩陣具有相同的秩。
5. **相同特徵多項式**：相似矩陣共享相同的特徵多項式。

### 直觀理解：
相似矩陣代表相同的線性變換，但處於不同的基中。矩陣 \\( P \\) 可視為座標變換，改變了線性變換所表示的基。

### 範例：
考慮兩個矩陣 \\( A \\) 和 \\( B \\)：

\\[ A = \begin{pmatrix} 1 & 2 \\ 0 & 3 \end{pmatrix}, \quad B = \begin{pmatrix} 3 & 0 \\ 2 & 1 \end{pmatrix} \\]

要檢查它們是否相似，我們需要找到一個可逆矩陣 \\( P \\) 使得 \\( B = P^{-1}AP \\)。

您是否想查看如何為特定矩陣 \\( A \\) 和 \\( B \\) 尋找此類矩陣 \\( P \\) 的範例？

---

是的，矩陣：

\\[
A = \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix}
\\]

確實具有奇異值分解（SVD）。讓我們逐步找出該矩陣的 SVD。

### 步驟 1：計算 \\( A^T A \\)

首先，我們計算矩陣 \\( A^T A \\)：

\\[
A^T = \begin{bmatrix} 1 & 3 \\ 2 & 4 \end{bmatrix}
\\]

現在，將 \\( A^T \\) 和 \\( A \\) 相乘：

\\[
A^T A = \begin{bmatrix} 1 & 3 \\ 2 & 4 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} = \begin{bmatrix} 1 + 9 & 2 + 12 \\ 2 + 12 & 4 + 16 \end{bmatrix} = \begin{bmatrix} 10 & 14 \\ 14 & 20 \end{bmatrix}
\\]

### 步驟 2：\\( A^T A \\) 的特徵值和特徵向量

為了找到奇異值，我們需要 \\( A^T A \\) 的特徵值。我們求解特徵方程 \\( \text{det}(A^T A - \lambda I) = 0 \\)：

\\[
\text{det}\begin{bmatrix} 10 - \lambda & 14 \\ 14 & 20 - \lambda \end{bmatrix} = 0
\\]

這給出：

\\[
(10 - \lambda)(20 - \lambda) - 14 \times 14 = 0
\\]

\\[
\lambda^2 - 30\lambda + 100 - 196 = 0
\\]

\\[
\lambda^2 - 30\lambda - 96 = 0
\\]

解此二次方程：

\\[
\lambda = \frac{-(-30) \pm \sqrt{(-30)^2 - 4(1)(-96)}}{2(1)} = \frac{30 \pm \sqrt{900 + 384}}{2} = \frac{30 \pm \sqrt{1284}}{2}
\\]

\\[
\lambda = \frac{30 \pm 35.86}{2}
\\]

因此，特徵值為：

\\[
\lambda_1 \approx 32.93 \quad \text{和} \quad \lambda_2 \approx 0.93
\\]

### 步驟 3：計算奇異值

奇異值是 \\( A^T A \\) 特徵值的平方根。因此，我們有：

\\[
\sigma_1 = \sqrt{32.93} \approx 5.73 \quad \text{和} \quad \sigma_2 = \sqrt{0.93} \approx 0.96
\\]

### 步驟 4：計算矩陣 \\( U \\) 和 \\( V \\)

為了找到矩陣 \\( U \\) 和 \\( V \\)，我們需要計算 \\( A^T A \\) 和 \\( A A^T \\) 的特徵向量，但由於這需要超出基本計算的詳細步驟，通常會以數值方式求解。

然而，基於上述特徵值，我們知道奇異值為 \\( 5.73 \\) 和 \\( 0.96 \\)，而 \\( U \\) 和 \\( V \\) 將是對應於 \\( A A^T \\) 和 \\( A^T A \\) 特徵向量的正交矩陣。

因此，矩陣 \\( A \\) 的 SVD 為：

\\[
A = U \Sigma V^T
\\]

其中：

- \\( \Sigma = \begin{bmatrix} 5.73 & 0 \\ 0 & 0.96 \end{bmatrix} \\)
- \\( U \\) 和 \\( V \\) 是對應於 \\( A A^T \\) 和 \\( A^T A \\) 特徵向量的正交矩陣。

您可以通過求解 \\( A^T A \\) 和 \\( A A^T \\) 的特徵值問題來找到 \\( U \\) 和 \\( V \\) 的精確值。

---

該陳述描述了矩陣作為線性變換的行為。讓我們分解理解為何會發生這種情況：

### 矩陣作為線性變換：
- **輸入空間**：該矩陣作用於來自 3 維空間的向量（因為它有 3 列）。這意味著它接受 3 分量向量作為輸入。
- **輸出空間**：該矩陣將這些向量映射到 2 維空間（因為它有 2 行）。這意味著它產生 2 分量向量作為輸出。

### 零空間：
- **定義**：矩陣的零空間（或核）由所有乘以該矩陣後得到零向量的向量組成。
- **維度**：矩陣的零度是此零空間的維度。在此情況下，零度為 1，意味著存在一個 1 維子空間的向量被映射到零。
- **解釋**：此 1 維子空間代表（在 3 維輸入空間中）一條直線上的向量，這些向量在 2 維輸出空間中被「壓縮」或「坍縮」為零向量。

### 為何發生這種情況：
- **秩-零度定理**：該定理指出，對於任何 \\(m \times n\\) 矩陣，秩（列空間的維度）加上零度（零空間的維度）等於列數 \\(n\\)。這裡，秩為 2，列數為 3，因此零度必須為 1。
- **線性相關性**：存在維度為 1 的零空間表明矩陣的列之間存在某種冗餘或線性相關性。這意味著其中一列可以表示為其他兩列的線性組合。

### 視覺化：
- 設想一個 3D 空間，其中特定直線（零空間）上的所有點都被映射到 2D 空間中的原點。這條直線代表被矩陣定義的變換「遺失」或「忽略」的向量。

這種行為是線性變換的基本面向，並突顯了矩陣如何降低它們所作用空間的維度。

---

為了確定哪個選項是矩陣可對角化的必要條件，我將檢查每個陳述。

一個方陣 A 可對角化，若且唯若存在一個可逆矩陣 P，使得 P⁻¹AP 是一個對角矩陣。這恰好發生在 A 具有一組完整的線性獨立特徵向量時。

讓我們分析每個選項：

a) 矩陣必須至少有一個特徵值。
雖然所有 n×n 矩陣（在複數域中）至少有一個特徵值，但僅此並不能保證可對角化。一個矩陣可能具有特徵值，但如果沒有足夠的線性獨立特徵向量，仍然不可對角化。

b) 矩陣必須具有相異的特徵值。
具有相異特徵值是充分但非必要條件。具有重複特徵值的矩陣，如果與那些重複特徵值相關聯有足夠的線性獨立特徵向量，仍然可以對角化。

c) 矩陣必須有足夠的線性獨立特徵向量。
這正是可對角化的必要且充分條件。具體來說，一個 n×n 矩陣可對角化，若且唯若它具有 n 個線性獨立特徵向量，形成向量空間的一組基。

因此，選項 c) 是正確答案：一個矩陣可對角化，若且唯若它具有足夠的線性獨立特徵向量。