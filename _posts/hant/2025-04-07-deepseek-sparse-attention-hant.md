---
audio: false
generated: true
image: false
lang: hant
layout: post
model: anthropic/claude-4.5-sonnet
title: DeepSeek 稀疏注意力機制詳解
translated: true
type: note
---

現在我已經掌握了關於 DeepSeek-V3.2-Exp 中 DeepSeek 稀疏注意力（DSA）的全面資訊。讓我提供詳細說明。

## DeepSeek-V3.2-Exp 中的 DeepSeek 稀疏注意力（DSA）

DeepSeek 稀疏注意力（DSA）是 DeepSeek-V3.2-Exp 模型中引入的一種新穎的細粒度稀疏注意力機制，代表了大型語言模型高效長上下文處理的重大進步。**DSA 首次實現了細粒度稀疏注意力，在保持幾乎相同的模型輸出質量的同時，大幅提升了長上下文訓練和推理效率**[1]

## 核心架構：雙組件系統

DSA 由兩個主要組件組成，共同協作實現高效稀疏注意力：[2]

### 1. **閃電索引器**

閃電索引器是一種快速、輕量級的評分機制，能夠迅速評估歷史令牌對當前查詢的重要性。**索引器為每個令牌保留一個 128 維的小型鍵快取**[3]（與傳統注意力中使用的完整鍵值快取相比）。

**工作原理：**
- 閃電索引器計算當前查詢令牌與序列中所有先前令牌的相關性分數
- 它使用壓縮的鍵表示（128 維而非完整維度鍵）來大幅減少記憶體和計算需求
- **儘管閃電索引器仍然具有 O(L²) 的複雜度，但與主要注意力機制相比，它所需的計算量要少得多**[4]
- 索引器快速按重要性對令牌進行排名，並識別前 K 個最相關的令牌

**關鍵優勢：** 索引器充當輕量級的「預過濾器」，能夠快速掃描長上下文，而無需承擔完整注意力計算的計算負擔。

### 2. **細粒度令牌選擇機制**

在閃電索引器識別出重要令牌後，細粒度選擇機制執行實際的稀疏注意力計算：

- 只有前 K 個最相關的令牌（由索引器確定）會接受完整的注意力計算
- 這種選擇性處理將注意力計算從 O(n²) 大幅減少到大約 O(nk)，其中 k 是選定令牌的數量（遠小於 n）
- **DSA 用選擇性處理取代了暴力方法，使用 DeepSeek 所稱的「閃電索引器」來快速對過往令牌進行評分，並識別每個查詢最重要的令牌**[2]

## 數學複雜度降低

傳統注意力機制需要計算每個令牌與所有其他令牌之間的關係，導致 O(n²) 的計算複雜度。**DeepSeek 稀疏注意力（DSA）將核心注意力複雜度從 O(L²) 降低到 O(Lk)，其中 k 是選定令牌的數量（遠小於 L）**[4]

這代表了注意力計算方式的根本轉變：
- **傳統完整注意力：** 每個查詢關注每個鍵值對 → O(n²)
- **DSA 稀疏注意力：** 每個查詢僅關注前 K 個最相關的對 → O(nk)
- 由於 k << n（k 通常是一個小常數或增長速度遠慢於 n），這實現了近線性擴展

## 與多潛在注意力（MLA）的整合

DSA 與 DeepSeek 在 V3 模型中使用的現有多潛在注意力（MLA）架構整合。稀疏注意力機制在 MLA 的壓縮鍵值表示之上運行，創建了一個兩階段壓縮策略：

1. **第一階段（MLA）：** 將鍵值表示壓縮到低維潛在空間中
2. **第二階段（DSA）：** 通過僅選擇最相關的令牌進行關注來進一步減少計算

這種雙重壓縮實現了單一技術無法達到的效率提升。[3]

## 性能和效率提升

DSA 在多個維度上帶來了顯著的效率改進：

### **速度提升：**
- 長文本處理的推理速度**提升 2-3 倍**[2]
- 訓練和推理階段的顯著加速
- 對於超過 32K 令牌的序列尤其有效

### **記憶體減少：**
- 由於壓縮的索引器鍵（128 維），鍵值快取需求更小
- 僅為選定的令牌存儲完整注意力
- 在相同的記憶體預算內實現更長上下文的處理

### **成本降低：**
效率提升直接轉化為顯著的成本降低。**API 定價降低了超過 50%，輸入成本低至每百萬令牌 0.07 美元（快取命中）**[5]

**新的 API 定價：**
- 輸入：每百萬令牌 0.14 美元（標準），每百萬令牌 0.07 美元（快取命中）
- 輸出：每百萬令牌 0.42 美元
- 這與 V3.1-Terminus 相比，**降低了 50% 以上**[6]

成本降低來自兩個因素：
1. 稀疏注意力機制大幅降低了計算成本
2. 引入快取機制減少了冗餘計算[5]

## 性能保持

DSA 的一個關鍵成就是在實現效率提升的同時保持了模型質量。DeepSeek-V3.2-Exp 使用與 V3.1-Terminus 相同的配置進行訓練，以嚴格評估稀疏注意力的影響。

**基準測試結果：**[1]

| 基準測試 | V3.1-Terminus | V3.2-Exp (DSA) |
|-----------|--------------|----------------|
| MMLU-Pro | 85.0 | 85.0 |
| GPQA-Diamond | 80.7 | 79.9 |
| LiveCodeBench | 74.9 | 74.1 |
| AIME 2025 | 88.4 | 89.3 |
| HMMT 2025 | 86.1 | 83.6 |

結果顯示，**V3.2-Exp 在公共基準測試中表現出與 V3.1-Terminus 相當的性能**[1]，部分任務甚至顯示出改進。稀疏注意力機制經過精心設計，以保留最重要的注意力連接，因此對輸出質量的影響微乎其微。

## DSA 與其他稀疏注意力方法的區別

### **細粒度 vs. 粗粒度：**
大多數先前的稀疏注意力方法使用粗粒度模式（固定模式、局部窗口、跨步注意力）。DSA 通過根據內容相關性動態學習關注哪些特定令牌，實現了**細粒度**稀疏性。

### **學習式選擇：**
與固定的稀疏模式不同，DSA 通過閃電索引器學習重要性評分，允許適應性注意力模式響應實際的語義關係。

### **硬件優化：**
DSA 從頭開始設計，旨在在現代 GPU 硬件上高效運行，這與一些顯示理論增益但實際加速有限的稀疏方法不同。

### **可訓練稀疏性：**
稀疏注意力模式在訓練期間學習（原生可訓練），不僅僅在推理時應用，從而實現更好的優化。

## 技術實現

DSA 的實現需要專門的 CUDA 內核以獲得最佳性能：

- 用於快速前 K 選擇的**索引器內核**（在 DeepGEMM 中可用）
- 用於在選定令牌上高效計算的**稀疏注意力內核**（在 FlashMLA 中可用）
- 支持分頁注意力以實現記憶體效率
- 與現有推理框架（vLLM、SGLang）整合[1]

## 使用案例和優勢

DSA 在以下場景中表現尤為出色：

1. **長上下文處理**（64K+ 令牌）：文檔分析、代碼理解、多輪對話
2. **高吞吐量應用**：成本和速度至關重要的場景
3. **記憶體受限的部署**：鍵值快取大小成為瓶頸的場景
4. **實時應用**：推理延遲重要的場景

## 戰略意義

**DeepSeek-V3.2-Exp 是邁向下一代架構的中間步驟**[1]，特別為 DeepSeek-V4 奠定了基礎。實驗性發布允許 DeepSeek：

- 大規模驗證稀疏注意力機制
- 收集實際性能數據
- 在全面部署前完善方法
- 測試與生產系統的整合

## 限制和注意事項

雖然 DSA 提供了顯著優勢，但有一些注意事項：

1. **複雜性：** 實現比標準注意力更複雜
2. **短序列的開銷：** 對於非常短的上下文，索引器的開銷可能不值得
3. **近似權衡：** 雖然質量得以保持，但理論上可能存在一些信息損失
4. **硬件要求：** 需要優化的內核以獲得最佳性能

## 未來影響

DSA 代表了 LLM 架構的一個重要演進方向。通過證明選擇性注意力可以在保持質量的同時顯著提高效率，它開啟了以下可能性：

- 處理更長的上下文（100 萬+ 令牌）
- 更實惠的 AI 服務
- 在較低性能硬件上的部署
- 複雜文檔的實時處理

該技術使 DeepSeek 在與其他前沿模型的競爭中具有優勢，同時顯著降低了運營成本，可能顛覆 AI API 市場的定價結構。[7]

總之，DeepSeek 稀疏注意力（DSA）是一種複雜的兩階段機制，結合了用於快速令牌重要性評分的輕量級閃電索引器和細粒度選擇性注意力計算。它在保持模型質量的同時實現了顯著的效率提升（50%+ 成本降低，2-3 倍速度提升），代表了使長上下文 LLM 實用且經濟可行的重大進步。

引用：
[1] https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp
[2] https://medium.com/@Techsankar381/deepseek-halves-ai-tooling-costs-with-breakthrough-sparse-attention-model-3840fb61a4e0
[3] https://x.com/vllm_project/status/1972617272901644345
[4] https://blogs.novita.ai/deepseek-v3-2-exp-on-novita-ai/
[5] https://dev.to/czmilo/deepseek-v32-exp-complete-analysis-2025-ai-model-breakthrough-and-in-depth-analysis-of-sparse-3gcl
[6] https://api-docs.deepseek.com/news/news250929
[7] https://www.implicator.ai/deepseek-cuts-inference-costs-by-10x/