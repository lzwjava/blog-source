---
audio: false
generated: true
lang: hant
layout: post
title: 電腦視覺仍不及人類
translated: true
type: note
---

王垠的博客文章指出，即使是在2019年的先進電腦視覺系統，距離實現人類水平的性能仍相當遙遠。該文主張這些系統在基礎物體識別（例如辨識汽車）方面表現掙扎，且容易對抗性樣本或輕微圖像變更所誤導，而人類卻能輕鬆識別物體。王垠認為該領域過度誇大進展，由於這些系統處理和理解圖像的根本局限性，真正的人類水平電腦視覺仍然難以實現。

### 這說法屬實嗎？
截至該文章於2019年10月發表時，王垠的論點基於當時電腦視覺的發展狀況確實有其道理：

- **有限的泛化能力**：電腦視覺模型（如卷積神經網絡）高度依賴訓練數據中的模式匹配。它們往往難以泛化到新情境或妥善處理邊緣案例，正如王垠所描述。例如當光照、角度或背景發生顯著變化時，模型可能錯誤分類物體。

- **對抗性攻擊的脆弱性**：王垠關於對抗性樣本（經細微修改誤導模型的圖像）的觀點是準確的。如Goodfellow等人（2014）的研究顯示，微小難以察覺的擾動就能導致模型以高置信度錯誤分類圖像，凸顯人類與機器視覺間的差距。

- **過度誇大的聲明**：該文章批評了圍繞電腦視覺的炒作。在2019年，儘管ResNet、YOLO及早期transformer等模型在基準測試（如ImageNet）中表現出色，但這些都是受控數據集。實際應用常暴露弱點，例如自動駕駛或人臉識別系統中的錯誤識別。

然而該文章的語氣過於絕對，斷言「不存在人類水平的電腦視覺」，這忽略了特定任務的進展。例如：
- **特定任務的成功**：截至2019年，電腦視覺系統在狹義任務中已超越人類，例如分類特定醫學影像（如檢測糖尿病視網膜病變）或在受控環境中識別特定物體。
- **2019年後的進展**：到2025年，視覺transformer（如ViT、CLIP）與大規模多模態模型（如GPT-4o、DALL·E 3）等進展已縮小差距。這些模型能處理更多元輸入，更好地跨情境泛化，並整合語言與視覺以提升推理能力。但它們仍未能完全複製人類視覺的穩健性、情境意識或直覺理解。

### 關鍵評估
王垠的核心主張——2019年的電腦視覺未達人類水平——大體屬實。當時的模型缺乏人類視覺的泛化能力、穩健性及直覺理解。然而他對進展的否定可能過於悲觀，因為此後該領域已取得重大突破。即使在2025年，雖然電腦視覺在特定領域表現卓越，但在開放世界場景中仍不及人類感知水平，原因包括：
- **情境推理**：人類能輕鬆整合感官數據與世界知識；機器在此方面表現掙扎。
- **邊緣案例**：模型在罕見或新穎情境中可能失敗，而人類能快速適應。
- **能源效率**：人類視覺遠比計算模型更節能。

這篇文章作為對過度炒作AI能力的批判仍然具有參考價值，但未充分考量該領域的快速發展。截至2025年，尚無單一來源確認已實現「人類水平」視覺，但兩者間的差距已顯著縮小。[](https://yinwang0.wordpress.com/2019/10/20/human-level-computer-vision/)