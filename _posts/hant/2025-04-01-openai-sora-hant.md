---
audio: false
generated: true
lang: hant
layout: post
title: OpenAI 嘅 Sora
translated: true
type: note
---

雖然 OpenAI 尚未發布關於 Sora 架構的詳細技術論文，但我們可以根據其公告以及生成式 AI（特別是文字轉圖像和影片生成領域）的整體進展，推斷其運作原理。以下是關鍵概念的解析：

**1. 擴散轉換器模型：**

* OpenAI 將 Sora 描述為**擴散轉換器**。這意味著它結合了兩種強大 AI 架構的優勢：
    * **擴散模型：** 這些模型透過逆轉噪點過程來學習生成數據。它們從隨機噪點開始，經過多個步驟逐漸細化，以產生符合給定提示的真實圖像或影片幀。可以想像成從靜電干擾開始，逐漸看到畫面浮現。
    * **轉換器網絡：** 轉換器最初是為自然語言處理而設計，擅長理解數據序列中的上下文和關係。在 Sora 的案例中，「序列」不是文字，而是跨空間和時間的一系列視覺修補程式或標記。

**2. 修補程式與標記：**

* 類似於大型語言模型將文字分解為標記的方式，Sora 很可能將影片分解為稱為**修補程式**的較小單位。對於影片而言，這些修補程式很可能是 3D 的，同時包含空間資訊（單一幀內）和時間資訊（跨多個幀）。
* 這些修補程式隨後被視為標記序列，由轉換器網絡進行處理。這使得模型能夠理解影片的不同部分隨時間的相互關係，對於生成連貫的動作和長距離依賴性至關重要。

**3. 文字轉影片生成過程：**

* **文字提示：** 過程始於用戶提供所需影片的文字描述。
* **理解提示：** Sora 利用其訓練所得的語言理解能力來解讀提示的細微差別和細節。這可能涉及類似於 DALL-E 3 所使用的技術，即對提示進行改寫或擴充以包含更具體的細節。
* **生成潛在空間表示：** 模型很可能將文字提示轉譯為較低維度「潛在空間」中的表示。這個空間捕捉了影片的本質。
* **在潛在空間中去噪：** 擴散過程在此潛在空間中開始。Sora 從帶有噪點的修補程式開始，並在文字提示及其訓練數據中學習到的模式引導下，迭代地對其進行去噪。轉換器架構有助於確保去噪過程在空間和時間上保持一致。
* **影片解壓縮：** 一旦在潛在空間中完成去噪過程，所得的表示會被「解碼」回一系列影片幀。

**4. 關鍵能力與技術：**

* **時間一致性：** 影片生成中的一個重大挑戰是在多個幀之間保持物件和場景的一致性。透過使用轉換器將影片作為時空修補程式序列進行處理，Sora 能夠更好地理解並保持這種一致性。
* **處理動作和攝影機移動：** Sora 已展現出生成具有複雜攝影機移動和真實物件動作的影片的卓越能力。這表明其架構能夠有效模擬視覺世界的動態。
* **理解 3D：** OpenAI 提到，Sora 似乎從其訓練數據中學會了如何生成 3D 內容，即使提示中沒有明確的 3D 資訊。這暗示了其對空間關係的深刻理解。
* **重新標記：** 與 DALL-E 3 類似，Sora 很可能使用稱為重新標記的技術來提高生成影片的保真度。這涉及使用影片轉文字模型為訓練影片創建詳細的標題，從而幫助文字轉影片模型更有效地學習。

**5. 訓練數據：**

* Sora 是在包含影片及可能帶有相應文字說明的圖像所組成的大規模數據集上進行訓練的。這些數據的規模和多樣性對於模型生成真實且多樣化影片內容的能力至關重要。OpenAI 提到使用了公開可用的影片以及經授權的版權影片進行訓練。

**本質上，Sora 利用擴散模型的力量來生成高品質的視覺內容，並借助轉換器架構來理解和模擬影片的時間動態。透過將影片分解為可管理的修補程式並將其作為序列處理，Sora 能夠從文字提示生成連貫、真實且富有想像力的影片片段。**

請注意，這是基於目前可用資訊的高層次解釋。OpenAI 未來可能會透露更多技術細節。