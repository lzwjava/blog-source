---
audio: false
generated: true
image: false
lang: hant
layout: post
title: 安全大型語言模型應用程式介面驗證層
translated: true
type: note
---

當你建立或使用 **LLM API** 時，通常需要設置防護措施以確保回應是安全、有效且實用的。以下是添加檢查的主要方式：

---

### 1. **輸入驗證**

* **結構檢查**：在發送給 LLM 前，確保請求的 JSON 符合預期結構。
* **提示清理**：移除或跳脫不必要的字符、惡意指令或注入嘗試。
* **長度檢查**：強制執行輸入的最大 token/字符限制，避免不必要的成本或截斷。

---

### 2. **輸出驗證**

* **JSON 結構驗證**：若 LLM 應返回 JSON，請透過 `json.loads()` 執行並使用結構驗證（例如使用 `pydantic`、`jsonschema`）。
* **正則表達式/格式檢查**：針對電子郵件、URL 或數字強制執行格式模式。
* **類型檢查**：驗證欄位是否為正確類型（字串、整數、列表等）。
* **範圍檢查**：確保數值或日期值在預期範圍內。

---

### 3. **安全性與內容檢查**

* **毒性或不當語言過濾器**：透過分類器處理輸出（例如 Perspective API、OpenAI 審核 API）。
* **政策過濾器**：定義規則以封鎖包含特定關鍵字或類別的回應。
* **幻覺檢測**：添加事實核查步驟（透過檢索增強檢查、多模型交叉驗證或基於規則的合理性檢查）。

---

### 4. **業務邏輯約束**

* **一致性規則**：若回應必須符合系統數據（例如可用帳戶餘額、配置值），在返回給用戶前進行交叉驗證。
* **防護機制**：使用如 **Guardrails AI**、**LMQL** 或 **Instructor** 等函式庫，以聲明式強制執行結構化輸出和約束。
* **後處理鉤子**：使用自定義邏輯包裝 LLM 回應（標準化大小寫、強制預設值、拒絕意外答案）。

---

### 5. **冗餘與交叉驗證**

* **自我檢查提示**：要求 LLM 重新驗證或解釋其自身的答案。
* **雙模型檢查**：使用較小/較快的 LLM 來驗證主模型的輸出（例如「此回應是否符合結構 X？」）。
* **投票/共識機制**：執行多次呼叫並比較答案以確保穩定性。

---

### 6. **操作防護措施**

* **速率限制**：防止 API 被濫用。
* **超時設置**：中止停滯的請求。
* **記錄與審計追踪**：保留請求和過濾回應的記錄。
* **後備方案**：若驗證失敗，可調整提示後重試，或返回安全的預設值/錯誤。

---

👉 實務上，一個良好的 LLM API 堆疊會分層實施這些措施：

1. 驗證輸入。
2. 呼叫 LLM。
3. 根據結構和業務規則驗證輸出。
4. 執行安全性和內容過濾。
5. 僅在檢查通過時返回（否則重試/使用後備方案）。

---

需要我展示一個 **Python 範例**，示範如何用 JSON 結構驗證和審核檢查來封裝 LLM API 呼叫嗎？