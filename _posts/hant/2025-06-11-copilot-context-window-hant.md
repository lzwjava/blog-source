---
audio: false
generated: true
lang: hant
layout: post
title: Copilot 上下文視窗解決方案
translated: true
type: note
---

你在使用 Copilot 這類 IDE 中的 AI 模型時提到了一個關鍵問題：上下文窗口的限制。雖然 4096 個 token 對於大型程式碼庫或複雜問題來說可能顯得不足，但確實存在解決方法和重要考量。

首先，讓我們釐清 Copilot 和 GPT-4o 的上下文：

* **Copilot 和 GPT-4o 上下文窗口：** 雖然 4096 個 token 是早期模型常見的上下文窗口大小，但 **GitHub Copilot Chat（在 VS Code 和 JetBrains IDE 中）現在提供了顯著更大的上下文窗口，通常利用 GPT-4o（甚至更新模型如 GPT-4.1），最高可達 64k 甚至 128k 個 token（特別是 VS Code Insiders 版本）**。這是一項重大改進，使得處理較大檔案和更複雜問題變得更加可行。

然而，即使有更大的上下文窗口，你仍然會遇到限制，尤其是在處理龐大程式碼庫或高度詳細的日誌/問題時。因此，你提出的解決方法非常相關：

### 上下文長度限制的解決方法：

1.  **拆分任務並提供聚焦的上下文（你的建議）：** 這是一個極佳且高效的策略。
    * **「這裡是程式碼，這裡是日誌，這裡是問題」**：這正是你應該做的。與其傾倒所有內容，不如篩選資訊。
        * **程式碼：** 僅提供與問題最相關的程式碼片段或檔案。如果是特定函數，只需包含該函數及其直接依賴項。
        * **日誌：** 從日誌中提取指示錯誤或異常行為的關鍵行。不要提供數百萬位元組的日誌檔案。
        * **問題描述：** 清晰、簡潔且精確地描述問題。說明你的預期、實際發生的情況以及任何特定的錯誤訊息。
    * **好處：** 通過縮小焦點，你能確保最重要的資訊符合 Copilot 的活動上下文窗口，從而獲得更加準確和相關的建議。

2.  **多輪對話（你的建議） - 是的，Copilot 會使用先前的對話：**
    * **在 VS Code 和 JetBrains IDE（Copilot Chat）中：** 絕對如此。聊天界面專為多輪對話設計。Copilot 會記住當前聊天會話中的先前對話輪次，並將其作為持續上下文的一部分。這對於完善解決方案和迭代問題至關重要。
    * **運作方式：** 當你在同一聊天線程中提出後續問題或提供額外資訊時，Copilot 會隱含地考慮你之前的提示及其自身的回應，以生成更具參考價值的回覆。
    * **多輪對話策略：**
        * **由廣至深：** 從一般性問題陳述開始，然後根據 Copilot 的初步建議，在後續對話中提供更具體的細節或相關程式碼/日誌。
        * **細化與澄清：** 如果 Copilot 的首次回應不盡正確，請不要重新開始。相反，告訴它哪裡不對，或者它需要考慮哪些額外限制。
        * **請求具體操作：** 「現在，將此修復應用到檔案 X」，或「你能為此情境也生成一個測試案例嗎？」

### 其他解決方法與提示：

* **利用 `@workspace` 和 `#file`：**
    * **`@workspace`：** 在 Copilot Chat（特別是 VS Code）中，你可以使用 `@workspace` 來告訴 Copilot 考慮你整個工作區中的相關檔案。雖然它不會攝取*整個*程式碼庫，但它會根據你的提示和當前檔案，智能地檢索並注入它認為相關的檔案片段。這對於較大的專案來說是一個強大的功能。
    * **`#file <filename>`：** 你可以使用 `#file` 在提示中明確引用特定檔案。這確保了這些檔案被包含在該特定查詢的上下文中。
* **總結大型輸入：** 如果你有一個非常長的相關日誌或文件但無法放入上下文，可以請 Copilot（或另一個 LLM）先對其進行總結，然後使用該總結作為上下文。
* **聚焦於「原因」：** 與其僅提供程式碼，不如解釋你*為什麼*認為存在問題或目標是什麼。這有助於 Copilot 理解意圖，即使它無法看到所有周邊程式碼。
* **分解複雜問題：** 對於大型錯誤修復或新功能，不要要求 Copilot 一次完成所有工作。將其分解為較小、可管理的子任務。例如：
    1.  「解釋此函數中的問題。」
    2.  「建議對此部分進行重構。」
    3.  「為重構後的程式碼生成單元測試。」
* **使用描述性變數/函數名稱：** 雖然這不是針對 token 限制的直接解決方法，但命名良好的變數和函數能為 Copilot 提供隱含的上下文，即使在有限顯式上下文的情況下也能使其建議更加準確。
* **儲存庫自訂指示：** 如果你擁有 Copilot Pro 訂閱，可以設定儲存庫層級的自訂指示。這允許你提供關於專案、編碼風格或常見陷阱的總體上下文，Copilot 將在該儲存庫內的所有互動中考慮這些資訊。這對於長期的一致性和品質極為寶貴。

總而言之，雖然舊資訊可能暗示 GPT-4o 有嚴格的 4096 token 限制，但現代 IDE 中的 Copilot 通常使用更大的上下文窗口。即便如此，你關於拆分任務和利用多輪對話的直覺是正確的，並且是在處理複雜軟體開發挑戰時，有效使用 Copilot 的最佳實踐。

---

根據搜尋結果，以下是關於 GPT-4.1 和 GitHub Copilot 的 token 限制及上下文保留資訊：

### GPT-4.1 Token 限制
- GPT-4.1 的上下文窗口相較其前代有顯著增大。它支援高達 100 萬個 token 的上下文窗口，這相較於 GPT-4o 的 128K token 限制是一個實質性的提升。這使得它適合在單一提示中處理需要處理大型程式碼庫或大量文本語料的任務。

### GitHub Copilot Token 限制與上下文保留
- GitHub Copilot 基於如 GPT-4 等模型，在 VSCode 和 IntelliJ IDEA 等 IDE 內的互動，其 token 限制通常約為 4096 個 token。然而，根據所使用的 Copilot 具體設定和版本，存在一些差異。

- 對於使用 Visual Studio Code Insiders 的 GitHub Copilot 用戶，可以存取高達 128K 個 token 的更大上下文窗口，這是 OpenAI 的 GPT-4o 模型所支援的最大值。這個更大的上下文窗口可以改善對大型檔案和儲存庫的處理。

- GitHub Copilot Chat 可以管理多輪對話，但跨這些對話的上下文保留可能會有所不同。雖然它可以保留先前互動的部分上下文，但通常建議提供早期對話輪次的總結或關鍵點，特別是在處理複雜任務時，以保持連續性。

### Token 限制的解決方法
- **分塊處理**：將大型任務分解為較小、可管理的部分。這有助於在有效處理任務每個環節的同時，保持在 token 限制內。
- **總結**：在將長篇程式碼或日誌提供給 Copilot 之前先進行總結。這有助於在 token 限制內保留基本資訊。
- **聚焦查詢**：與其一次提供全部上下文，不如聚焦於你試圖解決問題最相關的程式碼或日誌的特定部分。
- **多輪對話**：使用多輪對話來逐步建立上下文。雖然 Copilot 可能不會保留先前互動的所有上下文，但手動提供總結或關鍵點有助於保持連續性。

這些策略可以幫助你在 GitHub Copilot 的 token 限制內有效使用它，並改善跨多輪對話的上下文保留。