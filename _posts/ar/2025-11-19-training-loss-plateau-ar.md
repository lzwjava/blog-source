---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: استقرار خسارة التدريب بعد الهبوط الأولي
translated: true
type: note
---

يظهر سجل التدريب انخفاض الخسارة بثبات من ~10.87 في الخطوة 0 إلى حوالي 3.6-3.7 بحلول الخطوة 10000، بعدها يتباطأ التقدم بشكل ملحوظ، حيث تتقلب خسائر التدريب والتحقق في نطاق ضيق (على سبيل المثال، خسارة التدريب حوالي 3.64-3.71، وخسارة التحقق حوالي 3.57-3.65 من الخطوة 10000 إلى 14500). هذا لا يمثل هضبة صلبة بعد—لا يزال هناك اتجاه تنازلي طفيف—لكن معدل التحسن قد تضاءل، والزيادات الطفيفة العرضية في الخسارة (على سبيل المثال، خسارة التحقق في الخطوة 9500 مقابل 9000) تشير إلى عدم الاستقرار. نظرًا لأنك تستخدم nanoGPT (بناءً على السكريبت والإعدادات)، سأقوم بتحليل الأسباب المحتملة خطوة بخطوة، مع التركيز على الإعدادات، وأنماط السجل، والمشاكل الشائعة في تدريب المحولات مثل هذه. سأقترح أيضًا إصلاحات.

### 1. **التجهيز الزائد بسبب مجموعة بيانات صغيرة/محدودة**
   - **لماذا من المحتمل أن يكون هذا هو السبب الأساسي**: تلاحظ إعداداتك "بيانات صغيرة" و "single-parquet-4070"، مع تكييف prepare.py لملف واحد. تحتوي FineWeb (أو FineWeb-Edu) على أجزاء من مجموعة بيانات هائلة (~15 تريليون رمز إجمالاً لـ FineWeb)، لكن الملف الواحد قد يحتوي فقط على 100 مليون إلى 1 مليار رمز (اعتمادًا على الملف—على سبيل المثال، بعض أجزاء FineWeb بحجم ~10-50 جيجابايت، مما يترجم إلى ~50-250 مليون رمز بعد التحويل إلى رموز). مع إعداداتك:
     - الرموز لكل تكرار: ~524 ألف (16 batch_size * 32 grad_acc * 1024 block_size).
     - بحلول التكرار 14500: ~7.6 مليار رمز تمت رؤيتها (14500 * 524 ألف).
     - إذا كانت مجموعة البيانات أصغر بكثير من 7.6 مليار رمز (على سبيل المثال، 500 مليون-1 مليار)، فإن النموذج قد دار عليها عدة مرات (سيقوم DataLoader الخاص بـ nanoGPT بالتكرار إذا لزم الأمر). هذا يؤدي إلى الحفظ بدلاً من التعميم، مما يتسبب في استقرار الخسارة حيث يلائم النموذج الضوضاء بدلاً من الأنماط.
   - **الدليل من السجل**: تتبع خسائر التدريب والتحقق عن كثب (الفرق غالبًا <0.1)، وهي علامة كلاسيكية على التجهيز الزائد لمجموعة بيانات متجانسة/صغيرة. إذا كانت البيانات متنوعة وكبيرة (مثل FineWeb الكاملة)، قد تتوقع فصلًا أكبر في حالة التجهيز الزائد، أو استمرار الانخفاض الثابت. تقلبات خسارة التحقق (على سبيل المثال، الارتفاع في الخطوات 6000، 9500، 13000) تشير أيضًا إلى هذا—النماذج التي تعاني من تجهيز زائد تصبح حساسة لتباين الدُفعات.
   - **لماذا لا يوجد مزيد من التحسن**: من المحتمل أن النموذج (~40 مليون معامل، وليس 125 مليون—يحتوي تعليقك على خطأ في الحساب؛ إنه أقرب إلى GPT-2 مصغر جدًا) قد استخرج معظم الإشارات القابلة للتعلم من البيانات المحدودة. غالبًا ما يصطدم nanoGPT على البيانات الصغيرة بهذا الجدار أسرع من المقاييس المثلى لـ Chinchilla.

### 2. **مشاكل معدل التعلم والجدولة**
   - **التحليل**: LR=1e-3 مع تضاؤل جيب التمام إلى min_lr=1e-4 على مدى 20 ألف تكرار، warmup=500. هذا عدواني لنموذج/مجموعة بيانات صغيرة:
     - يمكن أن يتسبب معدل التعلم الأولي المرتفع في حدوث تذبذبات مبكرة (مرئية في قفزات الخسائر الفردية للتكرار، على سبيل المثال، 4.1096 في التكرار 10000).
     - قد يكون التضاؤل بطيئًا جدًا أو min_lr مرتفعًا جدًا، مما يمنع التقارب الدقيق. في أمثلة nanoGPT (مثل Shakespeare أو OpenWebText)، غالبًا ما يكون LR بين 3e-4 إلى 6e-4 لـ ~85 مليون معامل؛ قد يتجاوز 1e-3 الحد الأدنى على البيانات الصغيرة.
     - Warmup=500 قصير (~260 مليون رمز)، مما قد لا يثبت التدرجات بشكل كافٍ قبل بدء معدل التعلم الكامل.
   - **الدليل**: تنخفض الخسارة بسرعة في البداية (جيد لمعدل التعلم المرتفع)، لكنها تتباطأ/تتقلب لاحقًا، مما يشير إلى أن المُحسن يقفز حول الحد الأدنى بدلاً من الهبوط. Beta2=0.99 (مقارنة بـ 0.999 القياسي) يضيف تخميد زخم، مما يساعد على الاستقرار ولكن يمكن أن يبطئ التقارب إذا لم يتم ضبطه.
   - **سبب الاستقرار**: لا يستطيع المُحسن الهروب من المنطقة المسطحة؛ التدريب الإضافي يضيف فقط الضوضاء.

### 3. **عدم تطابق سعة النموذج والتنظيم**
   - **التفاصيل**: 40 مليون معامل (12 طبقة، 384 تضمين، 12 رأس) هو حجم ضئيل لنمذجة اللغة، حتى على "البيانات الصغيرة." إذا كان الملف الفردي يحتوي على تنوع جيد، فقد يعاني النموذج من نقص التجهيز (لا يمكنه التقاط الأنماط المعقدة)، لكن تقارب خسائر التدريب والتحقق يشير إلى العكس—التجهيز الزائد بسبب تجاوز السعة لمقياس البيانات.
     - تمت إضافة Dropout=0.1 "في حالة التجهيز الزائد"، وهو مناسب، ولكن قد لا يكون كافيًا. weight_decay=0.1 قياسي، ولكن على البيانات الصغيرة، قد تساعد القيم الأعلى (0.2-0.5) أو تقنيات مثل تجانس التسميات.
     - عدم وجود حدود تحيز (bias=False، مثل Llama/Mistral) جيد، ولكن عند دمجه مع الإسقاط، قد ينظم بشكل زائد، مما يحد من تقليل الخسارة.
   - **الدليل**: تستقر الخسائر حول إرباكية 3.5-3.7 (exp(3.6)≈36)، وهو أمر مقبول لنموذج مصغر على نص الويب ولكنه أعلى من معيار nanoGPT لـ Shakespeare (~1.5-2.0 خسارة على النماذج المصغرة). إذا كانت البيانات ذات ضوضاء/منخفضة الجودة (يمكن أن تكون FineWeb كذلك)، يصل النموذج إلى أرضية خطأ غير قابلة للاختزال.

### 4. **عوامل محتملة أخرى (أقل احتمالًا ولكن يجدر التحقق منها)**
   - **جودة البيانات/الإعداد**: قد يحتوي الملف الفردي على تكرارات أو ضوضاء أو عدم توازن (على سبيل المثال، مستندات قصيرة في الغالب). إذا لم يتم تكييف prepare.py بشكل مثالي، فقد تسبب مشاكل التحويل إلى رموز (vocab=50304 جيد) أو التقسيم غير السليم في جعل مجموعة التحقق مشابهة جدًا للتدريب، مما يخفي المشاكل.
   - **الأجهزة/التنفيذ**: التدريب على 4070 (12 جيجابايت VRAM) مع compile=True فعال، ولكن إذا كانت VRAM ممتلغة بالكامل (دفعة فعالة 512 تسلسل *1024=524 ألف رمز/تكرار)، فقد تنشأ حالات عدم استقرار خفية مثل أخطاء الدقة المختلطة (float16 مع GradScaler). يظهر السجل عدم وجود قيم NaN، لكن FutureWarning غير ضار.
   - **إعدادات التقييم**: eval_iters=200 قد تكون قليلة جدًا لتحقيق استقرار خسارة التحقق على البيانات الصغيرة—التباين قد يجعلها تبدو مستقرة. Always_save_checkpoint قيد التشغيل، لذا يمكنك تحميل نقاط التفتيش السابقة للمقارنة.
   - **ليس خطأ في nanoGPT**: السكريبت قياسي؛ fused AdamW و compile يعملان (MFU ~10-12% جيد لـ 4070).

### كيفية الإصلاح والتحسين
لكسر مرحلة الاستقرار، رتب أولويات الحصول على المزيد من البيانات إذا أمكن—هذا هو الرافعة الأكبر. وإلا:
- **أضف المزيد من البيانات**: انتقل إلى ملفات متعددة أو أجزاء كاملة من FineWeb. قم بتحديث prepare.py لتحميل مجموعة فرعية أكبر (على سبيل المثال، 10-50 مليار رمز). يجب أن يستأنف هذا انخفاض الخسارة.
- **ضبط المعاملات الفائقة**:
  - اخفض معدل التعلم الأولي إلى 5e-4 أو 3e-4؛ عيّن min_lr=5e-5. مدد فترة الإحماء إلى 1000-2000 تكرار.
  - زد الإسقاط إلى 0.2 إذا استمر التجهيز الزائد.
  - جرب تدريبًا أطول (حتى 50 ألف تكرار) لكن راقب أي زيادة في خسارة التحقق.
  - أضف --gradient_clip=1.0 إذا كانت التذبذبات ناتجة عن تدرجات مت exploding.
- **تحسينات التنظيم**: زد weight_decay إلى 0.2. جرب --init_from='resume' من نقطة تفتيش واخفض معدل التعلم للضبط الدقيق.
- **تعديلات النموذج**: إذا كانت البيانات صغيرة حقًا، فصغر حجم النموذج (على سبيل المثال، n_embd=256, n_layer=6) لتقليل التجهيز الزائد. أو قم بالزيادة إذا سمحت سعة VRAM.
- **التشخيصات**: ارسم الخسائر (استخدم wandb_log=True للرسوم البيانية). تحقق من الإرباكية (exp(loss))—إذا كانت ~30-40، فهذا معقول للنموذج المصغر/بيانات الويب؛ استهدف <10 مع التحسينات.
- **أعد تشغيل التجارب**: ابدأ تشغيلًا جديدًا باستخدام هذه التعديلات. إذا بدأت خسارة التحقق في الاختلاف، فهذا يؤكد التجهيز الزائد.

إذا شاركت المزيد من التفاصيل (على سبيل المثال، حجم مجموعة البيانات الدقيق من prepare.py، السجل الكامل، أو مخططات tensorboard)، يمكنني تحليل هذا بشكل أكبر.