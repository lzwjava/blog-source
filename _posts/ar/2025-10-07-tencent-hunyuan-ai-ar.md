---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: عائلة نماذج الذكاء الاصطناعي هونيوان من تينسنت
translated: true
type: note
---

### مقدمة لعائلة هونيوان للذكاء الاصطناعي من تنسنت

تمثل هونيوان من تنسنت مجموعة راقية من نماذج الذكاء الاصطناعي المتقدمة التي طورها عملاق التكنولوجيا الموجود في شنتشن، مع التركيز على الابتكار مفتوح المصدر، والقدرات متعددة الوسائط، والدمج السلس في التطبيقات الواقعية. تم الكشف عنها لأول مرة في أواخر عام 2023 كنموذج لغوي كبير أساسي (LLM)، وقد توسعت هونيوان منذ ذلك الحين لتصبح نظامًا بيئيًا متعدد الاستخدامات يشمل توليد النصوص، والرؤية، والترجمة، والتصميم ثلاثي الأبعاد، والمزيد. وبحلول أكتوبر 2025، عززت موقعها كواحدة من أبرز منصات الذكاء الاصطناعي مفتوحة المصدر في الصين، مع إطلاق أكثر من 30 نموذجًا جديدًا في العام الماضي وحده. يعكس هذا التكرار السريع التزام تنسنت بتعميم الذكاء الاصطناعي من خلال المصادر المفتوحة بالكامل، بما في ذلك حقوق الاستخدام التجاري للعديد من المكونات، واستضافتها على منصات مثل Hugging Face حيث جمعت ملايين التنزيلات.

تكمن القوة الأساسية لهونيوان في كفاءتها وقابليتها للتوسع، مستفيدةً من بنى مثل Mixture-of-Experts (MoE) لأداء عالٍ مع متطلبات حاسوبية أقل. إنها تتفوق في معالجة السياقات الطويلة (حتى 256 ألف رمز)، والاستدلال المعقد، والمهام متعددة الوسائط، مما يجعلها مثالية لسير عمل المؤسسات، وأدوات الإبداع، وتطبيقات المستهلكين. تضع المقاييس نماذج هونيوان باستمرار في المقدمة أو بالقرب منها في قوائم المتصدرين مفتوحة المصدر، وغالبًا ما تنافس أو تتجاوز القادة العالميين مثل GPT-4.5 و Imagen 3 من جوجل في السرعة والدقة وتعدد الاستخدامات – خاصة في المجالات الناطقة باللغة الصينية ومتعددة الوسائط.

#### النماذج الرئيسية والإصدارات الحديثة لعام 2025
تشمل مجموعة هونيوان النماذج اللغوية الكبيرة الكثيفة، ومتغيرات MoE، وأدوات متعددة الوسائط المتخصصة. فيما يلي تفصيل لأبرز النماذج، مع التركيز على تطورات عام 2025:

- **Hunyuan-A13B (النموذج اللغوي الكبير الأساسي، صدر عام 2024، تم تحديثه عام 2025)**: قوة خفيفة الوزن من نوع MoE بإجمالي 80 مليار معلمة ولكن 13 مليار معلمة فقط نشطة أثناء الاستدلال، مما يمكن معالجة أسرع بثلاث مرات عبر grouped query attention (GQA) ودعم التكميم. يبرز في الرياضيات والعلوم والبرمجة والاستدلال المنطقي، محققًا نتائج تنافسية في مقاييس مثل MMLU و GSM8K. مثالي للنشر على الحافة ودمج النظام البيئي.

- **Hunyuan-T1 (نموذج التفكير العميق، مارس 2025)**: النموذج اللغوي الكبير الذي طورته تنسنت والمركز على الاستدلال، حيث سجل 87.2 عبر المقاييس الرئيسية وتفوق على GPT-4.5 في سرعة التوليد (60-80 رمزًا في الثانية). يتعامل مع حل المشكلات المعقدة والمهام متعددة اللغات بدقة عالية، مما يمثل قفزة في قدرات "التفكير العميق" للتطبيقات الصناعية.

- **Hunyuan-TurboS (النموذج اللغوي الكبير المُحَسَّن للسرعة، يونيو 2025)**: يوازن بين الاستدلال السريع والاستدلال القوي، مسجلاً متوسط 77.9% على 23 مقياسًا آليًا. قوي بشكل خاص في مهام المعالجة اللغوية الطبيعية (NLP) الصينية، ويعيد تعريف الكفاءة للدردشة في الوقت الفعلي وتوليد المحتوى.

- **Hunyuan-Large (النموذج الأساسي المدرب مسبقًا، تحديثات مستمرة)**: نموذج كثيف راقٍ يتفوق على منافسيه من MoE والنماذج الكثيفة المماثلة في الفهم اللغوي الشامل والتوليد. يعمل كالعمود الفقري للمتغيرات المُحَسَّنة.

- **Hunyuan-Large-Vision (نموذج الرؤية متعدد الوسائط، أغسطس 2025)**: يضع معيارًا جديدًا للذكاء الاصطناعي للصور الصينية، محتلًا المرتبة الأولى في قائمة المتصدرين للرؤية على LMArena. يعالج ويولد صورًا مع الوعي السياقي، مدعومًا مهام مثل كشف الأشياء ووصف المشاهد.

- **نموذج هونيوان للترجمة (سبتمبر 2025)**: إنجاز ثنائي البنية للترجمة بالذكاء الاصطناعي مفتوحة المصدر، يدعم أكثر من 30 لغة. يضع معيارًا لعام 2025 في الدقة والطلاقة، ويتعامل مع السياقات الثقافية الدقيقة بشكل أفضل من السابقين.

- **Hunyuan Image 3.0 (مولد الصور من النص، 28 سبتمبر 2025)**: جوهرة التاج في الإصدارات الحديثة – أكبر نموذج صور مفتوح المصدر في العالم حتى الآن. يتصدر ترتيب LMArena للصور من النص، متجاوزًا Imagen 3 من جوجل و Midjourney في الواقعية والتفاصيل حسب تصويت المستخدمين. يتميز بـ MoE لسرعة استدلال مضاعفة ثلاث مرات، ومصدر مفتوح تجاري بالكامل (الأوزان والكود على Hugging Face)، ودمج "الدماغ LLM" لصياغات التحسين التكراري.

- **مجموعة التوليد ثلاثي الأبعاد وتوليد العوالم**:
  - **Hunyuan3D-2 (يونيو 2025)**: يولد أصولًا ثلاثية الأبعاد عالية الدقة من النص أو الصور، مع مواد PBR وترميز VAE؛ مفتوح المصدر بالكامل بما في ذلك كود التدريب.
  - **Hunyuan3D-3.0، وHunyuan3D AI، وHunyuan3D Studio (سبتمبر 2025)**: أدوات متقدمة لتحويل النص إلى 3D للإعلام والألعاب، تم تنزيلها أكثر من 2.6 مليون مرة على Hugging Face – وهي أكثر النماذج ثلاثية الأبعاد مفتوحة المصدر شيوعًا globally.
  - **HunyuanWorld-1.0 (يوليو 2025)**: أول مولد عوالم ثلاثية الأبعاد قادر على المحاكاة ومفتوح المصدر، يخلق بيئات غامرة للواقع الافتراضي/المعزز والمحاكاة.

#### القدرات والمقاييس
تم هندسة نماذج هونيوان للاتساع والعمق:
- **الاستدلال واللغة**: متفوق في الرياضيات (مثل مقياس MATH)، والبرمجة (HumanEval)، والعلوم (SciQ)، حيث غالبًا ما يطابق أداء Hunyuan-T1 و -A13B أداء مستوى o1.
- **متعدد الوسائط**: دمج سلس للنص، والصور، والفيديو، وثلاثي الأبعاد؛ على سبيل المثال، يتفوق Image 3.0 في الواقعية الضوئية والتكوينات المعقدة.
- **الكفاءة**: تصميمات MoE تقلل التكاليف؛ TurboS و A13B يمكنان النشر على أجهزة المستهلك.
- **الترجمة والفروق الثقافية الدقيقة**: نموذج الترجمة لعام 2025 يتصدر في اللغات قليلة الموارد.
بشكل عام، تحتل هونيوان مراتب عالية among النماذج الصينية المفتوحة (عبر C-Eval و CMMLU)، مع مساواة عالمية في ساحات مثل LMArena و Hugging Face Open LLM Leaderboard.

#### النظام البيئي مفتوح المصدر والدمج
ألزمت تنسنت نفسها بالكامل بجعل هونيوان مفتوح المصدر، حيث أطلقت كود الاستدلال، وأوزان النماذج، وحتى خطوط أنابيب التدريب للاستخدام التجاري. وقد أدى هذا إلى تنمية مجتمع نابض بالحياة، حيث شهدت نماذج مثل Hunyuan3D-2.1 و Image 3.0 اعتمادًا سريعًا. تمتد عمليات الدمج عبر إمبراطورية تنسنت: تشغيل مساعد وايانباو AI الذكي في WeChat، و Tencent Cloud's ADP3.0 للذكاء الاصطناعي المؤسسي، وأدوات عالمية للإبداع. في سبتمبر 2025، أطلقت تنسنت قدرات الذكاء الاصطناعي القائمة على السيناريوهات worldwide، مما سرع من كفاءة القطاعات الصناعية مثل الألعاب، والتجارة الإلكترونية، والإعلام.

اعتبارًا من أكتوبر 2025، تواصل هونيوان التطور، مع إشارات لنماذج موحدة أكبر. يمزجها بين القوة والانفتاح والعمليّة يجعلها الخيار الأمثل للمطورين والشركات التي تتطلع إلى استكشاف مشهد الذكاء الاصطناعي.

#### المراجع
- [Tencent Announces Global Rollout of Scenario-Based AI Capabilities](https://www.tencent.com/en-us/articles/2202183.html)
- [Tencent Hunyuan Image 3.0 Complete Guide](https://dev.to/czmilo/tencent-hunyuan-image-30-complete-guide-in-depth-analysis-of-the-worlds-largest-open-source-57k3)
- [Tencent's Hunyuan-Large-Vision Sets a New Benchmark](https://the-decoder.com/tencents-hunyuan-large-vision-sets-a-new-benchmark-as-chinas-leading-multimodal-model/)
- [The New Benchmark for Open-Source AI Translation in 2025](https://dev.to/czmilo/tencent-hunyuan-translation-model-complete-guide-the-new-benchmark-for-open-source-ai-translation-4ab)
- [China's New Model Hunyuan-T1 Beats GPT 4.5](https://www.analyticsvidhya.com/blog/2025/03/hunyuan-t1/)
- [Tencent's Hunyuan-A13B: A Smart Approach to Efficient Large Language Models](https://blog.shinkai.com/tencents-hunyuan-a13b-a-smart-approach-to-efficient-large-language-models/)
- [Hunyuan3D-2 on GitHub](https://github.com/Tencent-Hunyuan/Hunyuan3D-2)
- [HunyuanWorld-1.0 on GitHub](https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0)
- [Tencent releases versatile open-source Hunyuan AI models](https://www.artificialintelligence-news.com/news/tencent-releases-versatile-open-source-hunyuan-ai-models/)
- [Tencent's AI model Hunyuan Image 3.0 tops leaderboard](https://www.scmp.com/tech/big-tech/article/3328003/tencents-ai-model-hunyuan-image-30-tops-leaderboard-beating-googles-nano-banana)