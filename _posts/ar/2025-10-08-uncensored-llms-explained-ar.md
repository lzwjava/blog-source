---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: نماذج اللغة الكبيرة غير الخاضعة للرقابة موضحة
translated: true
type: note
---

### ما هي نماذج LLM غير الخاضعة للرقابة؟

نماذج اللغة الكبيرة (LLMs) غير الخاضعة للرقابة هي أنظمة ذكاء اصطناعي مصممة بدون مرشحات أمان مدمجة أو "حواجز" تقيد عادةً الردود المتعلقة بالموضوعات الحساسة أو المثيرة للجدل أو التي يحتمل أن تكون ضارة. على عكس النماذج القياسية، تهدف هذه النماذج إلى الرد على *أي* استفسار – بدءًا من الأسئلة البريئة إلى الأسئلة المتطرفة أو غير الأخلاقية أو غير القانونية – دون رفض أو حكم أو إعادة توجيه. هذا يجعلها جذابة للمستخدمين الذين يبحثون عن إبداع غير خاضع للرقابة أو بحث أو لعب أدوار، لكنه يزيد أيضًا من المخاطر المتعلقة بإساءة الاستخدام.

#### كيف تختلف عن النماذج الخاضعة للرقابة مثل ChatGPT؟
تخضع النماذج الخاضعة للرقابة (مثل ChatGPT أو Gemini أو Claude) لتعلم التعزيز من التغذية الراجعة البشرية (RLHF) وتدريب على السلامة للتوافق مع المبادئ التوجيهية الأخلاقية، التي غالبًا ما تكون متجذرة في المعايير الثقافية الغربية. هذا يؤدي إلى:
- **الرفض**: قد تقول "لا يمكنني المساعدة في هذا" للاستفسارات حول العنف أو المحتوى الصريح أو الموضوعات المتحيزة.
- **التخفيف من التحيز**: تكون الردود "صحيحة سياسيًا" ولكن يمكن أن تبدو مقيدة أو منحازة ثقافيًا.

تقوم النماذج غير الخاضعة للرقابة بإزالة هذه الطبقات، مع إعطاء الأولوية للقدرة الخام ونية المستخدم. قد تولد هذه النماذج قصصًا صريحة، أو أدلة خطوة بخطوة للإجراءات المحفوفة بالمخاطر، أو آراءً غير منقحة، ولكن بدون "أخلاقيات" النموذج التي تفرض حدودًا.

#### كيف يتم بناء نماذج LLM غير الخاضعة للرقابة؟
تبدأ بـ **النماذج الأساسية** – وهي نماذج محولات مدربة مسبقًا مثل Llama أو Mistral أو Qwen – التي تتنبأ بالنص بناءً على مجموعات بيانات شاسعة. ثم يتم **ضبطها بدقة**:
- على مجموعات بيانات غير خاضعة للرقابة للأسئلة والأجوبة (مثل إزالة جميع أمثلة "الرفض").
- باستخدام تقنيات مثل LoRA (التكيف ذو الرتبة المنخفضة) للكفاءة.
- ضبط مطالبات النظام لتشجيع الإخراج غير المقيد، أحيانًا مع "مكافآت" للامتثال.
- **التقطير** يصغر النماذج الأكبر (مثل تقليص 70B معامل إلى 7B) مع الحفاظ على الأداء، مما يجعلها قابلة للتشغيل على أجهزة المستهلك العادية.

تخلق هذه العملية متغيرات "ممحوة" أو "دولفين" (مسماة على مجموعات بيانات الضبط الدقيق مثل Dolphin).

#### أمثلة شائعة
لقد ذكرت Mistral و DeepSeek و Distill (يشير على الأرجح إلى المتغيرات المقطرة) و Qwen – هذه كلها قواعد قوية للضبط الدقيق غير الخاضع للرقابة. إليك تفصيل لها:

- **متغيرات Mistral غير الخاضعة للرقابة**:
  - **Dolphin Mistral 7B/24B**: تم ضبطها بدقة على مجموعة Dolphin 2.8 بيانات لتحقيق صفر حالات رفض. رائع لتمثيل الأدوار والبرمجة والكتابة الإبداعية. يدعم حتى 32K رمز سياق.
  - **Mistral 7B Dolphin Uncensored**: نموذج خفيف الوزن (7B معامل) غير خاضع للرقابة تمامًا، غالبًا ما يتم تشغيله محليًا عبر Ollama.

- **متغيرات DeepSeek غير الخاضعة للرقابة**:
  - **سلسلة DeepSeek-R1-Distill-Qwen** (مثل 1.5B، 7B، 14B، 32B): مقطرة من النموذج الضخم R1 الخاص بـ DeepSeek إلى قواعد Qwen. تتقن هذه النماذج في الرياضيات/الاستدلال (تتفوق على GPT-4o في بعض المعايير) وتأتي في إصدارات غير خاضعة للرقابة مثل UncensoredLM-DeepSeek-R1-Distill-Qwen-14B. مثالية لحل المشكلات بدون مرشحات.

- **متغيرات Qwen غير الخاضعة للرقابة**:
  - **Liberated Qwen**: ضبط دقيق غير خاضع للرقابة مبكر يلتزم بدقة بمطالبات النظام، ويحقق نتائج عالية في المعايير مثل MT-Bench و HumanEval.
  - **Qwen 2.5-32B Uncensored**: نموذج عملاق بـ 32B معامل للمهام المتقدمة؛ يمكن الوصول إليه عبر واجهات برمجة التطبيقات أو التشغيل المحلي.
  - **Qwen3 8B Uncensored**: أصغر حجمًا، فعال للتعليم/البحث، مع إصدارات "ممحوة" للاستدعار التام والبرمجة.

تشمل النماذج البارزة الأخرى Llama2-Uncensored أو Nous-Hermes (المقطرة من Llama)، لكن أمثلتك تتماشى مع القوى العاملة مفتوحة المصدر من Mistral AI و DeepSeek AI وسلسلة Qwen التابعة لشركة Alibaba.

#### الإيجابيات والسلبيات

| الجانب | الإيجابيات | السلبيات |
|--------|------|------|
| **المرونة** | تجيب على أي شيء؛ رائع لسرد القصص غير الخاضع للرقابة، أو التحليل غير المتحيز، أو اختبار الحالات المتطرفة. | خطر إخراج محتوى ضار (مثل المعلومات المضللة، خطاب الكراهية، أو النصائح غير القانونية). |
| **الأداء** | غالبًا ما تكون أسرع/أرخص في التشغيل محليًا؛ تحيز ثقافي أقل. | يمكن أن "تهلوس" بشكل كبير بدون شبكات أمان؛ يصعب التحكم بها. |
| **إمكانية الوصول** | مجانية/مفتوحة المصدر على Hugging Face؛ تعمل على أجهزة الكمبيوتر المحمولة عبر Ollama أو LM Studio. | قضايا أخلاقية/قانونية – قد يؤدي إساءة الاستخدام إلى انتهاك القوانين؛ ليست مناسبة للأطفال/أماكن العمل. |

#### الاعتبارات الأخلاقية
بينما تمكن هذه النماذج المستخدمين، فإنها تضخم الطبيعة ذات الاستخدام المزدوج للذكاء الاصطناعي: مفيدة لحرية التعبير أو اختبار اختراق السلامة، ولكنها خطيرة إذا تم تسليحها (مثلًا للاحتيال أو التطرف). يؤكد المطورون على الاستخدام المسؤول، لكن تسمية "غير خاضعة للرقابة" تثير الجدل – تحقق دائمًا من المخرجات.

#### كيفية الوصول إليها
- **التشغيل المحلي**: استخدم Ollama (مثل `ollama run dolphin-mistral`) أو Hugging Face للتنزيلات. تحتاج إلى وحدة معالجة رسومية مناسبة (مثل 8GB VRAM لنماذج 7B).
- **السحابة/واجهات برمجة التطبيقات**: تستضيف منصات مثل OpenRouter أو نظام Grok البيئي مستويات مجانية؛ Jarvislabs.ai لتأجير وحدات معالجة الرسومية.
- ابدأ صغيرًا: جرب Dolphin Mistral على هاتفك عبر تطبيقات مثل Private LLM.

للتعمق أكثر، راجع هذه الموارد:

[Uncensored LLM Models: A Complete Guide](https://docs.jarvislabs.ai/blog/llm_uncensored)  
[DeepSeek-R1 Distilled Models Explained](https://medium.com/data-science-in-your-pocket/what-are-deepseek-r1-distilled-models-329629968d5d)  
[Dolphin Mistral Uncensored Guide](https://www.youtube.com/watch?v=yqMBI_Q0_Yc)  
[Liberated Qwen Overview](https://venturebeat.com/ai/meet-liberated-qwen-an-uncensored-llm-that-strictly-adheres-to-system-prompts)  
[Uncensored Qwen 2.5-32B Trial](https://eduardo-rogers.medium.com/you-can-try-uncensored-qwen-2-5-32b-model-here-3560e31cc3b5)