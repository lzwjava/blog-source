---
audio: false
generated: true
lang: ar
layout: post
title: كودين إن
translated: true
type: note
---

مكتبة `nvidia-cudnn-cu12` هي جزء من مكتبة CUDA Deep Neural Network الخاصة بـ NVIDIA، والمعروفة شائعًا باسم cuDNN. تم تصميم هذه المكتبة لتسريع أطر عمل التعلم العميق على وحدات معالجة الرسومات من NVIDIA. على وجه التحديد، تم تصميم `nvidia-cudnn-cu12` للاستخدام مع CUDA 12، وهي منصة الحوسبة المتوازية ونموذج واجهة برمجة التطبيقات (API) من NVIDIA.

توفر cuDNN تطبيقات مُحسنة بدقة للروتينات القياسية مثل الالتواء (Convolution) في الاتجاهين الأمامي والخلفي، والتجميع (Pooling)، والتطبيع (Normalization)، وطبقات التنشيط (Activation). هذه الروتينات أساسية لتدريب الشبكات العصبية العميقة وتسريع أوقات الحساب بشكل كبير، مما يجعلها حاسمة للتطبيقات في مجالات مثل التعرف على الصور والكلام، ومعالجة اللغة الطبيعية، والمزيد.

تُستخدم المكتبة على نطاق واسع في كل من الأبحاث والصناعة لتعزيز أداء نماذج التعلم العميق من خلال الاستفادة من قوة تسريع وحدة معالجة الرسومات (GPU). وهي تدعم منصات متنوعة ومتوافقة مع إصدارات متعددة من CUDA، مما يضمن المرونة والقابلية الواسعة للتطبيق عبر تكوينات الأجهزة المختلفة.

---

تتضمن مكتبة `nvidia-cudnn-cu12`، وهي جزء من cuDNN من NVIDIA، مجموعة من واجهات برمجة التطبيقات (APIs) المصممة لتسريع عمليات الشبكات العصبية العميقة على وحدات معالجة الرسومات من NVIDIA. توفر المكتبة تطبيقات مُحسنة للعديد من العمليات الرئيسية المستخدمة في التعلم العميق. فيما يلي بعض المكونات وواجهات برمجة التطبيقات الرئيسية المضمنة:

1.  **عمليات الالتواء (Convolution Operations)**: واجهات برمجة التطبيقات (APIs) لإجراء عمليات الالتواء في الاتجاهين الأمامي والخلفي، وهي أساسية في العديد من بنى الشبكات العصبية، وخاصة الشبكات العصبية الالتفافية (CNNs).
2.  **عمليات التجميع (Pooling Operations)**: واجهات برمجة التطبيقات (APIs) لأنواع مختلفة من عمليات التجميع مثل التجميع الأقصى (Max Pooling) والتجميع المتوسط (Average Pooling)، والتي تُستخدم لتقليل الأبعاد المكانية لحجم الإدخال للطبقة الالتفافية التالية.
3.  **عمليات التطبيع (Normalization Operations)**: واجهات برمجة التطبيقات (APIs) للتطبيع الدفعي (Batch Normalization)، والذي يساعد في تثبيت وتسريع تدريب الشبكات العصبية العميقة.
4.  **دوال التنشيط (Activation Functions)**: واجهات برمجة التطبيقات (APIs) لدوال التنشيط المختلفة مثل ReLU (Rectified Linear Unit)، والدالة السيجمويدية (Sigmoid)، والداة الظلية الزائدية (tanh)، والتي تُدخل عدم الخطية في النموذج، مما يمكنه من تعلم أنماط معقدة.
5.  **عمليات الشبكات العصبية المتكررة (RNN Operations)**: واجهات برمجة التطبيقات (APIs) للعمليات شائعة الاستخدام في الشبكات العصبية المتكررة (RNNs)، مثل LSTM (Long Short-Term Memory) و GRU (Gated Recurrent Unit).
6.  **تحويلات الموتر (Tensor Transformations)**: واجهات برمجة التطبيقات (APIs) لعمليات معالجة الموترات (Tensors)، وهي أساسية لإعداد البيانات لطبقات الشبكة العصبية ومعالجة المخرجات.
7.  **عمليات التحسين (Optimization Operations)**: واجهات برمجة التطبيقات (APIs) التي تدعم خوارزميات التحسين المختلفة المستخدمة أثناء تدريب الشبكات العصبية.

تم تصميم مكتبة cuDNN لاستخدامها مع منصة CUDA من NVIDIA ويمكن الوصول إليها من خلال واجهة برمجة تطبيقات C المباشرة وواجهة C++ مفتوحة المصدر، مما يجعلها متعددة الاستخدامات للتكامل في أطر عمل وتطبيقات التعلم العميق المختلفة. هذا يسمح للمطورين بتعريف العمليات الحسابية كرسم بياني للعمليات على الموترات، والاستفادة من تسريع وحدة معالجة الرسومات (GPU) لتحسين الأداء.

---

# استخدام cuDNN في Python و C

cuDNN (مكتبة CUDA Deep Neural Network) هي مكتبة NVIDIA المعجزة بوحدة معالجة الرسومات (GPU) للشبكات العصبية العميقة. إليك كيفية استخدامها في كل من Python و C:

## استخدام cuDNN في Python

الطريقة الأكثر شيوعًا لاستخدام cuDNN في Python هي من خلال أطر عمل التعلم العميق التي تحتوي على تكامل مع cuDNN:

### 1. الاستخدام مع PyTorch

```python
import torch

# التحقق مما إذا كان cuDNN مفعلًا
print(torch.backends.cudnn.enabled)  # يجب أن يكون True

# إنشاء بعض الموترات والعمليات التي ستستخدم cuDNN
x = torch.randn(1, 3, 224, 224, device='cuda')  # موتر رباعي الأبعاد (دفعة, قنوات, ارتفاع, عرض)
conv = torch.nn.Conv2d(3, 64, kernel_size=3, padding=1).cuda()

# هذا الالتواء سوف يستخدم cuDNN في الخلفية
output = conv(x)
print(output.shape)
```

### 2. الاستخدام مع TensorFlow

```python
import tensorflow as tf

# التحقق مما إذا كان cuDNN متاحًا
print(tf.test.is_built_with_cuda())  # يجب أن يكون True
print(tf.test.is_built_with_cudnn())  # يجب أن يكون True

# إنشاء نموذج بسيط سوف يستخدم cuDNN
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(10, activation='softmax')
])

# هذا سوف يستخدم cuDNN لعمليات الالتواء والتجميع
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
```

## استخدام cuDNN في C

لاستخدام cuDNN مباشرة في C، تحتاج إلى استخدام واجهة برمجة تطبيقات C الخاصة بـ cuDNN:

### مثال أساسي لـ cuDNN في C

```c
#include <cudnn.h>
#include <cuda_runtime.h>
#include <stdio.h>

int main() {
    cudnnHandle_t cudnn;
    cudnnCreate(&cudnn);  // تهيئة cuDNN
    
    // إنشاء واصف للموتر
    cudnnTensorDescriptor_t input_descriptor;
    cudnnCreateTensorDescriptor(&input_descriptor);
    
    // تعيين أبعاد الموتر الرباعي (بتنسيق NCHW)
    int n = 1, c = 3, h = 224, w = 224;
    cudnnSetTensor4dDescriptor(input_descriptor,
                              CUDNN_TENSOR_NCHW,
                              CUDNN_DATA_FLOAT,
                              n, c, h, w);
    
    // إنشاء واصف للمرشح للالتواء
    cudnnFilterDescriptor_t filter_descriptor;
    cudnnCreateFilterDescriptor(&filter_descriptor);
    int out_channels = 64, k = 3;
    cudnnSetFilter4dDescriptor(filter_descriptor,
                             CUDNN_DATA_FLOAT,
                             CUDNN_TENSOR_NCHW,
                             out_channels, c, k, k);
    
    // إنشاء واصف للالتواء
    cudnnConvolutionDescriptor_t conv_descriptor;
    cudnnCreateConvolutionDescriptor(&conv_descriptor);
    int pad = 1, stride = 1;
    cudnnSetConvolution2dDescriptor(conv_descriptor,
                                   pad, pad, stride, stride,
                                   1, 1,  // التمدد
                                   CUDNN_CROSS_CORRELATION,
                                   CUDNN_DATA_FLOAT);
    
    // إيجاد خوارزمية الالتواء
    cudnnConvolutionFwdAlgo_t algo;
    cudnnGetConvolutionForwardAlgorithm(cudnn,
                                       input_descriptor,
                                       filter_descriptor,
                                       conv_descriptor,
                                       input_descriptor,
                                       CUDNN_CONVOLUTION_FWD_PREFER_FASTEST,
                                       0,  // لا يوجد حد للذاكرة
                                       &algo);
    
    printf("Using convolution algorithm: %d\n", algo);
    
    // التنظيف
    cudnnDestroyTensorDescriptor(input_descriptor);
    cudnnDestroyFilterDescriptor(filter_descriptor);
    cudnnDestroyConvolutionDescriptor(conv_descriptor);
    cudnnDestroy(cudnn);
    
    return 0;
}
```

لترجمة برنامج C هذا:
```bash
nvcc your_program.c -o your_program -lcudnn
```

## النقاط الرئيسية

1.  **الاستخدام في Python**:
    *   يتفاعل معظم المستخدمين مع cuDNN بشكل غير مباشر من خلال أطر عمل مثل PyTorch أو TensorFlow.
    *   تستخدم هذه الأطر عمل cuDNN تلقائيًا عندما يكون متاحًا ومناسبًا.

2.  **الاستخدام المباشر في C**:
    *   يوفر تحكمًا أكبر ولكنه يتطلب المزيد من التعليمات البرمجية النمطية.
    *   تحتاج إلى إدارة الواصفات (Descriptors) للموترات والمرشحات والالتواءات، إلخ.
    *   يتطلب إدارة ذاكرة دقيقة.

3.  **المتطلبات الأساسية**:
    *   وحدة معالجة رسومات NVIDIA مع دعم CUDA.
    *   مجموعة أدوات CUDA مثبتة بشكل صحيح.
    *   مكتبة cuDNN مثبتة وفي مسار المكتبة الخاص بك.

4.  **الأداء**:
    *   توفر cuDNN تطبيقات مُحسنة للغاية.
    *   قد تكون خوارزميات مختلفة متاحة لنفس العملية.
    *   تسمح بعض الأطر بإجراء معايير واختيار أسرع خوارزمية.

لمعظم تطبيقات التعلم العميق، يوصى باستخدام cuDNN من خلال إطار عمل عالي المستوى مثل PyTorch أو TensorFlow، حيث يوفر توازنًا جيدًا بين الأداء وسهولة الاستخدام.