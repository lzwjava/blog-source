---
audio: false
generated: true
image: false
lang: ar
layout: post
title: إصلاح خطأ 500 في خادم MCP
translated: true
type: note
---

الخطأ الذي تواجهه هو خطأ 500 من الخادم الداخلي من نقطة نهاية API محلية على `http://127.0.0.1:3456`، والتي يبدو أنها خادم Model Context Protocol (MCP). يُستخدم هذا عادةً لربط نماذج اللغة الكبيرة المحلية (LLMs) مثل تلك التي تديرها Ollama بالتطبيقات مثل Claude Desktop، أو إضافات VS Code (مثل Copilot)، أو بيئات التطوير المتكاملة (IDEs) مثل Cursor لمهام البرمجة بمساعدة الذكاء الاصطناعي. يشير خطأ JavaScript/TypeScript الأساسي — "Cannot read properties of undefined (reading 'includes')" — إلى أن كود الخادم يحاول الوصول إلى دالة `.includes()` على متغير غير معرّف أو له قيمة null، على الأرجح أثناء معالجة الطلب، أو التعامل مع الاستجابة، أو التفاعل مع Ollama.

غالباً ما تنشأ هذه المشكلة عندما يتم استدعاء الـ API لتحليل أو إصلاح الكود (في هذه الحالة، سكريبت `recommend_posts.py` الخاص بك)، لكن الخادم يفشل بسبب مشكلة في التهيئة، أو تبعيات مفقودة، أو استجابة غير متوقعة من نموذج LLM الخلفي.

### خطوات استكشاف الأخطاء وإصلاحها
1.  **التحقق من تشغيل وتكوين Ollama**:
    *   عادةً ما يكون Ollama (محرك LLMs المحلي) هو الخلفية لخوادم MCP. تأكد من تثبيته وتشغيله على المنفذ الافتراضي (11434).
    *   اختبره بتشغيل `curl http://localhost:11434/api/tags` في الطرفية. يجب أن يعرض هذا الأمر قائمة النماذج المثبتة. إذا فشل أو أعاد قائمة فارغة، قم بتثبيت نموذج باستخدام `ollama pull <اسم-النموذج>` (مثال: `ollama pull llama3`).
    *   إذا لم يستجب Ollama، ابدأ تشغيله بـ `ollama serve` وتأكد من عدم وجود تعارض في المنافذ.

2.  **إعادة تشغيل خادم MCP**:
    *   قد يكون خادم MCP على المنفذ 3456 في حالة غير مستقرة. أوقف العملية: `kill -9 $(lsof -t -i:3456)`.
    *   أعد تشغيله وفقًا لإعداداتك (مثال: إذا كنت تستخدم أداة مثل `ollama-mcp`، شغّل أمر البدء من وثائقها). ابحث في سجلات البدء عن مؤشرات على اتصال ناجح بـ Ollama.

3.  **التحقق من تعارض المنافذ أو تداخل Claude Desktop**:
    *   غالبًا ما يستخدم Claude Desktop (إذا كان مثبتًا) المنفذ 3456 للمصادقة أو MCP. إذا كان يعمل، أغلق التطبيق أو أوقف عمليته كما هو مذكور أعلاه.
    *   إذا كنت تستخدم Cursor أو VS Code، تأكد من أن ملف settings.json يحتوي على عنوان URL الأساسي الصحيح للـ API وبدون أخطاء إملائية. غيّر المنفذ مؤقتًا عن طريق تعيين متغير بيئة مثل `PORT=4567` عند بدء تشغيل خادم MCP، ثم حدّث عنوان URL الأساسي لـ API ليطابقه.

4.  **تحديث البرامج والتحقق من السجلات**:
    *   حدّث Ollama: `ollama update`.
    *   إذا كنت تستخدم جسر MCP محددًا (مثال: من مستودعات GitHub مثل emgeee/mcp-ollama أو patruff/ollama-mcp-bridge)، احصل على أحدث نسخة وأعد البناء/إعادة التثبيت.
    *   شغّل خادم MCP مع تسجيل مفصل (أضف flags مثل `--debug` إذا كانت مدعومة) وافحص الناتج للعثور على أدلة حول ما هو غير معرّف (مثال: استجابة مفقودة من Ollama أو حمولة طلب غير صالحة).
    *   في Cursor أو بيئة التطوير المتكاملة الخاصة بك، تحقق من وحدة تحكم المطور (Ctrl+Shift+I في Cursor) للحصول على تفاصيل خطأ إضافية.

5.  **اختبار الـ API مباشرة**:
    *   قم بمحاكاة طلب بسيط إلى الـ API باستخدام curl: `curl -X POST http://127.0.0.1:3456/v1/chat/completions -H "Content-Type: application/json" -d '{"model": "اسم-النموذج-الخاص-بك", "messages": [{"role": "user", "content": "Hello"}]}'`.
    *   إذا أعاد نفس خطأ 500، فإن المشكلة من جانب الخادم. إذا عمل، فقد تكون المشكلة متعلقة بكيفية تنسيق بيئة التطوير المتكاملة للطلبات (مثال: حمولة طلب مشوهة عند تضمين محتويات الملف).

6.  **الحلول البديلة**:
    *   التبديل إلى نقطة نهاية Ollama المباشرة المتوافقة مع OpenAI: عيّن عنوان URL الأساسي لـ API الخاص بك إلى `http://127.0.0.1:11434/v1` (Ollama يدعم هذا) وتجاوز MCP إذا لم يكن ضروريًا لميزات السياق المتقدمة.
    *   استخدام تنفيذ مختلف لـ MCP أو أداة أخرى. جرب، على سبيل المثال، إعداد Ollama بسيط بدون MCP لإصلاح الكود.
    *   إذا كنت في Cursor، ارجع إلى استخدام النماذج السحابية (مثال: Claude عبر الـ API الرسمي) مؤقتًا عن طريق إزالة عنوان URL الأساسي المخصص.
    *   أعِد تثبيت التبعيات: إذا كان خادم MCP الخاص بك يستخدم Node.js، شغّل `npm install` في دليله لإصلاح أي وحدات مفقودة.

إذا لم تحل هذه الخطوات المشكلة، فقد ينشأ الخطأ من خلل في إصدار جسر MCP المحدد الذي تستخدمه، خاصة إذا كان التعامل مع محتويات الملفات أو التوصيات ينشطه. ابحث في مشاكل GitHub لمستودع MCP المحدد الخاص بك مع رسالة الخطأ نفسها، أو افتح مشكلة جديدة مع تفاصيل إعداداتك.

[فشل في تسجيل نموذج Ollama: TypeError: Cannot read properties of undefined (reading 'includes')](https://github.com/microsoft/vscode-copilot-release/issues/8461)  
[خادم Ollama MCP على GitHub](https://github.com/emgeee/mcp-ollama)  
[وثائق Model Context Protocol](https://modelcontextprotocol.io/introduction)  
[وثائق Ollama](https://github.com/ollama/ollama)