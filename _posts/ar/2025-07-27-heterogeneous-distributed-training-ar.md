---
audio: false
generated: true
lang: ar
layout: post
title: التدريب الموزع باستخدام راي على أجهزة مختلطة
translated: true
type: note
---

نعم، يمكنك استخدام Python للتوزيع التدريبي لنماذج التعلم الآلي عبر جهاز MacBook Air M2 الخاص بك (الذي يستخدم Apple Silicon مع نهاية MPS الخلفية لتسريع GPU) وجهازك المكتبي Intel i9 المزود بكرت شاشة NVIDIA 4070Ti (الذي يدعم CUDA). ومع ذلك، هذا الإعداد غير متجانس (بمعنى وجود بنى معمارية وأنظمة تشغيل ومسرعات مختلفة)، لذا فهو ليس بسهولة مجموعة متجانسة (مثلًا، جميع وحدات معالجة الرسومات من NVIDIA). التدريب الموزع الأصلي في أطر العمل مثل PyTorch لن يعمل بسلاسة فورًا بسبب عدم توافق النهايات الخلفية—فـ PyTorch على جهاز Mac يستخدم MPS، بينما على الجهاز المكتبي يستخدم CUDA، ومكتبات الاتصال مثل NCCL (المطلوبة للمزامنة الفعالة بين وحدات معالجة الرسومات) مخصصة لـ NVIDIA فقط وغير متوفرة على Apple Silicon.

مع ذلك، يمكنك تحقيق التدريب الموزع باستخدام مكتبات تنظيم عالية المستوى مثل Ray، والتي تجرد الاختلافات في العتاد. توجد خيارات أخرى مثل Dask أو أطر عمل مخصصة ولكنها أكثر محدودية للتعلم العميق. سأوضح الجدوى والنهج الموصى به والبدائل أدناه.

### النهج الموصى به: استخدام Ray للتدريب الموزع
Ray هو إطار عمل موزع قائم على Python وهو محايد للعتاد ويدعم توسيع نطاق أحمال عمل التعلم الآلي عبر أجهزة مختلطة (مثل macOS على Apple Silicon وWindows/Linux على NVIDIA). يتم تثبيته على كلا المنصتين ويمكنه التعامل مع المسرعات غير المتجانسة عن طريق تشغيل المهام على العتاد المتاح لكل جهاز (MPS على Mac، وCUDA على الجهاز المكتبي).

#### آلية العمل
- **الإعداد**: قم بتثبيت Ray على كلا الجهازين عبر pip (`pip install "ray[default,train]"`). ابدأ مجموعة Ray: جهاز واحد كعقدة رئيسية (مثل جهازك المكتبي)، وقم بتوصيل الـ Mac كعقدة عاملة عبر الشبكة. يتعامل Ray مع الاتصال عبر بروتوكوله الخاص.
- **نمط التدريب**: استخدم Ray Train لتوسيع نطاق أطر العمل مثل PyTorch أو TensorFlow. للإعدادات غير المتجانسة:
  - استخدم بنية "خادم المعاملات": يقوم منسق مركزي (على جهاز واحد) بإدارة أوزان النموذج.
  - حدد عمالاً يعملون على عتاد محدد: استخدم الديكورات مثل `@ray.remote(num_gpus=1)` لجهازك المكتبي من NVIDIA (CUDA) و `@ray.remote(num_cpus=2)` أو ما شابه لجهاز Mac (MPS أو استخدام المعالج كبديل).
  - يحسب كل عامل التدرجات على جهازه المحلي، ويرسلها إلى خادم المعاملات للمتوسط، ويستقبل الأوزان المحدثة.
  - يقوم Ray تلقائيًا بتوزيع دفعات البيانات والمزامنة عبر الأجهزة.
- **مثال على سير العمل**:
  1. حدد نموذجك في PyTorch (اضبط الجهاز على `"mps"` على Mac، و `"cuda"` على الجهاز المكتبي).
  2. استخدم واجهة برمجة تطبيقات Ray لتغليف حلقة التدريب الخاصة بك.
  3. شغل السكريبت على العقدة الرئيسية؛ يقوم Ray بتوزيع المهام على العمال.
- **الأداء**: سيكون التدريب أبطأ من مجموعة NVIDIA خالصة بسبب النفقات العامة للشبكة وعدم وجود اتصال مباشر بين وحدات معالجة الرسومات (مثلًا، عبر NCCL). وحدة معالجة الرسومات M2 في جهاز Mac أضعف من 4070Ti، لذا قم بموازنة أحمال العمل وفقًا لذلك (مثلًا، دفعات أصغر على Mac).
- **القيود**:
  - الأفضل للتدريب المتوازي للبيانات أو ضبط المعاملات الفائقة؛ التدريب المتوازي للنموذج (تقسيم نموذج كبير عبر الأجهزة) أكثر تعقيدًا في الإعدادات غير المتجانسة.
  - للنماذج الكبيرة جدًا (مثلًا، 1B+ معامل)، أضف تقنيات مثل الدقة المختلطة، أو نقطة فحص التدرج، أو التكامل مع DeepSpeed.
  - يمكن أن تؤدي زمن انتقال الشبكة بين الأجهزة إلى اختناق؛ تأكد من أنها على نفس شبكة LAN سريعة.
  - تظهر الأمثلة المجربة أنها تعمل على Apple M4 (مشابه لـ M2) + وحدات معالجة رسومات NVIDIA أقدم، لكن قم بتحسين القوة لجهاز 4070Ti الخاص بك.

يتوفر مثال عملي ورمز في إطار عمل يسمى "distributed-hetero-ml"، والذي يبسط هذا للعتاد غير المتجانس.

#### لماذا يناسب Ray إعدادك
- متعدد المنصات: يعمل على macOS (Apple Silicon)، وWindows، وLinux.
- يتكامل مع PyTorch: استخدم Ray Train لتوسيع نطاق الكود الحالي الخاص بك.
- لا حاجة لعتاد متطابق: يكتشف ويستخدم MPS على Mac وCUDA على الجهاز المكتبي.

### بديل: استخدام Dask لأحمال العمل الموزعة
Dask هي مكتبة Python أخرى للحوسبة المتوازية، مناسبة لمعالجة البيانات الموزعة وبعض مهام التعلم الآلي (مثلًا، عبر Dask-ML أو XGBoost).
- **الكيفية**: أنشئ مجموعة Dask (مجدول واحد على جهازك المكتبي، وعمال على كلا الجهازين). استخدم مكتبات مثل CuPy/RAPIDS على جانب NVIDIA لتسريع GPU، واستخدم المعالج أو MPS كبديل على Mac.
- **حالات الاستخدام**: جيدة لطرق المجموعات، أو بحث المعاملات الفائقة، أو نماذج نمط scikit-learn. للتعلم العميق، قم بإقرانها بـ PyTorch/TensorFlow، لكن المزامنة يدوية وأقل كفاءة من Ray.
- **القيود**: غير مُحسّن للتدريب المتزامن للتعلم العميق (مثلًا، لا يوجد خادم معاملات مدمج)؛ أفضل للمهام المتوازية بسهولة. دعم GPU يتطلب CUDA على NVIDIA، لكن جهاز Mac سيستخدم المعالج أو تكامل MPS المحدود.
- **الإعداد**: `pip install dask distributed`، ثم ابدأ مجموعة وقدم الوظائف.

### خيارات واعتبارات أخرى
- **Horovod**: غلاف التدريب الموزع هذا (لـ PyTorch/TensorFlow) يُثبت على macOS، لكنه يفتقر إلى الدعم الصريح لـ MPS. يمكنه استخدام Gloo أو MPI للاتصال (عبر المنصات)، لكن الكفاءة تنخفض بدون NCCL على جهاز Mac. ممكن لكن غير مجرب لمزيجك الدقيق—جربه إذا لم يناسبك Ray.
- **أطر عمل مخصصة**: أدوات مثل HetSeq تسمح بالتدريب على وحدات معالجة الرسومات غير المتجانسة، لكنها موجهة نحو مزيج NVIDIA/AMD، وليس Apple Silicon + CUDA.
- **التحديات عبر جميع الخيارات**:
  - اختلافات نظام التشغيل: افترض أن جهازك المكتبي يعمل بنظام Linux/Windows؛ تأكد من توافق إصدارات Python (يُوصى بـ 3.10+).
  - التبعيات: قم بتثبيت PyTorch مع MPS على Mac (`pip install torch --extra-index-url https://download.pytorch.org/whl/cpu`) وCUDA على الجهاز المكتبي.
  - مشاركة البيانات: استخدم نظام ملفات مشترك (مثل NFS) أو تخزين سحابي لمجموعات البيانات.
  - الاختبار: ابدأ صغيرًا — درّب شبكة CNN بسيطة على MNIST للتحقق.
- **متى تتجنب هذا النهج**: إذا كانت النماذج صغيرة، درّب فقط على 4070Ti (أسرع). للإنتاج، فكر في وحدات معالجة الرسومات السحابية للتجانس.

إذا قدمت المزيد من التفاصيل (مثل إطار العمل PyTorch/TensorFlow، نوع النموذج، نظام التشغيل على الجهاز المكتبي)، يمكنني تحسين هذا.

[كونك فقيرًا بوحدات معالجة الرسومات يجعلك مبدعًا](https://www.dilawar.ai/2025/07/04/Multi-Cluster%20Distributed%20Training%20on%20Heterogeneous%20Hardware/)  
[توثيق Ray - التثبيت](https://docs.ray.io/en/latest/ray-overview/installation.html)  
[Ray Train: تدريب نماذج قابلة للتوسع](https://docs.ray.io/en/latest/train/train.html)  
[توثيق Dask - وحدات معالجة الرسومات](https://docs.dask.org/en/stable/gpu.html)  
[دليل تثبيت Horovod](https://horovod.readthedocs.io/en/latest/install_include.html)  
[HetSeq على GitHub](https://github.com/yifding/hetseq)  
[تدريب PyTorch المسرّع على أجهزة Mac](https://developer.apple.com/metal/pytorch/)