---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: النماذج العامة تتفوق على الذكاء الاصطناعي المتخصص
translated: true
type: note
---

أنت تطرح سؤالاً جيداً وفي وقته المناسب. indeed, فإن البندول في صناعة الذكاء الاصطناعي قد تأرجح بالفعل مرة أخرى نحو **نماذج الأساس العامة** لتصبح أكثر منطقية (والمهيمنة اقتصادياً) من النماذج الضيقة المتخصصة في المجالات لمع حالات الاستخدام. إليك السبب وراء أن نهج "BloombergGPT / Med-PaLM / FinanceGPT / LawGPT" أصبح أقل جاذبية في 2024–2025:

### 1. تلوث البيانات والتداخل هائل
مجموعات البيانات التدريبية الأولية الحديثة (مثل RefinedWeb, FineWeb, Dolma, RedPajama v2، إلخ) تحتوي بالفعل على كميات هائلة من النصوص في المجالات المالية والقانونية والطبية وبرمجيات الحاسوب. على سبيل المثال:
- Common Crawl وحدها تحتوي على مليارات من ملفات هيئة الأوراق المالية والبورصات الأمريكية (SEC)، والمستندات القضائية، ومستودعات GitHub، وأوراق arXiv العلمية، والأخبار المالية، إلخ.
- النموذج العام المدرب على 10–30 تريليون رمز (token) يرى تقريباً نفس كمية البيانات عالية الجودة في المجالات المالية/القانونية/البرمجية التي يراها النموذج "المتخصص في مجال محدد" المدرب على 1 تريليون رمز من بيانات المجال المختارة يدوياً.

النتيجة: الفجوة في الأداء بين النموذج العام بحجم 100–400 مليار معلمة ونموذج "FinanceGPT" بحجم 100 مليار معلمة قد تقلصت بشكل كبير. BloombergGPT (2023) تفوق على النماذج العامة بنسبة ~10–20% في المهام المالية، ولكن Llama 3.1 405B أو Qwen2.5 72B اليوم غالباً ما يطابق أو يتجاوز أرقام BloombergGPT دون أي تدريب متخصص في المجال.

### 2. حدود المجالات أصبحت غير واضحة ومتحركة
لقد أشرت إلى هذا بشكل مثالي: التمويل + الذكاء الاصطناعي، العملات المشفرة + القانون، التكنولوجيا الحيوية + التمويل، البرمجة + الرياضيات + الفيزياء، إلخ. المعرفة متشابكة بشدة الآن.
- النموذج "المالي" البحت سيفشل في الإجابة على أسئلة التمويل اللامركزي (DeFi) والعقود الذكية لأنه لم يرَ ما يكفي من البرمجيات.
- النموذج "القانوني" البحت سيواجه صعوبة في قضايا تنظيم الذكاء الاصطناعي التي تتطلب فهم الـ Transformers وبيانات التدريب.
- النموذج "البرمجي" البحت سيكون سيئاً في كتابة خوارزميات التداول التي تحتاج إلى معرفة ببنية السوق الدقيقة (market microstructure).

النماذج العامة تتعامل مع هذه المجالات المركبة بشكل طبيعي لأنها رأت كل شيء مختلطاً معاً—تماماً مثل العالم الحقيقي.

### 3. MoE تجعل التخصص شبه مجاني
خليط الخبراء (Mixture-of-Experts) (مثل Mixtral, DeepSeek-V3, Qwen2.5-MoE, Grok-1.5، إلخ) يقوم بالفعل بتوجيه خفيف للمجال داخلياً. بعض الخبراء (Experts) يتعلمون التفاعل أكثر مع البرمجيات، والبعض الآخر مع الشؤون المالية، والبعض الآخر مع النصوص الطبية الحيوية، إلخ، دون الحاجة إلى فصل البيانات بشكل صريح. تحصل على معظم فائدة التوجيه الخاص بالمجال دون أي جهد هندسي أو مبيعات إضافي.

### 4. الاقتصاديات والتوزيع قد تغيرا
تفكير 2023: "درب نموذج FinanceGPT بحجم 50 مليار معلمة على بيانات احتكارية → بع وصول API للبنوك بسعر 50–200 دولار لكل مليون رمز."
واقع 2025:
- البنوك يمكنها ببساطة استخدام Claude 3.5 / GPT-4o / Llama 405B + RAG على مستنداتها الداخلية والحصول على 95–98% من الأداء مقابل 1/50 من التكلفة.
- النماذج مفتوحة المصدر المتطورة (مثل Llama 3.1 405B, Qwen2.5 72B, DeepSeek-V3) أصبحت الآن جيدة enough لدرجة أن معظم الشركات تفضل الضبط الدقيق (fine-tuning) أو حقن السياق (context injection) بدلاً من دفع علاوة كبيرة للحصول على نموذج مغلق ومتخصص في مجال محدد.
- تكلفة الاستضافة والاستدلال (inference) لنموذج مخصص بحجم 70–400 مليار معلمة في مجال محدد مرتفعة جداً إذا كانت قاعدة عملائك صغيرة.

### 5. ما بعد التدريب (SFT + RL) يغلق almost الفجوة المتبقية بأكملها
حتى إذا كان النموذج العام متأخراً قليلاً في المعرفة الخالصة للمجال بعد التدريب الأولي، فإن 500–5000 مثالاً عالي الجودة (اصطناعي أو مكتوب بواسطة الإنسان) في الضبط الدقيق تحت الإشراف (supervised fine-tuning) + DPO/RLHF المخصص لذلك المجال سيدفعه إلى مستوى الطراز الأول (state-of-the-art) على أي حال. هذا أرخص وأسرع بـ 100 مرة من جمع وتنظيف تيرابايتات من بيانات التدريب الأولي الخاصة بالمجال.

### متى لا تزال النماذج المتخصصة في مجال محدد منطقية (الحالات القليلة المتبقية)
- البيئات شديدة التنظيم أو الحساسة أمنياً حيث لا يمكنك حرفياً إرسال البيانات إلى OpenAI/Anthropic/Meta (بعض قطاعات الدفاع، بعض البنوك المركزية، بعض أنظمة الرعاية الصحية).
- عندما يكون لديك بيانات احتكارية ضخمة غير موجودة حقاً على الإنترنت العام (على سبيل المثال، تريليونات من سجلات الصفقات الخاصة، عقود من المذكرات القانونية الداخلية) ويمكنك إثبات أن النماذج العامة تفتقد الإشارة (signal).
- النماذج الصغيرة جداً التي تعمل على الجهاز (on-device) أو في الأنظمة المعزولة (air-gapped) (على سبيل المثال، مساعد قانوني يعمل entirely داخل جدار الحماية لشركة محاماة بأقل من 7 مليار معلمة).

بالنسبة لـ 95%+ من حالات الاستخدام التجارية في 2025، ومع ذلك، فإن الإجابة هي:
نموذج عام متطور (مفتوح أو مغلق) + ما بعد التدريب الخاص بالمجال / RAG / استخدام الأدوات >> نموذج مخصص مدرب مسبقاً على مجال محدد.

إذن نعم — أنت محق تماماً: جوهر الـ Transformer هو التنبؤ بالنص، بغض النظر عن المجال، ومشكلة خلط البيانات + قوانين التحجيم (scaling laws) + MoE + انخفاض تكلفة ما بعد التدريب جعلت النماذج المتخصصة بحتة في مجال محدد في الغالب ظاهرة لعام 2022–2023.