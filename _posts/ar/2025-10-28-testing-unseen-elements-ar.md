---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: اختبار التعميم باستخدام عناصر غير مرئية
translated: true
type: note
---

في حديث إيليا سوتسكيفر أثناء حصوله على جائزة "اختبار الزمن" في مؤتمر NeurIPS 2024 عن ورقته البحثية لعام 2014 "التعلم من تسلسل إلى تسلسل مع الشبكات العصبية" (والأعمال المبكرة ذات الصلة مثل أطروحة الدكتوراه الخاصة به حول نمذجة اللغة باستخدام RNN)، استذكر الجهود المبكرة لبناء نماذج لغة عصبية قادرة على التعميم. كان التحدي الرئيسي هو ضمان ألا تقوم النماذج بمجرد حفظ بيانات التدريب فحسب، بل أن تكون قادرة على معالجة المدخلات الجديدة – أي تجنب الإفراط في التخصيص.

الطريقة "الساذجة" المحددة التي أشير إليها للكشف عن هذا تتضمن اختبار النموذج على **كلمات أو n-grams (تسلسلات متعددة الكلمات) غير مرئية غير موجودة في مجموعة تدريب النموذج (غالبًا ما تسمى "قاعدة البيانات")**.

### لماذا هذه الطريقة؟
- **خطر الإفراط في التخصيص في نماذج اللغة المبكرة**: كانت النماذج الأساسية البسيطة مثل نماذج n-gram (على سبيل المثال، bigrams أو trigrams) غالبًا ما "تفرط في التخصيص" من خلال التنبؤ بطلاقة فقط إذا ظهر التسلسل الدائم في التدريب عدة مرات. فهي تُخصص احتمالًا يقارب الصفر لأي شيء جديد، مما يؤدي إلى فشل في التعميم.
- **اختبار الكشف الساذج**: للتحقق من التعميم الحقيقي (وليس الإفراط في التخصيص)، يتم التدريب على مجموعة تحقق/اختبار محجوزة مُصممة بعناصر "غير مرئية" متعمدة:
  - استبدال العبارات الشائعة بأخرى مُختلقة ولكنها معقولة (على سبيل المثال، في أطروحته، اختبار إكمال الجملة على اقتباس مزيف مثل "(ABC et al., 2003)" – وهي سلسلة لم يصادفها النموذج مطلقًا بسبب عدم شيوع الحروف الاستهلالية غير المعتادة واسم المؤلف).
  - قياس ما إذا كان النموذج يخصص احتمالات معقولة، أو يولد اكتمالات متماسكة، أو يحافظ على درجات perplexity/BLEU منخفضة على الرغم من وجود العنصر الجديد.
- إذا فشل النموذج (على سبيل المثال، ارتفاع perplexity أو مخرجات غير متماسكة) على هذه العناصر غير المرئية بينما يتفوق على بيانات التدريب المألوفة، فهو يفرط في التخصيص (يحفظ التفاصيل بدلاً من تعلم الأنماط). وإذا نجح، فهو يقوم بالتعميم من خلال التمثيلات المكتسبة (مثل حالات LSTM التي تلتقط القواعد النحوية والدلالات).

### أمثلة من عمله
- **في ورقة seq2seq (2014)**: استخدموا مفردات ثابتة (80k كلمة فرنسية، 160k كلمة إنجليزية)، مع استبدال الكلمات خارج المفردات (OOV) بـ "UNK". للكشف عن مشاكل التعميم، قاموا بخصم درجات BLEU لحدوث OOV ورسموا بيانيًا للأداء مقابل "متوسط رتبة تكرار الكلمة" (كلما كانت الكلمة أندر، كانت أشبه بالكلمات غير المرئية). تعاملت LSTM مع الكلمات النادرة/غير المرئية بشكل جيد دون تدهور، على عكس النماذج الأساسية.
- **في أطروحة الدكتوراه الخاصة به (2013، حول نمذجة اللغة باستخدام RNN)**: من أجل إكمال الجمل المنظم، اختبروا على سلاسل جديدة تمامًا مثل "(ABC et al., 2003)" (غير مرئية في التدريب due to ندرتها). قام الـ Multiplicative RNN (MRNN) بالتعميم بقوة (على سبيل المثال، التنبؤ بالسنة/السياق بشكل صحيح)، بينما لم تستطع النماذج الأساسية من نوع n-gram ذلك إلا إذا كانت هناك تطابقات exact – مما يسلط الضوء على إفراطها في التخصيص.

كان اختبار "التحقق من الكلمات/n-grams غير المرئية" هذا إرشاديًا مبسطًا ومبكرًا قبل التقنيات المتقدمة مثل dropout أو منحنيات التحقق. أشار سوتسكيفر في الحديث إلى كيف أن مثل هذه الرؤى دفعت نحو التوسع إلى نماذج LLM الحديثة، حيث يظل التعميم على البيانات غير المرئية الهائلة أساسيًا.

[التعلم من تسلسل إلى تسلسل مع الشبكات العصبية (arXiv PDF)](https://arxiv.org/pdf/1409.3215.pdf)  
[أطروحة دكتوراه إيليا سوتسكيفر (PDF)](https://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)  
[فيديو حديث إيليا سوتسكيفر في NeurIPS 2024](https://www.youtube.com/watch?v=YD-9NG1Ke5Y)