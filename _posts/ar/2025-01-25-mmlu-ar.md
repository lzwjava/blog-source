---
audio: true
lang: ar
layout: post
title: معيار MMLU
translated: true
---

هذا المنشور يقوم بتقييم نموذج لغوي على معيار MMLU (الفهم اللغوي متعدد المهام الضخم).

معيار MMLU هو اختبار شامل لقدرة النموذج على أداء مهام متنوعة عبر مجموعة واسعة من الموضوعات. يتكون من أسئلة اختيار من متعدد تغطي مجالات متنوعة مثل الرياضيات، التاريخ، القانون، والطب.

**روابط مجموعة البيانات:**

*   [Papers with Code](https://paperswithcode.com/dataset/mmlu)
*   [Hugging Face Datasets](https://huggingface.co/datasets/cais/mmlu)

```python
import torch
from datasets import load_dataset
import requests
import json

# تحميل مجموعة بيانات MMLU
subject = "abstract_algebra"  # اختر الموضوع الخاص بك
dataset = load_dataset("cais/mmlu", subject, split="test")

# تنسيق النص مع أمثلة قليلة
def format_mmlu_prompt(example, few_shot_examples=5):
    prompt = "The following are multiple choice questions (with answers) about {}.\n\n".format(subject.replace("_", " "))
    
    # إضافة أمثلة قليلة
    few_shot_dataset = load_dataset("cais/mmlu", subject, split="validation")
    for i in range(few_shot_examples):
        ex = few_shot_dataset[i]
        prompt += f"Question: {ex['question']}\n"
        prompt += "Choices:\nA. {}\nB. {}\nC. {}\nD. {}\n".format(*ex['choices'])
        prompt += f"Answer: {ex['answer']}\n\n"
    
    # إضافة السؤال الحالي
    prompt += f"Question: {example['question']}\n"
    prompt += "Choices:\nA. {}\nB. {}\nC. {}\nD. {}\n".format(*example['choices'])
    prompt += "Answer:"
    return prompt

# حلقة التقييم
correct = 0
total = 0

for example in dataset:
    prompt = format_mmlu_prompt(example)
    
    # إرسال طلب إلى llama-server
    url = "http://localhost:8080/v1/chat/completions"
    headers = {"Content-Type": "application/json"}
    data = {
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 5,
        "temperature": 0,
    }
    
    response = requests.post(url, headers=headers, data=json.dumps(data))
    
    if response.status_code == 200:
        output_text = response.json()["choices"][0]["message"]["content"]
        predicted_answer = output_text.strip()[0] if len(output_text.strip()) > 0 else ""
    else:
        predicted_answer = ""
        print(f"Error: {response.status_code} - {response.text}")
    
    # المقارنة مع الإجابة الصحيحة
    if predicted_answer.upper() == example["answer"]:
        correct += 1
    total += 1

# حساب الدقة
accuracy = correct / total
print(f"Subject: {subject}")
print(f"Accuracy: {accuracy:.2%} ({correct}/{total})")
```

السجل:

```bash
% python scripts/mmlu.py

Evaluating:   9%| 9/100 [01:31<15:19, 10.10s/it]Processed 10/100. Current Accuracy: 0.00% (0/10)
Evaluating:  19%| 19/100 [03:14<12:47,  9.47s/it]Processed 20/100. Current Accuracy: 0.00% (0/20)
Evaluating:  26%| 26/100 [04:30<13:44, 11.14s/it]
```