---
audio: true
lang: ar
layout: post
title: معيار MMLU
translated: true
---

هذا المنشور يقوم بتقييم نموذج لغوي على معيار MMLU (فهم اللغة متعدد المهام الضخم).

معيار MMLU هو اختبار شامل لقدرة النموذج على أداء مهام متنوعة عبر مجموعة واسعة من الموضوعات. يتكون من أسئلة متعددة الخيارات تغطي مجالات متنوعة مثل الرياضيات، التاريخ، القانون، والطب.

**روابط مجموعة البيانات:**

*   [Papers with Code](https://paperswithcode.com/dataset/mmlu)
*   [Hugging Face Datasets](https://huggingface.co/datasets/cais/mmlu)

لتشغيل خادم llama:

```bash
build/bin/llama-server -m models/7B/mistral-7b-instruct-v0.2.Q4_K_M.gguf --port 8080
```

لتشغيل كود اختبار MMLU:

```python
import torch
from datasets import load_dataset
import requests
import json
from tqdm import tqdm

# تحميل مجموعة بيانات MMLU
subject = "college_computer_science"  # اختر الموضوع الخاص بك
dataset = load_dataset("cais/mmlu", subject, split="test")

# تنسيق النص بدون أمثلة قليلة
def format_mmlu_prompt(example):
    prompt = "الأسئلة التالية هي أسئلة متعددة الخيارات حول {}".format(subject.replace("_", " "))
    prompt += ". يرجى الإجابة بحرف الخيار الصحيح (A, B, C, أو D) فقط."
    prompt += " أجب بالحرف فقط. لا حاجة لشرح."
    
    # إضافة السؤال الحالي
    prompt += f"السؤال: {example['question']}\n"
    prompt += "الخيارات:\nA. {}\nB. {}\nC. {}\nD. {}\n".format(*example['choices'])
    return prompt

# حلقة التقييم
correct = 0
total = 0

for i, example in tqdm(enumerate(dataset), total=len(dataset), desc="Evaluating"):
    prompt = format_mmlu_prompt(example)
    
    # إرسال طلب إلى خادم llama
    url = "http://localhost:8080/v1/chat/completions"
    headers = {"Content-Type": "application/json"}
    data = {
        "messages": [{"role": "user", "content": prompt}]
    }
    
    print(f"Input to API: {data}")
    response = requests.post(url, headers=headers, data=json.dumps(data))
    
    if response.status_code == 200:
        output_text = response.json()["choices"][0]["message"]["content"]
        predicted_answer = output_text.strip()[0] if len(output_text.strip()) > 0 else ""
        print(f"Output from API: {output_text}")
    else:
        predicted_answer = ""
        print(f"Error: {response.status_code} - {response.text}")
    
    # المقارنة مع الإجابة الصحيحة
    
    answer_map = {0: "A", 1: "B", 2: "C", 3: "D"}
    ground_truth_answer = answer_map.get(example["answer"], "")
    is_correct = predicted_answer.upper() == ground_truth_answer
    if is_correct:
        correct += 1
    total += 1
    
    print(f"السؤال: {example['question']}")
    print(f"الخيارات: A. {example['choices'][0]}, B. {example['choices'][1]}, C. {example['choices'][2]}, D. {example['choices'][3]}")
    print(f"الإجابة المتوقعة: {predicted_answer}, الإجابة الصحيحة: {ground_truth_answer}, صحيح: {is_correct}")
    print("-" * 30)

    if (i+1) % 10 == 0:
        accuracy = correct / total
        print(f"تمت معالجة {i+1}/{len(dataset)}. الدقة الحالية: {accuracy:.2%} ({correct}/{total})")


# حساب الدقة
accuracy = correct / total
print(f"الموضوع: {subject}")
print(f"الدقة: {accuracy:.2%} ({correct}/{total})")
```

السجل:

```bash
% python scripts/mmlu.py

Evaluating:   9%| 9/100 [01:31<15:19, 10.10s/it]Processed 10/100. Current Accuracy: 0.00% (0/10)
Evaluating:  19%| 19/100 [03:14<12:47,  9.47s/it]Processed 20/100. Current Accuracy: 0.00% (0/20)
Evaluating:  26%| 26/100 [04:30<13:44, 11.14s/it]

...

Processed 100/100. Current Accuracy: 40.00% (40/100)
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [15:15<00:00,  9.16s/it]
Subject: college_computer_science
Accuracy: 40.00% (40/100)
```