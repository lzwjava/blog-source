---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: مقدمة في تعزيز التدرج
translated: true
type: note
---

### ما هو التعزيز المتدرج؟

التعزيز المتدرج هو تقنية قوية في تعلم الآلة المجمعة تُستخدم في مهام التعلم الخاضع للإشراف مثل الانحدار والتصنيف والترتيب. إنه نوع من خوارزميات التعزيز الذي يبني نموذجًا تنبؤيًا قويًا من خلال الجمع بين عدة متعلمين ضعفاء (عادة أشجار قرار بسيطة) بطريقة تسلسلية. الفكرة الأساسية هي تحسين النموذج بشكل تكراري من خلال التركيز على الأخطاء (البواقي) التي ارتكبتها النماذج السابقة، مما "يعزز" الأداء الكلي بشكل فعال.

#### المفهوم الأساسي
في صميمه، يعامل التعزيز المتدرج عملية التعلم على أنها مشكلة تحسين. فهو يقلل من دالة الخسارة (على سبيل المثال، متوسط مربع الخطأ للانحدار أو خسارة السجل للتصنيف) باستخدام **النزول المتدرج**. يتم تدريب كل نموذج جديد في التسلسل للتنبؤ **بالناقد المتدرج** لدالة الخسارة فيما يتعلق بتنبؤات المجموعة الحالية. بهذه الطريقة، تقوم الخوارزمية "بتصحيح" أخطاء النماذج السابقة خطوة بخطوة.

#### آلية العمل: خطوة بخطوة
1. **تهيئة النموذج**: ابدأ بنموذج أساسي بسيط، غالبًا مجرد متوسط المتغير المستهدف (للانحدار) أو لوغاريتم الاحتمالات (للتوزيف).

2. **حساب البواقي (البواقي الزائفة)**: في كل تكرار، احسب البواقي - الاختلافات بين القيم الفعلية والمتوقعة. تمثل هذه "الأخطاء" التي يحتاج النموذج التالي إلى معالجتها.

3. **ملاءمة متعلم ضعيف**: درب متعلمًا ضعيفًا جديدًا (على سبيل المثال، شجرة قرار ضحلة) على هذه البواقي. الهدف هو التنبؤ باتجاه وحجم التصحيحات المطلوبة.

4. **تحديث المجموعة**: أضف المتعلم الجديد إلى المجموعة، مع تحجيمه بمعدل تعلم صغير (معامل انكماش، عادة <1) لمنع الإفراط في المطابقة. التنبؤ المحدث هو:
   \\[
   F_m(x) = F_{m-1}(x) + \eta \cdot h_m(x)
   \\]
   حيث \\( F_m(x) \\) هي المجموعة بعد \\( m \\) تكرار، \\( \eta \\) هو معدل التعلم، و \\( h_m(x) \\) هو المتعلم الضعيف الجديد.

5. **التكرار**: كرر لعدد ثابت من الجولات (أو حتى الاقتراب)، في كل مرة باستخدام البواقي المحدثة من المجموعة الكاملة.

هذه العملية هي "متدرجة" لأن البواقي تقارب متدرج دالة الخسارة، مما يسمح للخوارزمية بأداء شكل من أشكال النزول المتدرج الوظيفي في فضاء النماذج.

#### المزايا الرئيسية
- **دقة عالية**: غالبًا ما يتفوق على الخوارزميات الأخرى في البيانات الجدولية من خلال التقاط أنماط معقدة دون الحاجة إلى الكثير من هندسة السمات.
- **المرونة**: يدعم دوال خسارة مخصصة والتقييد (على سبيل المثال، عقوبات L1/L2) للتعامل مع الإفراط في المطابقة.
- **الكفاءة**: قابل للتوزيع المتوازي في التطبيقات مثل XGBoost، الذي يحسن عملية التعزيز للسرعة والقابلية للتوسع.

#### العلاقة بـ XGBoost
كما ذكرت في استفسارك، فإن XGBoost (التعزيز المتدرج المتطرف) هو تطبيق شائع ومحسن لهذا الإطار. فهو يضيف تحسينات مثل التقسيم القائم على المدرج التكراري للتدريب الأسرع والتحقق المتقاطع المدمج، مما يجعله الخيار المفضل في المسابقات مثل Kaggle.

للتعمق أكثر، يشكل التعزيز المتدرج الأساس لمتغيرات مثل LightGBM و CatBoost، حيث يقوم كل منهما بتعديل جوانب مثل نمو الشجرة أو معالجة البيانات الفئوية.

#### المراجع
- [آلات التعزيز المتدرج: برنامج تعليمي](https://www.stat.cmu.edu/~cshalizi/402/lectures/18-gbm.pdf) (ملاحظات محاضرة جامعة كارنيغي ميلون)
- [توثيق XGBoost: مقدمة إلى أشجار التعزيز](https://xgboost.readthedocs.io/en/stable/tutorials/model.html)
- [فهم آلات التعزيز المتدرج](https://towardsdatascience.com/understanding-gradient-boosting-machines-9be756fe76ab) (مقال Towards Data Science)