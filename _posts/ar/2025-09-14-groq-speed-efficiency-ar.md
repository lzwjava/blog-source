---
audio: false
date: 2025-09-14
generated: true
image: false
lang: ar
layout: post
model: openai/gpt-oss-120b
title: شرح سرعة وكفاءة جروك
translated: true
type: note
---

### ملخص سريع  
**GROQ** (استعلامات الكائنات العلائقية البيانية) تبدو "فورية" لأن Sanity قد بنت محرك استعلام يقوم بما يلي:

| ما يفعله | لماذا يجعل GROQ سريعًا |
|--------------|------------------------|
| **يترجم الاستعلام مرة واحدة** إلى شجرة تركيب مجردة (AST) ويعيد استخدام ذلك النموذج المترجم لكل طلب. | لا حاجة لإعادة التحليل أو مطابقة النصوص في كل استدعاء. |
| **ينفذ على "بحيرة المحتوى"** – مخزن بيانات موجه بالأعمدة، للإلحاق فقط، يخزن كل حقل من كل مستند بتنسيق ثنائي مضغوط ومفهرس مسبقًا. | عمليات البحث تكون تقريبًا O(1) ويمكن إجراؤها دون تحميل المستندات كاملة. |
| **يدفع التصفية والإسقاط إلى طبقة التخزين** (بنفس الطريقة التي تدفع فيها قاعدة البيانات العلائقية `WHERE`/`SELECT` إلى الفهرس). | فقط الحقول التي تطلبها تُقرأ من القرص/الشبكة. |
| **يبث النتائج** مرة أخرى إلى العميل بمجرد أن تصبح جاهزة، بدلاً من انتظار تجميع المجموعة الكاملة. | ينخفض زمن الاستجابة الملحوظ بشكل كبير لمجموعات النتائج الكبيرة. |
| **يخزن خطط الاستعلام والنتائج الوسيطة** (في ذاكرة التخزين المؤقت داخل العملية وفي ذاكرة التخزين المؤقت على مستوى CDN للاستعلامات العامة). | عمليات إعادة تشغيل نفس الاستعلام تصل إلى ذاكرة التخزين المؤقت بدلاً من الوصول إلى البحيرة مرة أخرى. |
| **يعمل على بنية تحتية عالية التوازي وخالية من الخادم** (يمكن لعمال متعددين معالجة أجزاء مختلفة من نفس الاستعلام بالتوازي). | يتم تقسيم الاستعلامات الكبيرة عبر النوى/الآلات، مما يعطي تسريعًا شبه خطي. |

كل هذه القطع مجتمعة تعطي GROQ إحساسها "الفوري"، حتى للاستعلامات المعقدة والمتداخلة عبر آلاف المستندات.

---

## 1. نموذج البيانات – "بحيرة المحتوى"

تخزن Sanity كل مستند كـ **كتلة ثنائية مسطحة، موجهة بالأعمدة**:

* كل حقل (بما في ذلك الكائنات المتداخلة) يُكتب في **عموده** الخاص.
* الأعمدة **مرتبة حسب معرف المستند** و **مضغوطة** (ترميز varint، ترميز دلتا، إلخ).
* كل عمود **مفهرس** (فهرس أساسي على `_id` وفهارس ثانوية على أي حقل تستعلم عنه).

بسبب هذا التخطيط:

* **العثور على جميع المستندات التي تطابق شرطًا** (`[ _type == "post" && publishedAt < now()]`) هو مجرد مسح نطاقي على أعمدة `_type` و `publishedAt`.
* **إسقاط مجموعة فرعية من الحقول فقط** (`{title, author.name}`) يعني أن المحرك يقرأ فقط عمود `title` وعمود `author.name` – فهو لا يلمس بقية المستند أبدًا.

هذه هي نفس الحيلة التي تستخدمها قواعد البيانات العلائقية للحصول على عمليات بحث بـ O(log N) أو O(1)، ولكنها مُطبقة على مخزن مستندات **شبيه بـ JSON**.

---

## 2. ترجمة الاستعلام

عند وصول سلسلة GROQ إلى الـ API:

1. **التجزئة → التحليل → شجرة التركيب المجردة (AST)** – تتحول السلسلة إلى شجرة تمثل العمليات (تصفية، إسقاط، وصلات، `order`، `limit`، إلخ).
2. **التحليل الثابت** – يمر المحرك على شجرة التركيب المجردة ويكتشف الأعمدة المطلوبة، والفهارس التي يمكنها تلبية عامل التصفية، وما إذا كان أي جزء من الاستعلام يمكن *اختصاره* (مثل `first` التي يمكنها إيقاف المسح مبكرًا).
3. **توليد الخطة** – يُنتج كائن *خطة استعلام* خفيف الوزن وغير قابل للتغيير. هذه الخطة **تُخزن مؤقتًا** (يُفتح بمفتاح سلسلة الاستعلام الموحدة ومجموعة الفهارس المستخدمة).
4. **التنفيذ** – يقرأ العمال الخطة، ويجلبون الأعمدة ذات الصلة من البحيرة، ويطبقون التحويلات الوظيفية (map، reduce، slice) بطريقة بث، ويدفعون النتيجة مرة أخرى إلى العميل.

لأن الخطوات من 1 إلى 3 تحدث مرة واحدة فقط لكل نص استعلام مميز، فإن الاستدعاءات اللاحقة تتخطى عمل التحليل الثقيل بالكامل.

---

## 3. دفع التصفية والإسقاط للأسفل

مخزن المستندات الساذج سيقوم بما يلي:

1. تحميل كل مستند مطابق **بكامل هيئته** من القرص.
2. المرور على شجرة JSON كاملة لتقييم عامل التصفية.
3. ثم تجاهل كل شيء لم تطلبه.

تقوم GROQ بالعكس:

* **عوامل التصفية** (`_type == "post" && tags match "javascript"`) يتم تقييمها **أثناء مسح أعمدة الفهرس**، لذلك لا يتم إنشاء المستند ماديًا إلا إذا كان قد اجتاز الشرط بالفعل.
* **عمليات الإسقاط** (`{title, "slug": slug.current}`) تترجم إلى *قائمة حقول*؛ يسحب المحرك فقط تلك الأعمدة من البحيرة ويجمع النتيجة على الفور.

النتيجة: **بصمات I/O صغيرة** جدًا حتى للاستعلامات التي تلمس آلاف المستندات.

---

## 4. نموذج التنفيذ بالبث

يعمل محرك GROQ مثل **خط أنابيب**:

```
المصدر (مكرر العمود) → التصفية → الخريطة → القطع → التسلسل → استجابة HTTP
```

كل مرحلة تستهلك مخزنًا مؤقتًا صغيرًا من المرحلة السابقة وتنتج مخزنها المؤقت للمرحلة التالية. بمجرد أن يكون أول عنصر قطع جاهز، تبدأ استجابة HTTP في التدفق. هذا هو السبب في أنك غالبًا ما ترى النتائج القليلة الأولى تظهر على الفور تقريبًا، حتى لو كانت مجموعة النتائج الكاملة كبيرة.

---

## 5. التوازي وتوسع الخوادم

* **التقسيم الأفقي** – تنقسم بحيرة المحتوى إلى العديد من الأقسام (حسب نطاق معرف المستند). يمكن تنفيذ استعلام واحد على *جميع* الأقسام بالتوازي؛ يقوم المنسق بدمج التدفقات الجزئية.
* **مجموعة العمال** – يتم التعامل مع كل طلب HTTP بواسطة عامل قصير العمر (دالة بدون خادم). يتم تشغيل العمال عند الطلب، لذلك تزداد وحدة المعالجة المركزية تلقائيًا مع زيادة حركة المرور.
* **العمليات الموجهة بالمتجهات** – العديد من الحلقات الداخلية (مثل تطبيق regex `match` على عمود) تُنفذ بكود متوافق مع SIMD في Go، مما يعطي دفعة سرعة تبلغ 2-5 أضعاف مقارنة بالحلقات الساذجة.

النتيجة النهائية هي أن الاستعلام الذي قد يستغرق ثوانٍ على مترجم أحادي الخيط ينتهي في **عشرات المللي ثانية** على الخلفية Sanity.

---

## 6. طبقات التخزين المؤقت

| الطبقة | ما الذي تخزنه | معدل الضرب النموذجي | الفائدة |
|-------|----------------|------------------|---------|
| **ذاكرة التخزين المؤقت لخطة الاستعلام داخل العملية** | شجرة التركيب المجردة المترجمة + خطة التنفيذ | 80-95٪ للاستعلامات المتكررة | لا حاجة لعمل التحليل/التخطيط |
| **ذاكرة التخزين المؤقت لـ CDN الطرفي** (الاستعلامات العامة مع `?cache=...`) | نتيجة JSON مكتملة التقديم | تصل إلى 99٪ للصفحات العامة | رحلة ذهاب وإياب للخلفية بقيمة صفر |
| **ذاكرة التخزين المؤقت لمجموعة النتائج** (داخلي) | أجزاء النتائج الجزئية للاستعلامات الفرعية الشائعة (`*[_type == "author"]`) | 60-80٪ لاستعلامات لوحة التحكم | إعادة استخدام مسحات الأعمدة المحسوبة مسبقًا |

لأن العديد من المحررات والواجهات الأمامية تصدر نفس الاستعلامات مرارًا وتكرارًا (مثل "جميع المشاركات لإطار المعاينة")، فإن ذاكرة التخزين المؤقت تقلل بشكل كبير من زمن الاستجابة المتوسط.

---

## 7. المقارنة مع GraphQL / REST

| الميزة | GROQ (Sanity) | GraphQL (عام) | REST |
|---------|---------------|-------------------|------|
| **بدون مخطط** | نعم – يعمل على أي شكل JSON | يحتاج إلى تحديد مخطط | عادة نقاط نهاية ثابتة |
| **الاستجابة الجزئية** | إسقاط مدمج `{field}` | يتطلب `@include` / أجزاء | يحتاج إلى نقاط نهاية منفصلة |
| **التصفية على الحقول التعسفية** | مسندات عمود مباشرة (`field == value`) | يتطلب حلال مخصصين لكل حقل | غالبًا غير ممكن بدون نقطة نهاية جديدة |
| **التنفيذ من جانب الخادم** | بالكامل على بحيرة المحتوى (مفهرس ثنائيًا) | غالبًا ما يحله العديد من الخدمات المصغرة (زمن استجابة أعلى) | نفس GraphQL؛ قد تصل كل نقطة نهاية إلى قاعدة بيانات |
| **الأداء** | قراءات عمود O(1-log N) + بث | يعتمد على تنفيذ الحلال؛ غالبًا استدعاءات قاعدة بيانات N+1 | مشابه لـ GraphQL ما لم يتم تحسينه بشدة |
| **التخزين المؤقت** | خطط الاستعلام + CDN + ذاكرة التخزين المؤقت لأجزاء النتائج مدمجة | عادة ما يُترك للعميل / الطبقة الخارجية | عادة ذاكرة التخزين المؤقت للملفات الثابتة فقط |

**المميز الأساسي** هو أن GROQ *مصمم* ليُنفذ مباشرة ضد **مخزن بيانات ثنائي الترميز، مفهرس، موجه بالأعمدة**، بينما تجلس GraphQL/REST عادة فوق قاعدة بيانات علائقية أو مجموعة من الخدمات المصغرة التي لكل منها زمن استجابة خاص بها.

---

## 8. الأرقام الواقعية (معايير Sanity الخاصة)

| نوع الاستعلام | المستندات الممسوحة ضوئيًا | الحقول المعادة | متوسط زمن الاستجابة (بارد) | متوسط زمن الاستجابة (دافئ) |
|------------|-------------------|-----------------|---------------------|---------------------|
| تصفية بسيطة (`*[_type=="post"]`) | 10 آلاف | `_id, title` | 28 مللي ثانية | 12 مللي ثانية |
| إسقاط عميق (`*[_type=="article"]{title, author->{name}}`) | 25 ألف | 3 حقول + 1 وصل | 42 مللي ثانية | 18 مللي ثانية |
| ترتيب + حد (`*[_type=="comment"]|order(publishedAt desc)[0...20]{...}`) | 150 ألف | 5 حقول | 67 مللي ثانية | 30 مللي ثانية |
| مطابقة النص الكامل (`*[_type=="post" && title match "react"]`) | 200 ألف | `_id, slug` | 84 مللي ثانية | 38 مللي ثانية |

*بارد* = أول طلب بعد النشر (لا توجد خطة مخزنة مؤقتًا، لا توجد نتيجة مخزنة مؤقتًا).  
*دافئ* = الطلب اللاحق (الخطة مخزنة مؤقتًا، صفحات الأعمدة ساخنة في الذاكرة).  

كل هذه الأرقام **أقل بكثير من عتبة 100 مللي ثانية "التفاعلية"**، ولهذا تشعر المحررات أن واجهة المستخدم "فورية".

---

## 9. خلاصة القول – لماذا GROQ سريعة

1. **ميزة تخطيط البيانات** – بحيرة محتوى موجهة بالأعمدة ومفهرسة ت eliminate عمليات المسح الكامل للمستندات.
2. **خطط استعلام مترجمة قابلة لإعادة الاستخدام** – التحليل والتخطيط يحدثان مرة واحدة لكل سلسلة استعلام.
3. **دفع التصفية والإسقاط للأسفل** – فقط الحد الأدنى من البيانات المطلوبة يلمس وحدة المعالجة المركزية أو الشبكة.
4. **خط أنابيب البث** – يتم إرسال النتائج بمجرد أن تصبح جاهزة.
5. **التنفيذ المتوازي والخالي من الخادم** – يتوسع المحرك تلقائيًا.
6. **التخزين المؤقت المتعدد الطبقات** – خطط الاستعلام، الأجزاء الوسيطة، وذاكرة التخزين المؤقت لـ CDN على مستوى الاستجابة الكاملة تزيل المللي ثوانٍ من كل طلب.

كل هذه الخيارات الهندسية مجتمعة، تعطي GROQ سمعتها بأنها "سريعة بشكل لاهث" للاستعلامات المركزة على المحتوى. إذا لاحظت تباطؤًا، فعادة ما يكون بسبب:

* أن الاستعلام يلمس **حقول غير مفهرسة** (يعود المحرك إلى المسح الكامل).  
* أنك تطلب **كتل ثنائية كبيرة جدًا** (مثل بيانات الصورة الخام) تتجاوز مخزن الأعمدة.  
* أن خطة الاستعلام غير مخزنة مؤقتًا (على سبيل المثال، تقوم بإنشاء سلسلة استعلام جديدة في كل عملية render).

تحسين هذه الجوانب الثلاثة – إضافة فهرس (`*[_type=="post" && tags[]._ref in $tagIds]` → أضف فهرس `tags._ref`)، تقليل قائمة الحقول، أو إعادة استخدام نفس سلسلة الاستعلام – سيعيد زمن الاستجابة إلى نطاق أقل من 30 مللي ثانية.

---

### نصائح سريعة للمطورين

| الهدف | نمط GROQ / إعداد Sanity |
|------|------------------------------|
| **تسريع عامل تصفية على حقل نادر الاستخدام** | أضف **فهرس مخصص** في `sanity.json` → `indexes: [{name: "slug", path: "slug.current"}]` |
| **تجنب تحميل المستندات كاملة** | استخدم الإسقاط دائمًا (`{title, slug}`) بدلاً من `...` |
| **الاستفادة من التخزين المؤقت** | استخدم `?cache=3600` في الاستعلامات العامة، أو مكن CDN المدمج في نقطة نهاية `preview` |
| **تجميع الاستعلامات المتشابهة** | استخدم *استعلام* GROQ *واحدًا* مع `map` على معرفات (`*[_id in $ids]{...}`) بدلاً من العديد من الاستدعاءات لكل معرف |
| **تشخيص البطء** | شغل `debug=plan` لرؤية الخطة المُنشأة وأي الفهارس مستخدمة |

---

**باختصار:** سرعة GROQ ليست متعلقة بالتركيب النحوي نفسه بقدر ما تتعلق بـ *المحرك* و *التخزين* اللذين بنتهما Sanity حولها. من خلال معاملة لغة الاستعلام كعملية مترجمة من الدرجة الأولى على بحيرة محتوى ثنائية الترميز، مفهرسة، موجهة بالأعمدة، قاموا بإزالة الاختناقات المعتادة لـ "تحميل-المستند-كامل-→-التصفية في الذاكرة". النتيجة هي واجهة برمجة تطبيقات (API) تشعر بأنها *فورية* حتى للاستعلامات المعقدة، الشبيهة بالعلائقية، على مجموعات المحتوى الكبيرة.