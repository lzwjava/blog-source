---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: تحسين خدمة نماذج اللغة متعددة أهداف مستوى الخدمة
translated: true
type: note
---

### نظرة عامة
يقدم البحث المعنون "SLOs-Serve: Optimized Serving of Multi-SLO LLMs" نظام SLOs-Serve، وهو نظام مصمم لتقديم نماذج اللغة الكبيرة (LLMs) بكفاءة في التطبيقات متعددة المراحل حيث يكون لكل مرحلة (مثل المعالجة المسبقة للمدخلات Prefill، وتوليد الرموز Decode) ولكل تطبيق (مثل روبوتات الدردشة، ومساعدات البرمجة) أهداف مستوى خدمة (SLOs) محددة. تضمن أهداف مستوى الخدمة هذه زمن انتقال منخفض للجوانب الموجهة للمستخدم، مثل زمن وصول أول رمز (TTFT) للمعالجة المسبقة وعدد الرموز في وقت الإخراج (TPOT) للتوليد. غالبًا ما تنتهك أنظمة التقديم التقليدية مثل vLLM أو Sarathi-Serve أهداف مستوى الخدمة التفصيلية هذه تحت موارد مشتركة، خاصة أثناء فترات الذروة أو أحمال العمل المختلطة.

### التحديات والإسهامات الرئيسية
حدد المؤلفون التحديات في تقديم الخدمة متعددة أهداف مستوى الخدمة:
- **الطلبات متعددة المراحل**: تتطلب التطبيقات مثل نماذج اللغة الكبيرة للاستدلال (أهداف مستوى خدمة صارمة أثناء مراحل "التفكير") أو وكلاء استدعاء الأدوات (حلقات ذات معالجة مسبقة/توليد صارمة) ضمانات محددة لكل مرحلة.
- **التنافس على الموارد**: يؤدي مشاركة وحدات معالجة الرسومات إلى انتهاكات أهداف مستوى الخدمة في الإعدادات المشتركة أو المنفصلة.
- **حركة المرور المتقطعة**: تسبب الزيادات المفاجئة في الحمل إرباكًا للمجدولين.

تشمل إسهامات نظام SLOs-Serve ما يلي:
- مجدول يعتمد على البرمجة الديناميكية (DP) يقوم بتحسين توزيع الرموز (ميزانية المعالجة المسبقة، أحجام الدُفعات) لتلبية أهداف مستوى الخدمة مع تعظيم الإنتاجية.
- دعم للمعالجة المسبقة المجزأة، والتوليد الاستباقي المتكيف مع أهداف مستوى الخدمة (تخصيص أطوال التكهن لكل فئة SLO)، والتحكم في القبول المرن (ضمان أهداف مستوى الخدمة للطلبات المقبولة، وتأجيل الأخرى).
- بنية موزعة مع توجيه متعدد النسخ المتماثلة ومرونة في مواجهة الذروات، مبنية على vLLM للتجميع في دفعات وعلى Ray للتنسيق.

| التطبيق      | هدف مستوى الخدمة للمعالجة المسبقة | هدف مستوى الخدمة للتوليد | مثال               |
|---------------|-----------------------------------|--------------------------|---------------------|
| التلخيص       | صارم (مثل أقصى تباطؤ 3x)          | مرن (100ms TPOT)         | معالجة المستندات   |
| البرمجة       | مرن                               | صارم (50ms TPOT)         | توليد الكود        |
| روبوت الدردشة | مرن                               | مرن                      | الاستفسارات التفاعلية |
| استدعاء الأداة | صارم (حلقات)                      | صارم (حلقات)، مرن (نهائي)| سير عمل الوكيل     |
| الاستدلال     | صارم (تفكير)                      | صارم (تفكير)، مرن (رد)   | سلسلة الفكر        |

### تصميم النظام
- **المجدول (الخوارزمية 1)**: يستخدم البرمجة الديناميكية لقبول الطلبات وتخطيط الدفعات، ونمذجة وقت التنفيذ عبر متنبئ مستوحى من نموذج Roofline (دقة R² > 0.8). تتتبع الحالات الذاكرة، وميزانية المعالجة المسبقة، والطلبات المقبولة؛ تعطي التحولات الأولوية للمواعيد النهائية المبكرة وتحقيق أهداف مستوى الخدمة.
- **تشكيل الدفعة**: تحديد الحجم الديناميكي (حتى 512+ رمزًا) بناءً على أضيق TPOT، مما يمكن من دفعات أكبر لإنتاجية أعلى دون انتهاكات لأهداف مستوى الخدمة.
- **التوليد الاستباقي**: يتكيف مع أطوال التكهن (مثل 1-10 رموز) لكل فئة SLO لتعزيز ميزانية المعالجة المسبقة، ويحل المشكلة عبر التعداد لتحقيق التوازن الأمثل بين المعالجة المسبقة والتوليد.
- **تعدد النسخ المتماثلة والذروات**: يقوم المتحكم المركزي بتوجيه الطلبات بشكل استباقي؛ تذهب الطلبات غير القابلة للتحقيق إلى قائمة انتظار بأفضل جهد، ويتم إيقافها إذا لزم الأمر.

يستكشف التصميم المقايضات، مثل أن الدفعات الأكبر تزيد الإنتاجية ولكنها تخاطر بزيادة زمن الانتظار (كما هو موضح في الأشكال التي تظهر مناطق جدوى أهداف مستوى الخدمة).

### التقييم
تم الاختبار على 6 سيناريوهات (روبوت دردشة، برمجة، تلخيص، مختلط، استدعاء أداة، استدلال) باستخدام بيانات تتبع حقيقية (أحمال عمل Azure LLM) ومجموعات بيانات (مثل ShareGPT, HumanEval). النماذج: OPT-7B/13B/30B, ToolLlama-7B. الأجهزة: 4×A100 GPUs (الرئيسية)، حتى 8×H100.

- **مكاسب السعة**: متوسط تحسن بمقدار 2.2× مقارنة بـ vLLM/Sarathi-Serve/DistServe (المتوسط الهندسي عبر السيناريوهات). على سبيل المثال، 2.4× في الاستدلال، 2.1× في البرمجة أثناء الذروات.
- **التحجيم**: فائق الخطية مع النسخ المتماثلة (حتى 6.2× في استدعاء الأداة تحت الذروات) عبر التوجيه.
- **دراسات الاستبعاد**: تضيف آلية التكهن 1.66×، والتوجيه 1.19×، ومعالجة الذروات 1.34×.
- النفقات العامة: <10ms لكل استدعاء للجدولة.

تظهر الأشكال أن نظام SLOs-Serve يحافظ على زمن الانتظار p99 قريبًا من الأهداف المستهددة أثناء الذروات، بينما تتدهور أداء الأنظمة الأساسية للمقارنة.

### الاستنتاجات
يتقدم نظام SLOs-Serve في تقديم نماذج اللغة الكبيرة من خلال ضمان تعدد أهداف مستوى الخدمة في بيئات متنوعة ومتقطعة، مما يطلق كفاءة تزيد عن 2x. يمكن أن يمتد العمل المستقبلي إلى أطوال توليد غير معروفة أو مراحل أكثر. يوضح النظام أن الجدولة المخصصة لأهداف مستوى الخدمة هي المفتاح لنشر نماذج اللغة الكبيرة ذات جودة الإنتاج.

[SLOs-Serve: Optimized Serving of Multi-SLO LLMs](https://arxiv.org/abs/2504.08784)