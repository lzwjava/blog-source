---
audio: false
generated: true
lang: ar
layout: post
title: رؤية الحاسوب تعجز عن مجاراة البشر
translated: true
type: note
---

تدوينة Yin Wang يجادل بأن أنظمة رؤية الحاسوب، حتى المتقدمة منها في عام 2019، كانت بعيدة كل البعد عن تحقيق أداءً مماثلاً للبشر. وتدعي أن هذه الأنظمة تواجه صعوبة في التعرف الأساسي على الكائنات (مثل التعرف على سيارة) ويمكن خداعها بسهولة من خلال الأمثلة الخادعة أو التعديلات الطفيفة على الصورة، على عكس البشر الذين يتعرفون على الأشياء دون جهد. يقترح Wang أن المجال يبالغ في تقدير تقدمه وأن الرؤية الحاسوبية الحقيقية المماثلة للبشر تبقى بعيدة المنال بسبب قيود أساسية في كيفية معالجة هذه الأنظمة للصور وفهمها.

### هل هذا صحيح؟
اعتبارًا من تاريخ نشر التدوينة في أكتوبر 2019، كان طرح Wang وجيهاً بناءً على حالة مجال رؤية الحاسوب في ذلك الوقت:

-   **محدودية التعميم**: اعتمدت نماذج رؤية الحاسوب، مثل الشبكات العصبية التلافيفية (CNNs)، بشكل كبير على مطابقة الأنماط ضمن بيانات التدريب. وغالبًا ما فشلت في التعميم على سياقات جديدة أو التعامل مع الحالات الحدية بشكل جيد، كما يصف Wang. على سبيل المثال، يمكن أن تسيء النماذج تصنيف الكائنات عندما تتغير الإضاءة أو الزوايا أو الخلفيات بشكل كبير.

-   **القابلية للاختراق بالهجمات الخادعة**: كانت نقطة Wang حول الأمثلة الخادعة – الصور المعدلة بطريقة خفية لتضليل النماذج – دقيقة. أظهرت الأبحاث، مثل بحث Goodfellow et al. (2014)، أن الاضطرابات الصغيرة غير المحسوسة يمكن أن تسبب للنماذج سوء تصنيف الصور بثقة عالية، مما يسلط الضوء على فجوة بين الرؤية البشرية والآلية.

-   **المزاعم المبالغ فيها**: تنتقد التدوينة الضجة المحيطة برؤية الحاسوب. في عام 2019، بينما أظهرت نماذج مثل ResNet و YOLO والمحوّلات المبكرة نتائج مذهلة في المعايير المرجعية (مثل ImageNet)، كانت هذه مجموعات بيانات خاضعة للرقابة. غالبًا ما كشفت التطبيقات الواقعية عن نقاط ضعف، مثل حالات التعريف الخاطئ في القيادة الذاتية أو أنظمة التعرف على الوجوه.

ومع ذلك، فإن نبرة التدوينة قطعية، مدعية أن "لا وجود لرؤية حاسوبية بمستوى البشر". هذا يتغاضى عن التقدم في مهام محددة. على سبيل المثال:
-   **النجاح في مهام محددة**: بحلول عام 2019، تفوقت أنظمة رؤية الحاسوب على البشر في مهام ضيقة مثل تصنيف بعض الصور الطبية (مثل الكشف عن اعتلال الشبكية السكري) أو التعرف على كائنات محددة في بيئات خاضعة للرقابة.
-   **التقدم منذ عام 2019**: بحلول عام 2025، سدت التطورات مثل محولات الرؤية (مثل ViT, CLIP) والنماذج متعددة الوسائط واسعة النطاق (مثل GPT-4o, DALL·E 3) الفجوة. تتناول هذه النماذج مدخلات أكثر تنوعًا، وتعمم بشكل أفضل عبر السياقات، وتدمج اللغة والرؤية لتحسين التفكير. ومع ذلك، فإنها لا تُقلّد تمامًا متانة الرؤية البشرية أو وعيها السياقي أو فهمها البديهي.

### تقييم نقدي
ادعاء Wang الأساسي – أن رؤية الحاسوب في عام 2019 لم تكن بمستوى البشر – كان صحيحًا إلى حد كبير. افتقرت النماذج إلى التعميم والمتانة والفهم البديهي المميز للرؤية البشرية. ومع ذلك، فإن رفضه للتقدم قد يكون متشائمًا أكثر من اللازم، حيث تم إنجاز تقدم كبير منذ ذلك الحين. حتى في عام 2025، بينما تتفوق رؤية الحاسوب في مجالات محددة، فإنها لا تزال قاصرة عن الإدراك البشري في السيناريوهات المفتوحة بسبب مشاكل مثل:
-   **الاستدلال السياقي**: يدمج البشر بيانات الحواس مع المعرفة العالمية دون جهد؛ بينما تعاني الآلات من ذلك.
-   **الحالات الحدية**: يمكن أن تفشل النماذج في المواقف النادرة أو الجديدة حيث يتكيف البشر بسرعة.
-   **كفاءة الطاقة**: الرؤية البشرية أكثر كفاءة في استخدام الطاقة من النماذج الحسابية.

تبقى التدوينة ذات صلة كنقد للمبالغة في قدرات الذكاء الاصطناعي لكنها لا تأخذ في الاعتبار التقدم السريع في المجال. لا يوجد مصدر واحد يؤكد تحقيق رؤية "مماثلة للبشر" بحلول عام 2025، لكن الفجوة ضاقت بشكل ملحوظ.