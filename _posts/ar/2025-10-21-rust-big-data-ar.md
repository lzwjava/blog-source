---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: إمكانات رست لتحليل البيانات الضخمة
translated: true
type: note
---

### Rust مناسبة للبيانات الضخمة (#rust2018)

**المؤلف:** آندي غروف  
**تاريخ النشر:** 28 يناير 2018

هذه المدونة هي مقالة استشرافية كُتبت كجزء من مبادرة "#rust2018"، حيث يشارك المؤلف رؤيته لدور لغة Rust في العام القادم. يجادل آندي غروف، وهو مطور كان يبني أنظمة معالجة بيانات موزعة باستخدام Apache Spark، بأن إمكانات Rust غير المستغلة يمكن أن تحدث ثورة في معالجة البيانات الضخمة نظرًا لقوتها الأساسية في سلامة الذاكرة والأداء والقدرة على التنبؤ – دون مشاكل جامع القمامة أو النفقات العامة وقت التشغيل الشائعة في لغات مثل Java.

#### الحجج الرئيسية لاستخدام Rust في مجال البيانات الضخمة
يبدأ غروف بسرد رحلته مع Rust: حيث قدمها له زميل في العمل قبل بضع سنوات وأصبح مفتونًا بها بعد حضور مؤتمر RustConf في عام 2016. ويشيد بقدرة Rust على القضاء على نقاط الضعف الأمنية الشائعة مثل تجاوز سعة المخازن المؤقتة مع تقديم سرعة تشبه لغة C. بالنسبة للعمل على جانب الخادم، يسلط الضوء على حزم مثل *futures* و *tokio* لبناء تطبيقات غير متزامنة قابلة للتوسع. لكن شغفه الحقيقي يكمن في مجال البيانات الضخمة، حيث يمكن لـ Rust معالجة نقاط الألم في الأدوات الحالية.

في وظيفته اليومية، يعمل غروف مع Apache Spark، الذي أصبح الخيار المفضل للمعالجة الموزعة للبيانات ولكنه بدأ كمشروع أكاديمي بسيط وتوسع نطاقه من خلال إصلاحات هندسية بطولية. واجه Spark المبكر صعوبات مع:
- **النفقات العامة لتحويل البيانات إلى تنسيق تسلسلي في Java**: كانت عملية خلط البيانات بين العقد بطيئة وتستهلك الكثير من الذاكرة.
- **توقفات جمع القمامة (GC)**: تسببت هذه التوقفات في أداء غير متوقع، مما أدى إلى أخطاء "OutOfMemory" التي تتطلب ضبطًا لا نهاية له.

وقد خفف "مشروع Tungsten" الخاص بـ Spark (الذي أطلق حوالي عام 2014) من هذه المشاكل عن طريق:
- تخزين البيانات خارج منطقة الذاكرة المؤقتة (off-heap) بتنسيقات ثنائية (مثل تنسيق Parquet العمودي) لتجاوز جمع القمامة.
- استخدام إنشاء الشفرة على مستوى المرحلة بأكملها لتحسين تنفيذ وحدة المعالجة المركزية عبر bytecode.

هذه التغييرات حولت الاختناقات من خصائص JVM الغريبة إلى حدود وحدة المعالجة المركزية الخام، مما أثبت أن مكاسب الأداء تأتي من الكفاءة منخفضة المستوى وليس من التجريدات عالية المستوى.

فرضية غروف الجريئة: إذا تم بناء Spark بلغة Rust من اليوم الأول، لكان حتى التطبيق الأساسي قد حقق الأداء والموثوقية مباشرة. يضمن نموذج الملكية في Rust سلامة الذاكرة دون الحاجة إلى جامع القمامة، متجنبًا تضخم التسلسل والتوقفات غير المنتظمة. لا مزيد من تعديل إعدادات JVM – فقط تنفيذ سريع يمكن التنبؤ به. يرى أن هذه هي "الفرصة الفريدة" لـ Rust لتتفوق على المنافسين الحاليين مثل Spark، خاصة مع التضخم الهائل في أحجام البيانات.

#### مشروع DataFusion
لوضع هذه الرؤية موضع التنفيذ، أطلق غروف **DataFusion**، وهو نموذج أولي لمحرك استعلام مفتوح المصدر مكتوب بلغة Rust. في وقت كتابة هذا المقال (أوائل 2018)، كان في مرحلة ألفا ولكنه يعرض بالفعل:
- **واجهة برمجة تطبيقات DataFrame** لتحميل ملفات Parquet وتشغيل عمليات مثل التصفيات والجمع والتجميعات (مثال: [parquet_dataframe.rs](https://github.com/andygrove/datafusion/blob/master/examples/parquet_dataframe.rs)).
- **واجهة برمجة تطبيقات SQL** للاستعلامات التقريرية على نفس البيانات (مثال: [parquet_sql.rs](https://github.com/andygrove/datafusion/blob/master/examples/parquet_sql.rs)).

يخطط للعمل عليه في وقت فراغه خلال عام 2018 لصقل مهاراته في Rust وبناء شيء مفيد. بدعوة المجتمع للمساهمة، يشير إلى المستودع: [github.com/apache/arrow-datafusion](https://github.com/apache/arrow-datafusion).

#### التحديثات (حتى مايو 2024)
تتضمن المشاركة ملحقًا استذكاريًا يسلط الضوء على نمو DataFusion:
- التبرع به لمشروع Apache Arrow في فبراير 2019.
- الإعلان عن Ballista (طبقة التنفيذ الموزعة) في يوليو 2019: [الإعلان عن Ballista](https://andygrove.io/2019/07/announcing-ballista/).
- كتاب نُشر ذاتيًا بعنوان *How Query Engines Work* (فبراير 2020) يشرح داخليات DataFusion/Ballista: [رابط Leanpub](https://leanpub.com/how-query-engines-work).
- التبرع بـ Ballista لمشروع Apache Arrow في أبريل 2021.
- تبرعت Apple بـ **DataFusion Comet** (مارس 2024) لتعزيز Spark باستخدام التسريع القائم على Rust: [مدونة Arrow](https://arrow.apache.org/blog/2024/03/06/comet-donation/) و [GitHub](https://github.com/apache/datafusion-comet).
- انضم غروف إلى Apple في أبريل 2024 للعمل على Comet.
- تخرج DataFusion ليصبح مشروعًا من المستوى الأول في Apache في مايو 2024: [مدونة Arrow](https://arrow.apache.org/blog/2024/05/07/datafusion-tlp/).

يختتم غروف بتشجيع القراء على الخوض في محركات الاستعلام عبر كتابه، ووضع Rust كمغير لقواعد اللعبة للتطبيقات المكثفة البيانات.

[Rust مناسبة للبيانات الضخمة (#rust2018)](https://andygrove.io/2018/01/rust-is-for-big-data/)