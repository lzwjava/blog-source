---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: 'آنابورنا لابس: سيليكون مخصص من إيه دبليو إس'
translated: true
type: note
---

### ما هي Annapurna Labs؟

**Annapurna Labs** هي شركة إسرائيلية لأشباه الموصلات متخصصة في **معالجات عالية الأداء وموفرة للطاقة** للحوسبة السحابية، والشبكات، والتخزين، وأحمال عمل الذكاء الاصطناعي. **تم الاستحواذ عليها من قبل أمازون في يناير 2015** مقابل ما يُقال إنه ~350-370 مليون دولار وتعمل الآن كشركة تابعة مملوكة بالكامل لـ **Amazon Web Services (AWS)**.

تصمم Annapurna Labs **رقاقات سيليكون مخصصة** تشغل جزءًا كبيرًا من بنية AWS الأساسية، مما يمكن أمازون من تقليل الاعتماد على بائعي الرقاقات الخارجيين مثل Intel و Broadcom و NVIDIA لأحمال عمل معينة.

---

### الرقاقات الرئيسية التي صممتها Annapurna Labs (المستخدمة في AWS)

| عائلة الرقاقة | النوع | الميزات الرئيسية | حالة الاستخدام الأساسية في AWS |
|-------------|------|--------------|-----------------------|
| **Alpine** | نظام على رقاقة (SoC) قائم على ARM | وحدات معالجة مركزية متعددة النواة ARMv8، استهلاك منخفض للطاقة، شبكات وتخزين مدمج | أوائل نسخ EC2، وحدات تحكم التخزين |
| **Graviton** | وحدة معالجة مركزية (CPU) قائمة على ARM | نوى 64-bit ARM Neoverse (مصممة من AWS)، عدد نوى مرتفع، DDR5، PCIe Gen4/5 | **نسخ EC2 Graviton** (حوسبة للأغراض العامة) |
| **Nitro** | بطاقة شبكة ذكية / تفريغ حمل | وحدات معالجة مركزية ARM + مسرعات مخصصة للتخيل، الأمان، التخزين، الشبكات | **نظام EC2 Nitro**، EBS، VPC، تفريغ حمل الأمان |
| **Inferentia** | استدلال الذكاء الاصطناعي | معالجة موترية عالية الإنتاجية، زمن انتقال منخفض، نوى نيورون | **نسخ EC2 Inf1/Inf2** لاستدلال تعلم الآلة |
| **Trainium** | تدريب الذكاء الاصطناعي | قابلة للتطوير لنماذج اللغة الكبيرة، نطاق ترددي عالي للذاكرة، وصلة NeuronLink | **نسخ EC2 Trn1/Trn2** لتدريب نماذج اللغة الكبيرة (LLMs) |

---

### عائلات الرقاقات الرئيسية (حتى عام 2025)

#### 1. **AWS Graviton (وحدة معالجة مركزية)**
- **الهيكلية**: نوى مخصصة قائمة على ARM Neoverse (ليست جاهزة)
- **الأجيال**:
  - **Graviton1** (2018): 16 نواة ARMv8، مستخدمة في نسخ A1
  - **Graviton2** (2020): 64 نواة Neoverse N1، ~40% أفضل في السعر/الأداء من x86
  - **Graviton3** (2022): Neoverse V1، DDR5، bfloat16، أفضل بما يصل إلى 60% من Graviton2
  - **Graviton4** (2024): Neoverse V2، 96 نواة، أداء/طاقة أفضل بـ 2.7x من Graviton3
- **الاستخدام**: يشغل **~30–40% من أحمال عمل EC2 على AWS** (خاصة الحاويات، الخدمات المصغرة، قواعد البيانات)

#### 2. **AWS Inferentia (استدلال الذكاء الاصطناعي)**
- **Inferentia2** (2023): أداء أفضل بـ 4 مرات من Inferentia1، يدعم FP16/BF16/INT8
- مُحسّن لـ **الاستدلال الفوري** (محركات التوصية، الكلام، الرؤية)
- مستخدم في **SageMaker**، **EC2 Inf2**

#### 3. **AWS Trainium (تدريب الذكاء الاصطناعي)**
- **Trainium2** (أُعلن في 2024، الشحن في 2025): أداء تدريب أفضل بـ 4 مرات من Trainium1
- مصمم للمنافسة مع **NVIDIA H100** في تدريب نماذج اللغة الكبيرة
- يدعم **نماذج ذات تريليون معامل**، ذاكرة عالية النطاق الترددي (HBM)

#### 4. **نظام Nitro (بطاقة شبكة ذكية / وحدة معالجة البيانات)**
- أنظمة على رقاقة (SoCs) مخصصة قائمة على ARM مع مسرعات أجهزة
- يُفرّغ حمل برنامج hypervisor، والشبكات، والتخزين، والتشفير
- يُمكن من تحقيق **أداء الخوادم العارية في البيئات المُؤَظْرة**

---

### لماذا Annapurna مهمة

- **التكلفة والكفاءة**: تدعي AWS **تحسين السعر/الأداء بنسبة تصل إلى 40%** مقارنة بـ x86
- **التكامل الرأسي**: أمازون تتحكم في الرقاقات → ابتكار أسرع، تكاليف أقل
- **الدفعة في الذكاء الاصطناعي**: Trainium/Inferentia تتحدى هيمنة NVIDIA مباشرة في الذكاء الاصطناعي السحابي
- **مرونة سلسلة التوريد**: يقلل الاعتماد على سلسلة توريد Intel/TSMC فقط

---

### الملخص

> **Annapurna Labs = السلاح السري للسيليكون في AWS.**  
> هم يبنون **وحدات المعالجة المركزية Graviton القائمة على ARM**، و **Inferentia (للاستدلال)**، و **Trainium (للتدريب)**، و **رقاقات تفريغ الحمل Nitro** — جميعها مُحسنة للسحابة.  
> هذه تشغل خدمات AWS **الأرخص، الأسرع، والأكثر صداقة للبيئة** وهي سبب رئيسي لقدرة AWS على التغلب على المنافسين في السعر مع توسيع نطاق الذكاء الاصطناعي.

أعلمني إذا كنت تريد الغوص في تفاصيل أي رقاقة محددة (مثلًا، Graviton4 مقابل Apple M4، Trainium2 مقابل H100).