---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: الحوسبة تقود مستقبل الذكاء الاصطناعي
translated: true
type: note
---

في ستانفورد CS25 (مقرر حول بنى المحولات "Transformer")، قدم هيونغ وون تشونغ، العالم الباحث في OpenAI، محاضرة ضيف بعنوان "تشكيل مستقبل الذكاء الاصطناعي" (جزء من سلسلة V4). ناقش فيها أهمية تحديد "القوة الدافعة المسيطرة" وراء التغيرات الكبرى في أي مجال للتنبؤ بمساره المستقبلي بفعالية.

### النقاط الرئيسية من مناقشته
- **تشبيه إسقاط القلم**: للتوضيح، يستخدم تشونغ مثالاً فيزيائياً بسيطاً: إذا أسقطت قلماً، فإن مساره يمكن التنبؤ به لأننا نفهم **القوة المسيطرة**—الجاذبية—التي تتغلب على العوامل الثانوية مثل مقاومة الهواء. من خلال التركيز على هذه القوة المسيطرة، نبسط الأنظمة المعقدة ونتنبأ تنبؤات موثوقة. ويجادل بأنه ينبغي علينا تطبيق نفس العدسة على الذكاء الاصطناعي.

- **القوة المسيطرة في الذكاء الاصطناعي**: بالنسبة لأبحاث الذكاء الاصطناعي، فإن القوة الدافعة المسيطرة هي **الانخفاض الأسي في تكاليف الحوسبة** (أي قوة حوسبية أرخص وأكثر وفرة). لقد كان هذا هو الممكن الرئيسي للتقدم السريع، مما سمح للنماذج بالتكامل مع المزيد من البيانات والمعاملات. يؤكد تشونغ أن فهم هذه القوة يحول التركيز نحو بناء طرق عامة قابلة للتطوير بدلاً من التصاميم المعقدة مفرطة الهندسة والمليئة بالتحيزات.

- **الارتباط بـ "الدرس المر"**: يشير إلى مقالة ريتش سوتن "الدرس المر"، التي تدعي أن تقدم الذكاء الاصطناعي يأتي من الاستفادة من المزيد من الحوسبة والبيانات بأساليب تعلمية أبسط (مثل المحولات "Transformers") بدلاً من التحيزات الاستقرائية المصممة بواسطة الإنسان. مع اعتبار الحوسبة القوة المسيطرة، يجب أن تعطي هندسة البنى الأولوية للتطوير—مثل تفضيل المحولات ذات وحدة فك التشفير فقط "decoder-only" على الإعدادات الأكثر تعقيداً التي تحتوي على مشفر وفك تشفير، حيث أن الهيكل الإضافي يصبح غير ضروري مع وفرة الموارد.

- **الآثار الأوسع**: يعرض تشونغ رسوماً بيانية تاريخية لنمو الحوسبة مقابل أداء الذكاء الاصطناعي، مشيراً إلى أن الاتجاهات السابقة (مثل قانون مور) تشير إلى أن الاستمرار في التطوير سيقود إلى تحقيق طفرات مستقبلية. نصحته: "عندما نتحدث عن شيء ما في المستقبل، فإن أفضل مكان للحصول على النصيحة هو النظر إلى التاريخ."

هذا الإطار يساعد في تفسير سبب تركيز نماذج الذكاء الاصطناعي الحديثة (مثل تلك من OpenAI) على التطوير الهائل بدلاً من التعديلات الدقيقة المُحسّنة.

[ستانفورد CS25: V4 - تشكيل مستقبل الذكاء الاصطناعي مع هيونغ وون تشونغ](https://www.linkedin.com/pulse/stanford-cs25-v4-shaping-future-ai-hyung-won-chung-tarazona-md-lf9pe)  
[محاضرة الفيديو الكاملة على يوتيوب](https://www.youtube.com/watch?v=orDKvo8h71o)