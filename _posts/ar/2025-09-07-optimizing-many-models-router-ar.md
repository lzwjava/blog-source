---
audio: false
date: 2025-09-07
generated: true
image: false
lang: ar
layout: post
title: محسن كود الموجه للنماذج المتعددة
translated: true
type: note
---

إجابة قصيرة: نعم — يمكن أن يكون "موجه النماذج المتعددة" الخاص بك أقل أداءً مقارنة بمكدس متكامل بإحكام مثل Codex (مساعد الكود من OpenAI) الذي تم ضبطه من البداية إلى النهاية على عائلة واحدة من النماذج بالإضافة إلى سياق بيئة التطوير المتكاملة العميق. إليك السبب وكيفية إصلاحه بسرعة.

### لماذا قد تشعر أن Codex أفضل

* **عقل واحد لكل مهمة.** البقاء على نموذج واحد يحافظ على خطته الكامنة وأسلوب البرمجة. القفز بين النماذج في منتصف المهمة يعيد ضبط تلك الخطة وغالبًا ما يقدم اصطلاحات متضاربة.
* **التكامل الرأسي.** Codex (OpenAI) يتحكم في النموذج → استدعاءات الأدوات → فهرس المستودع → الاختبارات → التعديلات المضمنة. هذه الحلقة المغلقة تمنحه إشارات أكثر ثراءً (رسم بياني للرموز، خرائط حرارية للملفات، اختبارات فاشلة) مع قدر أقل من زمن الوصلات البرمجية الإضافية.
* **محاذاة الموجهات والسياسات.** الموجهات الخاصة بهم، ومشغلات الكود، واستدلالات "اصنع فرقًا بسيطًا وقابلًا للترجمة" يتم تصميمها معًا لعائلة GPT-5. يمكن للموجه العام بسهولة أن يحدد درجة الحرارة، أو تسلسلات التوقف، أو تنسيق الرقعة بشكل خاطئ لبعض النماذج.
* **زمن الاستجابة/الإنتاجية.** كل قفزة إضافية (الوكيل، برمجية OpenRouter الوسيطة، تفاوض النموذج) تضيف تشويشًا. سير عمل البرمجة تتسم بشدة التغذية الراجعة؛ 300-800 مللي ثانية من زمن الاستجابة المضاف في كل مرة يضر بشكل ملحوظ بـ "التدفق".
* **جودة السياق.** تكاملات بيئة التطوير المتكاملة التي تحسب خريطة المستودع (طوبولوجيا الملفات، الرموز، التغييرات الحديثة) تتغلب على "مجرد إلقاء سياق طويل". السياقات الطويلة بدون هيكل تهدر الرموز المميزة وتخفف الانتباه.

### ما في إعداداتك الذي يرجح أنه يؤذيك

* **انتشار النماذج.** أنت تخلط بين النماذج العامة، ونماذج البرمجة، ونماذج التفكير. المتغيرات "المفكرة" (مثل `claude-3.7-sonnet:thinking`، `deepseek-r1`) رائعة للبراهين ولكنها أبطأ وأكثر ثرثرة لتعديلات الكود.
* **عدم تطابق المسار الافتراضي.** `default: "openrouter,x-ai/grok-code-fast-1"` يبدو أنك تريد Grok Code Fast، لكنه غير مدرج في مصفوفة `models` الخاصة بك. هذا يمكن أن يسبب ارتدادًا صامتًا وعدم اتساق.
* **النوايا غير المحددة.** "افتراضي" واحد لكل شيء يعني أن التعديلات الصغيرة، وإعادة الهيكلة الثقيلة، وقراءات السياق الطويل جميعها تقاتل من خلال نفس المسار.
* **انحراف درجة الحرارة/التنسيق.** إذا لم تفرض درجة حرارة منخفضة + تنسيق رقعة صارم لكل نموذج، فإن المخرجات تختلف بشكل كبير عبر المزودين.

### اجعل الموجه الخاص بك يشبه "Codex"

1.  **اختر نموذجًا أساسيًا والتزم به لكل مهمة.** اختر مبرمجًا قويًا واحدًا كافتراضي (مثل `openai/gpt-5` أو `x-ai/grok-code-fast-1` أو `qwen/qwen3-coder`) واقلب فقط لأسباب واضحة (سياق طويل جدًا أو رياضيات ثقيلة).
2.  **قسم حسب النية (وليس حسب العلامة التجارية).**
    *   *تعديل صغير / إصلاح سريع:* نموذج سريع (GPT-5-mini أو Gemini-Flash).
    *   *إعادة هيكلة / تغيير متعدد الملفات:* GPT-5 (أو Claude Sonnet 3.7 غير المفكر).
    *   *قراءة سياق طويل جدًا:* Kimi-K2.
    *   *استدلال صعب قبل البرمجة:* DeepSeek-R1 لوضع المخطط → تسليمه لنموذج المبرمج لإنتاج الرقعة.
3.  **فرض عقد رقعة صارم.** اطلب دائمًا فرقًا موحدًا أو JSON صريح لـ "ApplyPatch" مع مسارات الملفات + الأجزاء. ارفض أي شيء آخر وأعد الموجه تلقائيًا.
4.  **قلل العشوائية للكود.** `temperature: 0–0.2`، لا عقوبات تردد/وجود، وحدد `top_p` ~0.9.
5.  **أعط خريطة مستودع، وليس رموزًا مميزة فقط.** قدّم فهرس رموز مضغوط: نقاط الدخول، الفئات/الدوال الرئيسية، أهداف الاختبار، الاختلافات الحديثة. هذا يتفوق على إلقاء 200 ألف رمز مميز من الملفات الخام.
6.  **احتفظ بحلقة الأداة ضيقة.** نموذج واحد يقترح رقعة → أنت تشغل البناء/الاختبارات/أدوات الفحص → أعد الإخفاقات إلى *نفس* النموذج للتكرار. تجنب تبديل النماذج في منتصف الحلقة.
7.  **قلص قائمة النماذج.** احتفظ بحد أقصى 3-5. كل نموذج إضافي يزيد التباين وأخطاء التوجيه.
8.  **أزل النماذج "المفكرة" من المسارات السريعة.** استخدمها فقط لإنتاج خطة تصميم قصيرة، ثم انتقل إلى مبرمج للتعديلات الفعلية.

### إعدادات أكثر رشاقة (فكرة جاهزة للاستخدام؛ قم بتكييف الأسماء وفقًا لإطار عملك)

```json
{
  "PROXY_URL": "http://127.0.0.1:7890",
  "LOG": true,
  "Providers": [
    {
      "name": "openrouter",
      "api_base_url": "https://openrouter.ai/api/v1/chat/completions",
      "api_key": "",
      "models": [
        "openai/gpt-5",
        "openai/gpt-5-mini",
        "x-ai/grok-code-fast-1",
        "moonshotai/kimi-k2",
        "anthropic/claude-3.7-sonnet",
        "qwen/qwen3-coder"
      ],
      "transformer": {"use": ["openrouter"]}
    }
  ],
  "Router": {
    "default": "openrouter,openai/gpt-5",
    "quickEdit": "openrouter,openai/gpt-5-mini",
    "refactor": "openrouter,openai/gpt-5",
    "reasonPlan": "openrouter,anthropic/claude-3.7-sonnet",
    "longContext": "openrouter,moonshotai/kimi-k2",
    "longContextThreshold": 220000,
    "webSearch": "openrouter,qwen/qwen3-coder"
  }
}
```

### هياكل الموجهات التي تثبت المخرجات (بدون جداول)

*   **النظام:** "أنت مهندس برمجيات كبير. أنتج رقعًا بسيطة وقابلة للترجمة. حافظ على الأسلوب متسقًا مع المستودع. إذا كنت غير متأكد، اطرح سؤالًا توضيحيًا واحدًا، وإلا تقدم."
*   **القواعد:** "أخرج فقط فرقًا موحدًا (تنسيق git). لا تدرج أبدًا أي تعليقات. إذا كان الملف غير موجود، أنشئه وأدرجه في الفرق. احفظ ترويسات التراخيص."
*   **كتلة السياق:** خريطة المستودع (الملفات، الرموز الرئيسية)، الأخطاء الحالية، أهداف الاختبار.
*   **حلقة الأداة:** بعد الفرق، شغل تلقائيًا `البناء + الاختبارات + أدوات الفحص`؛ أعد الإخفاقات فقط إلى نفس النموذج.

### نظافة عملية

*   قلص قائمة النماذج الخاصة بك وأصلح الإعداد الافتراضي إلى نموذج موجود فعليًا في `models`.
*   عيّن درجات حرارة لكل مسار؛ حافظ على درجة حرارة الكود عند 0–0.2.
*   خزن خريطة المستودع بين الأدوار؛ لا تعيد إرسال سياقات ضخمة ما لم تتغير الملفات.
*   تجنب تبديل النماذج في منتصف المهمة.
*   فضّل "الفرق" على "استبدل هذا الملف بالكامل" لتقليل الاستيرادات الوهمية.

إذا أردت، الصق موجهات الموجه الخاص بك وإعدادات درجة الحرارة، وسأشددها لكل مسار حتى يتصرف Claude Code ومكدسك بشكل أكثر اتساقًا مع موثوقية نمط Codex.