---
audio: false
generated: true
lang: ar
layout: post
title: ุฅุตูุงุญ ุฎุทุฃ ุชุญููู ูููุฐุฌ Llama.cpp
translated: true
type: note
---

ุจูุงุกู ุนูู ุงูุฎุทุฃ `gguf_init_from_file_impl: failed to read key-value pairs`ุ ูุฅู ููู ุงููููุฐุฌ ุงูุฎุงุต ุจู ุฅูุง **ุชุงูู**ุ ุฃู **ุบูุฑ ููุชูู**ุ ุฃู **ุบูุฑ ูุชูุงูู** ูุน ุฅุตุฏุงุฑ llama.cpp ุงูุฎุงุต ุจู. ุฅููู ููููุฉ ุฅุตูุงุญู:

### 1. **ุงูุชุญูู ูู ุงููููุฐุฌ ูุฅุนุงุฏุฉ ุชุญูููู**
   ```bash
   # ุชุญูู ูู ุญุฌู ุงูููู ุงูุญุงูู (ูุฌุจ ุฃู ูููู ุงูุชูููู Q6_K ุจุญุฌู ~6.1 ุฌูุฌุงุจุงูุช ููููุฐุฌ 8B):
   ls -lh /home/lzw/Projects/llama.cpp/models/DeepSeek-R1-0528-Qwen3-8B-UD-Q6_K_XL.gguf

   # ุงููุงุชุฌ ุงููุชููุน:
   # -rw-r--r-- 1 lzw lzw 6.1G Jun  2 10:00 ...Q6_K_XL.gguf
   ```
   - ุฅุฐุง ูุงู ุงูุญุฌู ุฃูู ูู 6 ุฌูุฌุงุจุงูุชุ **ุฃุนุฏ ุชุญููู ุงููููุฐุฌ**:
     ```bash
     rm /home/lzw/Projects/llama.cpp/models/DeepSeek-R1-0528-Qwen3-8B-UD-Q6_K_XL.gguf
     # ุฃุนุฏ ุงูุชุญููู ูู ุงููุตุฏุฑ ุงูุฃุตูู (ูุซู HuggingFace)
     ```

### 2. **ุชุญุฏูุซ llama.cpp**
ูุฏ ูููู ุงูุฅุตุฏุงุฑ ุงูุฐู ุชุณุชุฎุฏูู (ุงููุณุฎุฉ `7675c555`) ูุฏููุงู:
```bash
cd ~/Projects/llama.cpp
git pull origin master          # ุชุญุฏูุซ ุงูููุฏ
rm -rf build && mkdir build     # ุชูุธูู ูุฌูุฏ ุงูุจูุงุก
cd build
cmake .. -DLLAMA_CUBLAS=ON      # ุชูููู CUDA
make -j                         # ุฅุนุงุฏุฉ ุงูุชุฑุฌูุฉ
```

### 3. **ุงูุชุญูู ูู ุณูุงูุฉ ุงููููุฐุฌ**
ุงุฎุชุจุฑ ุงููููุฐุฌ ุจุงุณุชุฏูุงู ุจุณูุท:
```bash
~/Projects/llama.cpp/build/bin/main \
  -m /home/lzw/Projects/llama.cpp/models/DeepSeek-R1-0528-Qwen3-8B-UD-Q6_K_XL.gguf \
  -p "Hello" -n 10
```
- ุฅุฐุง ูุดู ูุฐุงุ ูุฅู ููู ุงููููุฐุฌ ุชุงูู ุจุงูุชุฃููุฏ.

### 4. **ุชุฌุฑุจุฉ ูููุฐุฌ ูุฎุชูู (ููุชุญูู)**
ุงุฎุชุจุฑ ุจูููุฐุฌ ูุนูู ุจุดูู ูุนุฑูู (ูุซู [TinyLlama](https://huggingface.co/TheBloke/TinyLlama-1.1B-1T-OpenOrca-GGUF)):
```bash
~/Projects/llama.cpp/build/bin/llama-server \
  -m /path/to/tinyllama.Q8_0.gguf \
  --port 8000
```
- ุฅุฐุง ูุฌุญ ูุฐุงุ ูุฅู ููู ุงููููุฐุฌ ุงูุฃุตูู ูู ุงููุดููุฉ.

### 5. **ุฅุนุงุฏุฉ ุชุญููู ุงููููุฐุฌ (ูุชูุฏู)**
ุฅุฐุง ูุดูุช ุฅุนุงุฏุฉ ุงูุชุญููู:
1. ุงุญุตู ุนูู ูููุฐุฌ Hugging Face ุงูุฃุตูู:
   ```bash
   huggingface-cli download deepseek-ai/DeepSeek-R1-0528-Qwen3-8B --local-dir ./deepseek-original
   ```
2. ุฃุนุฏ ุงูุชุญููู ุฅูู GGUF:
   ```bash
   python3 ~/Projects/llama.cpp/convert-hf-to-gguf.py \
     ./deepseek-original \
     --outtype q6_k  # ุทุงุจู ุงูุชูููู ุงูุฎุงุต ุจู
   ```

### ููุฎุต ุงูุญููู ุงูุดุงุฆุนุฉ:

| ุงููุดููุฉ | ุงูุญู |
|-------|----------|
| **ุชุญููู ุชุงูู** | ุฅุนุงุฏุฉ ุชุญููู ุงููููุฐุฌ |
| **llama.cpp ูุฏูู** | `git pull` + ุฅุนุงุฏุฉ ุงูุชุฑุฌูุฉ |
| **GGUF ุบูุฑ ูุชูุงูู** | ุงุณุชุฎุฏู ุฃุญุฏุซ ุฅุตุฏุงุฑ ูู `convert-hf-to-gguf.py` |
| **ุฃุฐููุงุช ุงูููู** | `chmod +r /path/to/model.gguf` |

> ๐ก **ููุงุญุธุฉ:** ูููุฐุฌ DeepSeek-R1 ุฌุฏูุฏ (ุชู ุฅุตุฏุงุฑู ูู 28 ูุงูู 2024). ุชุฃูุฏ ูู ุฃู llama.cpp ุงูุฎุงุต ุจู **ุชู ุชุญุฏูุซู ุฎูุงู ุงูุฃุณุจูุน ุงููุงุถู** ูุถูุงู ุงูุชูุงูู.

ุงุจุฏุฃ ุจุฅุนุงุฏุฉ ุชุญููู ุงููููุฐุฌ ูุชุญุฏูุซ llama.cpp โ ูุฐุง ูุญู 90% ูู ูุฐู ุงููุดุงูู. ุฃุนูููู ุฅุฐุง ููุช ุจุญุงุฌุฉ ุฅูู ูุฒูุฏ ูู ุงููุณุงุนุฏุฉ!