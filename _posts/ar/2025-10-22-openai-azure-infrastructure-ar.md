---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: البنية التحتية لأوبن إيه آي والاعتماد على أزور
translated: true
type: note
---

### نظرة عامة على البنية التقنية لشركة OpenAI

تم تحسين البنية التحتية لشركة OpenAI بشكل كبير للبحث والتدريب والنشر للذكاء الاصطناعي على نطاق واسع، مع التركيز على قابلية التوسع والأمان والتجارب السريعة. لقد قاموا ببناء جزء كبير منها حول Microsoft Azure منذ الانتقال من AWS في أوائل عام 2017، والتي توفر المنصة السحابية الأساسية لأجهزة الكمبيوتر الفائقة وأحمال العمل الخاصة بهم. مكّنت هذه التحول интеграة أفضل مع الأجهزة المتخصصة وكفاءة التكاليف. تشمل العناصر الرئيسية مستودع Python موحد للتطوير، و Kubernetes للتنسيق، وأدوات البث مثل Apache Kafka. أدناه، سأقوم بتفصيلها حسب الفئة، مع معالجة الاعتماد على Azure والتفاصيل المحددة لـ Kubernetes التي ذكرتها.

#### البنية التحتية السحابية: الاعتماد الكبير على Azure
تستخدم OpenAI خدمات Azure على نطاق واسع لبيئات البحث والإنتاج الخاصة بها، بما في ذلك تدريب نماذج الطليعة مثل سلسلة GPT. وهذا يشمل:
-   **Azure كمنصة أساسية**: تعمل جميع أحمال العمل الرئيسية على Azure، مع تخزين مرتبط بشكل خاص للبيانات الحساسة (مثل أوزان النماذج) لتقليل التعرض للإنترنت. يرتبط المصادقة بـ Azure Entra ID لإدارة الهوية، مما يتيح عناصر التحكم في الوصول القائمة على المخاطر والكشف عن الشذوذ.
-   **لماذا هذا الاعتماد الكبير على Azure؟**: يسلط مستند داخلي مسرب (يشير على الأرجح إلى منشور هندسة الأمان الخاص بهم لعام 2024) الضوء على دور Azure في تأمين الملكية الفكرية أثناء التدريب. فهو يدعم مجموعات GPU ضخمة لتجارب الذكاء الاصطناعي في مجالات مثل الروبوتات والألعاب وغيرها. تضمن شراكة OpenAI مع Microsoft الوصول منخفض الكمون إلى النماذج عبر خدمة Azure OpenAI، ولكن داخليًا، تعد هي العمود الفقري للحوسبة الفائقة المخصصة. كما أنهم يجمعون بين مراكز البيانات المحلية للمهام الثقيلة التي تتطلب معالجة بواسطة وحدات معالجة الرسومات، وإدارة مستويات التحكم (مثل etcd) في Azure من أجل الموثوقية والنسخ الاحتياطي.

هذا التكامل العميق يعني أن البنية التقنية لـ OpenAI ليست قابلة للنقل بسهولة — فهي مصممة خصيصًا لنظام Azure البيئي من أجل الأداء والامتثال.

#### التنسيق والتحجيم: Kubernetes (AKS) مع تحسينات Azure
يعد Kubernetes محوريًا في إدارة أحمال العمل، حيث يتعامل مع جدولة الدُفعات، وتنسيق الحاويات، وإمكانية النقل عبر المجموعات. تدير OpenAI تجاربها على خدمة Azure Kubernetes (AKS)، متوسعة إلى أكثر من 7500 عقدة في السنوات الأخيرة (بعد أن كانت 2500 في عام 2017).
-   **موثوقية AKS في نظام Azure البيئي**: كما أشرت، تبرز خدمة Kubernetes من Azure عند دمجها بالكامل في منتجات Azure. انتقلت OpenAI إلى Azure CNI (واجهة شبكة الحاوية) للشبكات، والتي تم بناؤها خصيصًا لسحابة Azure — حيث تتعامل مع البيئات عالية الأداء واسعة النطاق والتي لا يمكن لواجهات CNI العامة مثل Flannel التعامل معها بشكل موثوق على هذا النطاق. وهذا يسمح بالتحجيم الديناميكي دون اختناقات، وفحوصات صحة الـ Pods التلقائية، والتبديل التلقائي أثناء حالات التوقف. بدون عمليات التكامل الأصلية لـ Azure (مثل تخزين blob وهوية حمل العمل)، تنخفض الموثوقية بسبب الكمون، أو مشاكل المصادقة، أو قيود السعة. يضيف المحجم التلقائي المخصص الخاص بهم العقد أو يزيلها ديناميكيًا، مما يخفض التكاليف على الموارد الخاملة مع تمكين تحجيم التجارب بمقدار 10 أضعاف في غضون أيام.
-   **طبقة الأمان**: تفرض Kubernetes التحكم في الوصول based on الدور (RBAC) لأقل امتياز في الوصول، ووحدات تحكم القبول لسياسات الحاويات، ومنع خروج الشبكة افتراضيًا (مع قوائم السماح للمسارات المعتمدة). بالنسبة للوظائف عالية المخاطر، يقومون بإضافة gVisor لعزل إضافي. يحافظ تبديل الفشل متعدد المجموعات على استمرارية الوظائف أثناء المشاكل الإقليمية.

#### التطوير وإدارة الكود: نهج المستودع الأحادي
تحتفظ OpenAI بمستودع Python أحادي لمعظم أعمال البحث والهندسة. يقوم هذا بمركزة الكود والمكتبات والتبعيات، مما يسمح للفرق باستخدام أدوات Python المألوفة (مثل NumPy, PyTorch) جنبًا إلى جنب مع خطوط أنابيب الذكاء الاصطناعي المحددة. يتكامل بسلاسة مع معالجة الدفق الخاصة بهم، مما يقلل الاحتكاك للتجارب. يتم تأمين خطوط أنابيب CI/CD بموافقات متعددة الأطراف والبنية التحتية ككود (IaC) للنشر المتسق.

#### معالجة البيانات والدفق
-   **Apache Kafka**: هو العمود الفقري للأحداث للسجلات وبيانات التدريب والنتائج. إنه متعدد الأساسيات للحصول على أعلى disponibility، مع موصلات مخصصة (مثل تدفقات الاتحاد للقراءة، Prism Sink للكتابة) وكلاب حراسة للتكيف مع تغييرات الطوبولوجيا مثل حالات الفشل.
-   **PyFlink على Kubernetes**: لمعالجة دفق GenAI، باستخدام Flink Kubernetes Operator للأتمتة. يدعم واجهات برمجة تطبيقات DataStream/Table في Python، مع RocksDB للحالة وتخزين Azure blob لنقاط التفتيش — مؤمنة عبر هوية حمل العمل (بدون مفاتيح طويلة الأجل).

#### المراقبة والاتصال
-   **Prometheus**: لتصحيح الأخطاء والمقاييس.
-   **gRPC**: للاتصالات بين الخدمات.

#### التطور في عام 2025
تركز التحديثات الأخيرة (مثل تلك من OpenAI DevDay 2025) بشكل أكبر على واجهات برمجة تطبيقات النماذج وأدوات الوكلاء مثل AgentKit، لكن البنية التحتية تظل مركزية حول Azure-Kubernetes. لقد قاموا بفتح مصدر أدوات مثل المحجم التلقائي الخاص بهم لمشاركة المعرفة.

تعطي هذه البنية الأولوية لـ "عجلة البيانات" للتكرار الأسرع ولكنها تضحي بإمكانية النقل من أجل موثوقية Azure على النطاق الهائل. إذا كنت تبني شيئًا مشابهًا، فإن البدء بـ AKS + Kafka يمكن أن يحاكي ذلك، ولكن توقع تعديلات خارج Azure.

[كيف تستخدم OpenAI Kubernetes و Apache Kafka لـ GenAI](https://blog.bytebytego.com/p/how-openai-uses-kubernetes-and-apache)
[تأمين البنية التحتية للبحث للذكاء الاصطناعي المتقدم](https://openai.com/index/securing-research-infrastructure-for-advanced-ai/)
[دراسة حالة: Kubernetes في OpenAI](https://kubernetes.io/case-studies/openai/)
[كيف قاست OpenAI Kubernetes باستخدام Azure CNI للتعامل مع 7500 عقدة](https://medium.com/@PlanB./how-openai-scaled-kubernetes-with-azure-cni-to-handle-7-500-nodes-591162d0efa5)