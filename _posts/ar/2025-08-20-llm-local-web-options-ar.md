---
audio: false
generated: true
image: false
lang: ar
layout: post
title: خيارات خفيفة للعميل المحلي للذكاء الاصطناعي
translated: true
type: note
---

إذا كنت تبحث عن عملاء ويب خفيفي الوزن ومفتوحة المصدر لتشغيل نماذج LLM محليًا - مع اعتماديات أقل من Open WebUI - إليك بعض البدائل القوية:

**1. Lobe Chat**
- خفيف الوزن وقابل للتوسيع، يدعم Lobe Chat كلًا من نماذج LLM المحلية والبعيدة. يقدم نظام إضافات وواجهة مستخدم نظيفة، ويمكن تشغيله عبر Docker أو مباشرة على جهازك. معروف بسهولة إعداده وأدائه الجيد مع Ollama والخلفيات الأخرى.

**2. LM Studio**
- LM Studio هو تطبيق سطح مكتب يدعم نماذج GGUF (مثل Mistral وPhi 3 وGemma) ويوفر واجهة مستخدم بسيطة وسهلة الاستخدام. مثالي للاستدلال المحلي السريع ولا يتطلب إعدادًا معقدًا أو العديد من الاعتماديات.

**3. text-generation-webui (Oobabooga)**
- واجهة مستخدم ويب غنية بالميزات تعتمد على Gradio وتدعم خلفيات متعددة (transformers, GPTQ, AWQ, EXL2, llama.cpp). شديدة التخصيص ومستخدمة على نطاق واسع، وإن كانت إعداداتها تتطلب جهدًا أكبر قليلًا مقارنة بـ LM Studio.

**4. AnythingLLM**
- واجهة دردشة مستضافة ذاتيًا متعددة الاستخدامات تعمل بشكل جيد مع كل من النماذج المحلية والقائمة على السحابة. مصممة للاستخدام العام ومتاحة كتطبيق سطح مكتب، مما يجعلها مرنة وخفيفة الوزن نسبيًا.

**5. Jan**
- Jan هي واجهة دردشة متعددة المنصات قادرة على العمل دون اتصال بالإنترنت مع تخصيص بالسحب والإفلات وقوالب مسبقة الصنع. محسنة للأداء وتدعم واجهات برمجة تطبيقات LLM متعددة، مما يجعلها خيارًا جيدًا للمستخدمين المهتمين بالخصوصية.

**6. Ollama UI**
- مصممة خصيصًا لـ Ollama، هذه الواجهة بسيطة وسهلة النشر، مما يجعلها مناسبة إذا كنت تستخدم Ollama بالفعل لتقديم النماذج.

**7. Open-LLM-WebUI**
- واجهة ويب مفتوحة المصدر وبسيطة لتشغيل نماذج LLM المضغوطة محليًا. مصممة لسهولة الاستخدام والحد الأدنى من الإعداد، مما يجعلها بديلاً جيدًا لأولئك الذين يريدون شيئًا مباشرًا.

**جدول الملخص:**

| العميل                 | الميزات الرئيسية                           | تعقيد الإعداد     | الأفضل لـ                  |
|------------------------|--------------------------------------------|-------------------|----------------------------|
| Lobe Chat              | الإضافات، دعم Docker، واجهة مستخدم نظيفة   | منخفض             | الاستخدام العام، Ollama    |
| LM Studio              | تطبيق سطح مكتب، دعم GGUF، واجهة بسيطة      | منخفض جدًا        | الاستدلال المحلي السريع    |
| text-generation-webui  | متعدد الخلفيات، قابل للتخصيص بدرجة كبيرة  | متوسط             | المستخدمون المتقدمون       |
| AnythingLLM            | تطبيق سطح مكتب، مرن، استخدام عام           | منخفض             | الهجين المحلي/السحابي      |
| Jan                    | دون اتصال، سحب وإفلات، قوالب               | منخفض             | الخصوصية، التخصيص          |
| Ollama UI              | بسيط، مركّز على Ollama                     | منخفض جدًا        | مستخدمو Ollama             |
| Open-LLM-WebUI         | بسيط، خفيف الوزن                           | منخفض             | نماذج LLM المضغوطة        |

إذا كنت تريد الخيار الأخف وزنًا على الإطلاق، فإن **LM Studio** أو **Ollama UI** نقطة بداية رائعة. لمزيد من الميزات والمرونة، فإن **Lobe Chat** أو **text-generation-webui** خيارات قوية.

هل تريد المزيد من التفاصيل حول الإعداد أو حالات استخدام محددة لأي من هذه؟