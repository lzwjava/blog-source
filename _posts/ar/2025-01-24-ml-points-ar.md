---
audio: false
generated: false
lang: ar
layout: post
title: الذكاء الاصطناعي، التعلم العميق، وGPT
translated: true
---

1. تعلم الآلات (ML) هو مجال من علوم الحاسوب يتيح للنظم تعلم من البيانات وتحسين أدائها دون برمجة صريحة.

2. تعلم العميق (DL) هو فرع من ML يستخدم الشبكات العصبية متعددة الطبقات لتنمذج الأنماط المعقدة في البيانات.

3. الشبكات العصبية هي نماذج حاسوبية مستوحاة من الدماغ البشري، تتكون من عقد متصلة (أعصاب) تعمل على معالجة المعلومات في طبقات.

4. بيانات التدريب هي مجموعة البيانات المسماة أو غير المسماة المستخدمة لتعليم نموذج تعلم الآلات كيفية تنفيذ مهمة.

5. تعلم المشرف involves تدريب النموذج على بيانات مسماة، حيث لكل مثال مدخل ومخرج صحيح مرتبط.

6. تعلم غير مشرف يستخدم بيانات غير مسماة، مما يسمح للنموذج اكتشاف الأنماط المخفية أو التجمعات دون تعليم صريح.

7. تعلم التعزيز (RL) يدرّب الوكلاء على اتخاذ قرارات من خلال مكافأة السلوكيات المرغوبة و عقاب السلوكيات غير المرغوبة.

8. نماذج التوليد تعلم إنتاج بيانات جديدة تشبه أمثلة التدريب (مثل النص، الصور).

9. نماذج التمييز تركز على تصنيف المدخلات في فئات أو التنبؤ بنتيجة محددة.

10. نقل التعلم يسمح للنموذج الذي تم تدريبه على مهمة واحدة أن يتم إعادة استخدامه أو تحسينه على مهمة ذات صلة.

11. GPT (Generative Pre-trained Transformer) هو عائلة من نماذج اللغة الكبيرة التي تم تطويرها بواسطة OpenAI والتي يمكن أن تولد نصًا يشبه النص البشري.

12. ChatGPT هو نسخة تفاعلية من GPT، تم تحسينها للحوار والمهام التي تتبع التعليمات.

13. معمارية التحويل (Transformer) تم تقديمها في الورقة "Attention Is All You Need"، وتغيرت معالجة اللغة الطبيعية بشكل جذري من خلال الاعتماد على آليات الانتباه.

14. آليات الانتباه الذاتي تسمح للنموذج بتقييم أجزاء مختلفة من تسلسل المدخلات عند بناء تمثيل الإخراج.

15. التشفير الوضعي في التحويل يساعد النموذج على تحديد ترتيب الرموز في تسلسل.

16. التدريب مسبق هو المرحلة الأولى حيث يتعلم النموذج الميزات العامة من البيانات على نطاق واسع قبل تحسينها على مهام محددة.

17. تحسين هو عملية أخذ نموذج مدرب مسبقًا وتكييفه لمهمة أكثر تحديدًا باستخدام مجموعة بيانات أصغر، محددة بالمهمة.

18. نمذجة اللغة هي مهمة التنبؤ بالرمز التالي (الكلمة أو تحت الكلمة) في تسلسل، وهي أساسية لنماذج مثل GPT.

19. تعلم الصفر يسمح للنموذج التعامل مع المهام دون أمثلة تدريب صريحة، يعتمد على المعرفة العامة التي تعلمها.

20. تعلم قليل من الأمثلة يستفيد من عدد محدود من أمثلة محددة بالمهمة لتوجيه توقعات النموذج أو سلوكه.

21. RLHF (Reinforcement Learning from Human Feedback) يستخدم لتوازي إنتاجات النموذج مع تفضيلات الإنسان والقيم.

22. ملاحظات الإنسان يمكن أن تشمل التصنيفات أو التسميات التي توجيه إنتاج النموذج نحو إجابات أكثر مرغوبًا فيها.

23. هندسة التوجيه هي فن صياغة استفسارات المدخلات أو التعليمات لتوجيه نماذج اللغة الكبيرة بشكل فعال.

24. نافذة السياق تشير إلى أكبر كمية من النص التي يمكن للنموذج معالجةها في وقت واحد؛ نماذج GPT لديها طول سياق محدود.

25. الاستدلال هو المرحلة التي يقوم فيها النموذج المدرب بإصدار توقعات أو إنتاج إخراجات بناءً على المدخلات الجديدة.

26. عدد المعلمات هو عامل مهم في قدرة النموذج؛ النماذج الأكبر يمكن أن تكتشف أنماطًا أكثر تعقيدًا ولكن تتطلب حوسبة أكثر.

27. تقنيات ضغط النموذج (مثل تقليم، تكميم) تقلل من حجم النموذج وتسرع الاستدلال مع فقدان دقة ضئيل.

28. رؤوس الانتباه في التحويل تعمل على جوانب مختلفة من المدخلات في الوقت نفسه، مما يحسن القدرة التمثيلية.

29. نمذجة اللغة المغطاة (مثل في BERT) تتضمن التنبؤ بالرموز المفقودة في جملة، مما يساعد النموذج على تعلم السياق.

30. نمذجة اللغة التسلسلية (مثل في GPT) تتضمن التنبؤ بالرمز التالي بناءً على جميع الرموز السابقة.

31. معمارية التشفير والتشفير (مثل T5) تستخدم شبكة واحدة لتشفير المدخلات و أخرى لتشفيرها إلى تسلسل الهدف.

32. الشبكات العصبية المتجانية (CNNs) تتفوق في معالجة البيانات الشبيهة بالشبكة (مثل الصور) عبر طبقات التجزئة.

33. الشبكات العصبية المتكررة (RNNs) تعمل على معالجة البيانات التسلسلية من خلال تمرير حالات مخفية عبر خطوات الزمن، على الرغم من أنها يمكن أن تتعثر في التبعيات طويلة الأمد.

34. الذاكرة طويلة الأمد (LSTM) و GRU هي متغيرات RNN مصممة لتحسين التبعيات طويلة الأمد.

35. التطبيق التسلسلي يساعد على استقرار التدريب من خلال تطبيع إخراجات الطبقات المتوسطة.

36. الإفلات هو تقنية تنظيمية تفلت عصبونات عشوائيًا أثناء التدريب لمنع التعلّم الزائد.

37. خوارزميات المحرّك مثل هبوط التدرج العشوائي (SGD)، Adam، و RMSProp تحديث المعلمات النموذج بناءً على التدرج.

38. معدل التعلم هو معلم فرعي يحدد كيف يتم تحديث الوزن بشكل حاد أثناء التدريب.

39. المعلمات الفرعية (مثل حجم المجموعة، عدد الطبقات) هي إعدادات التكوين التي يتم اختيارها قبل التدريب لتحكم في كيفية تطور التعلم.

40. التعلّم الزائد يحدث عندما يتعلم النموذج البيانات التدريبية بشكل جيد جدًا، فانه لا يمكن أن يتعمم إلى البيانات الجديدة.

41. تقنيات التنظيم (مثل L2 weight decay، dropout) تساعد على تقليل التعلّم الزائد وتحسين التعميم.

42. مجموعة التحقق تستخدم لتعديل المعلمات الفرعية، بينما مجموعة الاختبار تقيم الأداء النهائي للنموذج.

43. التحقق المتقاطع يقسم البيانات إلى مجموعات متعددة، يدرّبها وتحقق منها بشكل نظامي للحصول على تقدير أداء أكثر استقرارًا.

44. مشاكل الانفجار والتسرب التدرج تحدث في الشبكات العميقة، مما يجعل التدريب غير مستقر أو غير فعال.

45. الإتصالات المتبقية (الاتصالات الجانبية) في الشبكات مثل ResNet تساعد على تقليل التدرج المتسرب من خلال تقصير مسارات البيانات.

46. قوانين التوسيع تشير إلى أن زيادة حجم النموذج و البيانات بشكل عام يؤدي إلى أداء أفضل.

47. كفاءة الحوسبة هي حاسمة؛ تدريب النماذج الكبيرة يتطلب حاسوب مخصص (GPUs، TPUs) و خوارزميات موفرة.

48. المعايير الأخلاقية تشمل التحيز، العدل، والضرر المحتمل - يجب اختبار النماذج ML و مراقبةها بعناية.

49. توسيع البيانات يوسع مجموعات البيانات التدريبية بشكل اصطناعي لتحسين استقرار النموذج (خاصة في مهام الصور والصوت).

50. معالجة البيانات (مثل التجزئة، التطبيع) هي ضرورية لتدريب النموذج بشكل فعال.

51. التجزئة تقسم النص إلى رموز (كلمات أو تحت كلمات)، هي الوحدات الأساسية التي يتم معالجةها بواسطة نماذج اللغة.

52. التشفير المتجهي يمثل الرموز أو المفاهيم كمتجهات رقمية، يحفظ العلاقات السيميائية.

53. التشفير الوضعي يضيف معلومات حول موضع كل رمز لمساعدة التحويل على فهم ترتيب التسلسل.

54. وزن الانتباه يكشف كيف يوزع النموذج التركيز عبر أجزاء مختلفة من المدخلات.

55. البحث بالشعاع هو استراتيجية فك التشفير في نماذج اللغة التي تظل بأكثر من خيار إخراج في كل خطوة للبحث عن أفضل تسلسل شامل.

56. البحث الجشع يختار الرمز الأكثر احتمالًا في كل خطوة، ولكن يمكن أن يؤدي إلى إجابات نهائية غير مثلى.

57. درجة الحرارة في العينة تعدل الإبداع في توليد اللغة: درجة حرارة أعلى = أكثر عشوائية.

58. طرق العينة Top-k و Top-p (Nucleus) تقيد الرموز المرشحة إلى k الأكثر احتمالًا أو احتمال تجمع p، توازن بين التنوع والتوافق.

59. الغموض يقيس كيف تنبأ نموذج الاحتمال بمثال؛ الغموض الأدنى يشير إلى أداء التنبؤ الأفضل.

60. الدقة والاسترجاع هي مقاييس لمهام التصنيف، تركز على الصواب والكمال، على التوالي.

61. F1 Score هو المتوسط الهارمونيك للدقة والاسترجاع، يوزن كلا المقاييس في قيمة واحدة.

62. الدقة هي الكسر من التوقعات الصحيحة، ولكن يمكن أن تكون مخادعة في مجموعات البيانات غير المتوازنة.

63. منطقة تحت منحنى ROC (AUC) تقيس أداء الفاصل عبر عتبات مختلفة.

64. جدول الارتباك يظهر عدد الإيجابيات الحقيقية، الإيجابيات الكاذبة، السلبية الكاذبة، والسلبية الحقيقية.

65. تقنيات تقدير الغموض (مثل Monte Carlo Dropout) تقيس مدى ثقة النموذج في توقعاته.

66. تعلم نشط يتضمن استفسار أمثلة بيانات جديدة التي يكون النموذج أقل ثقة بها، مما يحسن كفاءة البيانات.

67. تعلم على الإنترنت يحديث النموذج تدريجيًا مع وصول البيانات الجديدة، بدلاً من إعادة التدريب من الصفر.

68. خوارزميات التطورية و خوارزميات الوراثة تفضل نماذج أو معلمات فرعية باستخدام تطورات و اختيار مستوحاة من الأحياء.

69. طرق بايزية تضم معلومات مسبقة وتحديث الاعتقادات مع البيانات الواردة، مفيدة لتقدير الغموض.

70. طرق التجمع (مثل Random Forest، Gradient Boosting) تجمع عدة نماذج لتحسين الأداء والاستقرار.

71. التجميع (Bootstrap Aggregating) يدرّب عدة نماذج على مجموعات مختلفة من البيانات، ثم يوسط توقعاتها.

72. التجميع يتدرب تدريجيًا على نماذج جديدة لتعديل الأخطاء التي ارتكبتها النماذج المدربة سابقًا.

73. أشجار القرار المتزايدة (GBDTs) قوية للبيانات المهيئة، غالبًا ما تتفوق على الشبكات العصبية البسيطة.

74. نماذج التسلسل الذاتي تنبؤ بالقيمة التالية (أو الرمز) بناءً على الإخراجات السابقة في تسلسل.

75. التشفير الذاتي هو شبكة عصبية مصممة لتشفير البيانات إلى تمثيل مخفي ثم تشفيرها مرة أخرى، تعلم تمثيلات البيانات المضغوطة.

76. التشفير الذاتي المتغير (VAE) يضيف لفة احتمالية لتوليد بيانات جديدة تشبه مجموعة التدريب.

77. شبكة الخصم التوليدي (GAN) تطرح مولد ضد مصنف، تنتج صورًا، نصًا أو بيانات أخرى واقعية.

78. تعلم ذاتي يستفيد من كميات كبيرة من البيانات غير المسماة من خلال إنشاء مهام تدريب اصطناعية (مثل التنبؤ بالجزء المفقود).

79. نماذج الأساس هي نماذج مدربة مسبقًا كبيرة يمكن أن يتم تكييفها لمجموعة متنوعة من المهام المتدنية.

80. تعلم متعدد الوسائط يجمع بيانات من مصادر متعددة (مثل النص، الصور، الصوت) لإنشاء تمثيلات غنية.

81. تسمية البيانات هي غالبًا الجزء الأكثر استهلاكًا للوقت في ML، تتطلب تسمية دقيقة للدقة.

82. حوسبة الحافة تجلب استدلال ML أقرب إلى مصدر البيانات، تقليل التأخير واستهلاك النطاق.

83. تعلم فدرالي يدرّب النماذج عبر أجهزة أو خادمات موزعة تحمل عينات بيانات محلية، دون تبادلها.

84. ML مع الحفاظ على الخصوصية يشمل تقنيات مثل الخصوصية التفاضلية والتشفير الهومومورفي لحماية البيانات الحساسة.

85. الذكاء الاصطناعي قابل للشرح (XAI) يهدف إلى جعل قرارات النماذج المعقدة أكثر قابلية للشرح للإنسان.

86. التحيز والعدل في ML يحتاجان إلى مراقبة حريصة، يمكن أن يتعلم النماذج و يزداد التحيز الاجتماعي.

87. تغير المفهوم يحدث عندما تتغير الخصائص الإحصائية للمتغير الهدف مع مرور الوقت، تؤثر على أداء النموذج.

88. اختبار A/B يقارن بين نسختين أو أكثر من النموذج ليرى أيهما يعمل أفضل في بيئة حقيقية.

89. تسريع GPU يستغل الحوسبة المتوازية على بطاقات الرسوميات لتسريع تدريب ML بشكل كبير.

90. TPUs (Tensor Processing Units) هي وحدات معالجة متخصصة من Google لتحميل العملات العميقة بشكل فعال.

91. إطار عمل مفتوح المصدر (مثل TensorFlow، PyTorch) يوفر كتلة البناء وأدوات لتطوير نماذج ML.

92. تقديم النموذج هو الممارسة نشر النماذج المدربة حتى يمكن أن تتعامل مع التوقعات في الوقت الفعلي أو بالبatches.

93. قابلية التوسيع هي حاسمة لتعامل مع مجموعات البيانات الكبيرة أو حركة المرور الثقيلة، تتطلب استراتيجيات تدريب وتنبؤ موزعة.

94. MLOps يجمع تطوير ML مع الممارسات التشغيلية، يركز على التكرار، الاختبار، والتكامل المستمر.

95. التحكم في الإصدار للبيانات والنماذج يضمن تتبع التجارب المستقرة والتعاون.

96. استراتيجيات التقديم (مثل الحاويات، الخدمات الصغيرة) تحدد كيفية تجميع النماذج وتقديمها على نطاق واسع.

97. المراقبة تتبع أداء النموذج بعد التقديم، يراقب التدهور أو الانحرافات.

98. إعادة التدريب وتحديث النموذج يحافظ على نماذجها الحالية مع وصول البيانات الجديدة و الظروف المتغيرة.

99. تعقيد الوقت (O-notation) يقيس كيف يتغير وقت تنفيذ الخوارزمية مع حجم المدخلات؛ O(1) يشير إلى الوقت الثابت.

100. مستقبل ML يوعد بنماذج أكثر تعقيدًا وعمومية، ولكن يجب أن يعالج المعايير الأخلاقية والاجتماعية والبيئية.