---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: قائمة إيليا سوتسكيفر للقراءة في الذكاء الاصطناعي
translated: true
type: note
---

شارك إيليا سوتسكفير، المؤسس المشارك لأوبن أيه آي، قائمة قراءة موصى بها تضم حوالي 30 ورقة بحثية أساسية، ومنشور مدونة، ودورات، وموارد حول التعلم العميق والذكاء الاصطناعي مع جون كارماك حوالي عام 2020. وذكر تقريرًا أن إتقانها سيغطي "90٪ مما يهم اليوم" في هذا المجال. بينما القائمة الأصلية الكاملة المكونة من 30 عنصرًا غير مكتملة علنًا (ربما فُقدت بعض العناصر بسبب حذف البريد الإلكتروني)، فإن نسخة متداولة على نطاق واسع تتضمن 27 عنصرًا أساسيًا تشمل الشبكات التلافيفية، والشبكات المتكررة، والمحولات، ونظرية المعلومات، والمزيد. أدناه تلك القائمة المختارة، مجمعة حسب الفئة للتوضيح. يتضمن كل إدخال العنوان، والمؤلفين، والسنة، والنوع.

### الشبكات العصبية التلافيفية
1. **CS231n: Convolutional Neural Networks for Visual Recognition** - Fei-Fei Li, Andrej Karpathy, Justin Johnson - 2017 - Stanford Course
2. **ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)** - Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton - 2012 - Paper
3. **Deep Residual Learning for Image Recognition (ResNet)** - Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - 2015 - Paper
4. **Identity Mappings in Deep Residual Networks** - Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - 2016 - Paper
5. **Multi-Scale Context Aggregation by Dilated Convolutions** - Fisher Yu, Vladlen Koltun - 2015 - Paper

### الشبكات العصبية المتكررة
6. **Understanding LSTM Networks** - Christopher Olah - 2015 - Blog Post
7. **The Unreasonable Effectiveness of Recurrent Neural Networks** - Andrej Karpathy - 2015 - Blog Post
8. **Recurrent Neural Network Regularization** - Wojciech Zaremba, Ilya Sutskever, Oriol Vinyals - 2014 - Paper
9. **Neural Turing Machines** - Alex Graves, Greg Wayne, Ivo Danihelka - 2014 - Paper
10. **Deep Speech 2: End-to-End Speech Recognition in English and Mandarin** - Dario Amodei et al. - 2016 - Paper
11. **Neural Machine Translation by Jointly Learning to Align and Translate (RNNsearch)** - Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio - 2015 - Paper
12. **Pointer Networks** - Oriol Vinyals, Meire Fortunato, Navdeep Jaitly - 2015 - Paper
13. **Order Matters: Sequence to Sequence for Sets (Set2Set)** - Oriol Vinyals, Samy Bengio, Manjunath Kudlur - 2016 - Paper
14. **A Simple Neural Network Module for Relational Reasoning (Relation Networks)** - Adam Santoro, David Raposo, David G. Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, Timothy Lillicrap - 2017 - Paper
15. **Relational Recurrent Neural Networks** - Adam Santoro, Ryan Faulkner, David Raposo, Jack Rae, Mike Chrzanowski, Theophane Weber, Daan Wierstra, Oriol Vinyals, Razvan Pascanu, Timothy Lillicrap - 2018 - Paper

### المحولات (Transformers)
16. **Attention Is All You Need** - Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin - 2017 - Paper
17. **The Annotated Transformer** - Sasha Rush et al. - 2017 (annotated 2020) - Blog Post
18. **Scaling Laws for Neural Language Models** - Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei - 2020 - Paper

### نظرية المعلومات
19. **A Tutorial Introduction to the Minimum Description Length Principle** - Peter Grünwald - 2004 - Book Chapter
20. **Kolmogorov Complexity and Algorithmic Randomness (Chapter 14)** - Alexander Shen, Vladimir A. Uspensky, Nikolay Vereshchagin - 2017 - Book Chapter
21. **The First Law of Complexodynamics** - Scott Aaronson - 2011 - Blog Post
22. **Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton** - Scott Aaronson, Sean M. Carroll, Lauren Ouellette - 2014 - Paper
23. **Machine Super Intelligence** - Shane Legg - 2008 - Dissertation

### متنوع
24. **Keeping Neural Networks Simple by Minimizing the Description Length of the Weights** - Geoffrey E. Hinton, Drew van Camp - 1993 - Paper
25. **Variational Lossy Autoencoder** - Xi Chen, Diederik P. Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya Sutskever, Pieter Abbeel - 2017 - Paper
26. **GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism** - Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Mia Xu Chen, Dehao Chen, HyoukJoong Lee, Jiquan Ngiam, Quoc V. Le, Yonghui Wu, Zhifeng Chen - 2018 - Paper
27. **Neural Message Passing for Quantum Chemistry** - Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, George E. Dahl - 2017 - Paper

تشير التكهنات حول العناصر "المفقودة" الثلاثة غالبًا إلى أوراق بحثية حول التعلم الفوقي (مثل Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks بقلم تشيلسي فين وآخرون، 2017) أو أعمال التعلم المعزز حول اللعب الذاتي، استنادًا إلى محادثات سوتسكفير المعاصرة، لكن هذه غير مؤكدة.

[قائمة قراءة التعلم العميق من إيليا سوتسكفير](https://github.com/dzyim/ilya-sutskever-recommended-reading)
[ملخص قائمة القراءة للذكاء الاصطناعي لإيليا سوتسكفير](https://tensorlabbet.com/2024/09/24/ai-reading-list/)
[عناصر القراءة المفقودة من قائمة القراءة للذكاء الاصطناعي لإيليا سوتسكفير](https://tensorlabbet.com/2024/11/11/lost-reading-items/)