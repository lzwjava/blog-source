---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: نانوجي بي تي و نانو تشات لكارباثي موضَّحان
translated: true
type: note
---

### نظرة عامة
كلا المشروعين **nanoGPT** و **nanochat** هما مشروعان مفتوحا المصدر أنشأهما أندريه كارباثي (القائد السابق للذكاء الاصطناعي في OpenAI/تسلا) لتعليم الأساسيات الداخلية لنماذج اللغة الكبيرة (LLMs) من خلال تطبيقات بسيطة ومعدة من الصفر في PyTorch. إنهما أداتان تعليميتان بدلاً من أنظمة جاهزة للإنتاج، حيث يضعان البساطة وسهولة القراءة فوق التحسينات.

- **nanoGPT** (أُطلق في 2023): إطار عمل خفيف الوزن لتدريب نماذج المحولات (transformer) المشابهة لـ GPT على بيانات النص الخام، مع التركيز فقط على مرحلة التدريب المسبق (pretraining).
- **nanochat** (أُطلق في أكتوبر 2025): تطور موسع وشامل لنانو جي بي تي، يمكّن التدريب الشامل، الضبط الدقيق، الاستدلال، ونشر ذكاء اصطناعي محادثة على غرار ChatGPT.

### الاختلافات الرئيسية
إليك مقارنة جنبًا إلى جنب:

| الجانب              | nanoGPT                                                                 | nanochat                                                                 |
|---------------------|-------------------------------------------------------------------------|--------------------------------------------------------------------------|
| **التركيز الأساسي**   | التدريب المسبق لنموذج GPT على نص غير منظم (مثل مجموعة بيانات شكسبير). | خط أنابيب كامل: التدريب المسبق + الضبط الدقيق للمحادثة + الاستدلال في واجهة مستخدم ويب. |
| **النطاق**           | تنفيذ بسيط للمحولات (~400 سطر من التعليمات البرمجية الأساسية). لا توجد واجهة محادثة. | ~8,000 سطر إجمالاً، بما في ذلك الضبط الدقيق الشبيه بـ RLHF، أخذ العينات، وعرض توضيحي للمحادثة مبني على Streamlit. |
| **التدريب**        | نمذجة اللغة السببية (Causal language modeling) على التنبؤ بالرمز التالي (next-token). | يمتد ليشمل الضبط الدقيق تحت الإشراف (SFT) وتحسين التفضيلات (مثل DPO) للحوار. |
| **الاستدلال**       | توليد نص أساسي.                                                  | وضع محادثة تفاعلي مع مطالبات النظام/المستخدم/المساعد، أخذ العينات بدرجة حرارة (temperature sampling)، ومرشحات الأمان. |
| **الأجهزة/التكلفة**   | قابل للتدريب على وحدة معالجة رسومية واحدة (GPU) (مثلاً، 125 مليون معلمة في ساعات). | كفاءة مماثلة؛ يدعي "أفضل ChatGPT يمكن أن تشتريه بـ 100 دولار" عبر وحدات معالجة رسومية سحابية رخيصة. |
| **المصادر الإلهامية**    | يعلم أساسيات المحولات (transformer).                                             | يبني على nanoGPT + nanoGPT المعدل (نسخة مُلعبة)； يهدف إلى إنشاء "نسخة كاملة من ChatGPT." |
| **حالة الاستخدام**        | تعلم التدريب المسبق لنماذج اللغة الكبيرة (LLM).                                               | بناء/نشر ذكاء اصطناعي محادثة أساسي من الصفر.               |
| **نجوم GitHub**    | ~30 ألف+ (اعتبارًا من 2025).                                                     | أُطلق حديثًا؛ نمو سريع إلى 10 آلاف+ في أيام.                            |

في جوهر الأمر، nanoGPT يشبه بناء "الدماغ" لنموذج GPT، بينما يضيف nanochat "الفم" (واجهة المحادثة) و"الأذنين" (معالجة الحوار)، مما يجعله برنامجًا تعليميًا أكثر اكتمالاً لتطبيقات نماذج اللغة الكبيرة الحديثة. إذا كنت تبدأ في التعمق، ابدأ بـ nanoGPT لتعلم الأساسيات، ثم انتقل إلى nanochat للتعرف على الامتدادات الخاصة بالمحادثة.

### المراجع
- [مستودع nanochat على GitHub](https://github.com/karpathy/nanochat)
- [إعلان كارباثي على X](https://x.com/karpathy/status/1977755427569111362)
- [مقال فوربس عن nanochat](https://www.forbes.com/sites/lanceeliot/2025/10/15/make-your-own-chatgpt-clone-for-just-100-via-newly-released-nanochat-but-theres-a-catch/)
- [منشور على Medium: من nanoGPT إلى NanoChat](https://medium.com/@sebuzdugan/nanochat-build-your-own-chatgpt-clone-in-8-000-lines-of-code-e07a70cc435e)