---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: 'نانو شات كومباكت: إل إل إم كامل المكدس'
translated: true
type: note
---

### ما هو NanoChat؟

NanoChat هو تنفيذ مضغوط وكامل لمجموعة نظام نموذج اللغة الكبيرة (LLM) مشابه لـ ChatGPT، مبني في قاعدة كود واحدة بسيطة يسهل تعديلها ولا تتطلب سوى تبعيات قليلة. تم إنشاؤه بواسطة أندريه كارباثي (المشهور بعمله في الذكاء الاصطناعي، مثل nanoGPT)، وهو مصمم لتشغيل خطوة أنظمة نموذج اللغة الكبيرة بالكامل – من الترميز والتدريب المسبق إلى الضبط الدقيق، والتقييم، والاستدلال، وحتى واجهة ويب بسيطة للدردشة مع نموذجك – على أجهزة ميسورة التكلفة مثل عقدة واحدة تحتوي على 8 وحدات معالجة رسومية من نوع H100.

يتم وضعه كـ "أفضل نسخة من ChatGPT يمكن أن تشتريها بمبلغ 100 دولار"، ليخدم كخط أساسي لتطوير نماذج اللغة الكبيرة الصديقة للميزانية (بتكلفة إجمالية أقل من 1000 دولار). هذا يجعله المشروع الختامي للدورة القادمة LLM101n من Eureka Labs، مما يؤكد على البساطة بدلاً من التكوينات المعقدة.

### الميزات الرئيسية
- **خطوة متكاملة**: يدير كل شيء في حوالي 2000 سطر من الكود (مع ملف تبعيات `uv.lock` صغير). يدرب نموذجًا كفؤًا باستخدام 4e19 عملية فاصلة عائمة في حوالي 4 ساعات على إعداد 8xH100 بتكلفة حوالي 24 دولارًا في الساعة.
- **واجهة مستخدم شبيهة بـ ChatGPT**: بعد التدريب، يمكنك تشغيل خادم ويب للتفاعل مع نموذجك تمامًا مثل ChatGPT الحقيقي.
- **تقرير التقييم**: يولد تلقائيًا ملف `report.md` يحتوي على درائج المعايير في مهام مثل ARC-Challenge، وGSM8K، وHumanEval، وMMLU، والمزيد. على سبيل المثال، تُظهر عينة تشغيل بقيمة 100 دولار تحسينات تدريجية عبر المراحل (BASE, MID, SFT, RL):

| المقياس        | BASE   | MID    | SFT    | RL     |
|---------------|--------|--------|--------|--------|
| CORE          | 0.2219 | -      | -      | -      |
| ARC-Challenge | -      | 0.2875 | 0.2807 | -      |
| ARC-Easy      | -      | 0.3561 | 0.3876 | -      |
| GSM8K         | -      | 0.0250 | 0.0455 | 0.0758 |
| HumanEval     | -      | 0.0671 | 0.0854 | -      |
| MMLU          | -      | 0.3111 | 0.3151 | -      |
| ChatCORE      | -      | 0.0730 | 0.0884 | -      |

(الوقت الإجمالي: ~3 ساعات و51 دقيقة للتشغيل الكامل.)
- **مرونة الأجهزة**: يعمل على Ampere 8xA100 (ببطء أكبر)، أو وحدات معالجة رسومية مفردة (مع تراكم تلقائي للتدرج)، أو إعدادات ذاكرة وصول عشوائي للفيديو أقل عن طريق ضبط أحجام الدُفعات. يستخدم PyTorch العادي؛ ويمكن تكييفه لأجهزة أخرى بتعديلات.
- **مصادر البيانات**: يجلب البيانات من مجموعات بيانات Hugging Face مثل FineWeb و SmolTalk.
- **إضافات**: يتضمن اختبارات (مثل اختبار أداة الترميز المعتمدة على Rust)، ومن السهل تجميع المستودع بأكمله (~330 كيلوبايت) للاستعلام مع نماذج لغة كبيرة أخرى.

مستوحى من مشروع nanoGPT السابق لكارباثي و modded-nanoGPT، ولكن تم تكبيره لتجربة دردشة كاملة.

### كيفية البدء
أسرع طريقة هي استخدام سكريبت `speedrun.sh`، الذي يدير نموذج فئة الـ 100 دولار من البداية إلى النهاية على 8xH100 (على سبيل المثال، عبر Lambda Labs):

1. شغّل مثيل 8xH100 واستنسخ المستودع.
2. شغّل:
   ```
   bash speedrun.sh
   ```
   (أو في جلسة screen للتسجيل: `screen -L -Logfile speedrun.log -S speedrun bash speedrun.sh`. افصل الجلسة باستخدام Ctrl+A+D وتابع السجل باستخدام `tail`.)

3. بمجرد الانتهاء (حوالي 4 ساعات)، فعّل البيئة (`source .venv/bin/activate`) وشغّل واجهة المستخدم:
   ```
   python -m scripts.chat_web
   ```
   افتح الرابط المحلي (مثال: http://your-ip:8000) للدردشة مع نموذجك. راجع `report.md` للاطلاع على النتائج.

للنماذج الأكبر (مثل فئة 300 دولار في حوالي 12 ساعة، متفوقًا على GPT-2 في بعض النتائج)، قم بتحرير `speedrun.sh` لتحميل المزيد من أجزاء البيانات وضبط أعماق/أحجام الدُفعات. شغّل الاختبارات مثل `python -m pytest tests/test_rustbpe.py -v -s`.

هو مرخص بترخيص MIT ومفتوح للمساهمات لدفع النماذج المصغرة إلى الأمام. للحصول على شرح مفصل، راجع قسم المناقشات في المستودع.

[مستودع NanoChat على GitHub](https://github.com/karpathy/nanochat)