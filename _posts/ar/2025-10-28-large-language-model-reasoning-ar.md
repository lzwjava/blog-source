---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: تقنيات استدلال النماذج اللغوية الكبيرة
translated: true
type: note
---

### النظرة العامة
قدم ديني زهو (على الأرجح المقصود "داني زهو") محاضرة بعنوان "الاستدلال في النماذج اللغوية الكبيرة" كجزء من مساق ستانفورد CS25: Transformers United (الإصدار 5). وقد قدم فيها نظرة شاملة عن الاستدلال في النماذج اللغوية الكبيرة، مع التركيز على التقنيات العملية والأسس النظرية والتحديات المستمرة. فيما يلي ملخص منظم لأبرز النقاط، مأخوذ مباشرة من شرائحه والملاحظات المرافقة.

### تعريف الاستدلال في النماذج اللغوية الكبيرة
- الاستدلال في النماذج اللغوية الكبيرة هو في الأساس حول **إنشاء رموز وسيطة** (أو خطوات) بين المطالبة المدخلة والمخرجات النهائية، بدلاً من القفز مباشرة إلى الإجابة. هذه العملية تمكن النموذج من تحليل المشكلات المعقدة.
- لا يحتاج إلى محاكاة الاستدلال البشري تمامًا – الهدف هو حل المشكلات بشكل فعال. على سبيل المثال، حل سؤال "ما آخر حرفين من كلمة 'artificial intelligence'؟" عن طريق ربط نهايات الكلمات خطوة بخطوة يعطي "le"، مما يوضح كيف تساعد الخطوات الوسيطة في الحساب.
- الخلفية النظرية: للمشكلات التي يمكن حلها بواسطة دوائر منطقية بحجم *T*، يمكن للمحولات (Transformers) ذات الحجم الثابت معالجتها عن طريق إنتاج *O(T)* من الرموز الوسيطة، متجنبة الحاجة إلى تكبير هائل للنموذج.

### الدوافع
- النماذج اللغوية الكبيرة المدربة مسبقًا قادرة بطبيعتها على الاستدلال دون الحاجة إلى تحفيز خاص أو ضبط دقيق؛ الخرافة القائلة بأنها لا تستطيع ذلك تم دحضها – المشاكل تنشأ من طرق فك التشفير (decoding) التي تفشل في إبراز مخرجات مستدلة.
- هذا النهج يتوافق مع "الدرس المر": الاستفادة من الحساب (عبر توليد الرموز) بدلاً من الاختصارات الشبيهة بالبشر، مما يمكن من ظهور سلوكيات بشرية من خلال التنبؤ بالرمز التالي.
- التركيز على التحسين من أجل مقاييس الهدف النهائي مثل الصحة، باستخدام البيانات المولدة من النموذج بدلاً من الشروحات البشرية المكلفة.

### الأفكار الأساسية
- **فك التشفير بسلسلة الأفكار (CoT)**: إنشاء استجابات مرشحة متعدلة واختيار تلك ذات الثقة الأعلى في الإجابة النهائية. المسارات المستدلة غالبًا ما يكون لديها ثقة أعلى من التخمينات المباشرة (مثل حساب التفاحات في سيناريو ما).
- **التحجيم عبر الطول، وليس العمق**: تدريب النماذج على توليد تسلسلات أطول (*O(T)* رموز) للمشكلات التسلسلية، مما يجعلها قوية بشكل تعسفي دون تضخيم حجم النموذج.
- **التجميع بدلاً من المحاولات الفردية**: توليد ودمج استجابات متعددة (على سبيل المثال، عبر التصويت الأغلبية) يتفوق على المخرجات الفردية؛ استرجاع المشكلات المشابهة + الاستدلال يتفوق على الاستدلال وحده.
- مثال: "وضع التفكير" في Gemini 2.0 يحل الألغاز مثل تشكيل الرقم 2025 من الأرقام 1-10 عن طريق prioritization العمليات (مثال: 45 × 45 = 2025).

### التقنيات الرئيسية
- **التحفيز (Prompting)**: استخدام أمثلة قليلة العينة (few-shot) أو عبارات مثل "لنفكر خطوة بخطوة" لاستنباط الخطوات الوسيطة (مثل مسائل الرياضيات اللفظية). التحفيز دون أمثلة (zero-shot) يعمل ولكنه أقل موثوقية.
- **الضبط الدقيق المشرف عليه (SFT)**: التدريب على الحلول خطوة بخطوة التي وضحها البشر لتعزيز احتمالية المسارات المستدلة.
- **التحسين الذاتي**: إنشاء بيانات التدريب الخاصة بك عن طريق تصفية الحلول المستدلة الصحيحة من مخرجات النموذج.
- **الضبط الدقيق بالتعلم المعزز (ReFT)**: مكافأة الاستجابات الكاملة الصحيحة (الاستدلال + الإجابة) ومعاقبة الخاطئة بشكل تكراري، باستخدام مدقق (verifier). هذا يعمم بشكل أفضل للمهام القابلة للتحقق؛ الإشادة لأعضاء الفريق مثل Jonathan Lai.
- **الاتساق الذاتي (Self-Consistency)**: أخذ عينات من مسارات متعددة، ثم تجميعها (مثل الإجابة الأكثر تكرارًا). البديل الشامل للمهام مفتوحة النهاية يسمح للنموذج باختيار الإجابة بنفسه.
- **الاسترجاع + الاستدلال**: جلب أمثلة مرتبطة لتعزيز الأداء (مثال: تذكر معادلات المسافة لاستعلامات المساحة).
- **محسنات أخرى**: "خذ خطوة للوراء" للتجريد؛ التهميش (Marginalization) لتصحيح انحيازات فك التشفير الاحتمالي.

### القيود
- **التحفيز (Prompting)**: بسيط لكنه هش – يحتاج إلى أمثلة محددة للمهمة؛ المحفزات العامة تؤدي أداءً أقل.
- **الضبط الدقيق المشرف عليه (SFT)**: لا يعمم بشكل جيد على المشكلات خارج التوزيع التدريبي (مثال: يفشل في عد حروف "strawberry" الجديد رغم التدريب).
- **التعلم المعزز (RL)**: يعتمد على مدققات موثوقة، غير متاحة لكل المهام (مثال: الكتابة الإبداعية).
- **التحديات العامة**: النماذج اللغوية الكبيرة هي متنبئات احتمالية، لذا فإن فك التشفير الطماع (greedy decoding) يفضل إجابات سلسة لكنها خاطئة. التجميع يساعد لكنه لا يحل مشاكل المجالات غير القابلة للتحقق.
- عدم محاذاة فك التشفير: حتى النماذج القوية قد لا تصنف المخرجات المستدلة في الأعلى دون تدخل.

### الاتجاهات المستقبلية
- الدفع beyond المعايير القياسية إلى التطبيقات الواقعية، خاصة المهام غير القابلة للتحقق (مثال: تحسين الترجمة دون مقاييس مثالية).
- زيادة نطاق التجميع والاسترجاع لتحقيق مكاسب أكبر.
- تحسين فك التشفير (عبر التهميش مثلًا) لمحاذاة أفضل للمخرجات الاحتمالية مع الصحة.
- البناء نحو أنظمة "تتذكر" المسارات الاستدلالية الناجحة عبر الجلسات.

هذه المحاضرة تسلط الضوء على الضبط الدقيق بالتعلم المعزز كقوة رئيسية حالية، مع تحول نحو النظر إلى الاستدلال كمشكلة توليد قابلة للتحجيم.

### المراجع
- [شرائح استدلال النماذج اللغوية الكبيرة (PDF)](https://dennyzhou.github.io/LLM-Reasoning-Stanford-CS-25.pdf)
- [منشور ديني زهو على X حول النقاط الرئيسية](https://x.com/denny_zhou/status/1948499173986201915)
- [فيديو المحاضرة على YouTube](https://www.youtube.com/watch?v=ebnX5Ur1hBk)
- [صفحة مساق CS25](https://web.stanford.edu/class/cs25/)