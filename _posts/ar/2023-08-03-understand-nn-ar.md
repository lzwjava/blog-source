---
audio: false
generated: false
lang: ar
layout: post
title: ููู ุงูุดุจูุงุช ุงูุนุตุจูุฉ
translated: true
---

ุฒูููู:

ุจุงูุทุจุน! ุฅุฐุง ููุช ุชูุตุฏ ููุฏูุง ูุนูููุงุ ูุฑุฌู ูุดุงุฑูุชู ููุง ูุณุฃููู ุณุนูุฏูุง ุจุดุฑุญู ูู. ุฅุฐุง ููุช ุชูุตุฏ ููุฏูุง ุนุงููุง ุฃู ููููููุง ุจุฑูุฌููุง ูุนูููุงุ ููุฑุฌู ุชูุถูุญ ุฐูู ุญุชู ุฃุชููู ูู ุชูุฏูู ุงูุดุฑุญ ุงูููุงุณุจ. ๐

```python
        self.weights = [w-(eta/len(mini_batch))*nw
                        for w, nw in zip(self.weights, nabla_w)]
        self.biases = [b-(eta/len(mini_batch))*nb
                       for b, nb in zip(self.biases, nabla_b)]
```

ุชูุช ุชุฑุฌูุฉ ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุฃุนูุงู ุฅูู ุงูุนุฑุจูุฉ ููุง ููู:

```python
        self.weights = [w-(eta/len(mini_batch))*nw
                        for w, nw in zip(self.weights, nabla_w)]
        self.biases = [b-(eta/len(mini_batch))*nb
                       for b, nb in zip(self.biases, nabla_b)]
```

ูู ุงูููุฏ ุฃุนูุงูุ ูุชู ุชุญุฏูุซ ุงูุฃูุฒุงู (`weights`) ูุงูุงูุญูุงุฒุงุช (`biases`) ุจุงุณุชุฎุฏุงู ูุงุนุฏุฉ ุงูุชุญุฏูุซ ุงููุนุชูุฏุฉ ุนูู ุงูุชุฏุฑุฌ (gradient descent). ูุชู ุชุนุฏูู ูู ูุฒู ูุงูุญูุงุฒ ุจูุงุกู ุนูู ุงูุชุฏุฑุฌ ุงููุญุณูุจ (`nabla_w` ู `nabla_b`) ููุนุฏู ุงูุชุนูู (`eta`)ุ ูุน ุงูุฃุฎุฐ ูู ุงูุงุนุชุจุงุฑ ุญุฌู ุงูุฏูุนุฉ ุงูุตุบูุฑุฉ (`mini_batch`).

ChatGPT:

ุจุงูุทุจุน! ุงูููุฏ ุงูุฐู ูุฏูุชู ูุจุฏู ุฌุฒุกูุง ูู ุฎูุงุฑุฒููุฉ ุชุนูู ุงูุขูุฉุ ูุชุญุฏูุฏูุง ุชูููุฐ ูุฎูุงุฑุฒููุฉ ุงูุงูุญุฏุงุฑ ุงูุชุฏุฑุฌ ุงูุนุดูุงุฆู (Stochastic Gradient Descent - SGD) ูุชุญุฏูุซ ุงูุฃูุฒุงู ูุงูุชุญูุฒุงุช ูู ุดุจูุฉ ุนุตุจูุฉ ุฃุซูุงุก ุนูููุฉ ุงูุชุฏุฑูุจ. ุฏุนูุง ูุญููู ุฎุทูุฉ ุจุฎุทูุฉ:

1. `self.weights` ู `self.biases`:
ูู ุงููุญุชูู ุฃู ุชููู ูุฐู ุงููุชุบูุฑุงุช ุฌุฒุกูุง ูู ูุฆุฉ ุดุจูุฉ ุนุตุจูุฉุ ุญูุซ ุชูุซู ุงูุฃูุฒุงู ูุงูุงูุญูุงุฒุงุช ุงูุฎุงุตุฉ ุจุงูุดุจูุฉ. ูู ุงูุดุจูุฉ ุงูุนุตุจูุฉุ ุงูุฃูุฒุงู ูู ูุนุงููุงุช ุชูุนุฏู ููุฉ ุงูุงุชุตุงูุงุช ุจูู ุงูุฎูุงูุง ุงูุนุตุจูุฉ ูู ุงูุทุจูุงุช ุงููุฎุชููุฉุ ุจูููุง ุงูุงูุญูุงุฒุงุช ูู ูุนุงููุงุช ุชุชุญูู ูู ุนุชุจุฉ ุชูุดูุท ุงูุฎููุฉ ุงูุนุตุจูุฉ.

2. `nabla_w` ู `nabla_b`:
ูู ุงููุญุชูู ุฃู ุชุฎุฒู ูุฐู ุงููุชุบูุฑุงุช ุชุฏุฑุฌุงุช ุฏุงูุฉ ุงูุชูููุฉ ุจุงููุณุจุฉ ููุฃูุฒุงู ูุงูุชุญูุฒุงุช ุนูู ุงูุชูุงูู. ุฎูุงู ุนูููุฉ ุงูุชุฏุฑูุจุ ูุชู ุญุณุงุจ ุงูุชุฏุฑุฌุงุช ูุชุญุฏูุฏ ููููุฉ ุชุบูุฑ ุฏุงูุฉ ุงูุชูููุฉ ุจุงููุณุจุฉ ููุฃูุฒุงู ูุงูุชุญูุฒุงุชุ ููุชู ุงุณุชุฎุฏุงู ูุฐู ุงููุนูููุงุช ูุชุญุฏูุซ ุงููุนููุงุช ูุชูููู ุงูุชูููุฉ.

3. `eta`:
ูุฐุง ูู ูุนุฏู ุงูุชุนููุ ูุงูุฐู ูุชุญูู ูู ุญุฌู ุงูุฎุทูุฉ ุงูุชู ูุชู ุงุชุฎุงุฐูุง ูู ุงุชุฌุงู ุงูุชุฏุฑุฌุงุช ุฃุซูุงุก ุชุญุฏูุซ ุงููุนููุงุช. ูููู ุฃู ูุคุฏู ูุนุฏู ุงูุชุนูู ุงูุฃุนูู ุฅูู ุชูุงุฑุจ ุฃุณุฑุน ุฃุซูุงุก ุงูุชุฏุฑูุจุ ููููู ูุฏ ูุชุณุจุจ ุฃูุถูุง ูู ุนุฏู ุงูุงุณุชูุฑุงุฑ. ูุฏ ูุคุฏู ูุนุฏู ุงูุชุนูู ุงูุฃุตุบุฑ ุฅูู ุชุญุณูู ุงูุงุณุชูุฑุงุฑ ููููู ูุฒูุฏ ูู ููุช ุงูุชุฏุฑูุจ.

4. `mini_batch`:
ูุฐุง ุนุจุงุฑุฉ ุนู ูุฌููุนุฉ ูุฑุนูุฉ ูู ุจูุงูุงุช ุงูุชุฏุฑูุจ ุชูุณุชุฎุฏู ูู ูู ุชูุฑุงุฑ ูู ุชูููุฐ ุฎูุงุฑุฒููุฉ ุงูุงูุญุฏุงุฑ ุงูุชุฏุฑุฌู ุงูุนุดูุงุฆู (Stochastic Gradient Descent). ุฎูุงุฑุฒููุฉ ุงูุงูุญุฏุงุฑ ุงูุชุฏุฑุฌู ุจุงุณุชุฎุฏุงู ุงูุฏููุนุงุช ุงูุตุบูุฑุฉ (Mini-batch Gradient Descent) ูู ูุณุฎุฉ ูุนุฏูุฉ ูู ุฎูุงุฑุฒููุฉ ุงูุงูุญุฏุงุฑ ุงูุชุฏุฑุฌู ุงูุนุดูุงุฆูุ ุญูุซ ูุชู ุชูุณูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุชุฏุฑูุจ ุงููุงููุฉ ุฅูู ุฏูุนุงุช ุฃุตุบุฑุ ููุชู ุชุญุฏูุซ ุงููุนููุงุช ุจุงุณุชุฎุฏุงู ูู ุฏูุนุฉ ุตุบูุฑุฉ ุนูู ุญุฏุฉ.

ุงูุขูุ ุฏุนููุง ูููู ูุธุฑุฉ ุนูู ุงูููุฏ ููุณู:

```python
self.weights = [w-(eta/len(mini_batch))*nw
                for w, nw in zip(self.weights, nabla_w)]
```

ูู ุงูููุฏ ุฃุนูุงูุ ูุชู ุชุญุฏูุซ ุงูุฃูุฒุงู (`self.weights`) ุจุงุณุชุฎุฏุงู ูุงุนุฏุฉ ุงูุชุญุฏูุซ ุงูุชุงููุฉ:

- `w`: ุงููุฒู ุงูุญุงูู.
- `eta`: ูุนุฏู ุงูุชุนูู (learning rate).
- `len(mini_batch)`: ุญุฌู ุงูุฏูุนุฉ ุงูุตุบูุฑุฉ (mini-batch).
- `nabla_w`: ุงูุชุฏุฑุฌ (gradient) ุจุงููุณุจุฉ ูููุฒู.

ูุชู ุชุญุฏูุซ ูู ูุฒู ุนู ุทุฑูู ุทุฑุญ ุฌุฒุก ูู ุงูุชุฏุฑุฌ ูุถุฑูุจูุง ูู ูุนุฏู ุงูุชุนูู ููุณูููุง ุนูู ุญุฌู ุงูุฏูุนุฉ ุงูุตุบูุฑุฉ. ูุฐุง ุงูุชุญุฏูุซ ูุชู ุชุทุจููู ุนูู ุฌููุน ุงูุฃูุฒุงู ุจุงุณุชุฎุฏุงู list comprehension.

ูุฐุง ุงูุณุทุฑ ูููู ุจุชุญุฏูุซ ุฃูุฒุงู ุงูุดุจูุฉ ุงูุนุตุจูุฉ. ูุณุชุฎุฏู ูุงุฆูุฉ ุงุณุชูุนุงุจูุฉ (list comprehension) ููุชููู ุนุจุฑ ูู ูุฒู `w` ูุงูุชุฏุฑุฌ ุงููุชูุงุธุฑ `nw`. ููู ูุฒูุ ูุชู ุทุฑุญ ุฌุฒุก ูู ุงูุชุฏุฑุฌ (ูุถุฑูุจูุง ูู ูุนุฏู ุงูุชุนูู `eta` ูุญุฌู ุงูุฏููุนุฉ ุงูุตุบูุฑุฉ) ูู ุงููุฒู ุงูุฃุตูู. ูุฐู ูู ุงูุทุฑููุฉ ุงูุชู ูุชู ุจูุง ุชุญุฏูุซ ุงูุฃูุฒุงู ูุชูููู ุฏุงูุฉ ุงูุชูููุฉ.

```python
self.biases = [b-(eta/len(mini_batch))*nb
               for b, nb in zip(self.biases, nabla_b)]
```

ูู ุงูููุฏ ุฃุนูุงูุ ูุชู ุชุญุฏูุซ ููู ุงูุงูุญูุงุฒุงุช (`biases`) ุจุงุณุชุฎุฏุงู ูุงุนุฏุฉ ุงูุชุญุฏูุซ ุงูุชุฏุฑุฌ ุงูุชูุงุฒูู (gradient descent). ูุชู ุฐูู ุนู ุทุฑูู ุทุฑุญ ุฌุฒุก ูู ุงูุชุฏุฑุฌ (`nabla_b`) ูุถุฑูุจูุง ูู ูุนุฏู ุงูุชุนูู (`eta`) ููุณูููุง ุนูู ุญุฌู ุงูุฏูุนุฉ ุงูุตุบูุฑุฉ (`mini_batch`) ูู ูู ูููุฉ ุงูุญูุงุฒ ุญุงููุฉ (`b`). ูุชู ุชูููุฐ ูุฐู ุงูุนูููุฉ ููู ุฒูุฌ ูู ุงูุงูุญูุงุฒุงุช ุงูุญุงููุฉ ูุงูุชุฏุฑุฌุงุช ุงูููุงุจูุฉ ููุง ุจุงุณุชุฎุฏุงู ุงูุฏุงูุฉ `zip`.

ูุฐุง ุงูุณุทุฑ ูููู ุจุชุญุฏูุซ ุงูุชุญูุฒุงุช (biases) ูุดุจูุฉ ุงูุนุตุจูุฉ ุจุทุฑููุฉ ูุดุงุจูุฉ. ูุณุชุฎุฏู ูุงุฆูุฉ ุงุณุชูุนุงุจ (list comprehension) ููุชููู ุนุจุฑ ูู ุชุญูุฒ `b` ูุงูุชุฏุฑุฌ (gradient) ุงูููุงุจู ูู `nb`. ููู ุชุญูุฒุ ูุชู ุทุฑุญ ุฌุฒุก ูู ุงูุชุฏุฑุฌ (ูุถุฑูุจูุง ูู ูุนุฏู ุงูุชุนูู `eta` ูุญุฌู ุงูุฏููุนุฉ ุงูุตุบูุฑุฉ) ูู ุงูุชุญูุฒ ุงูุฃุตูู.

ุจุงุฎุชุตุงุฑุ ุชููู ูุฐู ุงูุฃุณุทุฑ ูู ุงูููุฏ ุจุชุญุฏูุซ ุงูุฃูุฒุงู ูุงูุงูุญูุงุฒุงุช ููุดุจูุฉ ุงูุนุตุจูุฉ ุจุงุณุชุฎุฏุงู ุฎูุงุฑุฒููุฉ ุงูุงูุญุฏุงุฑ ุงูุชุฏุฑุฌู ุงูุนุดูุงุฆู (Stochastic Gradient Descent). ูุชู ุชูุฑุงุฑ ูุฐู ุงูุนูููุฉ ููู ูุฌููุนุฉ ุตุบูุฑุฉ (mini-batch) ุฎูุงู ูุฑุญูุฉ ุงูุชุฏุฑูุจ ูุชุญุณูู ูุนููุงุช ุงูุดุจูุฉ ูุชุนุฒูุฒ ุฃุฏุงุฆูุง ูู ุงููููุฉ ุงููุญุฏุฏุฉ.

----

Zhiwei: ูุง ูู ูููุฐุฌ ุงููุบุฉ SpaCyุ

ChatGPT: SpaCy ูู ููุชุจุฉ ููุชูุญุฉ ุงููุตุฏุฑ ููุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ (NLP) ุชู ุชุทููุฑูุง ุจูุงุณุทุฉ Explosion AI. ุชู ุชุตููููุง ูุชููู ูุนุงูุฉ ูุณุฑูุนุฉ ูุฌุงูุฒุฉ ููุฅูุชุงุฌุ ููุง ูุฌุนููุง ุฎูุงุฑูุง ุดุงุฆุนูุง ูููุงู ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ ุงููุฎุชููุฉ. ุชููุฑ SpaCy ููุงุฐุฌ ูุบููุฉ ููุฏุฑุจุฉ ูุณุจููุง ูููููุง ูุนุงูุฌุฉ ูููู ุงููุตูุตุ ููุง ูุณูุญ ูููุทูุฑูู ุจุชูููุฐ ููุงู ูุฎุชููุฉ ูู ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ ูุซู ูุณู ุฃุฌุฒุงุก ุงูููุงูุ ูุงูุชุนุฑู ุนูู ุงูููุงูุงุช ุงููุณูุงุฉุ ูุชุญููู ุงูุฌููุ ูุบูุฑ ุฐูู.

ุงูููุฒุงุช ุงูุฑุฆูุณูุฉ ููููุฐุฌ ุงููุบุฉ SpaCy ุชุดูู:

1. **ุงูุชุฌุฒุฆุฉ (Tokenization):** ูููู ูู SpaCy ุชูุณูู ุงููุต ุฅูู ูููุงุช ุฃู ูุญุฏุงุช ูุฑุฏูุฉ (tokens)ุ ูุน ูุฑุงุนุงุฉ ุงูููุงุนุฏ ุงููุบููุฉ ุงููุฎุชููุฉ ูุงูุชุนููุฏุงุช.

2. **ุชุญุฏูุฏ ููุน ุงููููุฉ (Part-of-speech Tagging):** ูููู ููููุชุจุฉ ุชุนููู ุนูุงูุงุช ุชุญุฏุฏ ููุน ุงููููุฉ ููู ูุญุฏุฉ ูุบููุฉ (token)ุ ููุง ูุดูุฑ ุฅูู ูุง ุฅุฐุง ูุงูุช ุงููููุฉ ุงุณููุงุ ูุนููุงุ ุตูุฉูุ ุฅูุฎ.

3. ุงูุชุนุฑู ุนูู ุงูููุงูุงุช ุงููุณูุงุฉ (NER): ูููู ูู SpaCy ุชุญุฏูุฏ ูุชุตููู ุงูููุงูุงุช ูุซู ุฃุณูุงุก ุงูุฃุดุฎุงุตุ ูุงูููุธูุงุชุ ูุงูููุงูุนุ ูุงูุชูุงุฑูุฎุ ูุบูุฑูุง.

4. ุชุญููู ุงูุชุจุนูุงุช (Dependency Parsing): ููููู ุชุญููู ุงูุจููุฉ ุงููุญููุฉ ููุฌููุฉ ูุชุญุฏูุฏ ุงูุนูุงูุงุช ุจูู ุงููููุงุช.

5. ุงูุชุตุฑูู: ูููู ูู SpaCy ุชุญููู ุงููููุงุช ุฅูู ุดูููุง ุงูุฃุณุงุณู ุฃู ุงูุฌุฐุฑ (ุงููุงูุงุช).

6. ูุชุฌูุงุช ุงููููุงุช: ุชููุฑ ุงูููุชุจุฉ ูุชุฌูุงุช ุงููููุงุชุ ุงููุนุฑููุฉ ุฃูุถูุง ุจุงุณู ุชุถูููุงุช ุงููููุงุชุ ููู ุชูุซููุงุช ุนุฏุฏูุฉ ูุซููุฉ ูููููุงุช ุชุนุจุฑ ุนู ุงููุนูู ุงูุฏูุงูู.

SpaCy ูุฏุนู ูุบุงุช ูุชุนุฏุฏุฉ ููุฃุชู ูุน ููุงุฐุฌ ูุฏุฑุจุฉ ูุณุจููุง ููุบุงุช ูุฎุชููุฉุ ููุง ูุฌุนูู ูุณุชุฎุฏููุง ุนูู ูุทุงู ูุงุณุน ูู ุชุทุจููุงุช ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ (NLP) ุงููุชููุนุฉุ ุจูุง ูู ุฐูู ุงุณุชุฎุฑุงุฌ ุงููุนูููุงุชุ ุชุญููู ุงููุดุงุนุฑุ ุฑูุจูุชุงุช ุงูุฏุฑุฏุดุฉุ ุงูุชุฑุฌูุฉ ุงููุบููุฉุ ูุบูุฑูุง. ุจุงูุฅุถุงูุฉ ุฅูู ุฐููุ ูุณูุญ SpaCy ูููุทูุฑูู ุจุชุฏุฑูุจ ููุงุฐุฌ ูุฎุตุตุฉ ุนูู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจูู ุฅุฐุง ูุฒู ุงูุฃูุฑ.

---

Zhiwei: ูุง ูู ูููุฐุฌ ุงููุบุฉ SpaCyุ

ChatGPT: SpaCy ูู ููุชุจุฉ ููุชูุญุฉ ุงููุตุฏุฑ ููุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ (NLP) ุชู ุชุทููุฑูุง ุจูุงุณุทุฉ Explosion AI. ุชู ุชุตููููุง ูุชููู ูุนุงูุฉ ูุณุฑูุนุฉ ูุณููุฉ ุงูุงุณุชุฎุฏุงูุ ููุง ูุฌุนููุง ุฎูุงุฑูุง ุดุงุฆุนูุง ูููุงู ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ ุงููุฎุชููุฉ. ุชููุฑ SpaCy ููุงุฐุฌ ูุบููุฉ ููุฏุฑููุจุฉ ูุณุจููุง ููุนุฏูุฏ ูู ุงููุบุงุชุ ููุง ูุณูุญ ูููุณุชุฎุฏููู ุจุชูููุฐ ููุงู ูุซู ุงูุชุฌุฒุฆุฉ (tokenization)ุ ููุถุน ุนูุงูุงุช ุนูู ุฃุฌุฒุงุก ุงูููุงู (part-of-speech tagging)ุ ูุงูุชุนุฑู ุนูู ุงูููุงูุงุช ุงููุณูุงุฉ (named entity recognition)ุ ูุชุญููู ุงูุชุจุนูุงุช (dependency parsing)ุ ูุงููุฒูุฏ.

ุฌููุฑ ุณุฑุนุฉ ูููุงุกุฉ SpaCy ูููู ูู ุชุทุจููุงุชู ูููุงูู ุจูุงูุงุชู ุงูููุญุณููุฉ ุจุงุณุชุฎุฏุงู Cythonุ ููุง ูุฌุนูู ููุงุณุจูุง ุจุดูู ุฎุงุต ููุจูุฆุงุช ุงูุฅูุชุงุฌูุฉ ูุงูุชุทุจููุงุช ุงููุงูุนูุฉ. ุชูุช ูุชุงุจุฉ ุงูููุชุจุฉ ุจูุบุฉ Python ูุชุฃุชู ูุน ููุงุฐุฌ ููุฏุฑุจุฉ ูุณุจููุง ููุนุฏูุฏ ูู ุงููุบุงุชุ ุจูุง ูู ุฐูู ุงูุฅูุฌููุฒูุฉุ ุงูุฃููุงููุฉุ ุงููุฑูุณูุฉุ ุงูุฅุณุจุงููุฉุ ูุบูุฑูุง.

ุชุณุชุฎุฏู ููุงุฐุฌ ุงููุบุฉ ูู SpaCy ุชูููุงุช ุงูุชุนูู ุงูุนููู ูุชุนูู ุงูุฃููุงุท ุงูุฃุณุงุณูุฉ ูู ุจูุงูุงุช ุงููุบุฉ ุงูุทุจูุนูุฉ. ูุชู ุชุฏุฑูุจ ูุฐู ุงูููุงุฐุฌ ุนูู ูุฌููุนุงุช ูุจูุฑุฉ ูู ุงููุตูุตุ ููููู ุจุนุฏ ุฐูู ุงุณุชุฎุฏุงู ุงูุชูุซููุงุช ุงูุชู ุชู ุชุนูููุง ูู ููุงู ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ ุงููุฎุชููุฉ. ูููู ุฃูุถูุง ุถุจุท ุงูููุงุฐุฌ ุงููุฏุฑุจุฉ ูุณุจููุง ุนูู ุจูุงูุงุช ูุญุฏุฏุฉ ูุชุญููู ุฃุฏุงุก ุฃูุถู ูู ุงูููุงู ุงููุชุนููุฉ ุจูุฌุงู ูุนูู.

ุฌุนูุช ุงูุจููุฉ ูุณูููุฉ ุงูุงุณุชุฎุฏุงู ูู SpaCy ุฎูุงุฑูุง ุดุงุฆุนูุง ุจูู ุงููุทูุฑูู ูุงูุจุงุญุซูู ูู ูุฌุชูุน ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ (NLP). ุบุงูุจูุง ูุง ูุชู ุงุณุชุฎุฏุงููุง ูู ููุงู ูุซู ุงุณุชุฎุฑุงุฌ ุงููุนูููุงุชุ ุชุตููู ุงููุตูุตุ ุงูุชุนุฑู ุนูู ุงูููุงูุงุช ุงููุณูุงุฉุ ูุณู ุฃุฌุฒุงุก ุงูููุงูุ ูุงูุชุญููู ุงููุญูู. ุจุงูุฅุถุงูุฉ ุฅูู ุฐููุ ูุณูุญ ุงูุชุตููู ุงููุนูุงุฑู ูู SpaCy ูููุณุชุฎุฏููู ุจุฏูุฌูุง ุจุณูููุฉ ูู ุณูุฑ ุนูููู ูุฎุทูุท ุฃูุงุจูุจ NLP ุงูุญุงููุฉ.

---

ุชุดููู: ูู ููููู ุฃู ุชุดุฑุญุ

```python
class Llama:
    @staticmethod
    def build(
        ckpt_dir: str,
        tokenizer_path: str,
        max_seq_len: int,
        max_batch_size: int,
        model_parallel_size: Optional[int] = None,
    ) -> "Llama":
        if not torch.distributed.is_initialized():
            torch.distributed.init_process_group("nccl")
        if not model_parallel_is_initialized():
            if model_parallel_size is None:
                model_parallel_size = int(os.environ.get("WORLD_SIZE", 1))
            initialize_model_parallel(model_parallel_size)
```

```python
local_rank = int(os.environ.get("LOCAL_RANK", 0))
torch.cuda.set_device(local_rank)
```

        # ูุฌุจ ุฃู ูููู seed ูู ููุณู ูู ุฌููุน ุงูุนูููุงุช
        torch.manual_seed(1)

```python
if local_rank > 0:
    sys.stdout = open(os.devnull, "w")
```

```python
        start_time = time.time()
        checkpoints = sorted(Path(ckpt_dir).glob("*.pth"))
        assert len(checkpoints) > 0, f"ูู ูุชู ุงูุนุซูุฑ ุนูู ูููุงุช ููุงุท ุชูุชูุด ูู {ckpt_dir}"
        assert model_parallel_size == len(
            checkpoints
        ), f"ุฌุงุฑู ุชุญููู ููุทุฉ ุชูุชูุด ูู MP={len(checkpoints)} ูููู ุญุฌู ุงูุนุงูู ูู {model_parallel_size}"
        ckpt_path = checkpoints[get_model_parallel_rank()]
        checkpoint = torch.load(ckpt_path, map_location="cpu")
        with open(Path(ckpt_dir) / "params.json", "r") as f:
            params = json.loads(f.read())
```

ูู ุจุชุดุบูู ุงูุฃูุฑ ุซู ุงุญุตู ุนูู ุณุฌู ุงูุฃุฎุทุงุก.

```shell
% torchrun --nproc_per_node 1 example_text_completion.py \
    --ckpt_dir llama-2-7b/ \
    --tokenizer_path tokenizer.model \
    --max_seq_len 128 --max_batch_size 4
ููุงุญุธุฉ: ุฅุนุงุฏุฉ ุงูุชูุฌูู ุบูุฑ ูุฏุนููุฉ ุญุงูููุง ูู Windows ุฃู MacOs.
Traceback (ุขุฎุฑ ุงุณุชุฏุนุงุก ุฃุฎูุฑ):
  File "/Users/lzwjava/projects/llama/example_text_completion.py", line 55, in <module>
    fire.Fire(main)
  File "/Users/lzwjava/anaconda3/lib/python3.10/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/Users/lzwjava/anaconda3/lib/python3.10/site-packages/fire/core.py", line 475, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/Users/lzwjava/anaconda3/lib/python3.10/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/Users/lzwjava/projects/llama/example_text_completion.py", line 18, in main
    generator = Llama.build(
  File "/Users/lzwjava/projects/llama/llama/generation.py", line 62, in build
    torch.distributed.init_process_group("nccl")
  File "/Users/lzwjava/anaconda3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 907, in init_process_group
    default_pg = _new_process_group_helper(
  File "/Users/lzwjava/anaconda3/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1013, in _new_process_group_helper
    raise RuntimeError("Distributed package doesn't have NCCL " "built in")
RuntimeError: ุงูุญุฒูุฉ ุงูููุฒุนุฉ ูุง ุชุญุชูู ุนูู NCCL ูุฏูุฌ
ERROR:torch.distributed.elastic.multiprocessing.api:ูุดู (ุฑูุฒ ุงูุฎุฑูุฌ: 1) local_rank: 0 (pid: 23273) ูู ุงูููู ุงูุซูุงุฆู: /Users/lzwjava/anaconda3/bin/python
```

```plaintext
Traceback (most recent call last):
  File "/Users/lzwjava/anaconda3/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.0.1', 'console_scripts', 'torchrun')())
  File "/Users/lzwjava/anaconda3/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/Users/lzwjava/anaconda3/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/Users/lzwjava/anaconda3/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/Users/lzwjava/anaconda3/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/Users/lzwjava/anaconda3/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
============================================================
example_text_completion.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-03_15:35:37
  host      : 1.0.0.127.in-addr.arpa
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 23273)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
```

ุชุนูู ุชุชุจุน ููุฏุณ ุงูุฃุฎุทุงุก.

ุงุณุฃู ChatGPT ุนู ูุนูู Backend.NCCL ูู Pytorchุ

---

ุชุดููู:

```code```

```python
import torch
from transformers import LlamaTokenizer, LlamaForCausalLM
```

```python
model_path = '.'
# model_path = 'openlm-research/open_llama_7b'
```

```python
tokenizer = LlamaTokenizer.from_pretrained(model_path)
model = LlamaForCausalLM.from_pretrained(
    model_path, torch_dtype=torch.float16, device_map='auto',
)
```

```python
prompt = 'Q: ูุง ูู ุฃูุจุฑ ุญููุงูุ\nA:'
input_ids = tokenizer(prompt, return_tensors="pt").input_ids
generation_output = model.generate(
    input_ids=input_ids, max_new_tokens=32
)
print(tokenizer.decode(generation_output[0]))
```

ุฎุทุฃ:

```shell
/home/lzw/anaconda3/envs/llama/lib/python3.11/site-packages/transformers/generation/utils.py:1445: UserWarning: ุฃูุช ุชุณุชุฏุนู .generate() ูุน ูุฌูุฏ `input_ids` ุนูู ููุน ุฌูุงุฒ ูุฎุชูู ุนู ุฌูุงุฒ ุงููููุฐุฌ ุงูุฎุงุต ุจู. `input_ids` ููุฌูุฏ ุนูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU)ุ ุจูููุง ุงููููุฐุฌ ููุฌูุฏ ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (CUDA). ูุฏ ุชูุงุฌู ุณููููุงุช ุบูุฑ ูุชููุนุฉ ุฃู ุชูููุฏ ุฃุจุทุฃ. ูุฑุฌู ุงูุชุฃูุฏ ูู ุฃูู ููุช ุจูุถุน `input_ids` ุนูู ุงูุฌูุงุฒ ุงูุตุญูุญ ุนู ุทุฑูู ุงุณุชุฏุนุงุก input_ids = input_ids.to('cuda') ูุจู ุชุดุบูู `.generate()`.
  warnings.warn(
Traceback (most recent call last):
  File "/home/lzw/Projects/open_llama_3b/run.py", line 17, in <module>
    generation_output = model.generate(
                        ^^^^^^^^^^^^^^^
  File "/home/lzw/anaconda3/envs/llama/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lzw/anaconda3/envs/llama/lib/python3.11/site-packages/transformers/generation/utils.py", line 1515, in generate
    return self.greedy_search(
           ^^^^^^^^^^^^^^^^^^^
  File "/home/lzw/anaconda3/envs/llama/lib/python3.11/site-packages/transformers/generation/utils.py", line 2332, in greedy_search
    outputs = self(
              ^^^^^
  File "/home/lzw/anaconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lzw/anaconda3/envs/llama/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 688, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/lzw/anaconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lzw/anaconda3/envs/llama/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 531, in forward
    inputs_embeds = self.embed_tokens(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lzw/anaconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lzw/anaconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 162, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/home/lzw/anaconda3/envs/llama/lib/python3.11/site-packages/torch/nn/functional.py", line 2210, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ูุงู ูู ุงููุชููุน ุฃู ุชููู ุฌููุน ุงูููุชุฑุงุช ุนูู ููุณ ุงูุฌูุงุฒุ ูููู ุชู ุงูุนุซูุฑ ุนูู ุฌูุงุฒูู ุนูู ุงูุฃููุ cuda:0 ู cpu! (ุนูุฏ ุงูุชุญูู ูู ุงููุณูุท index ูู ุทุฑููุฉ wrapper_CUDA__index_select)
```

ููููุฉ ุงูุฅุตูุงุญุ

ChatGPT:

ุชุดูุฑ ุฑุณุงูุฉ ุงูุฎุทุฃ ุงูุชู ุชูุงุฌููุง ุฅูู ูุฌูุฏ ุนุฏู ุชุทุงุจู ูู ุฃููุงุน ุงูุฃุฌูุฒุฉ ุจูู ููุชุฑ ุงูุฅุฏุฎุงู (`input_ids`) ููููุฐุฌู (`LlamaForCausalLM`). ููุชุฑ ุงูุฅุฏุฎุงู ููุฌูุฏ ุนูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (`cpu`)ุ ุจูููุง ุงููููุฐุฌ ููุฌูุฏ ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (`cuda`). ูุฅุตูุงุญ ูุฐุงุ ุชุญุชุงุฌ ุฅูู ุงูุชุฃูุฏ ูู ุฃู ููุชุฑ ุงูุฅุฏุฎุงู ููุฌูุฏ ุนูู ููุณ ุงูุฌูุงุฒ ุงูุฐู ููุฌุฏ ุนููู ุงููููุฐุฌ ูุจู ุชูููุฏ ุงููุต ุจุงุณุชุฎุฏุงู ุงููููุฐุฌ.

ุฅููู ุงูููุฏ ุงููุนุฏู ูุฅุตูุงุญ ุงููุดููุฉ:

```python
import torch
from transformers import LlamaTokenizer, LlamaForCausalLM
```

```python
model_path = '.'
# model_path = 'openlm-research/open_llama_7b'
```

```python
tokenizer = LlamaTokenizer.from_pretrained(model_path)
model = LlamaForCausalLM.from_pretrained(
    model_path, torch_dtype=torch.float16, device_map='auto',
)
```

prompt = 'Q: ูุง ูู ุฃูุจุฑ ุญููุงูุ\nA:'
input_ids = tokenizer(prompt, return_tensors="pt").input_ids

# ููู tensor input_ids ุฅูู ููุณ ุงูุฌูุงุฒ ุงูุฐู ูุนูู ุนููู ุงููููุฐุฌ
input_ids = input_ids.to(model.device)

```python
generation_output = model.generate(
    input_ids=input_ids, max_new_tokens=32
)
print(tokenizer.decode(generation_output[0]))
```

ูู ูุฐุง ุงูููุฏุ ุฃุถูุช ุงูุณุทุฑ `input_ids = input_ids.to(model.device)` ุจุนุฏ ุงูุญุตูู ุนูู ูุตูููุฉ `input_ids` ูู ุงูุฃุฏุงุฉ ุงููุฎุตุตุฉ ููุชุญููู (tokenizer). ูุฐุง ุงูุณุทุฑ ูููู ูุตูููุฉ `input_ids` ุฅูู ููุณ ุงูุฌูุงุฒ ุงูุฐู ูุนูู ุนููู ุงููููุฐุฌ (ุณูุงุก ูุงู CPU ุฃู GPU) ูุจู ุชูููุฏ ุงููุต. ูุฐุง ุงูุฅุฌุฑุงุก ูุฌุจ ุฃู ูุญู ูุดููุฉ "Expected all tensors to be on the same device".

ุชุฐูุฑ ุฃูู ุฅุฐุง ููุช ุชููู ุจุชุดุบูู ูุฐุง ุงูููุฏ ุนูู ุฌูุงุฒ ูุฏุนู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ููุงู ูููุฐุฌู ูุนูู ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุชุ ููู ุงูุฃูุถู ุนููููุง ุงูุงุญุชูุงุธ ุจูู ูู ุงููููุฐุฌ ูุจูุงูุงุช ุงูุฅุฏุฎุงู ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช ููุงุณุชูุงุฏุฉ ูู ุฅููุงููุงุช ุงููุนุงูุฌุฉ ุงููุชูุงุฒูุฉ.

---

Zhiwei: ูู ููููู ุดุฑุญ ุงูุฃููุงุฏ ุฃุฏูุงูุ

```python
   def generate(
        self,
        prompt_tokens: List[List[int]],
        max_gen_len: int,
        temperature: float = 0.6,
        top_p: float = 0.9,
        logprobs: bool = False,
        echo: bool = False,
    ) -> Tuple[List[List[int]], Optional[List[List[float]]]]:
        params = self.model.params
        bsz = len(prompt_tokens)
        assert bsz <= params.max_batch_size, (bsz, params.max_batch_size)
```

```python
min_prompt_len = min(len(t) for t in prompt_tokens)
max_prompt_len = max(len(t) for t in prompt_tokens)
assert max_prompt_len <= params.max_seq_len
total_len = min(params.max_seq_len, max_gen_len + max_prompt_len)
```

ุชู ุชุฑุฌูุฉ ุงูููุฏ ุฃุนูุงู ุฅูู:

```python
min_prompt_len = min(len(t) for t in prompt_tokens)
max_prompt_len = max(len(t) for t in prompt_tokens)
assert max_prompt_len <= params.max_seq_len
total_len = min(params.max_seq_len, max_gen_len + max_prompt_len)
```

```python
pad_id = self.tokenizer.pad_id
tokens = torch.full((bsz, total_len), pad_id, dtype=torch.long, device="cuda")
for k, t in enumerate(prompt_tokens):
    tokens[k, : len(t)] = torch.tensor(t, dtype=torch.long, device="cuda")
if logprobs:
    token_logprobs = torch.zeros_like(tokens, dtype=torch.float)
```

```python
prev_pos = 0
eos_reached = torch.tensor([False] * bsz, device="cuda")
input_text_mask = tokens != pad_id
for cur_pos in range(min_prompt_len, total_len):
    logits = self.model.forward(tokens[:, prev_pos:cur_pos], prev_pos)
    if logprobs:
        token_logprobs[:, prev_pos + 1 : cur_pos + 1] = -F.cross_entropy(
            input=logits.transpose(1, 2),
            target=tokens[:, prev_pos + 1 : cur_pos + 1],
            reduction="none",
            ignore_index=pad_id,
        )
    if temperature > 0:
        probs = torch.softmax(logits[:, -1] / temperature, dim=-1)
        next_token = sample_top_p(probs, top_p)
    else:
        next_token = torch.argmax(logits[:, -1], dim=-1)
```

```python
            next_token = next_token.reshape(-1)
            # ุงุณุชุจุฏุงู ุงูุฑูุฒ ููุท ุฅุฐุง ุชู ุฅูุดุงุก ุงููุต ุงููุทููุจ ุจุงููุนู
            next_token = torch.where(
                input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token
            )
            tokens[:, cur_pos] = next_token
            eos_reached |= (~input_text_mask[:, cur_pos]) & (
                next_token == self.tokenizer.eos_id
            )
            prev_pos = cur_pos
            if all(eos_reached):
                break
```

```python
        if logprobs:
            token_logprobs = token_logprobs.tolist()
        out_tokens, out_logprobs = [], []
        for i, toks in enumerate(tokens.tolist()):
            # ูุต ุฅูู ุงูุญุฏ ุงูุฃูุตู ูุทูู ุงูุชูููุฏ
            start = 0 if echo else len(prompt_tokens[i])
            toks = toks[start : len(prompt_tokens[i]) + max_gen_len]
            probs = None
            if logprobs:
                probs = token_logprobs[i][start : len(prompt_tokens[i]) + max_gen_len]
            # ูุต ุฅูู ุฑูุฒ ููุงูุฉ ุงูุฌููุฉ ุฅุฐุง ูุฌุฏ
            if self.tokenizer.eos_id in toks:
                eos_idx = toks.index(self.tokenizer.eos_id)
                toks = toks[:eos_idx]
                probs = probs[:eos_idx] if logprobs else None
            out_tokens.append(toks)
            out_logprobs.append(probs)
        return (out_tokens, out_logprobs if logprobs else None)
```

ุจุงูุทุจุน! ุงูููุฏ ุงูููุฏู ูู ุทุฑููุฉ ุชูุณูู `generate` ุชุฃุฎุฐ ูุตูุง ููุฏุฎููุง (prompt) ูุชููุดุฆ ูุตูุง ุจุงุณุชุฎุฏุงู ูููุฐุฌ ูุบูู. ุชู ุชุตููู ูุฐู ุงูุทุฑููุฉ ููุนูู ูุน ูููุฐุฌ ูููุฑูุฒ ูุนูููู ูุชููู ุจุฅูุดุงุก ุงููุต ุจุงุณุชุฎุฏุงู ุฅูุง ุฃุฎุฐ ุงูุนููุงุช ุงูุฌุดุนุฉ (greedy sampling) ุฃู ุฃุฎุฐ ุงูุนููุงุช ูู ุฃุนูู ุงูุงุญุชูุงูุงุช (top-p sampling). ุฅููู ุชูุตูู ูููููุฉ ุนูู ูุฐู ุงูุทุฑููุฉ:

1. **ูุนููุงุช ุงูุทุฑููุฉ:**
   - `prompt_tokens`: ูุงุฆูุฉ ุจุงูุฑููุฒ ุงููููุฒุฉ (tokens) ููุทูุจุงุชุ ุญูุซ ูุชู ุชูุซูู ูู ุทูุจ ููุงุฆูุฉ ูู ุงูุฃุนุฏุงุฏ ุงูุตุญูุญุฉ (ูุนุฑูุงุช ุงูุฑููุฒ).
   - `max_gen_len`: ุงูุทูู ุงูุฃูุตู ูููุงุชุฌ ุงูููููุฏ (ุจุงูุฑููุฒ).
   - `temperature`: ูุนููุฉ ุชุชุญูู ูู ุนุดูุงุฆูุฉ ุงููุงุชุฌ. ุงูููู ุงูุฃุนูู (ูุซู 1.0) ุชุฌุนู ุงููุงุชุฌ ุฃูุซุฑ ุนุดูุงุฆูุฉุ ุจูููุง ุงูููู ุงูุฃูู (ูุซู 0.6) ุชุฌุนูู ุฃูุซุฑ ุญุชููุฉ.
   - `top_p`: ูุนููุฉ ุชุชุญูู ูู ุชููุน ุงููุต ุงูููููุฏ. ุงูููู ุงูุฃุนูู (ูุซู 0.9) ุชุณูุญ ุจุนููุงุช ุฃูุซุฑ ุชููุนูุง.
   - `logprobs`: ุฅุฐุง ูุงูุช `True`ุ ูุฅู ุงูุทุฑููุฉ ุชูุฑุฌุน ุฃูุถูุง ุงูููุบุงุฑูุชูุงุช ุงูุงุญุชูุงููุฉ ููุฑููุฒ ุงููููุฏุฉ.
   - `echo`: ุฅุฐุง ูุงูุช `True`ุ ูุฅู ุงููุงุชุฌ ุงูููููุฏ ุณูุชุถูู ุงูุทูุจ ููุณู.

2. **ุงูุชููุฆุฉ:**
   ุชููู ุงูุทุฑููุฉ ุจุชููุฆุฉ ุงููุชุบูุฑุงุช ูุซู `params`ุ ู`bsz` (ุญุฌู ุงูุฏููุนุฉ)ุ ู`min_prompt_len`ุ ู`max_prompt_len`. ููุง ุชููู ุจุญุณุงุจ `total_len` ููู ุงูุทูู ุงูููู ูููุฎุฑุฌุงุช ุงููููุฏุฉ ุจูุง ูู ุฐูู ุงููุต ุงููุจุฏุฆู.

3. **ุฅูุดุงุก ุงูุฑููุฒ (Token Generation):**
   ุชููู ุงูุทุฑููุฉ ุจุฅูุดุงุก ุฑููุฒ ูููุต ุงููุงุชุฌ. ุชุณุชุฎุฏู ุญููุฉ ููุชูุฑุงุฑ ุนุจุฑ ุงูููุงุถุน ูู ุงูุชุณูุณู ุงููููุดุฃุ ุจุฏุกูุง ูู ููุงูุฉ ุงููุทุงูุจุฉ (prompt) ูุงูุชุญุฑู ููุฃูุงู.
   
   - ูุชู ุงูุญุตูู ุนูู ุงูููู ุงูููุบุงุฑูุชููุฉ (logits) ููู ููุถุน ุนู ุทุฑูู ุชูุฑูุฑ ุงูุชุณูุณู ุงูุฌุฒุฆู ุฅูู ุฏุงูุฉ ุงูุชูุฏู (forward function) ูููููุฐุฌ.
   - ุฅุฐุง ูุงูุช ูููุฉ `temperature` ุฃูุจุฑ ูู 0ุ ูุชู ุชุญููู ุงูููู ุงูููุบุงุฑูุชููุฉ ุฅูู ุงุญุชูุงูุงุช ุจุงุณุชุฎุฏุงู ุฏุงูุฉ softmax ูุน ูููุฉ ุฏุฑุฌุฉ ุงูุญุฑุงุฑุฉ ุงููุญุฏุฏุฉ. ุฅุฐุง ูุงูุช `temperature` ุชุณุงูู 0ุ ูุชู ุงุฎุชูุงุฑ ุงูุฑูุฒ ุฐู ุงููููุฉ ุงูููุบุงุฑูุชููุฉ ุงูุฃุนูู ุจุงุณุชุฎุฏุงู `torch.argmax`.
   - ูุชู ุชุญุฏูุฏ ุงูุฑูุฒ ุงูุชุงูู ุจูุงุกู ุนูู ุงูุงุญุชูุงูุงุช ุงููููุดุฃุฉ ุฃู ุงููููุฉ ุงููุญุฏุฏุฉ ุจูุงุณุทุฉ `argmax`ุ ููุชู ูุถุนู ูู ุงูููุถุน ุงูููุงุณุจ ูู ูุตูููุฉ `tokens`.
   - ูุชู ุงูุชุดุงู ุฑููุฒ ููุงูุฉ ุงูุชุณูุณู (EOS)ุ ูุฅุฐุง ูุตูุช ุฌููุน ุงูุชุณูุณูุงุช ุฅูู ุฑูุฒ EOSุ ูุชู ุฅููุงู ุนูููุฉ ุงูุฅูุดุงุก.
   - ูุชู ุงูุงุญุชูุงุธ ุจุงูุฑููุฒ ุงููููุดุฃุฉ ูู ูุตูููุฉ `tokens`.

4. **ูุนุงูุฌุฉ ุงููุงุชุฌ ุงููููุดุฃ:**
   - ูุชู ูุนุงูุฌุฉ ุงูุฑููุฒ ุงููููุดุฃุฉ ูุชูููู ุงููุงุชุฌ ุฅูู ุงูุทูู ุงูุฃูุตู ุงููุทููุจ (`max_gen_len`).
   - ุฅุฐุง ูุงูุช ูููุฉ `echo` ูู `True`ุ ูุชู ุชุถููู ุงููุต ุงููุทููุจ ูู ุงููุงุชุฌ ุงููููุดุฃ.
   - ุฅุฐุง ุชู ููุงุฌูุฉ ุฑูุฒ `eos`ุ ูุชู ูุทุน ุงููุต ุงููููุดุฃ ุนูุฏ ุชูู ุงูููุทุฉ.

5. **ุงูุฅุฑุฌุงุน:**
   ุชูุฑุฌุน ุงูุฏุงูุฉ ูุฌููุนุฉ (tuple) ุชุญุชูู ุนูู ุงูุฑููุฒ ุงููููุฏุฉุ ูุฅุฐุง ูุงูุช `logprobs` ุชุณุงูู `True`ุ ูุฅููุง ุชูุฑุฌุน ุฃูุถูุง ุงูููุบุงุฑูุชูุงุช ุงูุงุญุชูุงููุฉ (log-probabilities) ููุฑููุฒ ุงููููุฏุฉ.

ูุฐู ุงูุทุฑููุฉ ุชููุฏ ุงููุต ูู ุฎูุงู ุงูุชูุจุค ุงูุชูุฑุงุฑู ููุฑููุฒ ุจูุงุกู ุนูู ุงูุณูุงู ุงูููุฏู ูู ุฎูุงู ุงููุทุงูุจุฉ ูุงูุฑููุฒ ุงูุชู ุชู ุฅูุดุงุคูุง ูุณุจููุง. ุชุณุชุฎุฏู ูุนููุงุช ุงูุชูููุฏ ุงููุญุฏุฏุฉ ููุชุญูู ูู ุงูุนุดูุงุฆูุฉ ูุงูุชููุน ูููุต ุงููููุฏ. ุชู ุชุตููู ูุฐู ุงูุทุฑููุฉ ูุงุณุชุฎุฏุงููุง ูุน ุจููุฉ ูููุฐุฌูุฉ ูุญุฏุฏุฉ ูููุนูุฏูููุ ุญูุซ ุชุนุชูุฏ ุนูู ุฎุตุงุฆุตูุง ูุทุฑููุง ูุชูููุฏ ุงููุต.

---