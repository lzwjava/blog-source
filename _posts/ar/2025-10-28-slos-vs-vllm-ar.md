---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: مقارنة ميزات SLOs-Serve مقابل vLLM
translated: true
type: note
---

### المقارنة: SLOs-Serve مقابل vLLM

يمتد SLOs-Serve على vLLM من خلال دمجه كمحرك تجميع أساسي مع إضافة طبقات لضمانات متعددة لأهداف مستوى الخدمة (SLO)، مما يجعله أكثر ملاءمة لبيئات الإنتاج ذات أعباء العمل المتنوعة والحساسة للزمن. يركز vLLM بشكل أساسي على الاستدلال عالي الإنتاجية لسيناريوهات SLO مفردة أو تعظيم الإنتاجية، باستخدام تقنيات مثل PagedAttention لكفاءة الذاكرة. فيما يلي مقارنة منظمة بناءً على الجوانب الرئيسية من ورقة SLOs-Serve وتصميم vLLM.

| الجانب                  | SLOs-Serve                                                                 | vLLM                                                                 |
|-------------------------|----------------------------------------------------------------------------|----------------------------------------------------------------------|
| **التركيز الأساسي**      | خدمة متعددة لأهداف مستوى الخدمة (SLO) لتطبيقات نماذج اللغة كبيرة الحجم متعددة المراحل (مثل: TTFT ضيق لمرحلة التعبئة المسبقة في الاستدلال، TPOT ضيق لمرحلة فك التشفير في البرمجة). يتعامل مع أعباء العمل المختلطة والمتفجرة بضمانات محددة لكل مرحلة. | التجميع عالي الإنتاجية لفك التشفير المستمر، مُحسَّن لأعباء العمل المقيدة بالذاكرة عبر PagedAttention. يفترض أهداف مستوى خدمة موحدة أو يُعطي الأولوية للإنتاجية الإجمالية. |
| **معالجة أهداف مستوى الخدمة (SLO)**       | دعم صريح متعدد لأهداف مستوى الخدمة: لكل مرحلة (التعبئة المسبقة/فك التشفير) ولكل تطبيق (مثل: 50 مللي ثانية TPOT للبرمجة مقابل 100 مللي ثانية للدردشة). يستخدم تحكم قبول مرن لرفض/تأجيل الطلبات المنتهكة. | لا يوجد دعم أصلي متعدد لأهداف مستوى الخدمة؛ يعتمد على إعدادات ثابتة (مثل: الحد الأقصى لحجم الدفعة). انتهاكات أهداف مستوى الخدمة شائعة تحت التنافس (مثل: ارتفاع زمن الوصول لأكثر من الضعف أثناء التدفقات المفاجئة). |
| **المجدول**          | قائم على البرمجة الديناميكية: يحسن ميزانيات التعبئة المسبقة، وأحجام الدُفعات، وأطوال التخمين لكل فئة من أهداف مستوى الخدمة. يتنبأ بزمن التنفيذ باستخدام نموذج Roofline (بدقة R² > 0.8). | مجدول التجميع المستمر: يحزم الطلبات بشكل جشع في دفعات ديناميكية، مركزًا على أعباء العمل الثقيلة بفك التشفير. لا يوجد تخطيط واعٍ بأهداف مستوى الخدمة. |
| **تحسين التعبئة المسبقة**| تعبئة مسبقة مجزأة مع تخمين تكيفي (1-10 وحدات نصية لكل SLO). يخصص "ميزانية التعبئة المسبقة" لتحقيق التوازن مع فك التشفير. | تعبئة مسبقة لمرة واحدة لكل طلب؛ يدعم التجزئة ولكن بدون تكيف مع أهداف مستوى الخدمة. عرضة لانسداد رأس الخط في الأحمال المختلطة. |
| **تحسين فك التشفير**| تكيف حجم الدفعة مع أهداف مستوى الخدمة (حتى 512+ وحدة نصية) وفك التشفير التخميني المصمم خصيصًا لأهداف TPOT. | فك تشفير مستمر بكفاءة مع تجميع استباقي؛ إنتاجية عالية (مثل: 10-20x أسرع من Hugging Face) لكنه يتجاهل المواعيد النهائية لكل طلب. |
| **إدارة الموارد**| توجيه متعدد النسخ المتماثلة عبر Ray؛ مرونة للتدفقات المفاجئة مع طوابير أفضل جهد وايقاف الأسبقية. يتعامل مع الإعدادات المجزأة. | عقدة مفردة أو موزعة أساسية (عبر دمج Ray)؛ لا يوجد توجيه استباقي أو تخصيص مُعطى الأولوية لأهداف مستوى الخدمة. |
| **الإنتاجية والسعة**| مكسب متوسط في السعة يبلغ 2.2× مقارنة بـ vLLM (المتوسط الهندسي عبر 6 سيناريوهات: روبوت الدردشة، البرمجة، إلخ). على سبيل المثال، 2.4× في تدفقات الاستدلال. تدرج فائق الخطية مع النسخ المتماثلة. | خط الأساس للإنتاجية: أسرع حتى 24x من البدائل في آثار فك التشفير الثقيلة، لكنه يتدهور تحت قيود أهداف مستوى الخدمة (مثل: فقدان 50% من السعة في أعباء العمل المختلطة). |
| **النفقات العامة**           | <10 مللي ثانية لكل جدولة؛ ضئيلة بسبب كفاءة البرمجة الديناميكية (O(n) حالات).             | منخفضة (<1 مللي ثانية للتجميع)؛ لكنه يفتقر إلى منطق أهداف مستوى الخدمة، لذلك لا توجد نفقات عامة مضافة.      |
| **حالات الاستخدام**          | تطبيقات إنتاجية ذات اتفاقيات مستوى خدمة صارمة: وكلاء استدعاء الأدوات، سلاسل استدلالية، حركة مرور متفجرة (مثل: آثار Azure). | إنتاجية البحث/التطوير: خدمة بسيطة، توليد سياق طويل، أحمال موحدة. |
| **القيود**        | يفترض معرفة أهداف مستوى الخدمة/المواعيد النهائية؛ هناك حاجة لامتدادات مستقبلية للأطوال غير المعروفة. مبني على vLLM، لذا يرث نقاط قوته في فك التشفير. | يواجه صعوبات مع المراحل المتعددة/أهداف مستوى الخدمة المتغيرة؛ زمن وصول عالي في الذيل في إعدادات GPU المشتركة (p99 >2x الهدف في التقييمات). |
| **التنفيذ**     | نموذج أولي مفتوح المصدر على vLLM + Ray؛ يدعم نماذج OPT/ToolLlama على وحدات معالجة الرسومات A100/H100. | مفتوح المصدر ناضج (GitHub)؛ معتمد على نطاق واسع، يدعم 100+ نموذج، نشر سهل. |

باختصار، يتفوق vLLM في الكفاءة الخام للخدمة الموجهة نحو الإنتاجية ولكنه يقصر في الامتثال لأهداف مستوى الخدمة في السيناريوهات المعقدة والحقيقية — مما يؤدي إلى تحقيق مكاسب 2x+ في SLOs-Serve عبر التحسينات المستهدفة. إذا كان عبء العمل الخاص بك يهدف purely إلى تعظيم الإنتاجية دون ضمانات للزمن، يبقى vLLM أبسط وأسرع في النشر.

[SLOs-Serve: Optimized Serving of Multi-SLO LLMs](https://arxiv.org/abs/2504.08784)  
[vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention](https://arxiv.org/abs/2309.06180)