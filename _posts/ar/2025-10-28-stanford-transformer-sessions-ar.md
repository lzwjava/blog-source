---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: أبرز جلسات المحولات في ستانفورد CS25
translated: true
type: note
---

### ستانفورد CS25: المحولات المتحدة – الجلسات الموصى بها

ستانفورد CS25: المحولات المتحدة هي دورة دراسية على شكل ندوة (الآن في نسختها الخامسة V5 اعتبارًا من 2025) تتعمق في بنى المحولات (Transformers) وتطبيقاتها عبر معالجة اللغات الطبيعية (NLP)، الرؤية الحاسوبية (CV)، التعلم المعزز (RL)، والمزيد. تضم الدورة محاضرات ضيف من باحثين رائدين مثل أندريج كارباثي، جيفري هينتون، وآشيش فاسواني. التسجيلات الكاملة متاحة على يوتيوب في قائمة تشغيل مجمعة، مما يجعلها في متناول الجميع للدراسة الذاتية. بينما جميع الجلسات عالية الجودة (إنها واحدة من "أكثر" الدورات شعبية في ستانفورد)، إلا أن بعضها يتميز بناءً على خبرة المتحدث، ملاحظات المشاهدين، والإشارات إليها في المراجعات لعُمقها، حداثتها، أو قيمتها التأسيسية.

إليك أفضل التوصيات الخاصة بي لأفضل الجلسات، مُرتبة بالأولوية للمبتدئين إلى المتعلمين المتقدمين. لقد أدرجت سبب أهمية مشاهدتها، الطول التقريبي، وروابط مباشرة:

1.  **مقدمة في المحولات (Transformers)** (أندريج كارباثي، ~1 ساعة)
    بداية أساسية يجب مشاهدتها—يقوم كارباثي بشرح ميكانيكا المحولات بطريقة بديهية، مع رسوم توضيحية ومقتطفات برمجية. مثالية إذا كنت جديدًا على الموضوع؛ يشار إليها غالبًا على أنها "أفضل مقدمة على الإطلاق" في ملاحظات الدراسة والمنتديات.
    [شاهد على يوتيوب](https://www.youtube.com/watch?v=zjkBMFhNj_g) (من V2)

2.  **توقف عن القلق وأحب المحول (Transformer)** (آشيش فاسواني، ~45 دقيقة)
    مقدمة من مؤلف الورقة البحثية الأصلية "الانتباه هو كل ما تحتاجه". يشارك قصصًا داخلية حول خيارات التصميم والاتجاهات المستقبلية—خالدة وملهمة لأي شخص في مجال الذكاء الاصطناعي. موصى بها بشدة لسياقها التاريخي.
    [شاهد على يوتيوب](https://www.youtube.com/watch?v=wjZofJX0v4M) (من V3)

3.  **التسلسلات الهرمية للكل-والجزء في الشبكة العصبية** (جيفري هينتون، ~50 دقيقة)
    يستكشف هينتون ("عراب الذكاء الاصطناعي") التمثيلات الهرمية في المحولات، وربطها بخوارزميات forward-forward. رؤى عميقة حول التوسع والذكاء الاصطناعي المستوحى من البيولوجيا؛ تشيد مناقشات Reddit بأفكارها المثيرة للتفكير.
    [شاهد على يوتيوب](https://www.youtube.com/watch?v=0zqYflM6H4w) (من V4)

4.  **العوامل العامة في عوالم مفتوحة النهاية** (جيم فان، NVIDIA، ~1 ساعة)
    تركز على بناء وكلاء ذكاء اصطناعي متعددي الاستخدامات باستخدام المحولات للروبوتات والألعاب. مشوقة جدًا مع عروض عملية؛ وصفها مستخدم على Reddit بأنها "رائعة" لنصائحها العملية في بناء الوكلاء في V5. رائعة لمحبي التعلم المعزز (RL).
    [شاهد على يوتيوب](https://www.youtube.com/watch?v=0zqYflM6H4w) انتظر، الرابط خاطئ—الصحيح هو: [شاهد على يوتيوب](https://www.youtube.com/watch?v=Serj6KSLy-M) (من V5)

5.  **الحدس حول النماذج اللغوية (LMs)، تشكيل مستقبل الذكاء الاصطناعي** (جايسون واي و هيونغ وون تشونغ، OpenAI، ~50 دقيقة)
    تتناول قوانين التوسع (scaling laws) والقدرات الناشئة للنماذج اللغوية الكبيرة. مليئة بحكايات من OpenAI؛ ممتازة لفهم سبب أداء نماذج مثل GPT بهذه الكفاءة. يتم الاستشهاد بها بشكل متكرر في المراجعات الحديثة على أنها تتطلع إلى المستقبل.
    [شاهد على يوتيوب](https://www.youtube.com/watch?v=3Z3g7PsylzQ) (من V4)

إذا كان وقتك محدودًا، ابدأ بمقدمة كارباثي ومحاضرة فاسواني—فهي تغطي الأساسيات. للحصول على أحدث محتوى من V5 (ربيع 2025)، تحقق من جلسة النظرة العامة أولاً. السلسلة الكاملة مجانية وشبيهة بالندوات، لذا فإن الجلسات تبني على بعضها البعض ولكن يمكن مشاهدتها بشكل منفرد.

**المراجع:**
-   [صفحة التسجيلات الرسمية لـ CS25](https://web.stanford.edu/class/cs25/recordings/)
-   [قائمة تشغيل يوتيوب الكاملة](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM)
-   [مناقشة Reddit حول محاضرات V5 للوكلاء الذكيين](https://www.reddit.com/r/stanford/comments/1mzhxpy/seeking_resources_for_stanford_cs25_v5_lectures/)
-   [منشور على X يوصي بأحدث المحاضرات](https://twitter.com/omarsar0/status/1756350236744663519)
-   [ملاحظات دراسة على Medium حول جلسة المقدمة](https://medium.com/@YanAIx/united-transformer-introduction-to-transformers-2a94eb3cc5b9)