---
audio: false
generated: true
lang: ar
layout: post
title: استخدام Apache Kafka في Java
translated: true
---

استخدام Apache Kafka في Java يتضمن إعداد عميل Kafka في تطبيق Java الخاص بك لإنتاج واستهلاك الرسائل. Kafka هو منصة تيار توزيعية، وكتب العميل الخاصة به تجعل من السهل التكامل. أدناه، سأرشدك عبر الخطوات الأساسية للحصول على البدء.

أولاً، عليك إعداد بيئتك. تأكد من أن Kafka مرفوع ومشغل على نظامك أو خادم. يمكنك تحميله من موقع Apache Kafka الرسمي واستخدامه لتشغيل ZooKeeper وKafka باستخدام النصات الموفرة. لأغراض البساطة، سأفترض أنك تعمل على Kafka محليًا مع الإعدادات الافتراضية (مثل `localhost:9092` كخادم البدء).

بعد ذلك، أضف اعتماد العميل Kafka إلى مشروعك Java. إذا كنت تستخدم Maven، أضف هذا إلى ملف `pom.xml` الخاص بك:

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>3.6.0</version> <!-- استخدم أحدث الإصدار -->
</dependency>
```

الآن، دعونا نكتب بعض الكود. سأريك كيف يمكنك إنشاء منتج وعميل بسيطين.

### مثال منتج Kafka
يرسل المنتج الرسائل إلى موضوع Kafka. إليك مثال أساسي:

```java
import org.apache.kafka.clients.producer.*;
import java.util.Properties;

public class SimpleProducer {
    public static void main(String[] args) {
        // إعداد خواص المنتج
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092"); // عنوان خادم Kafka
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // إنشاء مثال منتج
        try (Producer<String, String> producer = new KafkaProducer<>(props)) {
            // إرسال رسالة إلى موضوع يسمى "test-topic"
            String topic = "test-topic";
            for (int i = 0; i < 10; i++) {
                String key = "key" + i;
                String value = "Hello, Kafka " + i;
                ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);

                producer.send(record, (metadata, exception) -> {
                    if (exception == null) {
                        System.out.println("Sent message: " + value + " to partition " + metadata.partition());
                    } else {
                        exception.printStackTrace();
                    }
                });
            }
        }
    }
}
```

في هذا الكود:
- `bootstrap.servers` يحدد أين يعمل Kafka.
- المسلسلات تعرّف كيف يتم تحويل المفاتيح والقيم (كلاهما نص هنا) إلى بايتات.
- `ProducerRecord` يمثل الرسالة، و`send()` يرسلها بشكل غير متزامن مع استدعاء للرد على النجاح أو الفشل.

### مثال مستهلك Kafka
يشترك المستهلك في موضوع ويقرأ الرسائل. إليك مثال:

```java
import org.apache.kafka.clients.consumer.*;
import java.util.Collections;
import java.util.Properties;

public class SimpleConsumer {
    public static void main(String[] args) {
        // إعداد خواص المستهلك
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "test-group"); // معرف مجموعة المستهلك
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("auto.offset.reset", "earliest"); // ابدأ من بداية الموضوع

        // إنشاء مثال مستهلك
        try (KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {
            // الاشتراك في الموضوع
            consumer.subscribe(Collections.singletonList("test-topic"));

            // استعلام الرسائل
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(1000); // وقت الانتظار في الملي ثانية
                for (ConsumerRecord<String, String> record : records) {
                    System.out.printf("Received: key=%s, value=%s, partition=%d, offset=%d%n",
                            record.key(), record.value(), record.partition(), record.offset());
                }
            }
        }
    }
}
```

هنا:
- `group.id` يحدد مجموعة المستهلك للتنسيق.
- المفسرات تعيد تحويل البيانات البايتية إلى نص.
- `poll()` يستخرج الرسائل في حلقة، و`auto.offset.reset` يضمن أن تبدأ من الرسالة الأولى إذا لم يتم الالتزام بأي مرجع.

### تشغيل الكود
1. **إطلاق Kafka**: تأكد من تشغيل ZooKeeper وKafka (مثل `bin/zookeeper-server-start.sh config/zookeeper.properties` و`bin/kafka-server-start.sh config/server.properties` على أنظمة مشابهة لUnix).
2. **إنشاء موضوع**: استخدم أداة سطر الأوامر Kafka لإنشاء `test-topic` إذا لم يكن موجودًا: `bin/kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1`.
3. **تنفيد المنتج**: تنفذ فئة `SimpleProducer` لإرسال الرسائل.
4. **تنفيد المستهلك**: تنفذ فئة `SimpleConsumer` لرؤية الرسائل التي يتم استهلاكها.

### نصائح
- **معالجة الأخطاء**: أضف كتلة try-catch أو تسجيلات للكود الإنتاجي.
- **الإعدادات**: قم بتعديل خواص مثل `acks` (لضمان إنتاجية المنتج) أو `max.poll.records` (لحجم مجموعة المستهلك) بناءً على احتياجاتك.
- **المكتبات**: للتطبيقات المعقدة، فكر في استخدام Spring Kafka، الذي يسهل الإعداد والاستخدام.

هذا هو إعداد أساسي للحصول على البدء. أخبرني إذا كنت تريد الغوص في ميزات محددة مثل تقسيم البيانات، معالجة الأخطاء، أو التكامل مع تطبيق أكبر!