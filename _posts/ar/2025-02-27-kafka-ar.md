---
audio: false
generated: true
lang: ar
layout: post
title: استخدام أباتشي كافكا في جافا
translated: true
type: note
---

يتضمن استخدام Apache Kafka في Java إعداد عميل Kafka في تطبيق Java الخاص بك لإنتاج واستهلاك الرسائل. Kafka هي منصة بث موزعة، وتجعل مكتبات العميل Java من السهل دمجها. أدناه، سأرشدك عبر الخطوات الأساسية للبدء.

أولاً، ستحتاج إلى إعداد بيئتك. تأكد من تثبيت Kafka وتشغيله على نظامك أو على خادم. يمكنك تنزيله من موقع Apache Kafka الرسمي وبدء خادم ZooKeeper وخادم Kafka باستخدام البرامج النصية المقدمة. للتبسيط، سأفترض أنك تقوم بتشغيل Kafka محليًا بالإعدادات الافتراضية (مثل `localhost:9092` كخادم bootstrap).

بعد ذلك، أضف تبعية عميل Kafka إلى مشروع Java الخاص بك. إذا كنت تستخدم Maven، فقم بتضمين هذا في ملف `pom.xml` الخاص بك:

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>3.6.0</version> <!-- استخدم أحدث إصدار -->
</dependency>
```

الآن، دعنا نكتب بعض التعليمات البرمجية. سأوضح لك كيفية إنشاء منتج ومستهلك بسيط.

### مثال منتج Kafka
يرسل المنتج الرسائل إلى موضوع Kafka. إليك مثال أساسي:

```java
import org.apache.kafka.clients.producer.*;
import java.util.Properties;

public class SimpleProducer {
    public static void main(String[] args) {
        // تكوين خصائص المنتج
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092"); // عنوان خادم Kafka
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // إنشاء مثيل منتج
        try (Producer<String, String> producer = new KafkaProducer<>(props)) {
            // إرسال رسالة إلى موضوع يسمى "test-topic"
            String topic = "test-topic";
            for (int i = 0; i < 10; i++) {
                String key = "key" + i;
                String value = "Hello, Kafka " + i;
                ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);

                producer.send(record, (metadata, exception) -> {
                    if (exception == null) {
                        System.out.println("Sent message: " + value + " to partition " + metadata.partition());
                    } else {
                        exception.printStackTrace();
                    }
                });
            }
        }
    }
}
```

في هذا الكود:
- `bootstrap.servers` يحدد مكان تشغيل Kafka.
- تقوم المُسلسلات بتحديد كيفية تحويل المفاتيح والقيم (كلاهما سلاسل نصية هنا) إلى بايت.
- يمثل `ProducerRecord` الرسالة، ويقوم `send()` بإرسالها بشكل غير متزامن مع رد اتصال للتعامل مع النجاح أو الفشل.

### مثال مستهلك Kafka
يشترك المستهلك في موضوع ويقرأ الرسائل. إليك مثال:

```java
import org.apache.kafka.clients.consumer.*;
import java.util.Collections;
import java.util.Properties;

public class SimpleConsumer {
    public static void main(String[] args) {
        // تكوين خصائص المستهلك
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "test-group"); // معرف مجموعة المستهلك
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("auto.offset.reset", "earliest"); // ابدأ من بداية الموضوع

        // إنشاء مثيل مستهلك
        try (KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {
            // الاشتراك في الموضوع
            consumer.subscribe(Collections.singletonList("test-topic"));

            // جلب الرسائل
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(1000); // timeout بالمللي ثانية
                for (ConsumerRecord<String, String> record : records) {
                    System.out.printf("Received: key=%s, value=%s, partition=%d, offset=%d%n",
                            record.key(), record.value(), record.partition(), record.offset());
                }
            }
        }
    }
}
```

هنا:
- `group.id` يحدد مجموعة المستهلك للتنسيق.
- تقوم أجهزة إلغاء التسلسل بتحويل بيانات البايت مرة أخرى إلى سلاسل.
- يقوم `poll()` بجلب الرسائل في حلقة، ويضمن `auto.offset.reset` أنك تبدأ من أقدم رسالة إذا لم يتم حفظ إزاحة.

### تشغيل الكود
1. **بدء Kafka**: تأكد من تشغيل ZooKeeper و Kafka (مثل `bin/zookeeper-server-start.sh config/zookeeper.properties` و `bin/kafka-server-start.sh config/server.properties` على أنظمة تشبه Unix).
2. **إنشاء موضوع**: استخدم أداة سطر أوامر Kafka لإنشاء `test-topic` إذا لم يكن موجودًا: `bin/kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1`.
3. **تشغيل المنتج**: نفذ فئة `SimpleProducer` لإرسال الرسائل.
4. **تشغيل المستهلك**: شغل فئة `SimpleConsumer` لرؤية الرسائل التي يتم استهلاكها.

### نصائح
- **معالجة الأخطاء**: أضف كتل try-catch أو التسجيل لكود الإنتاج.
- **التكوين**: اضبط الخصائص مثل `acks` (لموثوقية المنتج) أو `max.poll.records` (لحجم دفعة المستهلك) بناءً على احتياجاتك.
- **المكتبات**: للتطبيقات الأكثر تعقيدًا، فكر في استخدام Spring Kafka، الذي يبسط التكوين والاستخدام.

هذا إعداد أساسي لتبدأ به. دعني أعرف إذا كنت تريد التعمق في ميزات محددة مثل التقسيم، أو معالجة الأخطاء، أو الدمج مع تطبيق أكبر!