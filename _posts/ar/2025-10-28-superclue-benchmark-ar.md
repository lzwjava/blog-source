---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: 'سوبركلو: معيار اللغة الصينية للنماذج اللغوية الكبيرة'
translated: true
type: note
---

سوبرCLUE هي مجموعة معايير تقييم شاملة مصممة لتقييم النماذج اللغوية الكبيرة الصينية (LLMs). تبني على معيار CLUE الأصلي (تقييم الفهم اللغوي الصيني)، وتوسعه لتقييم القدرات المتقدمة في النماذج اللغوية الكبيرة بدلاً من النماذج الأصغر فقط. تم تطوير سوبرCLUE من قبل فريق CLUEbenchmark—وهو جهد تعاوني يضم باحثين من مؤسسات مثل جامعة تسينغهوا وشركات في النظام البيئي للذكاء الاصطناعي الصيني—وتم إطلاقه لأول مرة في عام 2023 لمعالجة الفجوات في تقييم النماذج اللغوية الكبيرة الصينية وفقًا للمعايير الدولية.

### الميزات الرئيسية
- **مجالات التركيز**: تقيّم النماذج عبر أربعة محاور رئيسية:
  - الفهم اللغوي والتوليد (مثل: استيعاب القراءة، التلخيص).
  - المهارات والمعرفة المهنية (مثل: التفكير الرياضي، البرمجة).
  - الذكاء الوكيل (مثل: استخدام الأدوات، التخطيط).
  - السلامة (مثل: كشف التحيز، الامتثال الأخلاقي).
- **الهيكل**: مقسم إلى 12 مهمة أساسية، مع مجموعات بيانات مثل SuperCLUE-Math6 للمشكلات الرياضية متعددة الخطوات.
- **الغرض**: يساعد في تتبع التقدم في مجال الذكاء الاصطناعي الصيني، مسلطًا الضوء على كل من نقاط القوة (مثل التعامل مع الفروق الثقافية الدقيقة) والفجوات مقارنة بالنماذج العالمية مثل سلسلة GPT.
- **التحديثات**: اعتبارًا من منتصف عام 2025، يتم استخدامه للتقييمات الدورية، حيث تظهر لوائح المتصدرين أن النماذج الصينية مثل Qwen و GLM تقوم بسد الفجوة مع النماذج الدولية.

المعيار مفتوح المصدر ويتم صيانته بنشاط، حيث يتم مشاركة نتائج التقييمات غالبًا عبر أوراق arXiv ومستودع GitHub.

[SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark](https://arxiv.org/abs/2307.15020)  
[SuperCLUE GitHub Repository](https://github.com/CLUEbenchmark/SuperCLUE)  
[ChinAI: SuperCLUE Benchmarks —2025 Midyear Check-in](https://chinai.substack.com/p/chinai-324-superclue-large-model)