---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: أسباب مرحلة الثبات في التدريب والحلول
translated: true
type: note
---

سجل التدريب الذي نشرته يُظهر **جمودًا حادًا كلاسيكيًا** في تشغيل nanoGPT صغير النطاق على بيانات FineWeb-edu. ينخفض فقدان التحقق بشكل جيد في البداية (من ~10.9 → ~3.57 حول التكرار 14 ألف)، ولكن بعد ذلك يستوي تمامًا بل ويبدأ في **الارتفاع ببطء شديد** بعد ~13-14 ألف تكرار.

إليك الأسباب الحقيقية التي جعلت نموذجك يتوقف عن التحسن (مرتبة حسب الأهمية لهذا الإعداد المحدد):

### 1. أنت تبالغ في التخصيص لملف Parquet واحد
- اسم التشغيل الخاص بك: `125M-single-parquet-4070`
- أنت تدرب نموذجًا بحجم 40M–125M (يشير السجل إلى 40.56M معامل، على الأرجح تكوين GPT-2 الصغير الأصلي) على **ملف FineWeb parquet واحد فقط** (على الأرجح 10–15 جيجابايت → ~3–4 مليار رمز كحد أقصى، ولكن على الأرجح أقل بكثير بعد التصفية).
- بحلول التكرار 14000 مع batch_size=16، grad_accum=32، block_size=1024 تكون قد شاهدت بالفعل:
  14000 تكرار × 524288 رمز/تكرار ≈ **7.3 مليار رمز**
- هذا يعني أنك قد أكملت بالفعل **2–3 عصور كاملة** على نفس البيانات بالضبط.
- FineWeb-edu عالي الجودة ولكن لا يزال يحتوي على الكثير من النسخ شبه المكررة والنماذج القياسية. بعد 1.5–2 عصر على نفس الملف(ات)، سيقوم النموذج بحجم 40M–125M بحفظ كل شيء مفيد تقريبًا ويستوي الفقدان بشدة.

### 2. معدل التعلم أصبح مرتفعًا جدًا بعد الجمود
- أنت تستخدم `learning_rate = 1e-3`، مع تضاؤل جيب التمام إلى `min_lr = 1e-4` على مدى 20000 تكرار.
- عند التكرار 14000 لا يزال معدل التعلم ~2.5e-4 (تضاؤل جيب التمام بطيء في البداية).
- بمجرد أن يتعلم النموذج كل ما تقدمه البيانات، فإن الحفاظ على معدل التعلم بمئات الوحدات الجزئية يمنعه من الضبط الدقيق أكثر ويبدأ في الإضرار بالتعميم → يرتفع فقدان التحقق ببطء.

### 3. عدم تطابق حجم النموذج مع تنوع البيانات
نموذج بحجم 125M (أو حتى 40M الذي قمت بتهيئته فعليًا) على ملف parquet واحد يشبه إعطاء طالب جامعي كتابًا دراسيًا واحدًا فقط وطلب منه مواصلة دراسته لسنوات. بعد فترة يستطيع تلاوته بشكل مثالي، ولكن أداء وقت الاختبار على النص الجديد يتوقف عن التحسن بل ويتدهور قليلاً بسبب النسيان الكارثي للأنماط السابقة.

### 4. لا يوجد تنظيم قوي بما يكفي
- dropout = 0.1 مقبول، لكنه ليس كافيًا عندما تبالغ في التخصيص بهذه القوة
- weight_decay = 0.1 قياسي، لكنه لا يزال غير كافٍ لعصرين أو أكثر على بيانات صغيرة
- لا يوجد قص للتدرج (القيمة الافتراضية في nanoGPT هي 1.0، ولكن أحيانًا يضبط المستخدمون 0.5 أو أقل للبيانات الصغيرة)

### 5. الرموز التي تمت رؤيتها مقابل التنوع الحقيقي
على الرغم من أنك رأيت أكثر من 7 مليارات رمز، إلا أن **التنوع الفعال** هو ربما 1–1.5 مليار رمز فريد عالي الجودة بعد إزالة التكرار والنماذج القياسية والعينات ذات درجة edu المنخفضة، إلخ. هذا ببساطة لا يكفي لنموذج 125M لمواصلة التحسن بعد فقدان ~3.5–3.6 على توزيع النص هذا.

### الأدلة من سجلك الخاص

| الخطوة | فقدان التحقق | تعليق                              |
|--------|----------|--------------------------------------|
| 0      | 10.87    | عشوائي                                       |
| 2000   | 4.03     | تقدم سريع                            |
| 5000   | 3.76     | لا يزال جيدًا                                 |
| 8000   | 3.65     | يتباطأ                                    |
| 11000  | 3.61     | شبه مستوي                                |
| 13500  | 3.57     | **أدنى مستوى مطلق**                        |
| 14500  | 3.569    | بدأ في الارتفاع مرة أخرى → علامة على المبالغة في التخصيص |

### ما يجب عليك فعله بدلاً من ذلك لتحقيق فقدان أقل فعليًا

1. استخدم بيانات أكثر بكثير
   - استخدم عينة FineWeb-edu الكاملة البالغة 100+ جيجابايت (أو 10–20 ملف parquet على الأقل)
   - أو قم بالبث من HuggingFace datasets مع أجزاء متعددة

2. درب لعصر واحد بالضبط (أو أقل قليلاً) على بيانات متنوعة
   - ~10B–15B رمز إجمالي هي النقطة المثلى لـ 125M على FineWeb-edu
   - نمط Llama-3/Phi-3: 15B رمز → ~3.0–3.2 فقدان تحقق لنماذج فئة 125M

3. اخفض معدل التعلم النهائي
   - استخدم `min_lr = 5e-5` أو `3e-5` (شائع في تشغيلات النماذج الصغيرة الحديثة)
   - أو انتقل إلى تضاؤل خطي + فترة تثبيت معدل تعلم صفري أطول

4. نموذج أكبر قليلاً أو حيل معمارية أفضل
   - nanoGPT الأصلي هو بنمط GPT-2 (بدون ALiBi، RoPE قديم، إلخ)
   - تصل النماذج الحديثة 125M (Qwen2-0.5B, Phi-3-mini, Llama-3 8B المصغرة) إلى ~2.8–3.0 على نفس البيانات بسبب SwiGLU, RMSNorm, rotary embeddings، إلخ.

### ملخص – لماذا استقر تشغيلك عند ~3.57 ولن ينخفض أبدًا

أنت تدرب نموذجًا بحجم 40–125M لعدة عصور على ملف FineWeb parquet واحد فقط (~بضعة مليارات رمز إجمالي). لقد قام النموذج بالفعل بحفظ كل شيء مفيد بحلول ~13 ألف تكرار. التدريب المستمر مع معدل تعلم لا يزال مرتفعًا يقوم فقط بخلط الأوزان → جمود + تدهور طفيف بسبب المبالغة في التخصيص.

هذا هو الخطأ رقم واحد الذي يقع فيه الأشخاص عندما يجربون nanoGPT على FineWeb لأول مرة: "سأستخدم ملفًا واحدًا فقط للاختبار" → ينتهي بهم الأمر بهذا المنحنى للفقدان بالضبط.

الإصلاح: إما (أ) استخدام 10–50 ضعفًا من البيانات والتدرب لمدة ~1 عصر إجمالي، أو (ب) تقبل أن ~3.55–3.6 هو الحد الأدنى المطلق لهذا المزيج من النموذج والبيانات وتوقف عن التدريب.

إذا كنت تريد تشغيلاً يصل فعليًا إلى فقدان ~3.0–3.2 مع كود بنمط nanoGPT، فأنت تحتاج على الأقل إلى عينة FineWeb-edu الكاملة البالغة 100 جيجابايت (أو FineWeb-Edu 2.0 الأحدث) والتدرب لما لا يزيد عن ~15 مليار رمز.