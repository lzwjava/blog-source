---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: التسرب وأفضل ك يخدمان أغراضًا مختلفة
translated: true
type: note
---

### فهم أخذ العينات من أعلى قيم K مقابل الإسقاط (Dropout) في النماذج اللغوية الكبيرة

دعنا نشرح هذا خطوة بخطوة. سؤالك يخلط بين مفهومين—أخذ العينات من أعلى قيم K (المستخدم أثناء توليد المخرجات) والإسقاط (المستخدم أثناء تدريب النموذج)—ويتساءل عن سبب الحاجة إلى الإسقاط إذا كان أخذ العينات من أعلى قيم K يقدم بالفعل عنصرًا عشوائيًا. في الواقع، لكل منهما غرض مختلف تمامًا ويستخدم في مراحل مختلفة من دورة حياة النموذج. سأشرح "السبب" وراء استخدام الإسقاط، وتاريخه، وأهميته (أو عدمها) في النماذج اللغوية الكبيرة الحديثة مثل نماذج المحولات Transformer ونماذج GPT.

#### 1. **أخذ العينات من أعلى قيم K: العشوائية في توليد المخرجات (مرحلة الاستدلال)**
   - في النماذج اللغوية الكبيرة، عند توليد النص (على سبيل المثال، التنبؤ بالرمز التالي)، ينتج النموذج توزيعًا احتماليًا لجميع الرموز الممكنة في مفرداته.
   - تعمل آلية أخذ العينات من أعلى قيم K على النحو التالي: تقوم بترتيب الرموز حسب درجات احتمالاتها، والاحتفاظ فقط بأعلى k رمز الأكثر احتمالية (على سبيل المثال، k=50)، ثم أخذ عينة عشوائية من بين خيارات الـ k هذه بناءً على احتمالاتها. يضيف هذا العشوائية إلى المخرجات لتجنب النتائج الحتمية والمتكررة أو المملة—مثل اختيار الرمز الأكثر احتمالية دائمًا، مما قد يؤدي إلى حلقات مفرغة أو نص رتيب.
   - الهدف هنا هو **تنوع وإبداع الاستجابات المُولَّدة**. لا يتعلق الأمر بتدريب النموذج، بل يتعلق بكيفية استخدام النموذج المدرب بالفعل لإنتاج مخرجات متنوعة. بدونها، قد تولد النماذج اللغوية الكبيرة تسلسلات متوقعة ومتكررة.
   - تحدث هذه العشوائية في **وقت الاستدلال** (عندما يتم نشر النموذج والرد على الاستعلامات)، وليس أثناء التدريب.

#### 2. **الإسقاط (Dropout): منع التكيف المفرط أثناء التدريب**
   - الإسقاط هو أسلوب تنظيمي تم ابتكاره لجعل الشبكات العصبية أكثر متانة وأقل عرضة للتكيف المفرط. يحدث التكيف المفرط عندما يحفظ النموذج بيانات التدريب بشكل جيد للغاية (بما في ذلك الضوضاء أو الأنماط غير ذات الصلة) ولكن أداؤه يكون ضعيفًا على البيانات الجديدة غير المرئية.
   - آلية العمل: أثناء التدريب، يقوم الإسقاط "بإسقاط" (أي جعل قيمتها صفر) جزء عشوائي من الخلايا العصبية (أو التفعيلات) في طبقة معينة خلال كل مرورة أمامية. هذا يجبر الشبكة على تعلم تمثيلات موزعة زائدة عن الحاجة—بمعنى أنه لا توجد خلية عصبية واحدة تهيمن، ولا يمكن للنموذج الاعتماد على مجموعات محددة من الخلايا العصبية المتكيفة معًا. في وقت الاستدلال، يتم إيقاف تشغيل الإسقاط، ويتم استخدام الشبكة الكاملة (غالبًا مع تحجيم الأوزان للتعويض).
   - العشوائية في الإسقاط مؤقتة وتحدث فقط أثناء التدريب؛ لا علاقة لها بتوليد مخرجات متنوعة بل تهدف إلى **بناء نموذج أكثر قابلية للتعميم**. يعمل هذا كما لو كنت تدرب مجموعة من الشبكات الفرعية ضمنيًا.
   - لماذا هذا مطلوب حتى مع وجود بيانات هائلة في النماذج اللغوية الكبيرة؟ النماذج الكبيرة ذات المليارات من المعاملات يمكنها仍然 أن تتكيف بشكل مفرط مع الأنماط الدقيقة، أو الحفظ عن ظهر قلب، أو التحيزات في بيانات التدريب. يساعد الإسقاط من خلال إدخال ضوضاء تشجع على تعلم أوسع.

#### 3. **لماذا لا يحل أخذ العينات من أعلى قيم K محل الإسقاط (لهما أغراض مختلفة)**
   - يضيف أخذ العينات من أعلى قيم K عشوائية **بعد التدريب** لجعل المخرجات أكثر تشويقًا أو شبيهة بالإنسان. لا يؤثر على كيفية تعلم النموذج أو قدرته على التعميم.
   - يضيف الإسقاط ضوضاء **أثناء التدريب** لتحسين قدرة النموذج على معالجة المدخلات الجديدة دون تكيف مفرط. بدون أساليب التنظيم مثل الإسقاط، حتى النماذج اللغوية الكبيرة يمكن أن تصبح هشة—متفوقة على بيانات التدريب ولكنها تفشل في الحالات الحدية.
   - هما مستقلان: يمكن أن يكون لديك نموذج مدرب باستخدام الإسقاط ويستخدم أخذ العينات من أعلى قيم K أثناء الاستدلال، أو نموذج بدون إسقاط ولا يزال يستخدم أخذ العينات من أعلى قيم K. العشوائية أثناء التدريب (الإسقاط) تجعل النموذج الأساسي أقوى، بينما تتحكم العشوائية أثناء الاستدلال (أخذ العينات من أعلى قيم K) في تنوع المخرجات.
   - إذا كنت مرتبكًا لأن كلاهما يتضمن "عشوائية"، ففكر في الأمر بهذه الطريقة: الإسقاط يشبه إبعاد اللاعبين بشكل عشوائي أثناء التدريب لجعل الفريق أكثر تنوعًا. أخذ العينات من أعلى قيم K يشبه الاختيار العشوائي من بين أفضل الهدافين أثناء المباراة لإبقاء الأمور مثيرة. الأول يبني الأساس؛ والثاني يصقل الأداء.

#### 4. **متى تم اختراع الإسقاط؟**
   - تم اقتراح الإسقاط لأول مرة في عام 2012 من قبل جيفري هينتون وفريقه في جامعة تورنتو. اكتسب شهرة من خلال محاضرة لهينتون في 2012 وورقة بحثية لاحقة في 2014 لنيتيش سريفاستافا وآخرون، قامت بإضفاء الطابع الرسمي عليها تحت عنوان "الإسقاط: طريقة بسيطة لمنع التكيف المفرط للشبكات العصبية".
   - كان ذلك إنجازًا بارزًا للشبكات العصبية العميقة في ذلك الوقت، خاصة في رؤية الكمبيوتر (على سبيل المثال، استخدم AlexNet في 2012 نوعًا مختلفًا منه)، وسرعان ما أصبح أداة قياسية في أطر العمل مثل TensorFlow وPyTorch.

#### 5. **هل لا يزال الإسقاط مطلوبًا في عصر النماذج اللغوية الكبيرة/المحولات/GPT؟**
   - **في الشبكات العصبية التقليدية (ما قبل 2017):** نعم، كان حاسمًا لمنع التكيف المفرط في النماذج الأصغر ذات البيانات المحدودة، مثل الشبكات العصبية الالتفافية CNN للتعرف على الصور أو الشبكات العصبية المتكررة RNN المبكرة للتسلسلات.
   - **في نماذج المحولات والنماذج اللغوية الكبيرة:** لا يتم استخدامه دائمًا، لكنه لا يزال ذا صلة في كثير من الحالات. تضمنت ورقة بحث المحولات الأصلية (2017، "الانتباه هو كل ما تحتاجه") بوضوح الإسقاط (بنسبة 0.1) مطبقًا على مخرجات الطبقات الفرعية، والدمج، والتشفير الموضعي لتنظيم النموذج.
   - **نماذج GPT المحددة:** أوراق بحث OpenAI's GPT-2 (2019) وGPT-3 (2020) لا تذكر استخدام الإسقاط، مما يشير إلى أنها اعتمدت على أساليب تنظيمية أخرى مثل تناقص الوزن (التطبيع L2) ومجموعات البيانات الضخمة لتجنب التكيف المفرط. ومع ذلك، قد تتضمن بعض التطبيقات أو المتغيرات ذلك بشكل اختياري.
   - **المشهد الأوسع للنماذج اللغوية الكبيرة:** لا تزال العديد من نماذج المحولات الحديثة تستخدم الإسقاط، خاصة في طبقات الانتباه والطبقات الأمامية، لأنه حتى مع تريليونات الرموز في بيانات التدريب، يمكن أن يحدث التكيف المفرط (على سبيل المثال، مع الأنماط النادرة أو الحفظ). على سبيل المثال:
     - تناقش الأبحاث الحديثة استخدام الإسقاط في المراحل المبكرة من تدريب النماذج اللغوية الكبيرة لمكافحة عدم كفاية التكيف.
     - تظهر نماذج مثل BERT (الذي يستخدم الإسقاط بنسبة 0.1) أنه فعال للمحولات ثنائية الاتجاه.
     - تقوم تقنيات جديدة مثل "الإسقاط الديناميكي" (2024) بالبناء عليه لتحسين كفاءة التدريب في نماذج المحولات.
   - خلاصة القول: الإسقاط ليس إلزاميًا في "عصر GPT" بفضل المقياس (نماذج وبيانات هائلة)، لكنه ليس قديمًا. إنه اختياري ويعتمد على البنية—جيد لبعض الإعدادات (على سبيل المثال، لتوزيع رؤوس الانتباه بشكل أفضل)، ولكن يمكن تخطيه في حالات أخرى حيث تكون البدائل كافية. إذا تخطى النموذج استخدامه، فذلك لأن الطرق الأخرى (مثل تطبيع الطبقة، والتدريب المسبق واسع النطاق) تحقق تنظيمًا مشابهًا.

إذا لم يكن هذا واضحًا تمامًا أو كان لديك مثال محدد لنموذج لغوي كبير في ذهن، فلا تتردد في التوضيح!

### المراجع
- [Dilution (neural networks) - Wikipedia](https://en.wikipedia.org/wiki/Dilution_%28neural_networks%29)
- [Introduction of Dropout and Ensemble Model in the History of Deep Learning](https://medium.com/unpackai/introduction-of-dropout-and-ensemble-model-in-the-history-of-deep-learning-a4c2a512dcca)
- [Geoffrey Hinton introduces "dropout" technique for training neural nets](https://www.reddit.com/r/MachineLearning/comments/yz5tx/brains_sex_and_machine_learning_geoffrey_hinton/)
- [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://jmlr.org/papers/v15/srivastava14a.html)
- [Dropout | Wiki | HyperAI](https://hyper.ai/en/wiki/33851)
- [[Discussion] LLM Pre-training --- Should I use dropout?](https://www.reddit.com/r/MachineLearning/comments/16c1prf/discussion_llm_pretraining_should_i_use_dropout/)
- [Why did GPT-2 not use dropout in the model?](https://github.com/openai/gpt-2/issues/120)
- [The Role of Dropout in Neural Networks](https://medium.com/biased-algorithms/the-role-of-dropout-in-neural-networks-fffbaa77eee7)
- [STLM Engineering Report: Dropout](https://arxiv.org/html/2409.05423v1)
- [Dropout in Transformer](https://www.reddit.com/r/deeplearning/comments/18tgywb/dropout_in_transformer/)
- [Enhancing Transformer Training Efficiency with Dynamic Dropout](https://arxiv.org/abs/2411.03236)
- [Where is dropout placed in the original transformer?](https://stats.stackexchange.com/questions/535720/where-is-dropout-placed-in-the-original-transformer)
- [Residual Dropout: A Simple Approach to Improve Transformer's Data Efficiency](https://aclanthology.org/2024.sigul-1.35.pdf)
- [Language Models are Unsupervised Multitask Learners (GPT-2 Paper)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- [Language Models are Few-Shot Learners (GPT-3 Paper)](https://arxiv.org/pdf/2005.14165.pdf)
- [Attention Is All You Need (Transformer Paper)](https://arxiv.org/pdf/1706.03762.pdf)