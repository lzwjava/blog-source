---
audio: false
generated: true
image: false
lang: ar
layout: post
title: تدريب النماذج اللغوية الكبيرة بدون وحدات معالجة الرسوميات من إنفيديا
translated: true
type: note
---

أفترض أنك تشير إلى تدريب نموذج لغوي كبير مثل LongCat من Meituan أو نماذج مماثلة، وتسأل عما إذا كان من الممكن تدريب مثل هذا النموذج بدون وحدة معالجة رسومية من NVIDIA (بناءً على سياق "longcat" و "n gpu"). إذا كنت تشير إلى شيء آخر بـ "longcat"، يرجى التوضيح، وسأقوم بتعديل الرد accordingly.

تدريب النماذج اللغوية الكبيرة (LLMs) مثل LongCat، الذي يحتوي على 56 مليار معامل في إصدار LongCat-Flash، يتطلب عادةً موارد حاسوبية كبيرة، حيث أن وحدات معالجة الرسوميات (GPUs) (خاصة وحدات NVIDIA مع دعم CUDA) هي المعيار بسبب قدراتها على المعالجة المتوازية. ومع ذلك، من الممكن تدريب مثل هذه النماذج بدون وحدة معالجة رسومية من NVIDIA، على الرغم من أن ذلك يأتي مع تحديات ومقايضات. أدناه، سأوضح الجدوى والخيارات والاعتبارات للتدريب بدون وحدة معالجة رسومية من NVIDIA، باستخدام رؤى من المعلومات المتاحة والمعرفة العامة حول التعلم الآلي.

---

### **هل يمكنك تدريب LongCat (أو نماذج LLMs مماثلة) بدون وحدة معالجة رسومية من NVIDIA؟**
نعم، من الممكن تدريب نماذج LLMs بدون وحدة معالجة رسومية من NVIDIA، لكن ذلك يعتمد على حجم النموذج، والأجهزة المتاحة، وأهدافك (مثل التدريب الكامل مقابل الضبط الدقيق). إليك تحليل مفصل:

#### **1. تحديات التدريب بدون وحدة معالجة رسومية من NVIDIA**
- **القوة الحاسوبية**: نماذج LLMs مثل LongCat تتطلب عمليات matrix هائلة، وهي العمليات التي تتقن وحدات معالجة الرسوميات أداءها بسبب بنيتها المتوازية. وحدات المعالجة المركزية (CPUs) أو الأجهزة الأخرى (مثل وحدات معالجة الرسوميات من AMD، أو وحدات TPUs، أو الرسوميات المدمجة) تكون بشكل عام أبطأ وأقل كفاءة في هذه المهام.
- **قيود الذاكرة**: LongCat-Flash يحتوي على 56 مليار معامل، وحتى مع البنى الفعالة مثل Mixture of Experts (MoE)، فإن التدريب يتطلب ذاكرة كبيرة. على سبيل المثال، نموذج بحجم 7B معامل يحتاج إلى ~14 جيجابايت للاستدلال و ~70 جيجابايت للتدريب بحجم دفعة (batch size) يساوي 1. نموذج بحجم 56B سيتطلب ذاكرة أكبر بكثير، غالبًا تتجاوز ذاكرة الوصول العشوائي (RAM) لوحدة المعالجة المركزية النموذجية أو ذاكرة وحدة معالجة الرسوميات غير التابعة لـ NVIDIA.
- **الوقت**: التدريب على وحدة معالجة مركزية أو أجهزة غير تابعة لـ NVIDIA يمكن أن يكون أبطأ بـ 10–30 مرة من التدريب على وحدة معالجة رسومية من NVIDIA، مما يجعل التدريب الكامل للنماذج الكبيرة غير عملي لمعظم المستخدمين.
- **توافق البرمجيات**: العديد من أطر عمل التعلم الآلي (مثل PyTorch, TensorFlow) مُحسنة لـ CUDA من NVIDIA، وهو حصري لوحدات معالجة الرسوميات من NVIDIA. الأجهزة غير التابعة لـ NVIDIA قد تتطلب إعدادًا إضافيًا أو أطر عمل بديلة، والتي قد تكون أقل نضجًا أو دعمًا.

#### **2. بدائل وحدات معالجة الرسوميات من NVIDIA للتدريب**
إذا لم يكن لديك إمكانية الوصول إلى وحدة معالجة رسومية من NVIDIA، فإليك الخيارات المجدية:

##### **أ. التدريب باستخدام وحدة المعالجة المركزية (CPU) فقط**
- **الجدوى**: النماذج الأصغر (مثل 1B–7B معامل) أو الإصدارات المكممة (quantized) بشدة يمكن تدريبها على وحدات المعالجة المركزية، خاصة مع وحدات المعالجة المركزية الحديثة عالية النوى (مثل AMD Ryzen أو Intel Xeon). ومع ذلك، فإن نموذج بحجم 56B مثل LongCat من المرجح أن يكون غير قابل للتنفيذ على وحدة المعالجة المركزية بسبب قيود الذاكرة والوقت.
- **تقنيات لجعلها تعمل**:
  - **التكميم (Quantization)**: استخدم التكميم 4-bit أو 8-bit (مثلًا باستخدام مكتبات مثل `bitsandbytes`) لتقليل استخدام الذاكرة. على سبيل المثال، نموذج 7B مكمم بـ 4-bit يمكن أن يعمل على ~12 جيجابايت من ذاكرة الوصول العشوائي، مما يجعل تدريب وحدة المعالجة المركزية أكثر جدوى للنماذج الأصغر.
  - **Gradient Checkpointing**: يقلل من استخدام الذاكرة عن طريق إعادة حساب التنشيطات الوسيطة أثناء الانتشار الخلفي (backpropagation)، مُقايضًا السرعة بانخفاض استخدام الذاكرة. هذا مدعوم في أطر عمل مثل Hugging Face Transformers.
  - **أحجام دفعات أصغر (Smaller Batch Sizes)**: استخدم حجم دفعة يساوي 1 أو تراكم التدرجات (accumulate gradients) على خطوات متعددة ليتناسب مع حدود الذاكرة، على الرغم من أن هذا يمكن أن يقلل من استقرار التدريب.
  - **النماذج المقطرة (Distilled Models)**: استخدم إصدارًا أصغر ومقطرًا من النموذج (إذا كان متاحًا) لتقليل احتياجات الموارد.
- **الأدوات**: أطر العمل مثل PyTorch و TensorFlow تدعم التدريب على وحدة المعالجة المركزية. أدوات مثل `llama.cpp` أو `Ollama` مُحسنة لتشغيل نماذج LLMs على وحدات المعالجة المركزية مع النماذج المكممة.
- **القيود**: تدريب وحدة المعالجة المركزية بطيء (مثل 4.5–17.5 رمز/الثانية لنماذج 7B–11B) وغير عملي للنماذج الكبيرة مثل LongCat بدون تحسين كبير.

##### **ب. وحدات معالجة الرسوميات من AMD**
- **الجدوى**: يمكن استخدام وحدات معالجة الرسوميات من AMD (مثل سلسلة Radeon RX) للتدريب باستخدام أطر عمل مثل PyTorch ROCm (المكافئ من AMD لـ CUDA). ومع ذلك، فإن ROCm أقل نضجًا، ويدعم عددًا أقل من النماذج، ومقتصر على وحدات معالجة رسوميات محددة من AMD وبيئات Linux.
- **الإعداد**: قم بتثبيت PyTorch مع دعم ROCm على وحدة معالجة رسوميات متوافقة من AMD (مثل RX 6900 XT). قد تحتاج إلى التحقق من توافق النموذج، حيث أنه ليس مضمونًا أن جميع نماذج LLMs (بما في ذلك LongCat) ستعمل بسلاسة.
- **الأداء**: يمكن لوحدات معالجة الرسوميات من AMD أن تقترب من أداء وحدة معالجة الرسوميات من NVIDIA لمهام معينة ولكنها قد تتطلب تكوينًا أكثر ولديها دعم مجتمعي أقل لنماذج LLMs.
- **القيود**: ذاكرة VRAM المحدودة (مثل 16 جيجابايت على وحدات معالجة الرسوميات الاستهلاكية الراقية من AMD) تجعل تدريب النماذج الكبيرة مثل LongCat صعبًا بدون إعدادات متعددة وحدات المعالجة الرسومية أو التكميم.

##### **ج. وحدات معالجة Tensor من Google (TPUs)**
- **الجدوى**: وحدات TPUs من Google (المتاحة عبر Google Cloud أو Colab) هي بديل لوحدات معالجة الرسوميات من NVIDIA. وحدات TPUs مُحسنة لعمليات المصفوفات ويمكنها التعامل مع التدريب على نطاق واسع.
- **الإعداد**: استخدم TensorFlow أو JAX مع دعم TPU. يقدم Google Colab Pro إمكانية الوصول إلى TPU مقابل رسوم، مما يمكن أن يكون فعالاً من حيث التكلفة مقارنة باستئجار وحدات معالجة رسوميات من NVIDIA.
- **التكلفة**: غالبًا ما تكون وحدات TPUs أرخص من وحدات معالجة الرسوميات الراقية من NVIDIA على منصات السحابة. على سبيل المثال، يمكن أن يكون تسعير Google Cloud TPU أقل من حالات AWS EC2 مع وحدات معالجة رسوميات NVIDIA A100.
- **القيود**: يتطلب التدريب على TPUs إعادة كتابة الكود لـ TensorFlow أو JAX، والتي قد لا تدعم بنية MoE الخاصة بـ LongCat جاهزة. قد يكون نقل النماذج إلى وحدات TPUs معقدًا.

##### **د. خدمات السحابة بدون وحدات معالجة رسوميات من NVIDIA**
- **الخيارات**: يمكن استخدام منصات مثل Google Colab (مع وحدات TPUs أو وحدات المعالجة المركزية)، أو Kaggle (موارد مجانية لوحدات المعالجة المركزية/وحدات TPUs)، أو RunPod (تقدم خيارات غير تابعة لـ NVIDIA) للتدريب بدون وحدات معالجة رسومية محلية من NVIDIA.
- **الحلول فعالة التكلفة**: الطبقة المجانية من Google Colab تقدم وصولاً محدودًا إلى وحدات TPUs/وحدات المعالجة المركزية، بينما يوفر Colab Pro المزيد من الموارد. تقدم RunPod تأجير وحدات معالجة رسوميات غير تابعة لـ NVIDIA بأسعار معقولة (مثل 0.43 دولار/ساعة لجهاز ظاهري به 14 vCPU، 30 جيجابايت RAM، ووحدة RTX 3090، على الرغم من أن هذه仍然 تابعة لـ NVIDIA).
- **حالة الاستخدام**: الضبط الدقيق للنماذج الأصغر أو تشغيل الاستدلال أكثر جدوى من التدريب الكامل لنموذج 56B على هذه المنصات.

##### **هـ. أجهزة أخرى (مثل Apple M1/M2، وحدات معالجة الرسوميات من Intel)**
- **Apple Silicon**: أجهزة Mac ذات رقائق M1/M2 يمكنها تشغيل نماذج LLMs باستخدام أطر عمل مثل `llama.cpp` أو `Ollama` للاستدلال والضبط الدقيق. ومع ذلك، فإن تدريب نموذج 56B غير عملي due to limited memory (يصل إلى 128 جيجابايت على أجهزة Mac الراقية) والأداء الأبطأ مقارنة بوحدات معالجة الرسوميات.
- **وحدات معالجة الرسوميات Intel Arc**: تدعم وحدات معالجة الرسوميات من Intel OpenVINO للاستدلال المُحسن وبعض مهام التدريب، ولكنها لم تُستخدم بعد على نطاق واسع لنماذج LLMs ولديها ذاكرة VRAM محدودة.
- **القيود**: هذه الخيارات أكثر ملاءمة للاستدلال أو الضبط الدقيق للنماذج الصغيرة، وليس للتدريب الكامل للنماذج الكبيرة مثل LongCat.

#### **3. اعتبارات محددة لـ LongCat**
- **هندسة النموذج**: يستخدم LongCat-Flash بنية MoE، مما ينشط 18.6–31.3 مليار معامل لكل رمز (token)، مما يقلل الحمل الحسابي مقارنة بالنماذج الكثيفة (dense models). ومع ذلك، حتى مع MoE، فإن متطلبات الذاكرة والحساب كبيرة، مما يجعل التدريب على وحدة المعالجة المركزية فقط غير عملي للتدريب الكامل.
- **الضبط الدقيق مقابل التدريب الكامل**: التدريب الكامل لـ LongCat من الصفر سيتطلب موارد هائلة (على سبيل المثال، استثمرت Meituan مليارات في بنية تحتية لوحدات معالجة الرسوميات). الضبط الدقيق، خاصة مع تقنيات مثل LoRA أو QLoRA، أكثر جدوى على الأجهزة المحدودة. على سبيل المثال، يمكن لـ QLoRA ضبط نموذج 7B دقيقًا على وحدة معالجة رسومية واحدة سعة 24 جيجابايت، ولكن Scaling إلى 56B سيبقى صعبًا بدون إعدادات متعددة وحدات معالجة رسومية أو موارد سحابية.
- **التوفر مفتوح المصدر**: LongCat-Flash مفتوح المصدر، لذا يمكنك الوصول إلى أوزانه (weights) ومحاولة الضبط الدقيق. ومع ذلك، فإن عدم وجود وحدات معالجة رسومية من NVIDIA قد يتطلب تحسينًا كبيرًا (مثل التكميم، gradient checkpointing) ليتناسب مع الأجهزة البديلة.

#### **4. خطوات عملية للتدريب بدون وحدات معالجة رسوميات من NVIDIA**
إذا كنت ترغب في محاولة تدريب أو ضبط LongCat دقيقًا (أو نموذج مماثل) بدون وحدة معالجة رسومية من NVIDIA، اتبع هذه الخطوات:
1. **اختر نموذجًا أصغر أو ركز على الضبط الدقيق**: ابدأ بنموذج أصغر (مثل 1B–7B معامل) أو ركز على ضبط LongCat دقيقًا باستخدام LoRA/QLoRA لتقليل احتياجات الموارد.
2. **حسن للأداء على وحدة المعالجة المركزية أو الأجهزة البديلة**:
   - استخدم `llama.cpp` أو `Ollama` للاستدلال والضبط الدقيق المُحسن لوحدة المعالجة المركزية.
   - طبق التكميم 4-bit مع `bitsandbytes` أو `Hugging Face Transformers`.
   - مكن gradient checkpointing واستخدم أحجام دفعات صغيرة (مثل 1–4).
3. **استفد من موارد السحابة**: استخدم Google Colab (وحدات TPUs/وحدات المعالجة المركزية)، أو Kaggle، أو RunPod للوصول بأسعار معقولة إلى الأجهزة غير التابعة لـ NVIDIA.
4. **تحقق من توافق الإطار**: تأكد من أن إطار العمل الخاص بك (مثل PyTorch ROCm لـ AMD، TensorFlow/JAX لوحدات TPUs) يدعم بنية LongCat. قد تتطلب نماذج MoE معالجة محددة.
5. **اختبر محليًا أولاً**: أنشئ نموذجًا أوليًا (prototype) بمجموعة بيانات صغيرة وحجم دفعة على وحدة المعالجة المركزية للتحقق من الكود الخاص بك قبل التوسع إلى السحابة أو الأجهزة البديلة.
6. **راقب الأداء**: سيكون تدريب وحدة المعالجة المركزية بطيئًا، لذا ركز على الضبط الدقيق بدلاً من التدريب الكامل واستخدم أدوات مثل `Unsloth` للضبط الدقيق الأسرع مع استخدام أقل للذاكرة.

#### **5. التوصيات**
- **لهواة أو المستخدمين محدودي الميزانية**: ركز على ضبط نموذج أصغر دقيقًا (مثل 7B معامل) باستخدام وحدة معالجة مركزية أو وحدة TPU سحابية. الطبقة المجانية من Google Colab أو 30 ساعة/أسبوع من الموارد المجانية على Kaggle هي نقاط بداية جيدة.
- **لـ LongCat تحديدًا**: نظرًا لاحتوائه على 56B معامل، فإن التدريب الكامل بدون وحدات معالجة رسومية من NVIDIA من المرجح أن يكون غير قابل للتنفيذ على الأجهزة الاستهلاكية. الضبط الدقيق باستخدام QLoRA على وحدة معالجة مركزية عالية الذاكرة (مثل 64 جيجابايت RAM) أو وحدة TPU سحابية هو أفضل رهان لك.
- **إذا كنت تحتاج إلى وحدات معالجة رسوميات**: استئجار وحدات معالجة رسوميات من NVIDIA عبر RunPod أو AWS أو Google Cloud غالبًا ما يكون أكثر عملية من شراء الأجهزة. إذا كنت تفضل غير التابعة لـ NVIDIA، فإن وحدات معالجة الرسوميات من AMD مع ROCm أو وحدات TPUs مجدية ولكنها تتطلب إعدادًا أكثر.

#### **6. الخلاصة**
تدريب نموذج مثل LongCat بدون وحدة معالجة رسومية من NVIDIA ممكن تقنيًا ولكنه صعب للغاية due to its scale. للأغراض العملية، ركز على الضبط الدقيق مع تقنيات مثل QLoRA و gradient checkpointing و التكميم، باستخدام وحدة معالجة مركزية أو وحدة معالجة رسومية من AMD أو وحدة TPU. يمكن للمنصات السحابية مثل Google Colab أو RunPod توفير وصول بأسعار معقولة إلى الأجهزة غير التابعة لـ NVIDIA. إذا كنت تعمل دون اتصال بالإنترنت أو بميزانية محدودة، ابدأ بالنماذج الأصغر وحسن بشكل كبير للأداء على وحدة المعالجة المركزية.

إذا كان لديك أجهزة محددة (مثل مواصفات وحدة المعالجة المركزية، طراز وحدة معالجة الرسوميات من AMD) أو أهداف (مثل الضبط الدقيق لمهمة محددة)، دعني أعرف، ويمكنني تقديم دليل أكثر تخصيصًا. أيضًا، إذا كان "longcat" يشير إلى شيء آخر (مثل ميم أو سياق آخر)، يرجى التوضيح!