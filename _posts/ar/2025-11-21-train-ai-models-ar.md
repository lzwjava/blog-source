---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4.1-fast
title: تدريب نماذج الذكاء الاصطناعي على ذاكرة فيديو سعتها ١٢ جيجابايت
translated: true
type: note
---

إليك بعض المشاريع مفتوحة المصدر "الحقيقية" التي يمكنك تدريبها بالكامل (أو ضبط أجزاء كبيرة منها) على بطاقة RTX 4070 واحدة (12 جيجابايت من VRAM). إنها ممتازة لفهم كيفية عمل الأشياء فعليًا على مستوى عميق يتجاوز مجرد تشغيل النماذج التوضيحية.

| المشروع | النوع | لماذا هو تعليمي ومتقدم تقنيًا | الذاكرة VRAM التقريبية المطلوبة للتدريب | وقت التدريب التقريبي على 4070 | الرابط |
|---------|------|----------------------------------|-------------------------------------|-----------------------------|------|
| **nanoGPT** الخاص بـ Karpathy (تعرفه مسبقًا) | نموذج لغوي كبير (GPT-2 من الصفر) | معيار الذهب "لشيفرة GPT الدنيا والنظيفة" | ~10 جيجابايت لنموذج 124M | ساعات | https://github.com/karpathy/nanoGPT |
| **minGPT** الخاص بـ Karpathy | نموذج لغوي كبير | أصغر حجمًا، رائع لتصحيح كل سطر على حدة | <6 جيجابايت | دقائق–ساعات | https://github.com/karpathy/minGPT |
| **llm.c** الخاص بـ Karpathy | GPT-2 بـ CUDA الخام | درّب نموذج GPT-2 لائقًا بالكامل باستخدام CUDA الخام (بدون PyTorch). تعليمي بشكل مذهل لبرمجة GPU على مستوى منخفض | 8–10 جيجابايت (نموذج 124M) | 1–3 أيام لنموذج 124M على بيانات شكسبير | https://github.com/karpathy/llm.c |
| OpenLLaMA / LLaMA-Adapter / Lit-GPT (الضبط الدقيق) | ضبط نماذج لغوية كبيرة | اضبط نماذج 3B–7B باستخدام LoRA/QLoRA على بطاقة 4070 واحدة | 7B QLoRA ≈ 8–10 جيجابايت | بضع ساعات على Alpaca/ShareGPT | https://github.com/Lightning-AI/lit-gpt |
| **OpenDiT** / **PixArt-alpha** الخاص بـ Hiero | توليد صورة من نص قائم على DiT (بديل لـ Stable Diffusion مُدرَّب من الصفر) | درّب نموذج Diffusion Transformer من الصفر بدلاً من U-Net. بنية حديثة متطورة | 24M DiT ≈ 10–11 جيجابايت مع تفعيل حفظ التدرج | 1–2 أسبوع على مجموعة LAION الجمالية | https://github.com/NVIDIA/OpenDiT |
| **Stable Diffusion من الصفر** (إصدارات مصغرة) | انتشار U-Net | عدة مستودعات تتيح لك تدريب نماذج SD مصغرة (بدلاً من الضبط الدقيق فقط) | 64×64 tiny SD ≈ 6–9 جيجابايت | أيام | https://github.com/tea-mang/nano-diffusion, https://github.com/huggingface/diffusers (انظر أمثلة التدريب) |
| **BitNet** (النماذج المحولة 1-bit) | نموذج لغوي كبير 1-bit | نماذج Microsoft ذات الأوزان 1-bit. درّب نموذج BitNet b1.58 الخاص بك (مشابه لـ LLaMA لكن بأوزان ثلاثية) | نموذج 3B يتسع في <6 جيجابايت | ساعات–أيام | https://github.com/microsoft/BitNet |
| **Mamba** (نماذج state-space) | البنية الجيلية التالية بعد النماذج المحولة | بديل شائع جدًا للنماذج المحولة. درّب نموذج Mamba الخاص بك من الصفر | نماذج 130M–2.8B تتسع بسهولة | ساعات | https://github.com/state-spaces/mamba (شيفرات التدريب مُضمنة) |
| **RWKV** (شبكة RNN تتوسع مثل المحول) | نماذج Raven / Eagle / Finch | درّب نموذجًا متكررًا حقيقيًا يتصرف مثل المحول لكنه يستخدم VRAM ثابتًا | تدريب 3B–7B ممكن على 12 جيجابايت مع chunkwise | أيام | https://github.com/BlinkDL/RWKV-LM |
| محاولات استنساخ أوزان **Grok-1** المفتوحة (340B mixture-of-experts) | فهم MoE من الصفر | لا يمكنك تدريب النموذج الكامل 314B، لكن يمكنك تدريب إصدارات MoE مصغرة وفهم آلية التوجيه | 8-expert tiny MoE ≈ 10 جيجابايت | ساعات | https://github.com/cg123/mergekit (ابني نموذج MoE الخاص بك) + https://github.com/EleutherAI/gpt-neox للحصول على شيفرة MoE |
| **RetNet** (بديل Microsoft للمحول) | شبكات الإبقاء | بديل قوي آخر للمحول | مشابه لـ Mamba | | https://github.com/microsoft/torchscale (يتضمن تدريب RetNet) |

### ترتيبي الشخصي لأفضل 5 مشاريع "الأكثر تعليمية والقابلة للتنفيذ على 4070"

1.  **llm.c** – تدريب GPT-2 بـ C+CUDA بحت. لا شيء يعلمك backprop، أو النواة، أو تنفيذ flash-attention أفضل من هذا.
2.  **Mamba** – لأن نماذج state-space هي على الأرجح المستقبل وشيفرتها نظيفة.
3.  **BitNet b1.58** – تدريب نماذج LLM ذات 1-bit مذهل للغاية وفعال جدًا في استخدام VRAM.
4.  **OpenDiT / PixArt-alpha** – إذا كنت تريد نماذج الانتشار ولكن مع هياكل المحولات الحديثة بدلاً من U-Net القديمة.
5.  **RWKV** – بنية متكررة تتغلب على المحولات بنفس الحجم وتتدرب بشكل خطي.

جميع هذه المشاريع تعمل بشكل مريح على بطاقة RTX 4070 واحدة (أحيانًا باستخدام flash-attention، أو bitsandbytes/QLORA، أو تفعيل حفظ التدرج، أو حيل chunkwise الجديدة لـ RWKV).

اختر مشروعًا واغوص في الأعماق — ستخرج من هذه التجربة وانت تفهم هذه النماذج بمستوى لا يصل إليه معظم الباحثين.