---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: تجنب تجاوز ذاكرة وحدة معالجة الرسوم أثناء التقييم
translated: true
type: note
---

أنت تواجه مشكلة نفاد ذكرة VRAM الكلاسيكية على بطاقة RTX 4070 (ذات سعة 12 جيجابايت) أثناء تدريب نموذج GPT بحوالي 77 مليون معامل (مصمم في الأصل لـ 125 مليون، لكنك قللت `n_embd` إلى 576 → ~77 مليون) مع `batch_size=16`، و`block_size=1024`، و`gradient_accumulation_steps=32` في وضع FP16.

على الرغم من أن 77 مليون معامل يعتبر صغيرًا، إلا أن الدُفعة الجزئية الفعالة ضخمة بسبب الطريقة التي يحسب بها nanoGPT الخسارة في `estimate_loss()` – فهو ينفذ مرورًا أماميًا/خلفيًا كاملاً على دفعات التقييم دون حيل تراكم التدرجات، لذا أثناء التقييم يحاول فجأة وضع دفعة فعالة أكبر بكثير في الذاكرة.

### السبب الجذري
في `estimate_loss()`، يفعل nanoGPT هذا افتراضيًا:

```python
for _ in range(eval_iters):  # 200 مرة!
    x, y = get_batch('train')
    ...
    logits, loss = model(x, y)
```

كل استدعاء `get_batch` يُرجع `batch_size × block_size` رمزًا → 16 × 1024
مع `eval_iters = 200` → 200 مرور أمامي منفصل، لكن PyTorch يحتفظ برسم البيان الحسابي والتنشيطات الوسيطة لحلقة التقييم بأكملها في الذاكرة إذا لم تكن حريصًا. مجتمعة مع ذاكرة التخزين المؤقت KV الضخمة (12 طبقة × 12 رأسًا × 1024 × 576 × 2 بايت FP16 ≈ 1.6 جيجابايت فقط للتخزين المؤقت)، بالإضافة إلى الـ logits (16×1024×50304 × 2 بايت ≈ 1.6 جيجابايت لكل مرور أمامي)، فإنك تتجاوز بسهولة 12 جيجابايت على الرغم من أن التدريب نفسه يعمل بشكل جيد.

### الإصلاحات السريعة (اختر واحدة أو اجمع بينها)

**الخيار 1: تقليل حجم دفعة التقييم بشكل كبير (أسرع إصلاح)**
أضف هذه الأسطر إلى الإعدادات الخاصة بك (أو تجاوزها عبر سطر الأوامر):

```python
eval_batch_size = 4        # أضف هذا
# أو حتى 2 إذا استمر نفاد الذاكرة
eval_iters = 100           # يمكن التقليل أكثر قليلاً
```

يحترم nanoGPT `eval_batch_size` إذا أضفته (الإصدارات الحديثة تفعل ذلك). هذا يجعل التقييم يستخدم 4 تسلسلات فقط بدلاً من 16 → ذاكرة أقل خلال التقييم بـ ~4 مرات.

**الخيار 2: تقليل block_size للتقييم فقط (يحافظ على الدقة)**
```python
eval_block_size = 512      # أو 256
```
أضف هذا إلى الإعدادات – بعض النسخ المشتقة تدعمه، أو رقّع الدالة `get_batch` لاستخدام حجم كتلة مختلف عندما يكون `split=='val'`.

**الخيار 3: خفض eval_iters وتقبّل فقدانًا أكثر ضوضاءً قليلاً في التقييم**
```python
eval_iters = 50   # لا يزال تقديرًا جيدًا
```

**الخيار 4: تقليل حجم النموذج أكثر قليلاً (مع الحفاظ على الجودة الجيدة)**
أنت بالفعل عند 77 مليون، لكن يمكنك النزول بأمان أكثر:

```python
n_layer = 12
n_head  = 12
n_embd  = 512     # → ~62 مليون معامل، أكثر أمانًا
# أو حتى n_embd = 448 → ~53 مليون
```

**الخيار 5: تمكين gradient checkpointing (أكبر توفير للذاكرة)**
أضف هذا عند إنشاء النموذج (عدّل model.py أو مرّر علم):

```python
model = GPT(GPTConfig(..., grad_checkpoint=True))
```

أو أضفه بشكل ديناميكي في train.py قبل التدريب:

```python
if config.grad_checkpoint:
    model.gradient_checkpointing_enable()
```

هذا يقطع ذاكرة التنشيط بنسبة ~50-60% على حساب تدريب أبطأ بـ ~20-25%.

### التركيبة الموصى بها لبطاقة 4070 12 جيجابايت الخاصة بك

```python
# في config/train_fineweb.py
batch_size = 16
gradient_accumulation_steps = 32   # يحافظ على فعالية 512 تسلسل
block_size = 1024

eval_batch_size = 4        # حاسم
eval_iters = 100
eval_interval = 500

n_embd = 512               # ~62 مليون نموذج، آمن جدًا
# اختياري: إضافة gradient checkpointing
grad_checkpoint = True     # إذا كانت النسخة المشتقة من nanoGPT التي تستخدمها تدعمه
```

أو إذا كنت لا تريد تعديل `n_embd`، افعل فقط:

```python
eval_batch_size = 2
eval_iters = 100
```

هذا وحده سيعالج مشكلة نفاد الذاكرة بشكل شبه مؤكد.

اضبط أيضًا متغير البيئة هذا للمساعدة في تجزئة الذاكرة:

```bash
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
```

جرب `eval_batch_size=4` (أو `=2`) أولاً – 95% من الأشخاص الذين يمتلكون بطاقات 4070 بسعة 12 جيجابايت ويعانون من هذا الخطأ الدقيق يحلونه بهذه الطريقة عند تدريب nanoGPT على FineWeb.