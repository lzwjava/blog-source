---
audio: false
generated: true
image: false
lang: ar
layout: post
model: x-ai/grok-4-fast
title: طرق المجموعة للتنبؤات القوية
translated: true
type: note
---

في التعلم الآلي، يشير **التجميع** إلى طريقة تجمع بين التنبؤات أو المخرجات من نماذج فردية متعددة (غالبًا ما تسمى "المتعلمين الضعفاء"، مثل أشجار القرار البسيطة) لإنتاج تنبؤ نهائي أكثر دقة ومتانة مما يمكن لأي نموذج فردي تحقيقه بمفرده. الفكرة هي الاستفادة من "حكمة الحشد" بين النماذج - حيث يتم تقليل الأخطاء، والإفراط في التخصيص، والتباين عن طريق حساب المتوسط أو ترجيح نقاط قوتها مع التخفيف من نقاط الضعف.

في السياق المحدد لـ **تعزيز التدرج** (على سبيل المثال، خوارزميات مثل XGBoost أو LightGBM):
- إنه *تجميع للأشجار*: يتم بناء أشجار قرار ضعيفة بشكل تسلسلي، حيث يركز كل شجرة جديدة على تصحيح الأخطاء المتبقية (الأخطاء) الخاصة بالأشجار السابقة.
- عملية التعزيز هذه "تحسن تدريجيًا" النموذج العام، مما يؤدي إلى تجميع قوي وفعال للغاية لمهام مثل الانحدار أو التصنيف.

فكر في الأمر مثل فريق من المتدربين يتعلمون من أخطاء بعضهم البعض لبناء حرفي رئيسي. إذا كنت تتجه للتعمق أكثر، أوصي بالاطلاع على الورقة البحثية الأصلية لتعزيز التدرج بواسطة Friedman (2001) للرياضيات الكامنة وراءها.