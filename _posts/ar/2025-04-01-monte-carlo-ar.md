---
audio: false
generated: true
lang: ar
layout: post
title: بحث مونت كارلو الشجري
translated: true
type: note
---

دعنا نتعمق في دليل شامل حول **Monte Carlo Tree Search (MCTS)**، وهي خوارزمية قوية تُستخدم على نطاق واسع في مشاكل اتخاذ القرارات، خاصة في الألعاب والذكاء الاصطناعي. سأقوم بشرحها خطوة بخطوة، متناولًا أصولها، والمفاهيم الأساسية، وآليات العمل، والتنفيذ، ونقاط القوة، والضعف، والتطبيقات—كل ما تحتاج لفهمها بشكل شامل.

---

### ما هو بحث شجرة مونت كارلو؟

بحث شجرة مونت كارلو هو خوارزمية بحث إرشادية تجمع بين دقة البحث الشجري وعشوائية طرق مونت كارلو. إنها فعالة بشكل خاص للمشاكل ذات مساحات القرار الكبيرة والمعقدة حيث لا يكون استكشاف جميع الاحتمالات (كما في minimax) مجديًا. تبني MCTS شجرة بحث جزئية بشكل تدريجي، باستخدام محاكاة عشوائية لتوجيه استكشافها نحو الحركات الواعدة.

- **الأصول**: ظهرت MCTS في منتصف العقد الأول من القرن الحادي والعشرين، مع مساهمات كبيرة من ريمي كولوم (2006) وآخرين. اكتسبت شهرة عندما شغلت الذكاء الاصطناعي للعب Go، لا سيما في AlphaGo، مما أحدث ثورة في كيفية تعامل أجهزة الكمبيوتر مع الألعاب ذات مساحات الحالات الشاسعة.
- **حالة الاستخدام الرئيسية**: ألعاب مثل Go، الشطرنج، البوكر، وحتى المشاكل الواقعية مثل التخطيط أو التحسين.

---

### المفاهيم الأساسية

تعمل MCTS على **شجرة** حيث:
- **العُقد** تمثل حالات اللعبة أو نقاط القرار.
- **الحواف** تمثل الإجراءات أو الحركات التي تؤدي إلى حالات جديدة.
- **الجذر** هو الحالة الحالية التي يتم اتخاذ القرارات منها.

توازن الخوارزمية بين **الاستكشاف** (تجربة حركات جديدة) و**الاستغلال** (التركيز على الحركات الجيدة المعروفة) باستخدام نهج إحصائي. لا تتطلب دالة تقييم مثالية—فقط طريقة لمحاكاة النتائج.

---

### المراحل الأربع لـ MCTS

تكرر MCTS أربع خطوات متميزة في كل دورة محاكاة:

#### 1. **الاختيار**
- ابدأ من الجذر واجتيز الشجرة إلى عقدة ورقة (عقدة غير موسعة بالكامل أو حالة نهائية).
- استخدم **سياسة الاختيار** لاختيار العقد الفرعية. الأكثر شيوعًا هي صيغة **الحد الأعلى للثقة المطبق على الأشجار (UCT)**:
  \\[
  UCT = \bar{X}_i + C \sqrt{\frac{\ln(N)}{n_i}}
  \\]
  - \\(\bar{X}_i\\): متوسط المكافأة (معدل الفوز) للعقدة.
  - \\(n_i\\): عدد الزيارات للعقدة.
  - \\(N\\): عدد الزيارات للعقدة الأصل.
  - \\(C\\): ثابت الاستكشاف (عادة \\(\sqrt{2}\\) أو يتم ضبطه حسب المشكلة).
- توازن UCT بين الاستغلال (\\(\bar{X}_i\\)) والاستكشاف (الحد \\(\sqrt{\frac{\ln(N)}{n_i}}\\)).

#### 2. **التوسع**
- إذا لم تكن عقدة الورقة المختارة نهائية ولديها أطفال غير مُزارين، قم بتوسيعها بإضافة عقدة فرعية واحدة أو أكثر (تمثل حركات لم تُجرَّب).
- عادة، يُضاف طفل واحد فقط في كل تكرار للتحكم في استخدام الذاكرة.

#### 3. **المحاكاة (الانطلاق)**
- من العقدة الموسعة حديثًا، قم بتشغيل **محاكاة عشوائية** (أو انطلاق) إلى حالة نهائية (مثل فوز/خسارة/تعادل).
- تستخدم المحاكاة سياسة خفيفة الوزن—غالبًا حركات عشوائية موحدة—نظرًا لأن تقييم كل حالة بدقة مكلف للغاية.
- يتم تسجيل النتيجة (مثل +1 للفوز، 0 للتعادل، -1 للخسارة).

#### 4. **الإعادة الخلفية**
- انقل نتيجة المحاكاة مرة أخرى لأعلى الشجرة، محدثًا الإحصائيات لكل عقدة تمت زيارتها:
  - زيادة عدد الزيارات (\\(n_i\\)).
  - تحديث المكافأة الإجمالية (مثل مجموع الانتصارات أو متوسط معدل الفوز).
- وهذا يطور معرفة الشجرة حول المسارات الواعدة.

كرر هذه الخطوات لعدة تكرارات (مثل الآلاف)، ثم اختر أفضل حركة من الجذر بناءً على الطفل الأكثر زيارة أو أعلى متوسط مكافأة.

---

### كيف تعمل MCTS: مثال

تخيل لعبة tic-tac-toe بسيطة:
1. **الجذر**: حالة اللوحة الحالية (مثل دور X مع لوحة مملوءة جزئيًا).
2. **الاختيار**: تختار UCT حركة واعدة (مثل وضع X في المركز) بناءً على محاكاة سابقة.
3. **التوسع**: أضف عقدة فرعية لحركة لم تُجرَّب (مثل استجابة O في الزاوية).
4. **المحاكاة**: العب حركات عشوائية حتى تنتهي اللعبة (مثل فوز X).
5. **الإعادة الخلفية**: تحديث الإحصائيات—حركة المركز تحصل على مكافأة +1، ويزداد عدد الزيارات.

بعد آلاف التكرارات، تكشف الشجرة أن وضع X في المركز له معدل فوز عالٍ، لذلك يتم اختياره.

---

### الكود الزائف

إليك تنفيذ أساسي لـ MCTS:

```python
class Node:
    def __init__(self, state, parent=None):
        self.state = state
        self.parent = parent
        self.children = []
        self.visits = 0
        self.reward = 0

def mcts(root, iterations):
    for _ in range(iterations):
        node = selection(root)
        if not node.state.is_terminal():
            node = expansion(node)
        reward = simulation(node.state)
        backpropagation(node, reward)
    return best_child(root)

def selection(node):
    while node.children and not node.state.is_terminal():
        node = max(node.children, key=uct)
    return node

def expansion(node):
    untried_moves = node.state.get_untried_moves()
    if untried_moves:
        move = random.choice(untried_moves)
        new_state = node.state.apply_move(move)
        child = Node(new_state, parent=node)
        node.children.append(child)
        return child
    return node

def simulation(state):
    current = state.clone()
    while not current.is_terminal():
        move = random.choice(current.get_moves())
        current.apply_move(move)
    return current.get_result()

def backpropagation(node, reward):
    while node:
        node.visits += 1
        node.reward += reward
        node = node.parent

def uct(child):
    if child.visits == 0:
        return float('inf')  # استكشاف العقد غير المزارة
    return (child.reward / child.visits) + 1.41 * math.sqrt(math.log(child.parent.visits) / child.visits)

def best_child(node):
    return max(node.children, key=lambda c: c.visits)  # أو استخدم reward/visits
```

---

### نقاط قوة MCTS

1. **خوارزمية في أي وقت**: أوقفها في أي وقت واحصل على حركة معقولة بناءً على الإحصائيات الحالية.
2. **لا حاجة لدالة تقييم**: تعتمد على المحاكاة، وليس على الإرشادات الخاصة بالمجال.
3. **قابلة للتطوير**: تعمل في مساحات حالات هائلة (مثل Go مع \\(10^{170}\\) وضعًا محتملًا).
4. **قابلة للتكيف**: تركز بشكل طبيعي على الفروع الواعدة مع زيادة التكرارات.

---

### نقاط ضعف MCTS

1. **مكثفة حسابيًا**: تتطلب العديد من عمليات المحاكاة للحصول على نتائج جيدة، مما قد يكون بطيئًا دون تحسين.
2. **استكشاف سطحي**: قد تفوت استراتيجيات عميقة إذا كانت التكرارات محدودة.
3. **الاعتماد على العشوائية**: يمكن لسياسات الانطلاق الرديئة أن تشوه النتائج؛ تعتمد الجودة على دقة المحاكاة.
4. **استخدام الذاكرة**: يمكن أن يكون نمو الشجرة عنق زجاجة في البيئات محدودة الذاكرة.

---

### التحسينات والاختلافات

لمعالجة نقاط الضعف، غالبًا ما يتم تحسين MCTS:
- **الإرشادات في عمليات الانطلاق**: استخدم المعرفة الخاصة بالمجال (مثل تفضيل الحركات المركزية في tic-tac-toe) بدلاً من العشوائية البحتة.
- **التوازي**: قم بتشغيل عمليات محاكاة متعددة في وقت واحد (توازي الجذر أو توازي الشجرة).
- **RAVE (تقدير قيمة الإجراء السريع)**: شارك الإحصائيات عبر حركات متشابهة لتسريع التقارب.
- **التكامل مع الشبكات العصبية**: كما في AlphaGo، استخدم الشبكات العصبية لتوجيه الاختيار (شبكة السياسات) وتقييم الحالات (شبكة القيمة).

---

### التطبيقات

1. **الألعاب**:
   - Go (اختراق AlphaGo).
   - الشطرنج (مدمجة مع الشبكات العصبية في محركات مثل Leela Chess Zero).
   - البوكر (يتعامل مع المعلومات غير الكاملة مع التكيفات).
2. **الروبوتات**: تخطيط المسار في بيئات غير مؤكدة.
3. **التحسين**: حل المشاكل التوافقية مثل الجدولة أو تخصيص الموارد.
4. **إستراتيجية الوقت الحقيقي**: اتخاذ القرارات في سيناريوهات ديناميكية وغير متوقعة.

---

### نصائح عملية للتنفيذ

- **اضبط \\(C\\)**: اضبط ثابت استكشاف UCT بناءً على مشكلتك (\\(C = \sqrt{2}\\) هي نقطة بداية).
- **حد من نمو الشجرة**: قم بتقليم العقد أو تحديد التوسع لإدارة الذاكرة.
- **حسّن عمليات الانطلاق**: استخدم محاكاة خفيفة الوزن أو إرشادات لتوفير الوقت.
- **اختبر التكرارات**: جرب 100 أو 1000 أو 10000 تكرار لتحقيق التوازن بين السرعة والجودة.

---

### الخلاصة

MCTS هي خوارزمية متعددة الاستخدامات وأنيقة تبرز في المجالات التي تفشل فيها طرق البحث التقليدية. يكمن جمالها في بساطتها—المحاكاة العشوائية الموجهة بشجرة متنامية—ومع ذلك فإنها تتوسع لمعالجة بعض أصعب المشاكل في الذكاء الاصطناعي. سواء كنت تبرمج ذكاءً اصطناعيًا للعبة أو تحل مهمة تخطيط، تقدم MCTS نقطة بداية قوية، خاصة عند اقترانها بتحسينات حديثة مثل الشبكات العصبية.

إذا كنت ترغب، يمكنني أن أرشدك خلال تنفيذ محدد (مثل tic-tac-toe) أو استكشاف جانب معين—مثل ضبط UCT أو MCTS المتوازي—بمزيد من التفصيل. ما رأيك؟