---
audio: false
generated: true
image: false
lang: es
layout: post
model: x-ai/grok-4-fast
title: Correcci√≥n del Error de Divisibilidad en la Configuraci√≥n del Modelo
translated: true
type: note
---

El error es muy claro:

```python
assert config.n_embd % config.n_head == 0
```

Esto significa que **n_embd debe ser divisible uniformemente por n_head** (porque cada cabeza de atenci√≥n obtiene `n_embd // n_head` dimensiones).

Est√°s usando esta configuraci√≥n del modelo (probablemente la que te di antes):

```python
n_layer = 12
n_head  = 12
n_embd  = 512
```

512 √∑ 12 = 42.666‚Ä¶ ‚Üí no es un n√∫mero entero ‚Üí falla.

### Soluci√≥n: Elige un n_embd que sea divisible por n_head

Aqu√≠ tienes las **combinaciones seguras y probadas** que funcionan perfectamente en tu 4070 de 12 GB con un solo archivo Parquet de FineWeb:

#### Opci√≥n 1 ‚Äì Recomendada (125M par√°metros, mejor equilibrio calidad/velocidad)
```python
n_layer = 12
n_head  = 12
n_embd  = 576        # ‚Üê 576 √∑ 12 = 48 exactamente
```
‚Üí ~125M par√°metros, a√∫n cabe f√°cilmente en ~10.5 GB de VRAM con batch_size=16 + grad_acc=32 + block_size=1024

#### Opci√≥n 2 ‚Äì Dimensi√≥n de cabeza ligeramente mayor (130M par√°metros)
```python
n_layer = 12
n_head  = 12
n_embd  = 720        # 720 √∑ 12 = 60
```

#### Opci√≥n 3 ‚Äì Muy segura y com√∫n (115M par√°metros)
```python
n_layer = 12
n_head  = 12
n_embd  = 480        # 480 √∑ 12 = 40
```

#### Opci√≥n 4 ‚Äì Si quieres mantener n_embd=512 (estilo GPT-2 original)
```python
n_layer = 12
n_head  = 8          # 512 √∑ 8 = 64
# o
n_head  = 16         # 512 √∑ 16 = 32
```

### Soluci√≥n R√°pida: Solo cambia tu configuraci√≥n a esto (lista para copiar y pegar)

```python
# Modelo ‚Äì 12 capas, ~125M par√°metros, garantizado que funciona
n_layer = 12
n_head  = 12
n_embd  = 576        # ‚Üê ESTA ES LA √öNICA L√çNEA QUE NECESITAS CAMBIAR
dropout = 0.0
```

Todo lo dem√°s (batch_size=16, grad_acc=32, block_size=1024, etc.) se mantiene exactamente igual.

Despu√©s de cambiar a `n_embd = 576`, el error de aserci√≥n desaparece inmediatamente y el entrenamiento comenzar√° con normalidad.

Este modelo 12L/12H/576E es extremadamente popular en la comunidad nanoGPT en este momento ‚Äî mucha gente lo entrena exitosamente en tarjetas 4070/4070 Ti de 12 GB usando FineWeb.

Ejec√∫talo, funcionar√° al 100%. ¬°Av√≠same cuando veas el primer print de p√©rdida! üöÄ