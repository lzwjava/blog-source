---
audio: true
lang: es
layout: post
title: Pensamiento AI
translated: true
---

- Satya Nadella mencionó el paradox de Jevons. Vale la pena aprenderlo.

- Yin Wang: No hay 'inteligencia' en la inteligencia artificial, no 'neuronal' en red neuronal, no 'aprendizaje' en aprendizaje automático, y no 'profundidad' en aprendizaje profundo. Lo que realmente funciona en este campo se llama 'cálculo'. Por eso prefiero llamar a este campo 'cómputo diferenciable', y el proceso de construir modelos se llama 'programación diferenciable'.

- Yin Wang: El aprendizaje automático es realmente útil, incluso podríamos decir que es una teoría hermosa, porque es simplemente cálculo después de un cambio de imagen. Es la antigua y grande teoría de Newton, Leibniz, en una forma más simple, elegante y poderosa. El aprendizaje automático es básicamente el uso del cálculo para derivar y ajustar algunas funciones, y el aprendizaje profundo es el ajuste de funciones más complejas.

- Actualmente, los modelos de lenguaje grande no pueden filtrar por lenguaje de archivo como YAML o Python. Sin embargo, una parte significativa de la información en el mundo real está organizada de esta manera. Esto significa que podríamos entrenar modelos de lenguaje grande utilizando archivos.

- Para entrenar modelos de lenguaje grande, podríamos desarrollar un sistema que encuentre coincidencias exactas. Tal vez podamos combinar el algoritmo de búsqueda KMP (Knuth-Morris-Pratt) con la arquitectura transformer para mejorar las capacidades de búsqueda.