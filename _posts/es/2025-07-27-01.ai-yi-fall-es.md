---
audio: false
generated: true
image: false
lang: es
layout: post
title: Ascenso y Caída de 01.AI
translated: true
type: note
---

### Antecedentes de 01.AI y el Modelo Yi

Kai-Fu Lee, un prominente inversor en IA y ex ejecutivo de Google y Microsoft, fundó 01.AI en marzo de 2023 con el ambicioso objetivo de construir un modelo de lenguaje grande (LLM) "nativo" para rivalizar con líderes globales como la serie GPT de OpenAI, especialmente adaptado para el mercado chino. El producto estrella de la compañía, la serie Yi de modelos (por ejemplo, Yi-34B), se lanzó como un LLM de código abierto en noviembre de 2023. Inicialmente generó un hype significativo al llegar a lo más alto del ranking de LLM de código abierto de Hugging Face, superando a modelos como LLaMA 2 de Meta en benchmarks para tareas como razonamiento y generación de código. Esto impulsó a 01.AI a alcanzar el estatus de unicornio con una valoración de mil millones de dólares en meses, respaldada por inversores como Alibaba y Tencent.

Sin embargo, para 2025, 01.AI y Yi no han cumplido las expectativas iniciales de convertirse en una fuerza dominante en el panorama global de la IA. Si bien la compañía sigue operativa y se acerca a la rentabilidad (con ingresos proyectados de alrededor de 13,8 millones de dólares en 2024), ha sufrido una reestructuración importante, que incluye la escisión de equipos clave y un cambio de rumbo alejándose del desarrollo de modelos fundamentales. A continuación, esbozaré las principales razones de este déficit basándome en los análisis disponibles.

### Razones Clave del Bajo Rendimiento

1.  **Controversias y Problemas de Credibilidad con el Desarrollo de Yi**
    El éxito inicial de Yi-34B se vio empañado por las revelaciones de que no fue entrenado completamente desde cero, sino construido sobre la arquitectura LLaMA de Meta. En noviembre de 2023, 01.AI admitió un "descuido" en las convenciones de nomenclatura y actualizó los nombres de los tensores del modelo para reconocer su base LLaMA. Los críticos argumentaron que esto convertía a Yi más en un modelo ajustado (fine-tune) que en una innovación original, lo que llevó a acusaciones de sobrehype y posible contaminación de datos en los benchmarks. Esto erosionó la confianza en la comunidad de código abierto, donde la transparencia es clave, y las clasificaciones de Yi en el ranking descendieron tras el escrutinio. Algunos observadores señalaron que, si bien Yi tuvo un buen desempeño en tareas bilingües inglés-chino, su ventaja fue de corta duración a medida que los competidores lanzaban modelos más potentes.

2.  **Limitaciones de Recursos y Desafíos Geopolíticos**
    Entrenar modelos grandes como Yi requiere un poder computacional masivo, pero las restricciones a la exportación de GPUs avanzadas (por ejemplo, chips de Nvidia) por parte de EE. UU. han obstaculizado gravemente a las empresas chinas de IA. 01.AI "lo apostó todo" endeudándose para acumular GPUs antes de que se endurecieran los embargos a finales de 2023, utilizando según los informes alrededor de 2.000 GPUs para el entrenamiento de Yi a un costo de solo 3 millones de dólares, muy por debajo de los 80-100 millones de dólares estimados de OpenAI para GPT-4. Si bien esto demostró eficiencia, limitó la escalabilidad. A finales de 2024, la compañía disolvió sus equipos de algoritmos de pre-entrenamiento e infraestructura, señalando la incapacidad de sostener la carrera, intensiva en computación, por modelos cada vez más grandes en medio de la continua escasez de chips.

3.  **Intensa Competencia en el Ecosistema de IA de China**
    El sector de la IA en China es hipercompetitivo, con más de 100 startups de LLM compitiendo por el dominio. Modelos de rivales como DeepSeek (por ejemplo, DeepSeek-R1) y Qwen de Alibaba han superado desde entonces a Yi en benchmarks como LMSYS y en aplicaciones del mundo real, a menudo con mejor eficiencia y menos recursos. A nivel global, los avances de código abierto de Meta (LLaMA 3) y Mistral disminuyeron aún más la posición relativa de Yi. El propio Kai-Fu Lee señaló en 2024 que los mejores modelos chinos, incluido Yi, estaban solo unos 5 meses por detrás de los líderes estadounidenses como OpenAI, pero esta brecha se amplió a medida que las empresas occidentales aceleraban con mejor acceso a datos y hardware.

4.  **Cambio Estratégico hacia Aplicaciones sobre Modelos Fundamentales**
    A principios de 2025, 01.AI cambió su enfoque de la construcción de modelos fundamentales masivos como Yi a LLMs más pequeños, específicos de la industria, y aplicaciones de IA (por ejemplo, herramientas de productividad y soluciones empresariales). Kai-Fu Lee explicó esto como un "camino más inteligente" hacia la rentabilidad, enfatizando que la era de las "leyes de escala" (modelos más grandes = mejor rendimiento) está dando paso a aplicaciones específicas y rentables. Este cambio incluyó una reestructuración en diciembre de 2024, con la escisión de segmentos como los humanos digitales, y negando rumores de venta de equipos centrales a Alibaba Cloud. Si bien es pragmático—con el objetivo de monetizar más rápido en un mercado saturado—refleja la admisión de que competir directamente en IA fundamental era insostenible, quedando por debajo de la visión original de "dar a China su momento ChatGPT".

5.  **Presiones Económicas y del Mercado más Amplias**
    El ciclo de hype de la IA se ha enfriado a nivel global, con los inversores exigiendo caminos más rápidos hacia los ingresos ante los altos costes de entrenamiento y el escrutinio regulatorio. 01.AI recaudó 300 millones de dólares pero enfrentó presión para generar retornos, lo que llevó a un enfoque en precios como 0,99 RMB (0,14 dólares) por millón de tokens para modelos como Yi-Lightning. Además, la adopción empresarial de modelos de código abierto ha sido irregular, con muchos prefiriendo a actores establecidos. Lee destacó en entrevistas que la IA en 2025 priorizaría las aplicaciones sobre la experimentación, pero esto tuvo el costo de reducir el ambicioso alcance de Yi.

### Estado Actual y Perspectivas
A mediados de 2025, 01.AI es estable pero transformada: Se proyecta que será rentable pronto, con unos 90 empleados y una valoración mantenida de mil millones de dólares. Los modelos Yi todavía están disponibles en plataformas como Hugging Face, pero las actualizaciones se han ralentizado, y la compañía ahora enfatiza las plataformas de IA 2.0 para generar valor económico en China. Si bien no es un fracaso—Yi ayudó a cerrar las brechas de IA entre EE. UU. y China e inspiró esfuerzos de código abierto—no logró el impacto revolucionario esperado, en gran parte debido a los factores anteriores. De cara al futuro, el éxito dependerá de ejecutar la estrategia centrada en aplicaciones en medio de las continuas tensiones tecnológicas entre EE. UU. y China.

[Kr Asia: Kai-Fu Lee sets the record straight on 01.AI's pivot](https://kr-asia.com/kai-fu-lee-sets-the-record-straight-on-01-ais-pivot)  
[Tech in Asia: Kai-Fu Lee's 01.AI restructures and spins off key segments](https://www.techinasia.com/news/kai-fu-lees-01-ai-restructures-and-spins-off-key-segments)  
[Turing Post: How Kai-Fu Lee Shapes the AI Narrative in Both the U.S. and China](https://www.turingpost.com/p/01ai)  
[Yicai Global: Kai-Fu Lee Denies Report His 01.AI Startup Plans to Sell Pre-Training Team](https://www.yicaiglobal.com/news/01ai-isnt-selling-pre-training-team-to-alibabas-cloud-computing-arm-founder-says)  
[WIRED: Chinese Startup 01.AI Is Winning the Open Source AI Race](https://www.wired.com/story/chinese-startup-01-ai-is-winning-the-open-source-ai-race/)  
[TechCrunch: Valued at $1B, Kai-Fu Lee's LLM startup unveils open source model](https://techcrunch.com/2023/11/05/valued-at-1b-kai-fu-lees-llm-startup-unveils-open-source-model/)  
[SCMP: Tech unicorn 01.AI admits 'oversight' in naming AI model built on Meta's LLaMA](https://www.scmp.com/tech/tech-trends/article/3241680/chinese-tech-unicorn-01ai-admits-oversight-changing-name-ai-model-built-meta-platforms-llama-system)  
[Wikipedia: 01.AI](https://en.wikipedia.org/wiki/01.AI)  
[PitchBook: 01.AI 2025 Company Profile](https://pitchbook.com/profiles/company/532966-69)