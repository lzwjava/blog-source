---
audio: false
generated: true
image: false
lang: es
layout: post
title: Desglose Simplificado del Costo de Mistral Medium 3.1
translated: true
type: note
---

Me preguntas cuán "costoso" es Mistral Medium 3.1 — entendido. Permíteme desglosarlo claramente, sin el desorden.

---

## Precio de Mistral Medium 3.1

Según los datos más recientes:

*   Los **tokens de entrada** cuestan **\$0.40 por 1 millón de tokens**.
*   Los **tokens de salida** cuestan **\$2.00 por 1 millón de tokens**.
    ([Mistral AI][1])

Algunas fuentes presentan un promedio combinado — alrededor de **\$0.80 por millón de tokens**, asumiendo una proporción típica de 3:1 de entradas a salidas (es decir, 3 unidades de entrada por cada 1 unidad de salida).
([Artificial Analysis][2])

---

## ¿Eso es "Costoso"?

**Depende de con qué lo compares**:

*   En comparación con modelos de gama alta como GPT‑4, esto es muy económico — Mistral Medium 3 (y por extensión 3.1) ofrece un rendimiento cercano al estado del arte con un coste hasta **8 veces menor**.
    ([Mistral AI][3])

*   Una métrica interna de eficiencia muestra que ofrece un razonamiento al nivel de GPT‑4 por aproximadamente **el 20 % del coste**, lo que lo convierte en una opción económica para cargas de trabajo serias de IA.
    ([Mistral AI][1])

*   En una comparación puramente basada en tokens: si envías 1 millón de tokens, pagas \$0.40. Cuando el modelo responde con 1 millón de tokens, eso son \$2.00 más. Un intercambio equilibrado de 3:1 podría promediar alrededor de \$0.80 por millón de tokens — sigue siendo bastante razonable.
    ([Artificial Analysis][2])

---

### Conclusión

*   **¿Es Mistral Medium 3.1 caro?**
    **En realidad, no.** Ofrece un rendimiento de alta gama por una fracción del coste de modelos premium como GPT-4.

*   **Los costes por token son modestos** — \$0.40 para entradas y \$2.00 para salidas por millón de tokens, con un promedio de alrededor de \$0.80 si se asume una mezcla normal.

---

¿Te gustaría calcular los números para tu uso previsto (como si envías 10,000 tokens por prompt o esperas ciertas longitudes de respuesta)? Solo dilo — ¡puedo ayudarte a estimarlo!

[1]: https://iamistral.com/pricing/?utm_source=chatgpt.com "Mistral AI Pricing"
[2]: https://artificialanalysis.ai/models/mistral-medium-3-1?utm_source=chatgpt.com "Mistral Medium 3.1 - Intelligence, Performance & Price ..."
[3]: https://mistral.ai/news/mistral-medium-3?utm_source=chatgpt.com "Medium is the new large."