---
audio: false
generated: false
lang: es
layout: post
title: Introducci√≥n al Aprendizaje Autom√°tico (Machine Learning)
translated: true
---

Ya que estamos aprendiendo `Python`, tambi√©n es imprescindible hablar sobre aprendizaje autom√°tico (machine learning). Esto se debe a que muchas de sus bibliotecas est√°n escritas en Python. Para empezar, vamos a instalarlas y jugar un poco con ellas.

## TensorFlow

TensorFlow es una biblioteca de c√≥digo abierto desarrollada por Google para el aprendizaje autom√°tico y la inteligencia artificial. Es ampliamente utilizada para construir y entrenar modelos de aprendizaje profundo, como redes neuronales, y es compatible con una variedad de lenguajes de programaci√≥n, siendo Python el m√°s com√∫n. TensorFlow ofrece una gran flexibilidad y escalabilidad, lo que lo convierte en una herramienta esencial para investigadores y desarrolladores en el campo de la inteligencia artificial.

Inst√°lalo.

```shell
$ pip install tensorflow
ERROR: No se pudo encontrar una versi√≥n que satisfaga el requisito tensorflow
ERROR: No se encontr√≥ ninguna distribuci√≥n compatible para tensorflow
```

```shell
$ type python
python es un alias de `/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'
```

Sin embargo, `Tensorflow 2` solo es compatible con `Python 3.5‚Äì3.8`. Nosotros estamos usando `3.9`.

```shell
% type python3
python3 es /usr/bin/python3
% python3 -V
Python 3.8.2
```

Not√© que la versi√≥n de `python3` en mi sistema es `3.8.2`. ¬øD√≥nde se instala el `pip` correspondiente a esta versi√≥n de Python?

```shell
% python3 -m pip -V
pip 21.0.1 from /Users/lzw/Library/Python/3.8/lib/python/site-packages/pip (python 3.8)
```

El `pip` correspondiente est√° aqu√≠. Entonces voy a modificar el archivo `.zprofile`. Recientemente cambi√© mi `shell`. `.zprofile` es equivalente al antiguo `.bash_profile`. Agrego una l√≠nea.

```shell
alias pip3=/Users/lzw/Library/Python/3.8/bin/pip3
```

De esta manera, usamos `python3` y `pip3` para trabajar con `Tensorflow`.

```shell
% pip3 install tensorflow
...
Instalaci√≥n exitosa de absl-py-0.12.0 astunparse-1.6.3 cachetools-4.2.1 certifi-2020.12.5 chardet-4.0.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.27.1 google-auth-oauthlib-0.4.3 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 idna-2.10 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.15.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.3 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1
```

He instalado muchas bibliotecas. Utilic√© un ejemplo de la p√°gina oficial.

```python
import tensorflow as tf
```

mnist = tf.keras.datasets.mnist

```python
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
```

```python
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])
```

```python
predictions = model(x_train[:1]).numpy()
print(predictions)
```

El texto que has proporcionado es solo un bloque de c√≥digo vac√≠o. Si necesitas traducir algo espec√≠fico dentro de ese bloque o si hay m√°s contenido que necesitas traducir, por favor proporciona m√°s detalles. ¬°Estoy aqu√≠ para ayudarte! üòä

Ejec√∫talo.

```shell
$ /usr/bin/python3 tf.py
Descargando datos desde https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 10s 1us/paso
[[ 0.15477428 -0.3877643   0.0994779   0.07474922 -0.26219758 -0.03550266
   0.32226565 -0.37141111  0.10925996 -0.0115255 ]]
```

Se puede ver que se descarg√≥ el conjunto de datos y luego se gener√≥ el resultado.

A continuaci√≥n, veamos un ejemplo de clasificaci√≥n de im√°genes.

```python
# TensorFlow y tf.keras
import tensorflow as tf
```

# Bibliotecas auxiliares
import numpy as np
import matplotlib.pyplot as plt

```python
print(tf.__version__)
```

Error.

```shell
ModuleNotFoundError: No module named 'matplotlib'
```

*Nota: El mensaje de error no se traduce, ya que es un mensaje t√©cnico en ingl√©s que se utiliza com√∫nmente en el entorno de programaci√≥n.*

Inst√°lalo.

```shell
% pip3 install matplotlib
```

Correcto.

```shell
$ /usr/bin/python3 image.py
2.4.1
```

Ejemplo de c√≥digo para copiar y pegar.

```python
# TensorFlow y tf.keras
import tensorflow as tf
```

# Bibliotecas auxiliares
import numpy as np
import matplotlib.pyplot as plt

```python
fashion_mnist = tf.keras.datasets.fashion_mnist
```

```python
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
```

```python
class_names = ['Camiseta/top', 'Pantal√≥n', 'Jersey', 'Vestido', 'Abrigo',
               'Sandalia', 'Camisa', 'Zapatilla', 'Bolso', 'Bota de tobillo']
print(train_images.shape)
print(len(train_labels))
```

Se generaron los resultados. Observa que aqu√≠ tenemos `train_images`, `train_labels`, `test_images`, `test_labels`. Esto significa que los datos est√°n divididos en un conjunto de entrenamiento y un conjunto de prueba.

```shell
(60000, 28, 28)
60000
```

*Nota: El texto dentro del bloque de c√≥digo no se traduce, ya que es un formato espec√≠fico que no debe ser alterado.*

A continuaci√≥n, intentemos imprimir la imagen.

```python
print(train_images[0])
```

Mira los resultados.

```shell
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0
    0   1   4   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62
   54   0   0   0   1   3   4   0   0   3]
 [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134
  144 123  23   0   0   0   0  12  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178
  107 156 161 109  64  23  77 130  72  15]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216
  216 163 127 121 122 146 141  88 172  66]]
  ....
```

Aqu√≠ se presenta un extracto de los resultados.

```python
print(len(train_images[0][0]))
```

Se imprime `28`. As√≠ que est√° claro que es una matriz con un ancho de 28. Continuemos imprimiendo.

```python
    print(len(train_images[0][0][0])
TypeError: el objeto de tipo 'numpy.uint8' no tiene len()
```

Entonces, est√° bastante claro. Cada imagen es una matriz de `28*28*3`. La √∫ltima dimensi√≥n de la matriz almacena los valores de rgb. Sin embargo, nos dimos cuenta de que nuestra idea podr√≠a estar equivocada.

```python
print(train_images[0][1][20])
```

```shell
0
```

```python
print(train_images[0][1])
```

```shell
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
```

Cada imagen es una matriz de 28*28. Despu√©s de jugar un rato, finalmente descubrimos el secreto.

Primero, echemos un vistazo a la gr√°fica generada.

```python
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()
```

<img src="/assets/images/ml/tf.png" alt="tf" style="zoom:30%;" />

¬øVes la barra de colores a la derecha? `0` a `250`. Originalmente, esto es un degradado entre dos colores. Pero, ¬øc√≥mo sabe cu√°les son esos dos colores? ¬øD√≥nde se lo dijimos?

Luego, tambi√©n imprimimos la segunda imagen.

```python
plt.imshow(train_images[1])
```

<img src="/assets/images/ml/plt.png" alt="plt" style="zoom:30%;" />

Es muy interesante. ¬øSer√° esto algo predeterminado de las bibliotecas dependientes de `pyplot`? Sigamos ejecutando el c√≥digo proporcionado en el sitio web oficial.

```python
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()
```

<img src="/assets/images/ml/tf2.png" alt="tf2" style="zoom:20%;" />

Observa que aqu√≠ se muestran las im√°genes junto con sus categor√≠as. Finalmente, hemos descubierto el par√°metro `cmp`. Si no escribimos nada en `cmp`, definitivamente obtendremos el mismo esquema de colores que ten√≠amos antes. Efectivamente.

```shell
    plt.imshow(train_images[i])
```

<img src="/assets/images/ml/cmap.png" alt="cmap" style="zoom:20%;" />

En esta ocasi√≥n, buscamos `pyplot cmap`. Encontramos algunos recursos.

```shell
    plt.imshow(train_images[i], cmap=plt.cm.PiYG)
```

<img src="/assets/images/ml/cmap1.png" alt="cmap1" style="zoom:20%;" />

Modifica el c√≥digo.
```python
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)   ## Cambia esta l√≠nea
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.Blues)
    plt.xlabel(class_names[train_labels[i]])
plt.show()
```

Sin embargo, ocurri√≥ un error.

```shell
ValueError: num debe ser 1 <= num <= 10, no 11
```

¬øQu√© significa esto? ¬øQu√© significa exactamente el `5,5,i+1` anterior? ¬øPor qu√© no funciona cuando se cambia a `2`? Aunque intuitivamente sabemos que probablemente significa 5 filas y 5 columnas, ¬øpor qu√© se produce este error? ¬øC√≥mo se calcula el `11`? ¬øQu√© significa `num`? ¬øQu√© significa el `10`? Notamos que `2*5=10`. Entonces, tal vez el error ocurre cuando `i=11`. Cuando se cambia a `for i in range(10):`, se obtienen los siguientes resultados.

<img src="/assets/images/ml/plot3.png" alt="plot3" style="zoom:20%;" />

Esto es un vistazo r√°pido a la documentaci√≥n, donde aprendemos que `subplot(nrows, ncols, index, **kwargs)`. Mmm, hasta aqu√≠ lo tenemos bastante claro.

```python
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    # plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.Blues)
    plt.xlabel(class_names[train_labels[i]])
plt.show()
```

<img src="/assets/images/ml/plot_xticks.png" alt="plot_xticks" style="zoom:30%;" />

Nota que `0 25` se llama `xticks`. Cuando ampliamos o reducimos este cuadro, se mostrar√° de manera diferente.

![plot_scale](assets/images/ml/plot_scale.png)

Observa que al hacer zoom o reducir el cuadro, los `xticks` y `xlabels` se mostrar√°n de manera diferente.

```python
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])
```

```python
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

model.fit(train_images, train_labels, epochs=10)

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)

```python
print('\nPrecisi√≥n en la prueba:', test_acc)
```

Observa la forma en que se define el modelo aqu√≠, utilizando la clase `Sequential`. Presta atenci√≥n a estos par√°metros: `28,28`, `128`, `relu`, `10`. Nota que es necesario `compile` y `fit`. `fit` significa ajustar o entrenar el modelo. Observa que `28,28` corresponde al tama√±o de la imagen.

```shell
√âpoca 1/10
1875/1875 [==============================] - 2s 928us/paso - p√©rdida: 0.6331 - precisi√≥n: 0.7769
√âpoca 2/10
1875/1875 [==============================] - 2s 961us/paso - p√©rdida: 0.3860 - precisi√≥n: 0.8615
√âpoca 3/10
1875/1875 [==============================] - 2s 930us/paso - p√©rdida: 0.3395 - precisi√≥n: 0.8755
√âpoca 4/10
1875/1875 [==============================] - 2s 1ms/paso - p√©rdida: 0.3071 - precisi√≥n: 0.8890
√âpoca 5/10
1875/1875 [==============================] - 2s 1ms/paso - p√©rdida: 0.2964 - precisi√≥n: 0.8927
√âpoca 6/10
1875/1875 [==============================] - 2s 985us/paso - p√©rdida: 0.2764 - precisi√≥n: 0.8955
√âpoca 7/10
1875/1875 [==============================] - 2s 961us/paso - p√©rdida: 0.2653 - precisi√≥n: 0.8996
√âpoca 8/10
1875/1875 [==============================] - 2s 1ms/paso - p√©rdida: 0.2549 - precisi√≥n: 0.9052
√âpoca 9/10
1875/1875 [==============================] - 2s 1ms/paso - p√©rdida: 0.2416 - precisi√≥n: 0.9090
√âpoca 10/10
1875/1875 [==============================] - 2s 1ms/paso - p√©rdida: 0.2372 - precisi√≥n: 0.9086
313/313 - 0s - p√©rdida: 0.3422 - precisi√≥n: 0.8798
```

Precisi√≥n de la prueba: 0.879800021648407
```

El modelo ya ha sido entrenado. Vamos a ajustar los par√°metros.

```shell
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(28, activation='relu'),    # 128 -> 28
    tf.keras.layers.Dense(10)
])
```

Modifica el primer par√°metro de `Dense`.

```shell
√âpoca 1/10
1875/1875 [==============================] - 2s 714us/paso - p√©rdida: 6.9774 - precisi√≥n: 0.3294
√âpoca 2/10
1875/1875 [==============================] - 1s 715us/paso - p√©rdida: 1.3038 - precisi√≥n: 0.4831
√âpoca 3/10
1875/1875 [==============================] - 1s 747us/paso - p√©rdida: 1.0160 - precisi√≥n: 0.6197
√âpoca 4/10
1875/1875 [==============================] - 1s 800us/paso - p√©rdida: 0.7963 - precisi√≥n: 0.6939
√âpoca 5/10
1875/1875 [==============================] - 2s 893us/paso - p√©rdida: 0.7006 - precisi√≥n: 0.7183
√âpoca 6/10
1875/1875 [==============================] - 1s 747us/paso - p√©rdida: 0.6675 - precisi√≥n: 0.7299
√âpoca 7/10
1875/1875 [==============================] - 1s 694us/paso - p√©rdida: 0.6681 - precisi√≥n: 0.7330
√âpoca 8/10
1875/1875 [==============================] - 1s 702us/paso - p√©rdida: 0.6675 - precisi√≥n: 0.7356
√âpoca 9/10
1875/1875 [==============================] - 1s 778us/paso - p√©rdida: 0.6508 - precisi√≥n: 0.7363
√âpoca 10/10
1875/1875 [==============================] - 1s 732us/paso - p√©rdida: 0.6532 - precisi√≥n: 0.7350
313/313 - 0s - p√©rdida: 0.6816 - precisi√≥n: 0.7230
```

Precisi√≥n de la prueba: 0.7229999899864197
```

Se observa un cambio en la `Test accuracy` antes y despu√©s. `Epoch` es un registro de salida de la funci√≥n `fit`. Notamos que cuando el valor es `128`, la `accuracy` cambia de `0.7769` a `0.9086`. Mientras que cuando es `28`, la `accuracy` cambia de `0.3294` a `0.7350`. Esto nos lleva a notar que primero utilizamos el conjunto de entrenamiento para ajustar el `loss` y la `accuracy`. Luego, usamos el conjunto de prueba para evaluar. Primero, echemos un vistazo a `train_labels`.

```python
print(train_labels)
[9 0 0 ... 3 0 5]
print(len(train_labels))
60000
```

Esto significa que se utilizan los n√∫meros del `0 al 9` para representar estas categor√≠as. Coincidentemente, `class_names` tambi√©n tiene 10 elementos.

```shell
class_names = ['Camiseta', 'Pantal√≥n', 'Jersey', 'Vestido', 'Abrigo',
               'Sandalia', 'Camisa', 'Zapatilla', 'Bolso', 'Bota tobillera']
```

Vamos a hacer algunos cambios m√°s.

```python
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(28, activation='relu'),
    tf.keras.layers.Dense(5)   # 10 -> 5
])
```

```python
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

```python
model.fit(train_images, train_labels, epochs=10)
```

Se produjo un error.

```shell
tensorflow.python.framework.errors_impl.InvalidArgumentError: Se recibi√≥ un valor de etiqueta de 9 que est√° fuera del rango v√°lido de [0, 5). Valores de etiqueta: 4 3 2 9 4 1 6 0 7 9 1 6 5 2 3 8 6 3 8 0 3 5 6 1 2 6 3 6 8 4 8 4
         [[nodo sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (definido en /curiosity-courses/ml/tf/image.py:53) ]] [Op:__inference_train_function_538]
```

Pila de llamadas de funciones:
train_function
```

Cambia el tercer par√°metro de `Sequential`, que es `Dense`, a `15` y eso deber√≠a funcionar. La diferencia en los resultados no ser√° significativa. Prueba tambi√©n ajustar el valor de `Epoch`.

```python
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(28, activation='relu'),
    tf.keras.layers.Dense(15)
])
```

```python
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

En este c√≥digo, el modelo se compila utilizando el optimizador 'adam', la funci√≥n de p√©rdida `SparseCategoricalCrossentropy` (con `from_logits=True`) y se mide la precisi√≥n (`accuracy`) como m√©trica.

model.fit(train_images, train_labels, epochs=15)  # 10 -> 15

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)

```python
print('\nPrecisi√≥n en la prueba:', test_acc)
```

```shell
√âpoca 1/15
1875/1875 [==============================] - 2s 892us/paso - p√©rdida: 6.5778 - precisi√≥n: 0.3771
√âpoca 2/15
1875/1875 [==============================] - 2s 872us/paso - p√©rdida: 1.3121 - precisi√≥n: 0.4910
√âpoca 3/15
1875/1875 [==============================] - 2s 909us/paso - p√©rdida: 1.0900 - precisi√≥n: 0.5389
√âpoca 4/15
1875/1875 [==============================] - 1s 730us/paso - p√©rdida: 1.0422 - precisi√≥n: 0.5577
√âpoca 5/15
1875/1875 [==============================] - 1s 709us/paso - p√©rdida: 0.9529 - precisi√≥n: 0.5952
√âpoca 6/15
1875/1875 [==============================] - 1s 714us/paso - p√©rdida: 0.9888 - precisi√≥n: 0.5950
√âpoca 7/15
1875/1875 [==============================] - 1s 767us/paso - p√©rdida: 0.8678 - precisi√≥n: 0.6355
√âpoca 8/15
1875/1875 [==============================] - 1s 715us/paso - p√©rdida: 0.8247 - precisi√≥n: 0.6611
√âpoca 9/15
1875/1875 [==============================] - 1s 721us/paso - p√©rdida: 0.8011 - precisi√≥n: 0.6626
√âpoca 10/15
1875/1875 [==============================] - 1s 711us/paso - p√©rdida: 0.8024 - precisi√≥n: 0.6622
√âpoca 11/15
1875/1875 [==============================] - 1s 781us/paso - p√©rdida: 0.7777 - precisi√≥n: 0.6696
√âpoca 12/15
1875/1875 [==============================] - 1s 724us/paso - p√©rdida: 0.7764 - precisi√≥n: 0.6728
√âpoca 13/15
1875/1875 [==============================] - 1s 731us/paso - p√©rdida: 0.7688 - precisi√≥n: 0.6767
√âpoca 14/15
1875/1875 [==============================] - 1s 715us/paso - p√©rdida: 0.7592 - precisi√≥n: 0.6793
√âpoca 15/15
1875/1875 [==============================] - 1s 786us/paso - p√©rdida: 0.7526 - precisi√≥n: 0.6792
313/313 - 0s - p√©rdida: 0.8555 - precisi√≥n: 0.6418
```

Precisi√≥n de la prueba: 0.6417999863624573
```

Nota: Cambi√© a 15. La diferencia no es grande. `tf.keras.layers.Dense(88, activation='relu'),` es importante. Intent√© cambiar 128 a 88. Obtuve `Test accuracy: 0.824999988079071`. Con 128, fue `0.879800021648407`. Con 28, fue `0.7229999899864197`. ¬øEs mejor cuanto m√°s grande sea? Sin embargo, cuando lo cambi√© a `256`, fue `Test accuracy: 0.8409000039100647`. Esto nos hace reflexionar sobre el significado de `loss` y `accuracy`.

```python
probability_model = tf.keras.Sequential([model, 
                                         tf.keras.layers.Softmax()])
```

A continuaci√≥n, vamos a hacer una predicci√≥n. Observa que `Sequential` es igual que antes. F√≠jate en los par√°metros `model` y `tf.keras.layers.Softmax()`.

```python
probability_model = tf.keras.Sequential([model, 
                                         tf.keras.layers.Softmax()])
predictions = probability_model.predict(test_images)
```

```python
def plot_image(i, predictions_array, true_label, img):
  true_label, img = true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
```

```python
plt.imshow(img, cmap=plt.cm.binary)
```

```python
predicted_label = np.argmax(predictions_array)
if predicted_label == true_label:
    color = 'blue'
else:
    color = 'red'
```

```python
plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)
```

Traducci√≥n:

```python
plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)
```

En este caso, el c√≥digo no necesita ser traducido, ya que es una l√≠nea de c√≥digo en Python que utiliza variables y funciones espec√≠ficas. Sin embargo, si deseas una explicaci√≥n en espa√±ol, ser√≠a algo como:

```python
plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)
```

Aqu√≠, `plt.xlabel` est√° configurando la etiqueta del eje x de un gr√°fico. La etiqueta se forma utilizando el nombre de la clase predicha (`class_names[predicted_label]`), el porcentaje de confianza de la predicci√≥n (`100*np.max(predictions_array)`), y el nombre de la clase real (`class_names[true_label]`). El color de la etiqueta se establece con el par√°metro `color`.

```python
def plot_value_array(i, predictions_array, true_label):
  true_label = true_label[i]
  plt.grid(False)
  plt.xticks(range(10))
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)
```

```python
thisplot[predicted_label].set_color('rojo')
thisplot[true_label].set_color('azul')
```

```python
i = 0
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions[i], test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions[i],  test_labels)
plt.show()  
```

<img src="/assets/images/ml/pred.png" alt="pred" style="zoom:50%;" />

Esto indica que hay un 99% de probabilidad de que la imagen sea una `Ankle boot`. Observa que `plot_image` muestra la imagen de la izquierda, mientras que `plot_value_array` genera el gr√°fico de la derecha.

```python
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions[i], test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions[i], test_labels)
plt.tight_layout()
plt.show()
```

<img src="/assets/images/ml/pred1.png" alt="pred1" style="zoom:50%;" />

Observa que aqu√≠ solo se muestran m√°s resultados de pruebas. Por lo tanto, el flujo de uso lo tenemos bastante claro. Sin embargo, a√∫n no sabemos c√≥mo se calcula detr√°s de escena. Pero sabemos c√≥mo usarlos. Detr√°s de ellos est√° el c√°lculo. ¬øC√≥mo entender el c√°lculo?

Por ejemplo, hay un n√∫mero entre 1 y 100 que tienes que adivinar. Cada vez que adivinas, te digo si es m√°s peque√±o o m√°s grande. Adivinas 50. Te digo que es m√°s peque√±o. Adivinas 80. Te digo que es m√°s grande. Adivinas 65. Te digo que es m√°s grande. Adivinas 55. Te digo que es m√°s peque√±o. Adivinas 58. Te digo, "¬°S√≠, has adivinado correctamente!"

El aprendizaje autom√°tico, en esencia, simula un proceso similar en segundo plano. Solo que es un poco m√°s complejo. Podr√≠a haber muchos n√∫meros entre `1 y 100`, y se deben adivinar muchos n√∫meros. Adem√°s, cada vez que se adivina, se realizan muchos c√°lculos. Y cada vez que se determina si el n√∫mero es mayor o menor, tambi√©n se realizan muchos c√°lculos.



## PyTorch

Inst√°lalo. Esto es compatible con Python versi√≥n `3.9`.

```shell
$ pip install torch torchvision
Collecting torch
  Descargando torch-1.8.0-cp39-none-macosx_10_9_x86_64.whl (120.6 MB)
     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120.6 MB 224 kB/s
Collecting torchvision
  Descargando torchvision-0.9.0-cp39-cp39-macosx_10_9_x86_64.whl (13.1 MB)
     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13.1 MB 549 kB/s
Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from torch) (1.20.1)
Collecting typing-extensions
  Descargando typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)
Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.9/site-packages (from torchvision) (8.0.1)
Installing collected packages: typing-extensions, torch, torchvision
Successfully installed torch-1.8.0 torchvision-0.9.0 typing-extensions-3.7.4.3
```

Verif√≠calo.

```python
import torch
x = torch.rand(5, 3)
print(x)
```

Se produjo un error.

```shell
Traceback (most recent call last):
  File "torch.py", line 1, in <module>
    import torch
  File "torch.py", line 2, in <module>
    x = torch.rand(5, 3)
AttributeError: el m√≥dulo 'torch' est√° parcialmente inicializado y no tiene el atributo 'rand' (probablemente debido a una importaci√≥n circular)
```

Busqu√© el mensaje de error en Google. Resulta que el problema era porque nuestro archivo tambi√©n se llamaba `torch`. Hab√≠a un conflicto de nombres. Lo cambi√© y luego funcion√≥ correctamente.

```shell
tensor([[0.5520, 0.9446, 0.5543],
        [0.6192, 0.0908, 0.8726],
        [0.0223, 0.7685, 0.9814],
        [0.4019, 0.5406, 0.3861],
        [0.5485, 0.6040, 0.2387]])
```

Encontr√© un ejemplo.

```python
# -*- coding: utf-8 -*-
```

```python
import torch
import math
dtype = torch.float
device = torch.device("cpu")
# device = torch.device("cuda:0") # Descomenta esto para ejecutar en GPU
```

# Crear datos de entrada y salida aleatorios
x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)
y = torch.sin(x)

# Inicializar pesos aleatoriamente
a = torch.randn((), device=device, dtype=dtype)
b = torch.randn((), device=device, dtype=dtype)
c = torch.randn((), device=device, dtype=dtype)
d = torch.randn((), device=device, dtype=dtype)

```python
learning_rate = 1e-6
for t in range(2000):
    # Paso hacia adelante: calcular la predicci√≥n y
    y_pred = a + b * x + c * x ** 2 + d * x ** 3
```

    # Calcular e imprimir la p√©rdida
    loss = (y_pred - y).pow(2).sum().item()
    if t % 100 == 99:
        print(t, loss)

    # Retropropagaci√≥n para calcular los gradientes de a, b, c, d con respecto a la p√©rdida
    grad_y_pred = 2.0 * (y_pred - y)
    grad_a = grad_y_pred.sum()
    grad_b = (grad_y_pred * x).sum()
    grad_c = (grad_y_pred * x ** 2).sum()
    grad_d = (grad_y_pred * x ** 3).sum()

    # Actualizar pesos usando el descenso de gradiente
    a -= learning_rate * grad_a
    b -= learning_rate * grad_b
    c -= learning_rate * grad_c
    d -= learning_rate * grad_d
print(f'Resultado: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')
```

Ejec√∫talo.

```shell
99 1273.537353515625
199 849.24853515625
299 567.4786987304688
399 380.30291748046875
499 255.92752075195312
599 173.2559814453125
699 118.2861328125
799 81.72274780273438
899 57.39331817626953
999 41.198158264160156
1099 30.41307830810547
1199 23.227672576904297
1299 18.438262939453125
1399 15.244369506835938
1499 13.113286972045898
1599 11.690631866455078
1699 10.740333557128906
1799 10.105220794677734
1899 9.6804780960083
1999 9.39621353149414
Resultado: y = -0.011828352697193623 + 0.8360244631767273 x + 0.002040589228272438 x^2 + -0.09038365632295609 x^3
```

Aqu√≠ tienes el c√≥digo utilizando solo la biblioteca `numpy`:

```python
import numpy as np

# Crear un array de ejemplo
array = np.array([1, 2, 3, 4, 5])

# Realizar operaciones b√°sicas
suma = np.sum(array)
media = np.mean(array)
maximo = np.max(array)

print("Suma:", suma)
print("Media:", media)
print("M√°ximo:", maximo)
```

Este c√≥digo crea un array con `numpy`, realiza algunas operaciones b√°sicas como la suma, la media y el valor m√°ximo, y luego imprime los resultados.

```python
# -*- coding: utf-8 -*-
import numpy as np
import math
```

# Crear datos de entrada y salida aleatorios
x = np.linspace(-math.pi, math.pi, 2000)
y = np.sin(x)

# Inicializar pesos aleatoriamente
a = np.random.randn()
b = np.random.randn()
c = np.random.randn()
d = np.random.randn()

```python
learning_rate = 1e-6
for t in range(2000):
    # Paso hacia adelante: calcular la y predicha
    # y = a + b x + c x^2 + d x^3
    y_pred = a + b * x + c * x ** 2 + d * x ** 3
```

    # Calcular e imprimir la p√©rdida
    loss = np.square(y_pred - y).sum()
    if t % 100 == 99:
        print(t, loss)

    # Retropropagaci√≥n para calcular los gradientes de a, b, c, d con respecto a la p√©rdida
    grad_y_pred = 2.0 * (y_pred - y)
    grad_a = grad_y_pred.sum()
    grad_b = (grad_y_pred * x).sum()
    grad_c = (grad_y_pred * x ** 2).sum()
    grad_d = (grad_y_pred * x ** 3).sum()

    # Actualizar pesos
    a -= learning_rate * grad_a
    b -= learning_rate * grad_b
    c -= learning_rate * grad_c
    d -= learning_rate * grad_d

```python
print(f'Resultado: y = {a} + {b} x + {c} x^2 + {d} x^3')
```

Observa que hay dos formas de calcularlo.

En estos dos ejemplos, primero se genera un conjunto de valores para `x` e `y`. Luego, se asume que se trata de una ecuaci√≥n c√∫bica. A continuaci√≥n, se utilizan algunos m√©todos para calcular iterativamente los coeficientes. ¬øC√≥mo son estos algoritmos? Observa que se realiza un ciclo de `2000` iteraciones, y en cada una de ellas se ajusta con mayor precisi√≥n. Por ahora, no entraremos en detalles sobre esto.

## Finalmente

Actualmente, no entendemos c√≥mo se realizan los c√°lculos detr√°s del aprendizaje autom√°tico. Sin embargo, por el momento, eso no es importante. Con el conocimiento similar al que hemos mencionado anteriormente, ya podemos hacer muchas cosas. Tambi√©n podemos utilizar el aprendizaje autom√°tico para procesar texto, audio, etc. Cuando hayamos explorado docenas de ejemplos, ser√° el momento adecuado para aprender los principios.

## Pr√°ctica

* Los estudiantes exploran de la manera mencionada anteriormente.