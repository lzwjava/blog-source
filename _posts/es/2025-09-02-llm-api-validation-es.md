---
audio: false
generated: true
image: false
lang: es
layout: post
title: Capas de Validaci칩n de API de LLM Segura
translated: true
type: note
---

Al construir o utilizar una **API de LLM**, generalmente querr치s salvaguardas para garantizar que las respuestas sean seguras, v치lidas y 칰tiles. Estas son las principales formas de agregar verificaciones:

---

### 1. **Validaci칩n de Entrada**

* **Comprobaciones de esquema**: Aseg칰rate de que el JSON de la solicitud siga el esquema esperado antes de enviarlo al LLM.
* **Saneamiento del prompt**: Elimina o escapa caracteres no deseados, instrucciones maliciosas o intentos de inyecci칩n.
* **Comprobaciones de longitud**: Aplica l칤mites m치ximos de tokens/caracteres para las entradas para evitar costos innecesarios o truncamiento.

---

### 2. **Validaci칩n de Salida**

* **Validaci칩n de esquema JSON**: Si se supone que el LLM devuelve JSON, p치salo por `json.loads()` y val칤dalo contra un esquema (por ejemplo, con `pydantic`, `jsonschema`).
* **Comprobaciones de Regex/formato**: Para correos electr칩nicos, URLs o n칰meros, aplica patrones.
* **Comprobaci칩n de tipos**: Verifica que los campos sean del tipo correcto (string, integer, list, etc.).
* **Comprobaciones de rango**: Aseg칰rate de que los valores num칠ricos o de fecha est칠n dentro de los l칤mites esperados.

---

### 3. **Comprobaciones de Seguridad y Contenido**

* **Filtros de toxicidad o blasfemias**: Pasa la salida por un clasificador (por ejemplo, Perspective API, OpenAI moderation API).
* **Filtros de pol칤ticas**: Define reglas para bloquear respuestas que contengan ciertas palabras clave o categor칤as.
* **Detecci칩n de alucinaciones**: A침ade pasos de verificaci칩n de hechos (mediante comprobaciones aumentadas por recuperaci칩n, validaci칩n cruzada con m칰ltiples modelos o comprobaciones de coherencia basadas en reglas).

---

### 4. **Restricciones de L칩gica de Negocio**

* **Reglas de consistencia**: Si la respuesta debe coincidir con datos del sistema (por ejemplo, saldo de cuenta disponible, valores de configuraci칩n), verifica cruzadamente antes de devolverla al usuario.
* **Barreras de protecci칩n**: Usa bibliotecas como **Guardrails AI**, **LMQL** o **Instructor** para aplicar salidas estructuradas y restricciones de forma declarativa.
* **Hooks de post-procesamiento**: Envuelve las respuestas del LLM con l칩gica personalizada (normalizar may칰sculas y min칰sculas, aplicar valores predeterminados, rechazar respuestas inesperadas).

---

### 5. **Redundancia y Verificaci칩n Cruzada**

* **Prompts de auto-comprobaci칩n**: Pide al LLM que vuelva a validar o explique su propia respuesta.
* **Comprobaci칩n con doble modelo**: Usa un LLM m치s peque침o/r치pido para verificar la salida del modelo principal (por ejemplo, "쯘sta respuesta se ajusta al esquema X?").
* **Votaci칩n/consenso**: Ejecuta m칰ltiples llamadas y compara las respuestas para verificar estabilidad.

---

### 6. **Salvaguardas Operativas**

* **L칤mites de tasa**: Previene el abuso de la API.
* **Tiempos de espera**: Aborta las solicitudes que se cuelgan.
* **Registro y auditor칤a de trazas**: Mant칠n un registro de las solicitudes y respuestas filtradas.
* **Alternativas de respaldo**: Si la validaci칩n falla, reintenta con un prompt ajustado o devuelve un valor predeterminado/error seguro.

---

游녤 En la pr치ctica, una buena pila de API de LLM aplica estos en capas:

1. Valida la entrada.
2. Llama al LLM.
3. Valida la salida contra el esquema + reglas de negocio.
4. Ejecuta filtros de seguridad/contenido.
5. Devuelve la respuesta solo si las comprobaciones son exitosas (de lo contrario, reintenta/usar alternativa).

---

쯊e gustar칤a que te muestre un **ejemplo en Python** donde envolvemos una llamada a la API de un LLM con validaci칩n de esquema JSON y comprobaciones de moderaci칩n?