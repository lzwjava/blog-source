---
lang: es
layout: post
title: '# C√≥mo Funciona una Red Neuronal


  Las redes neuronales son una de las tecnolog√≠as m√°s fascinantes en el campo de la
  inteligencia artificial. Inspiradas en el funcionamiento del cerebro humano, estas
  redes son capaces de aprender y realizar tareas complejas, como reconocer im√°genes,
  traducir idiomas o incluso jugar videojuegos. Pero, ¬øc√≥mo funcionan exactamente?
  Vamos a desglosarlo paso a paso.


  ## 1. **Estructura B√°sica de una Red Neuronal**


  Una red neuronal est√° compuesta por capas de **neuronas artificiales** (tambi√©n
  llamadas nodos o unidades). Estas capas se dividen en tres tipos principales:


  - **Capa de Entrada (Input Layer):** Recibe los datos iniciales, como p√≠xeles de
  una imagen o palabras de un texto.

  - **Capas Ocultas (Hidden Layers):** Realizan la mayor parte del procesamiento.
  Aqu√≠ es donde ocurre la "magia" del aprendizaje.

  - **Capa de Salida (Output Layer):** Proporciona el resultado final, como una clasificaci√≥n
  o una predicci√≥n.


  Cada neurona en una capa est√° conectada a las neuronas de la siguiente capa mediante
  **pesos** (weights). Estos pesos determinan la importancia de cada conexi√≥n.


  ## 2. **Propagaci√≥n hacia Adelante (Forward Propagation)**


  El proceso comienza con la **propagaci√≥n hacia adelante**. Los datos de entrada
  se multiplican por los pesos y se suman, luego se aplica una **funci√≥n de activaci√≥n**
  para introducir no linealidad en el sistema. Esto permite que la red aprenda patrones
  complejos.


  Por ejemplo, si estamos trabajando con una red neuronal simple, el c√°lculo en una
  neurona podr√≠a verse as√≠:


  ```python

  z = (input1 * weight1) + (input2 * weight2) + bias

  output = activation_function(z)

  ```


  La funci√≥n de activaci√≥n m√°s com√∫n es la **ReLU (Rectified Linear Unit)**, que devuelve
  el valor m√°ximo entre 0 y la entrada.


  ## 3. **Funci√≥n de P√©rdida (Loss Function)**


  Una vez que la red ha producido una salida, necesitamos medir cu√°n buena o mala
  es esa predicci√≥n. Para ello, utilizamos una **funci√≥n de p√©rdida**. Esta funci√≥n
  compara la salida de la red con el valor real (etiqueta) y calcula el error.


  Por ejemplo, en un problema de clasificaci√≥n, podr√≠amos usar la **entrop√≠a cruzada**
  (cross-entropy) como funci√≥n de p√©rdida.


  ## 4. **Retropropagaci√≥n (Backpropagation)**


  Aqu√≠ es donde entra en juego el aprendizaje. La **retropropagaci√≥n** es el proceso
  de ajustar los pesos de la red para minimizar la funci√≥n de p√©rdida. Esto se hace
  utilizando el **descenso de gradiente**, que calcula c√≥mo cambiar los pesos para
  reducir el error.


  El gradiente se calcula utilizando la regla de la cadena, y los pesos se actualizan
  de la siguiente manera:


  ```python

  new_weight = old_weight - learning_rate * gradient

  ```


  El **tasa de aprendizaje (learning rate)** es un hiperpar√°metro que controla cu√°nto
  ajustamos los pesos en cada paso.


  ## 5. **Entrenamiento**


  El proceso de **entrenamiento** consiste en repetir los pasos de propagaci√≥n hacia
  adelante, c√°lculo de la p√©rdida y retropropagaci√≥n muchas veces (√©pocas) hasta que
  la red neuronal aprende a hacer predicciones precisas.


  ## 6. **Evaluaci√≥n y Predicci√≥n**


  Una vez entrenada, la red neuronal puede usarse para hacer predicciones sobre nuevos
  datos. Esto se conoce como **inferencia**. La red toma los datos de entrada, realiza
  la propagaci√≥n hacia adelante y produce una salida sin necesidad de ajustar los
  pesos.


  ## Conclusi√≥n


  Las redes neuronales son herramientas poderosas que imitan el funcionamiento del
  cerebro humano para resolver problemas complejos. Aunque el proceso puede parecer
  complicado, se basa en principios matem√°ticos s√≥lidos y en la iteraci√≥n continua
  para mejorar el rendimiento. Con el tiempo y los datos adecuados, una red neuronal
  puede aprender a realizar tareas incre√≠blemente precisas.


  ¬°Y eso es todo! Ahora tienes una idea b√°sica de c√≥mo funciona una red neuronal.
  ¬øListo para construir la tuya? üöÄ'
usemathjax: true
---

Hablemos directamente del n√∫cleo del funcionamiento de las redes neuronales. Es decir, el algoritmo de retropropagaci√≥n:

1. **Entrada x**: Establece la activaci√≥n correspondiente $$a^{1}$$ para la capa de entrada.
2. **Propagaci√≥n hacia adelante**: Para cada l=2,3,‚Ä¶,L, calcula $$z^{l} = w^l a^{l-1}+b^l$$ y $$a^{l} = \sigma(z^{l})$$.
3. **Error de salida $$\delta^{L}$$**: Calcula el vector $$\delta^{L} = \nabla_a C \odot \sigma'(z^L)$$.
4. **Retropropagaci√≥n del error**: Para cada l=L‚àí1,L‚àí2,‚Ä¶,2, calcula $$\delta^{l} = ((w^{l+1})^T \delta^{l+1}) \odot \sigma'(z^{l})$$.
5. **Salida**: El gradiente de la funci√≥n de costo est√° dado por $$\frac{\partial C}{\partial w^l_{jk}} = a^{l-1}_k \delta^l_j$$ y $$\frac{\partial C}{\partial b^l_j} = \delta^l_j$$.

Esto est√° copiado del libro *Neural Networks and Deep Learning* de Michael Nelson. ¬øTe parece abrumador? Puede serlo la primera vez que lo ves. Pero no lo ser√° despu√©s de un mes de estudio alrededor de ello. Perm√≠teme explicar.

## Entrada

Hay 5 fases. La primera fase es la Entrada. Aqu√≠ utilizamos d√≠gitos escritos a mano como entrada. Nuestra tarea es reconocerlos. Un d√≠gito escrito a mano tiene 784 p√≠xeles, que es 28*28. En cada p√≠xel, hay un valor de escala de grises que va de 0 a 255. La activaci√≥n significa que utilizamos alguna funci√≥n para activarlo, para cambiar su valor original a un nuevo valor con el fin de facilitar el procesamiento.

Digamos que ahora tenemos 1000 im√°genes de 784 p√≠xeles. Ahora entrenamos el programa para que reconozca qu√© d√≠gito muestran. Tenemos 100 im√°genes para probar ese efecto de aprendizaje. Si el programa puede reconocer los d√≠gitos de 97 im√°genes, decimos que su precisi√≥n es del 97%.

Entonces, iterar√≠amos sobre las 1000 im√°genes para entrenar los pesos y los sesgos. Hacemos que los pesos y los sesgos sean m√°s correctos cada vez que le damos una nueva imagen para que aprenda.

El resultado de un entrenamiento por lotes debe reflejarse en 10 neuronas. Aqu√≠, las 10 neuronas representan los n√∫meros del 0 al 9, y su valor var√≠a entre 0 y 1 para indicar su confianza en la precisi√≥n de la predicci√≥n.

Y la entrada es de 784 neuronas. ¬øC√≥mo podemos reducir 784 neuronas a 10 neuronas? Aqu√≠ est√° la cosa. Supongamos que tenemos dos capas. ¬øQu√© significa la capa? Esa es la primera capa, tenemos 784 neuronas. En la segunda capa, tenemos 10 neuronas.

Le damos a cada neurona en las 784 neuronas un peso, digamos,

$$w_1, w_2, w_3, w_4, ... , w_{784}$$

Y dale a la primera capa un sesgo, es decir, $$b_1$$.

Y as√≠, para la primera neurona en la segunda capa, su valor es:

$$w_1*a_1 + w_2*a_2+...+ w_{784}*a_{784}+b_1$$

Pero estos pesos y un sesgo son para $$neuron^2_{1}$$ (el primero en la segunda capa). Para $$neuron^2_{2}$$, necesitamos otro conjunto de pesos y un sesgo.

¬øQu√© tal la funci√≥n sigmoide? Usamos la funci√≥n sigmoide para mapear el valor anterior de 0 a 1.

$$
\begin{eqnarray} 
  \sigma(z) \equiv \frac{1}{1+e^{-z}}
\end{eqnarray}
$$

$$
\begin{eqnarray} 
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)}
\end{eqnarray}
$$

Tambi√©n utilizamos la funci√≥n sigmoide para activar la primera capa. Dicho esto, transformamos ese valor de escala de grises al rango de 0 a 1. As√≠ que ahora, cada neurona en cada capa tiene un valor entre 0 y 1.

Entonces, para nuestra red de dos capas, la primera capa tiene 784 neuronas y la segunda capa tiene 10 neuronas. La entrenamos para obtener los pesos y los sesgos.

Tenemos 784 * 10 pesos y 10 sesgos. En la segunda capa, para cada neurona, utilizaremos 784 pesos y 1 sesgo para calcular su valor. El c√≥digo aqu√≠ es como,

```python
    def __init__(self, sizes):
        self.num_layers = len(sizes)
        self.sizes = sizes
        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]
        self.weights = [np.random.randn(y, x)
                        for x, y in zip(sizes[:-1], sizes[1:])]
```

## Feedforward

El t√©rmino **feedforward** se refiere a un proceso en el que la informaci√≥n fluye en una direcci√≥n, desde la entrada hacia la salida, sin retroalimentaci√≥n. Este concepto es ampliamente utilizado en diversos campos, como la ingenier√≠a, la inteligencia artificial y la teor√≠a de control.

En el contexto de las redes neuronales, el **feedforward** es un tipo de arquitectura en la que las se√±ales se mueven en una sola direcci√≥n, desde la capa de entrada, a trav√©s de las capas ocultas, hasta la capa de salida. Este tipo de red se conoce como **red neuronal feedforward** y es la base de muchas aplicaciones de aprendizaje autom√°tico.

### Ejemplo de una Red Neuronal Feedforward

```python
import numpy as np

# Definir la funci√≥n de activaci√≥n (sigmoide)
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Definir la derivada de la funci√≥n sigmoide
def sigmoid_derivative(x):
    return x * (1 - x)

# Datos de entrada
inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])

# Salidas esperadas
expected_output = np.array([[0], [1], [1], [0]])

# Inicializar pesos aleatoriamente
np.random.seed(42)
weights = np.random.rand(2, 1)

# Tasa de aprendizaje
learning_rate = 0.1

# Entrenamiento de la red
for epoch in range(10000):
    # Feedforward
    input_layer = inputs
    outputs = sigmoid(np.dot(input_layer, weights))

    # C√°lculo del error
    error = expected_output - outputs

    # Ajuste de pesos usando el gradiente descendente
    adjustments = error * sigmoid_derivative(outputs)
    weights += np.dot(input_layer.T, adjustments) * learning_rate

print("Salidas despu√©s del entrenamiento:")
print(outputs)
```

En este ejemplo, la red neuronal feedforward aprende a realizar la operaci√≥n XOR a trav√©s del proceso de entrenamiento. La informaci√≥n fluye en una sola direcci√≥n, desde la entrada hasta la salida, sin retroalimentaci√≥n.

### Aplicaciones del Feedforward

- **Reconocimiento de patrones**: Las redes feedforward son ampliamente utilizadas en tareas de reconocimiento de im√°genes y voz.
- **Predicci√≥n**: Se utilizan para predecir resultados basados en datos de entrada, como en modelos de regresi√≥n.
- **Clasificaci√≥n**: Son eficaces en tareas de clasificaci√≥n, como la detecci√≥n de spam o la categorizaci√≥n de textos.

El feedforward es un concepto fundamental en el dise√±o de sistemas que requieren un flujo de informaci√≥n unidireccional y es la base de muchas tecnolog√≠as modernas.

> Propagaci√≥n hacia adelante: Para cada l=2,3,‚Ä¶,L calcula $$z^{l} = w^l a^{l-1}+b^l$$ y $$a^{l} = \sigma(z^{l})$$

Observa aqu√≠ que utilizamos el valor de la √∫ltima capa, es decir, $$a^{l-1}$$, junto con el peso de la capa actual, $$w^l$$, y su sesgo $$b^l$$, para aplicar la funci√≥n sigmoide y obtener el valor de la capa actual, $$a^{l}$$.

C√≥digo:

```python
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        # propagaci√≥n hacia adelante
        activation = x
        activations = [x] 
        zs = [] 
        for b, w in zip(self.biases, self.weights):
            z = np.dot(w, activation)+b
            zs.append(z)
            activation = sigmoid(z)
            activations.append(activation)
```
## Error de salida

> Error de salida $$\delta^{L}$$: Calcular el vector $$\delta^{L} = \nabla_a C \odot \sigma'(z^L)$$

Veamos qu√© significa $$\nabla$$.

> Del, o nabla, es un operador utilizado en matem√°ticas (especialmente en c√°lculo vectorial) como un operador diferencial vectorial, generalmente representado por el s√≠mbolo nabla ‚àá.

$$
\begin{eqnarray}
  w_k & \rightarrow & w_k' = w_k-\eta \frac{\partial C}{\partial w_k} \\
  b_l & \rightarrow & b_l' = b_l-\eta \frac{\partial C}{\partial b_l}
\end{eqnarray}
$$

Aqu√≠ $$\eta $$ es la tasa de aprendizaje. Utilizamos la derivada de C con respecto a los pesos y el sesgo, es decir, la tasa de cambio entre ellos. Esto es `sigmoid_prime` en el siguiente c√≥digo.

C√≥digo:

```python
        delta = self.cost_derivative(activations[-1], y) * \
            sigmoid_prime(zs[-1])
        nabla_b[-1] = delta
        nabla_w[-1] = np.dot(delta, activations[-2].transpose())
```

*Nota: El c√≥digo proporcionado no necesita traducci√≥n, ya que es un bloque de c√≥digo en Python y los nombres de variables y funciones deben mantenerse en ingl√©s para mantener la funcionalidad del programa.*

```python
    def cost_derivative(self, output_activations, y):
        return (output_activations-y)
```

En este bloque de c√≥digo, la funci√≥n `cost_derivative` calcula la derivada de la funci√≥n de costo con respecto a las activaciones de salida. La derivada se obtiene restando el valor objetivo `y` de las activaciones de salida `output_activations`. Este resultado se utiliza com√∫nmente en el proceso de retropropagaci√≥n para ajustar los pesos de la red neuronal.

## Retropropagar el error

> Retropropagar el error: Para cada l=L‚àí1,L‚àí2,‚Ä¶,2, calcular $$\delta^{l} = ((w^{l+1})^T \delta^{l+1}) \odot \sigma'(z^{l})$$

```python
     for l in range(2, self.num_layers):
            z = zs[-l]
            sp = sigmoid_prime(z)
            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp
            nabla_b[-l] = delta
            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())
        return (nabla_b, nabla_w)
```

## Salida

> Salida: El gradiente de la funci√≥n de costo est√° dado por $$\frac{\partial C}{\partial w^l_{jk}} = a^{l-1}_k \delta^l_j$$
y $$\frac{\partial C}{\partial b^l_j} = \delta^l_j $$

```python
    def update_mini_batch(self, mini_batch, eta):
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        for x, y in mini_batch:
            delta_nabla_b, delta_nabla_w = self.backprop(x, y)
            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
        self.weights = [w-(eta/len(mini_batch))*nw
                        for w, nw in zip(self.weights, nabla_w)]
        self.biases = [b-(eta/len(mini_batch))*nb
                       for b, nb in zip(self.biases, nabla_b)]
```

## Final

Es un art√≠culo corto. Y en su mayor parte, solo muestra el c√≥digo y la f√≥rmula matem√°tica. Pero para m√≠ est√° bien. Antes de escribirlo, no lo entend√≠a claramente. Despu√©s de escribirlo o simplemente copiar fragmentos de c√≥digo y del libro, entiendo la mayor parte. Despu√©s de ganar confianza gracias al profesor Yin Wang, leer alrededor del 30% del libro *Neural Networks and Deep Learning*, escuchar las conferencias de Andrej Karpathy en Stanford y los cursos de Andrew Ng, discutir con mi amigo Qi, y ajustar las bibliotecas de Anaconda, numpy y Theano para hacer funcionar el c√≥digo de hace a√±os, ahora lo entiendo.

Uno de los puntos clave son las dimensiones. Debemos conocer las dimensiones de cada s√≠mbolo y variable. Y simplemente realiza el c√°lculo diferenciable. Terminemos con las citas de Yin Wang:

> El aprendizaje autom√°tico es realmente √∫til, incluso se podr√≠a decir que es una teor√≠a hermosa, ¬°porque simplemente es c√°lculo despu√©s de un cambio de imagen! Es la antigua y gran teor√≠a de Newton y Leibniz, pero en una forma m√°s simple, elegante y poderosa. B√°sicamente, el aprendizaje autom√°tico es el uso del c√°lculo para derivar y ajustar algunas funciones, y el aprendizaje profundo es el ajuste de funciones m√°s complejas.

> No hay 'inteligencia' en la inteligencia artificial, no hay 'neural' en las redes neuronales, no hay 'aprendizaje' en el aprendizaje autom√°tico, y no hay 'profundidad' en el aprendizaje profundo. No hay 'profundidad' en el aprendizaje profundo. Lo que realmente funciona en este campo se llama 'c√°lculo'. Por eso prefiero llamar a este campo 'computaci√≥n diferenciable', y el proceso de construir modelos se llama 'programaci√≥n diferenciable'.