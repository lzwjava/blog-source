---
audio: false
generated: true
lang: es
layout: post
title: Problema de Proxy de Stable Diffusion
translated: true
type: note
---

Seg煤n el error y tu entorno, aqu铆 tienes c贸mo solucionar el problema "Unknown scheme for proxy URL":

### Soluci贸n:
El error ocurre porque **`httpx` no admite proxies `socks://` por defecto**. Tienes dos opciones:

#### Opci贸n 1: Eliminar la Referencia al Proxy SOCKS
1. Revisa tus variables de entorno en busca de configuraciones de proxy sobrantes:
   ```bash
   env | grep -i proxy
   ```
   Busca referencias a `socks://` (especialmente `ALL_PROXY` o `http_proxy`).

2. Anula la variable problem谩tica (reemplaza `VAR_NAME` con el nombre real encontrado arriba):
   ```bash
   unset VAR_NAME  # ej., unset ALL_PROXY
   ```

#### Opci贸n 2: Agregar Soporte SOCKS a `httpx`
1. Activa tu entorno virtual de Python:
   ```bash
   source /home/lzw/Projects/stable-diffusion-webui/venv/bin/activate
   ```

2. Instala las dependencias requeridas:
   ```bash
   pip install -U "httpx[socks]"
   ```

3. Desactiva el entorno:
   ```bash
   deactivate
   ```

### Por qu茅 sucede esto:
- Tus proxies principales (`HTTP_PROXY/HTTPS_PROXY`) usan `http://` (compatible), pero algo (probablemente otra aplicaci贸n/script) est谩 estableciendo un proxy `socks://` que `httpx` no puede manejar sin paquetes adicionales.
- El stack trace muestra que Gradio/`httpx` est谩 intentando usar `socks://127.0.0.1:7891`, que no aparece en tu salida de `checkproxy`.

### Verificaci贸n:
Despu茅s de aplicar la soluci贸n, ejecuta:
```bash
./webui.sh
```
El error del proxy SOCKS deber铆a desaparecer.

>  **Nota**: Si no configuraste intencionalmente un proxy SOCKS, investiga qu茅 aplicaciones podr铆an configurar proxies autom谩ticamente (ej., VPNs, gestores de red o archivos de configuraci贸n del shell como `~/.bashrc`).

---

El error `Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check` indica que PyTorch, utilizado por Stable Diffusion WebUI, no puede detectar o acceder a una GPU compatible. Esto probablemente se deba a bibliotecas CUDA faltantes, una GPU incompatible, problemas con los controladores o un problema de configuraci贸n. A continuaci贸n se presentan los pasos para solucionar este problema, adaptados a tu entorno (glibc 2.35, Python 3.10.12, GCC 11.4.0, probablemente basado en Ubuntu 22.04 seg煤n la versi贸n de glibc).

### Pasos para Solucionar el Problema

#### 1. **Verificar la Compatibilidad de la GPU y CUDA**
   - **Comprobar si tienes una GPU NVIDIA**:
     Ejecuta:
     ```bash
     lspci | grep -i nvidia
     ```
     Esto lista el hardware NVIDIA. Si no aparece nada, es posible que tu sistema no tenga una GPU NVIDIA, y PyTorch requiere una GPU NVIDIA para el soporte CUDA.
   - **Comprobar la instalaci贸n del controlador NVIDIA**:
     Ejecuta:
     ```bash
     nvidia-smi
     ```
     Si est谩 instalado, muestra una tabla con detalles de la GPU (ej., versi贸n del controlador, versi贸n de CUDA). Si no, instala el controlador NVIDIA:
     ```bash
     sudo apt-get update
     sudo apt-get install nvidia-driver-<version> nvidia-utils-<version> -y
     ```
     Reemplaza `<version>` con el controlador estable m谩s reciente (ej., `535` o `550`). Encuentra la versi贸n del controlador apropiada con:
     ```bash
     ubuntu-drivers devices
     sudo ubuntu-drivers autoinstall
     ```
   - **Comprobar la versi贸n de CUDA**:
     PyTorch requiere bibliotecas CUDA. Comprueba la versi贸n de CUDA instalada:
     ```bash
     nvcc --version
     ```
     Si no est谩 instalado, instala CUDA Toolkit:
     ```bash
     sudo apt-get install nvidia-cuda-toolkit -y
     ```
     Alternativamente, descarga el 煤ltimo CUDA Toolkit del sitio web de NVIDIA (ej., CUDA 11.8 o 12.1) y sigue su gu铆a de instalaci贸n.

#### 2. **Verificar la Instalaci贸n de PyTorch**
   El error sugiere que PyTorch est谩 instalado pero no puede usar la GPU. Aseg煤rate de tener la versi贸n correcta de PyTorch con soporte CUDA.
   - **Comprobar la instalaci贸n de PyTorch**:
     Ejecuta:
     ```bash
     python3 -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"
     ```
     La salida esperada debe incluir una versi贸n de PyTorch (ej., `2.0.1`) y `True` para `torch.cuda.is_available()`. Si es `False`, PyTorch no est谩 detectando la GPU.
   - **Reinstalar PyTorch con soporte CUDA**:
     Para Python 3.10 y CUDA (ej., 11.8), instala PyTorch en tu entorno de Stable Diffusion:
     ```bash
     cd /home/lzw/Projects/stable-diffusion-webui
     source venv/bin/activate
     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
     ```
     Reemplaza `cu118` con tu versi贸n de CUDA (ej., `cu121` para CUDA 12.1). Consulta las versiones compatibles en el sitio oficial de PyTorch.
   - **Verificar despu茅s de la reinstalaci贸n**:
     Ejecuta la comprobaci贸n nuevamente:
     ```bash
     python3 -c "import torch; print(torch.cuda.is_available()); print(torch.cuda.get_device_name(0))"
     ```

#### 3. **Omitir la Comprobaci贸n CUDA (Soluci贸n Temporal)**
   Si deseas ejecutar Stable Diffusion sin soporte de GPU (ej., para pruebas en CPU), omite la comprobaci贸n CUDA agregando `--skip-torch-cuda-test` a los argumentos de la l铆nea de comandos.
   - Edita `webui-user.sh` (o cr茅alo si no existe):
     ```bash
     nano /home/lzw/Projects/stable-diffusion-webui/webui-user.sh
     ```
     Agrega o modifica la l铆nea `COMMANDLINE_ARGS`:
     ```bash
     export COMMANDLINE_ARGS="--skip-torch-cuda-test"
     ```
     Guarda y sale.
   - Ejecuta el script:
     ```bash
     ./webui.sh
     ```
     Esto permite que Stable Diffusion se ejecute en CPU, pero el rendimiento ser谩 significativamente m谩s lento.

#### 4. **Asegurar que TCMalloc est茅 Configurado Correctamente**
   Tu salida muestra que TCMalloc (`libtcmalloc_minimal.so.4`) est谩 detectado y enlazado con `LD_PRELOAD`. Confirma que funciona:
   ```bash
   echo $LD_PRELOAD
   ```
   Si muestra `/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4`, est谩 listo. Si no, config煤ralo manualmente:
   ```bash
   export LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
   ```
   O agr茅galo a `webui-user.sh`:
   ```bash
   export LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
   ```

#### 5. **Comprobar Variables de Entorno y Rutas**
   Aseg煤rate de que tu entorno est茅 configurado correctamente:
   - **Comprobar LD_LIBRARY_PATH**:
     Las bibliotecas CUDA deben ser accesibles. Agr茅galas si es necesario:
     ```bash
     export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
     ```
     Agrega esto a `~/.bashrc` o `webui-user.sh` para que sea persistente.
   - **Activar el entorno virtual**:
     Siempre activa el entorno virtual de Stable Diffusion antes de ejecutar:
     ```bash
     cd /home/lzw/Projects/stable-diffusion-webui
     source venv/bin/activate
     ```

#### 6. **Actualizar Stable Diffusion WebUI**
   Tu versi贸n (`v1.10.1`, commit `82a973c`) podr铆a tener problemas de compatibilidad. Actualiza a la 煤ltima versi贸n:
   ```bash
   cd /home/lzw/Projects/stable-diffusion-webui
   git pull
   ```
   Luego, reinstala las dependencias:
   ```bash
   ./webui.sh
   ```

#### 7. **Resoluci贸n de Problemas**
   - **Si `nvidia-smi` falla**: Reinstala el controlador NVIDIA o comprueba si hay problemas de hardware con la GPU.
   - **Si PyTorch a煤n no detecta la GPU**:
     - Aseg煤rate de que CUDA y cuDNN est茅n instalados correctamente. Instala cuDNN si falta:
       ```bash
       sudo apt-get install libcudnn8
       ```
     - Verifica la compatibilidad de la versi贸n de CUDA con tu GPU y PyTorch. Por ejemplo, las GPU antiguas (ej., serie Kepler) pueden no ser compatibles con CUDA 12.
   - **Si los errores persisten**: Revisa los logs de Stable Diffusion para obtener errores detallados:
     ```bash
     cat /home/lzw/Projects/stable-diffusion-webui/log/webui.log
     ```
     Comparte cualquier error espec铆fico para obtener m谩s ayuda.
   - **Limitaciones de hardware**: Si tu GPU es demasiado antigua (ej., GPU NVIDIA anteriores a 2016), puede que no sea compatible con versiones modernas de CUDA. En este caso, usa `--skip-torch-cuda-test` o actualiza tu GPU.

#### 8. **Ejecutar la Aplicaci贸n**
   Despu茅s de aplicar las soluciones, ejecuta la WebUI:
   ```bash
   cd /home/lzw/Projects/stable-diffusion-webui
   ./webui.sh
   ```
   Si solucionaste el problema de la GPU, el error deber铆a desaparecer. Si usas `--skip-torch-cuda-test`, se ejecutar谩 en CPU.

### Notas
- **Informaci贸n del Sistema**: Tu configuraci贸n (glibc 2.35, Python 3.10.12, GCC 11.4.0) sugiere Ubuntu 22.04, que es compatible con CUDA 11.8 o 12.1 y versiones recientes de PyTorch.
- **Rendimiento**: Ejecutar en CPU (con `--skip-torch-cuda-test`) es un recurso, pero ser谩 lento. Se recomienda solucionar el soporte de la GPU para Stable Diffusion.
- **TCMalloc**: El problema de TCMalloc parece resuelto seg煤n tu salida. Aseg煤rate de que `LD_PRELOAD` permanezca configurado si encuentras problemas relacionados con la memoria.

Si a煤n enfrentas problemas o necesitas ayuda con mensajes de error espec铆ficos, 隆proporciona detalles adicionales (ej., modelo de GPU, versi贸n de CUDA o logs completos) y puedo refinar la soluci贸n!