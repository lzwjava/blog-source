---
audio: false
generated: true
image: false
lang: es
layout: post
title: Bibliotecas y Paquetes CUDA
translated: true
type: note
---

Aquí tienes un resumen rápido de cada paquete que estás instalando:

*   **nvidia-cusparselt-cu12**
    Biblioteca cuSPARSELt de NVIDIA para operaciones ultra eficientes con matrices dispersas de baja precisión en CUDA 12.

*   **nvidia-cusparse-cu12**
    Biblioteca cuSPARSE que proporciona rutinas generales de álgebra lineal dispersa (por ejemplo, resolvedores dispersos) en CUDA 12.

*   **nvidia-cudnn-cu12**
    Biblioteca cuDNN que ofrece primitivas altamente optimizadas (convoluciones, pooling, activaciones, etc.) para redes neuronales profundas en CUDA 12.

*   **nvidia-cublas-cu12**
    Biblioteca cuBLAS que implementa rutinas de alto rendimiento para álgebra lineal densa (BLAS) en CUDA 12.

*   **nvidia-cufft-cu12**
    Biblioteca cuFFT para calcular transformadas rápidas de Fourier en dispositivos con CUDA 12.

*   **nvidia-cusolver-cu12**
    Biblioteca cuSOLVER con rutinas para resolvedores directos densos y dispersos, problemas de valores propios, etc., en CUDA 12.

*   **nvidia-curand-cu12**
    Biblioteca cuRAND para la generación de números aleatorios de alta calidad en CUDA 12.

*   **nvidia-cufile-cu12**
    Biblioteca cuFile que permite E/S de archivos directa y asíncrona acelerada por GPU en CUDA 12.

*   **nvidia-nvtx-cu12**
    NVTX (NVIDIA Tools Extension) para anotar y perfilar rangos de código en CUDA 12.

*   **nvidia-nvjitlink-cu12**
    Biblioteca NVJITLink para enlazar kernels CUDA JIT en tiempo de ejecución en CUDA 12.

*   **nvidia-cuda-nvrtc-cu12**
    Compilador en tiempo de ejecución NVRTC para compilar kernels de CUDA C sobre la marcha en CUDA 12.

*   **nvidia-cuda-cupti-cu12**
    CUPTI (CUDA Profiling Tools Interface) para recopilar datos de profiling y tracing detallados en CUDA 12.

*   **nvidia-cuda-runtime-cu12**
    La biblioteca principal del runtime de CUDA para gestionar y lanzar kernels en CUDA 12.

*   **nvidia-nccl-cu12**
    Biblioteca NCCL que proporciona primitivas eficientes de comunicación colectiva multi-GPU y multi-nodo en CUDA 12.

*   **torch**
    La biblioteca principal de PyTorch para operaciones con tensores, diferenciación automática y construcción de modelos de aprendizaje profundo.

*   **networkx**
    Un paquete de Python para crear, manipular y analizar redes y estructuras de grafos complejas.

*   **mpmath**
    Una biblioteca en Python puro para aritmética real y compleja de precisión arbitraria.

*   **sympy**
    Una biblioteca de Python para matemáticas simbólicas (álgebra, cálculo, resolución de ecuaciones, etc.).

*   **triton**
    Un lenguaje y compilador que te permite escribir kernels GPU personalizados y de alto rendimiento más fácilmente que con CUDA directo.