---
audio: false
generated: true
lang: es
layout: post
title: 'Mistral NeMo: Potente LLM de 12 000 Millones de Parámetros'
translated: true
type: note
---

**Mistral NeMo** es un potente modelo de lenguaje grande (LLM) de 12 mil millones de parámetros desarrollado por **Mistral AI en colaboración con NVIDIA**. Está diseñado para ofrecer capacidades de procesamiento de lenguaje natural de vanguardia, destacándose especialmente en razonamiento, conocimiento del mundo y precisión en codificación dentro de su categoría de tamaño.

Estas son algunas características y aspectos clave de Mistral NeMo:

*   **12 Mil Millones de Parámetros:** Esto lo convierte en un modelo relativamente compacto pero altamente capaz, que equilibra rendimiento y eficiencia.
*   **Ventana de Contexto Grande:** Posee una ventana de contexto de hasta 128k tokens, lo que le permite procesar y comprender textos mucho más largos, documentos complejos y conversaciones multiturno de manera más efectiva.
*   **Rendimiento de Vanguardia:** Mistral NeMo establece un nuevo estándar para modelos de su clase de tamaño, demostrando un fuerte rendimiento en tareas relacionadas con el razonamiento, el conocimiento general del mundo y la generación de código.
*   **Soporte Multilingüe:** Diseñado para aplicaciones globales, es competente en muchos idiomas, incluidos inglés, francés, alemán, español, italiano, portugués, chino, japonés, coreano, árabe e hindi.
*   **Tokenizer Tekken:** Utiliza un nuevo tokenizador llamado Tekken (basado en Tiktoken), que es más eficiente para comprimir texto de lenguaje natural y código fuente en más de 100 idiomas en comparación con tokenizadores anteriores.
*   **Function Calling:** El modelo está entrenado en function calling, mejorando su capacidad para interactuar y ejecutar funciones programáticas específicas basadas en entradas de lenguaje natural.
*   **Conciencia de Cuantización:** Entrenado con conciencia de cuantización, permite inferencia FP8 sin comprometer el rendimiento, lo cual es crucial para un despliegue eficiente.
*   **Licencia de Código Abierto:** Mistral NeMo se publica bajo la licencia Apache 2.0, promoviendo la adopción generalizada, la personalización y la integración por parte de investigadores y empresas.
*   **Fácil Integración:** Su arquitectura estándar facilita su uso como un reemplazo directo para sistemas que ya utilizan Mistral 7B.
*   **Colaboración con NVIDIA:** El modelo fue entrenado en la plataforma de IA NVIDIA DGX Cloud y utiliza el ecosistema optimizado de hardware y software de NVIDIA, incluyendo TensorRT-LLM para un rendimiento de inferencia acelerado y la plataforma de desarrollo NeMo para construir modelos de IA generativa personalizados. También está disponible como un microservicio de inferencia NVIDIA NIM.

En esencia, Mistral NeMo pretende proporcionar un LLM versátil, de alto rendimiento y eficiente que pueda ejecutarse en una sola GPU, haciendo que las capacidades avanzadas de IA sean más accesibles para una amplia gama de aplicaciones empresariales como chatbots, resumen, traducción de idiomas y generación de código.