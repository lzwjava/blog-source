---
audio: false
generated: true
image: false
lang: fr
layout: post
model: x-ai/grok-4-fast
title: Historique de la publication et de l'open source de GPT-2
translated: true
type: note
---

### Article sur GPT-2
L'article sur GPT-2, intitulé « Language Models are Unsupervised Multitask Learners », a été publié le 14 février 2019, en même temps que le premier article de blog d'OpenAI annonçant le modèle.

### Publication en open source
GPT-2 a fait l'objet d'une publication échelonnée en raison de préoccupations concernant une utilisation potentielle abusive :
- **Petit modèle (124M paramètres)** : Publié le 14 février 2019.
- **Modèle moyen (355M paramètres)** : Publié en juillet 2019.
- **Gros modèle (774M paramètres)** : Publié le 20 août 2019.
- **Modèle complet (1.5B paramètres) et code open source** : Publiés le 5 novembre 2019, rendant les poids complets et l'implémentation publiquement disponibles sur GitHub.

Références :  
[Better language models and their implications](https://openai.com/index/better-language-models/)  
[GPT-2: 1.5B release](https://openai.com/index/gpt-2-1-5b-release/)