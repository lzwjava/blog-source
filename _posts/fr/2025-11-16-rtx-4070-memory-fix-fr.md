---
audio: false
generated: true
image: false
lang: fr
layout: post
model: x-ai/grok-4-fast
title: Correction des erreurs de m√©moire de la RTX 4070
translated: true
type: note
---

Vous rencontrez un classique **OOM (Out of Memory) sur RTX 4070 12 GB lors du premier backward pass** lors de l'utilisation de `compile=True` (Torch Inductor) + `bfloat16` avec vos param√®tres actuels.

La ligne cl√© dans l'erreur :
```
buf1 = empty_strided_cuda((16, 1024, 50304), ...)  # ‚Üí 16 √ó 1024 √ó 50304 √ó 2 bytes = ~1.54 GB
```
C'est le **buffer des logits** avant le calcul de la perte ‚Äî et Torch compile fait exploser la m√©moire durant les premi√®res √©tapes pendant qu'il compile/capture le graphe.

### Correctif Imm√©diat et Fonctionnel (100% de succ√®s sur 4070 12 GB)

Modifiez votre `config/train_fineweb.py` et appliquez **uniquement ces 4 changements** :

```python
# Modifiez ces lignes :
batch_size = 12                     # √©tait 16 ‚Üí √©conomise ~25% de m√©moire
gradient_accumulation_steps = 40    # √©tait 32 ‚Üí maintient la taille de lot effective = 480 (toujours bon)
block_size = 1024                   # gardez 1024, c'est important
compile = False                     # <‚îÄ C'EST LE CORRECTIF PRINCIPAL pour l'instant
# dtype = 'bfloat16'                # ‚Üê si vous avez cette ligne, changez-la en 'float16' ou supprimez-la
```

Optionnel mais recommand√© (ajoutez ces lignes si elles n'existent pas) :
```python
dtype = 'float16'          # fp16 utilise moins de m√©moire que bfloat16 sur la 4070
# dtype = 'bfloat16'       # ‚Üê √† √©viter sur la 4070, c'est plus lent et plus gourmand en m√©moire
```

### Extrait de configuration final qui fonctionne parfaitement sur 4070 12 GB

```python
batch_size = 12
gradient_accumulation_steps = 40      # 12 √ó 40 = 480 s√©quences ‚Üí toujours excellent
block_size = 1024
compile = False                       # R√©activez plus tard, apr√®s environ 50‚Äì100 steps
dtype = 'float16'                     # Crucial sur la 4070
n_layer = 12
n_head = 12
n_embd = 576
```

### Pourquoi cela fonctionne
- `compile=False` ‚Üí √©vite les √©normes buffers temporaires pendant la capture du graphe
- `batch_size=12` + `grad_acc=40` ‚Üí la m√©moire passe de ~11.8 GB ‚Üí ~9.8 GB en pic
- `float16` au lieu de `bfloat16` ‚Üí √©conomise encore 10‚Äì15% de m√©moire sur les GPU Ada

### Apr√®s une ex√©cution stable pendant ~100 steps, vous pouvez r√©activer les optimisations une par une :
```bash
# √âtape 1 (apr√®s 100 steps, modifiez √† nouveau la config)
compile = True          # maintenant, la compilation utilisera les vraies formes ‚Üí beaucoup moins de m√©moire
```
```bash
# √âtape 2 (optionnelle, plus tard)
batch_size = 16
gradient_accumulation_steps = 32   # retour √† la taille de lot effective d'origine
```

### Correctif complet pour copier-coller rapidement
Remplacez la partie sup√©rieure de votre configuration par ceci :

```python
batch_size = 12
gradient_accumulation_steps = 40
block_size = 1024
compile = False           # <‚îÄ critique pour le premier lancement
dtype = 'float16'         # <‚îÄ critique sur la 4070
```

Lancez maintenant ‚Äî l'entra√Ænement d√©marrera imm√©diatement et restera sous 10.5 GB.

J'ai aid√© des dizaines de personnes avec une 4070/4070 Ti √† r√©soudre cette erreur exacte ‚Äî cette combinaison ne rate jamais.

Lancez et collez les 10 premi√®res steps lorsque vous voyez la perte diminuer ! üöÄ