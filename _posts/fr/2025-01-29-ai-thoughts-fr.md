---
audio: false
lang: fr
layout: post
title: AI Thoughts
translated: true
---

- Satya Nadella a mentionné le paradoxe de Jevons. Il vaut la peine de l'étudier.

- Yin Wang : Il n'y a pas d'"intelligence" dans l'intelligence artificielle, pas de "neuronal" dans les réseaux neuronaux, pas d'"apprentissage" dans l'apprentissage automatique, et pas de "profondeur" dans l'apprentissage profond.  Ce qui fonctionne vraiment dans ce domaine s'appelle le "calcul". Je préfère donc appeler ce domaine le "calcul différentiable", et le processus de construction de modèles le "programmation différentiable".

- Yin Wang : L'apprentissage automatique est une théorie vraiment utile, on pourrait même dire belle, car c'est simplement le calcul maquillé ! C'est la vieille et grande théorie de Newton, Leibniz, sous une forme plus simple, élégante et puissante. L'apprentissage automatique est essentiellement l'utilisation du calcul pour dériver et ajuster certaines fonctions, et l'apprentissage profond est l'ajustement de fonctions plus complexes.

- Actuellement, les grands modèles de langage ne peuvent pas filtrer par langage de fichier comme YAML ou Python. Cependant, une part importante des informations dans le monde réel est organisée de cette manière. Cela signifie que nous pourrions entraîner de grands modèles de langage en utilisant des fichiers.

- Pour entraîner de grands modèles de langage, nous pourrions développer un système qui trouve des correspondances exactes. Nous pouvons peut-être combiner l'algorithme de recherche KMP (Knuth-Morris-Pratt) avec l'architecture du transformateur pour améliorer les capacités de recherche.

- Il n'y a pas de secrets technologiques. L'open source révélera tous les secrets jalousement gardés.

- L'IA affectera de nombreux outils, y compris ceux indirects. Les gens disent qu'ils n'auront pas besoin de Figma pour dessiner des prototypes, ils passeront directement au code. Je pense que Postman sera similaire ; les gens utiliseront directement Python ou d'autres scripts pour appeler ou tester les API.

- Une raison pour laquelle nous n'utilisons pas Postman ou Figma à l'ère de l'IA est que leurs fonctionnalités ne peuvent pas être générées par du texte. Ils manquent également d'un raccourci clavier Commande + K pour déclencher le remplacement de composants.

- Les interfaces utilisateur deviennent un obstacle à l'ère de l'IA. Pourquoi mettre à niveau Postman pour qu'il soit alimenté par l'IA pour tester les applications alors que nous pouvons utiliser directement la bibliothèque requests de Python ou d'autres langages de programmation pour tester le code, ce dernier étant alimenté par l'IA ?

- Pourquoi mettre à niveau Figma pour qu'il soit alimenté par l'IA pour la création d'interfaces utilisateur alors que la génération d'interfaces utilisateur basée sur le code, améliorée par l'IA, offre une approche plus directe et potentiellement plus puissante ?

- Les grands modèles de langage (LLM) changeront d'abord les applications liées au texte, comme Google, les moteurs de recherche, les éditeurs de texte et les outils d'écriture, Quizlet, Zendesk, DeepL, Medium, WordPress, Trello, Asana, Gmail, GitHub, Goodreads, Duolingo et Feedly.

- En revanche, les LLM n'auront pas d'impact significatif sur des technologies comme Git, Linux, les téléphones mobiles, le matériel, les navigateurs, les systèmes d'exploitation ou les appels vocaux et vidéo, car ceux-ci reposent principalement sur du code avec un contenu minimal.

- [Nouvelles plateformes alimentées par les workflows IA](./ai-workflow-fr)

- [La prochaine direction des éditeurs de code IA](./ai-code-fr)

- [Comment je vis bien à l'ère de l'IA et de la blockchain](./ai-blockchain-fr)
