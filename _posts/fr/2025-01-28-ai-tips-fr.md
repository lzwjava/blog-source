---
audio: false
generated: true
lang: fr
layout: post
title: Conseils sur les outils d'IA
translated: true
---

* Copiez le code exemple dans Cursor et utilisez des commentaires pour fournir un contexte.

* Dans la région de Hong Kong, il est acceptable d'utiliser les services DeepSeek ou Mistral, tandis qu'il n'est pas acceptable d'utiliser ChatGPT, Claude ou Gemini.

* La politique API d'une région est approximativement la même que sa politique d'application.

* Utilisez Cursor au lieu de Visual Studio Code.

* Il existe encore des cas où vous devez utiliser Visual Studio Code, comme pour les scénarios de l'éditeur de fusion git, où j'utilise toujours `git config --global core.editor "code --wait"`.

* À partir du jour de la sortie de Deepseek V3, nous n'avons plus besoin de s'abonner à des outils d'IA.

* Utilisez Gemini ou Grok pour générer des images de célébration de festival avec des invites comme "Générez une image joyeuse du Nouvel An du Serpent Lunaire avec les noms du texte inclus".

* Dans certains cas, même en fournissant du texte original aux modèles d'IA pour créer un tableau, quelques endroits dans la sortie peuvent différer de l'entrée. Par exemple, lors de l'utilisation du modèle Deepseek V3 dans Cursor pour générer un tableau de la liste pip, il peut inclure des versions comme `1.极狐0`. Ici, `极狐` fait référence à la plateforme GitLab chinoise.

* Lors de l'utilisation de l'API Deepseek ou Mistral pour traduire des titres avec des invites comme `Vous êtes un traducteur professionnel. Vous traduisez un fichier markdown pour un article de blog Jekyll de l'anglais vers le chinois. {text}`, cela peut entraîner des traductions incorrectes. En plus du texte que vous fournissez, la sortie inclut souvent une traduction excessive.

* Bien que parfois les modèles d'IA dans Cursor donnent un texte partiellement correct, nous pouvons les accepter, car nous pouvons ajouter des instructions de suivi qui feront que les modèles d'IA régénèrent les parties correctes.

* Évitez de fournir un contexte excessif aux grands modèles de langage s'il est peu probable qu'il soit utile. Par exemple, lors de la génération de lignes de dialogue conversationnel, évitez de fournir 100 points sur un sujet. Les grands modèles de langage contiennent déjà d'énormes quantités de données.

* Lors de la fourniture d'un contexte suffisant pour des tâches comme la traduction ou la génération de paroles de dialogue, évitez d'utiliser les fonctionnalités de chaîne de pensée, car cela peut être lent et conduire à des réponses verbeuses ou non utiles.

* Une façon de tester si un chatbot peut suivre les instructions d'un utilisateur est de lui demander d'expliquer quelque chose en anglais, puis de continuer l'entrée en chinois, en observant si le chatbot maintient sa sortie en anglais.

* Au lieu de fournir un contexte aux LLM, affinez un modèle basé sur un grand ensemble de données de texte ou de code, puis utilisez le modèle affiné.

* [Messages de Validation Git Alimentés par l'IA](./gitmessageai-en)

* [Génération Audio de Conversation](./conversation-style-en)

* [Transcription Google Cloud](./speech-to-text-en)

* [Essai llama.cpp](./llama-cpp-en)

* [Un Cas Utilisant la Recherche dans ChatGPT](./ai-search-en)

* [Deepseek, Mistral et Anthropic](./dma-en)