---
audio: false
generated: true
lang: fr
layout: post
title: 'Mistral NeMo : Un modèle de langage puissant à 12 milliards de paramètres'
translated: true
type: note
---

**Mistral NeMo** est un puissant grand modèle de langage (LLM) de 12 milliards de paramètres développé par **Mistral AI en collaboration avec NVIDIA**. Il est conçu pour offrir des capacités de traitement du langage naturel de pointe, excellant particulièrement dans le raisonnement, la connaissance du monde et la précision en programmation dans sa catégorie de taille.

Voici quelques caractéristiques et aspects clés de Mistral NeMo :

*   **12 Milliards de Paramètres :** Cela en fait un modèle relativement compact mais très performant, offrant un équilibre entre performances et efficacité.
*   **Grande Fenêtre de Contexte :** Il dispose d'une fenêtre de contexte allant jusqu'à 128k tokens, lui permettant de traiter et de comprendre des textes beaucoup plus longs, des documents complexes et des conversations à plusieurs tours plus efficacement.
*   **Performances de Pointe :** Mistral NeMo établit une nouvelle référence pour les modèles de sa catégorie, démontrant de solides performances dans les tâches liées au raisonnement, à la connaissance générale du monde et à la génération de code.
*   **Prise en Charge Multilingue :** Conçu pour des applications mondiales, il est performant dans de nombreuses langues, notamment l'anglais, le français, l'allemand, l'espagnol, l'italien, le portugais, le chinois, le japonais, le coréen, l'arabe et le hindi.
*   **Tokeniseur Tekken :** Il utilise un nouveau tokeniseur appelé Tekken (basé sur Tiktoken), qui est plus efficace pour compresser le texte en langage naturel et le code source dans plus de 100 langues par rapport aux tokeniseurs précédents.
*   **Appel de Fonction :** Le modèle est entraîné sur l'appel de fonction, améliorant sa capacité à interagir avec et à exécuter des fonctions programmatiques spécifiques basées sur des entrées en langage naturel.
*   **Prise en Compte de la Quantification :** Entraîné avec une prise en compte de la quantification, il permet l'inférence en FP8 sans compromettre les performances, ce qui est crucial pour un déploiement efficace.
*   **Licence Open-Source :** Mistral NeMo est publié sous licence Apache 2.0, favorisant une adoption, une personnalisation et une intégration généralisées par les chercheurs et les entreprises.
*   **Intégration Facile :** Son architecture standard le rend facile à utiliser comme remplacement direct pour les systèmes utilisant déjà Mistral 7B.
*   **Collaboration avec NVIDIA :** Le modèle a été entraîné sur la plateforme IA NVIDIA DGX Cloud et utilise l'écosystème matériel et logiciel optimisé de NVIDIA, y compris TensorRT-LLM pour des performances d'inférence accélérées et la plateforme de développement NeMo pour créer des modèles d'IA générative personnalisés. Il est également disponible en tant que microservice d'inférence NVIDIA NIM.

En substance, Mistral NeMo vise à fournir un LLM polyvalent, performant et efficace qui peut fonctionner sur un seul GPU, rendant les capacités d'IA avancées plus accessibles pour un large éventail d'applications d'entreprise comme les chatbots, la synthétisation, la traduction linguistique et la génération de code.