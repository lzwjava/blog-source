---
audio: false
generated: true
lang: fr
layout: post
title: Probl√®me de Proxy Stable Diffusion
translated: true
type: note
---

Sur base de l'erreur et de votre environnement, voici comment r√©soudre le probl√®me "Unknown scheme for proxy URL" :

### Solution :
L'erreur se produit car **`httpx` ne prend pas en charge les proxies `socks://` par d√©faut**. Vous avez deux options :

#### Option 1 : Supprimer la r√©f√©rence au proxy SOCKS
1. V√©rifiez les variables d'environnement pour des param√®tres de proxy ind√©sirables :
   ```bash
   env | grep -i proxy
   ```
   Recherchez les r√©f√©rences `socks://` (en particulier `ALL_PROXY` ou `http_proxy`).

2. D√©sactivez la variable probl√©matique (remplacez `VAR_NAME` par le nom r√©el trouv√© ci-dessus) :
   ```bash
   unset VAR_NAME  # par exemple, unset ALL_PROXY
   ```

#### Option 2 : Ajouter la prise en charge de SOCKS √† `httpx`
1. Activez votre environnement virtuel Python :
   ```bash
   source /home/lzw/Projects/stable-diffusion-webui/venv/bin/activate
   ```

2. Installez les d√©pendances requises :
   ```bash
   pip install -U "httpx[socks]"
   ```

3. D√©sactivez l'environnement :
   ```bash
   deactivate
   ```

### Pourquoi cela arrive :
- Vos proxies principaux (`HTTP_PROXY/HTTPS_PROXY`) utilisent `http://` (support√©), mais quelque chose (probablement une autre application/script) d√©finit un proxy `socks://` que `httpx` ne peut pas g√©rer sans paquets suppl√©mentaires.
- La stack trace montre que Gradio/`httpx` essaie d'utiliser `socks://127.0.0.1:7891`, qui n'appara√Æt pas dans votre sortie `checkproxy`.

### V√©rification :
Apr√®s correction, ex√©cutez :
```bash
./webui.sh
```
L'erreur de proxy SOCKS devrait dispara√Ætre.

> üí° **Note** : Si vous n'avez pas intentionnellement configur√© un proxy SOCKS, v√©rifiez les applications qui pourraient configurer automatiquement les proxies (par exemple, les VPN, les gestionnaires de r√©seau, ou les fichiers de configuration du shell comme `~/.bashrc`).

---

L'erreur `Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check` indique que PyTorch, utilis√© par Stable Diffusion WebUI, ne peut pas d√©tecter ou acc√©der √† un GPU compatible. Cela est probablement d√ª √† des biblioth√®ques CUDA manquantes, un GPU incompatible, des probl√®mes de pilote ou un probl√®me de configuration. Voici les √©tapes pour r√©soudre ce probl√®me, adapt√©es √† votre environnement (glibc 2.35, Python 3.10.12, GCC 11.4.0, probablement Ubuntu 22.04 bas√© sur la version de glibc).

### √âtapes pour r√©soudre le probl√®me

#### 1. **V√©rifier la compatibilit√© du GPU et de CUDA**
   - **V√©rifiez si vous avez un GPU NVIDIA** :
     Ex√©cutez :
     ```bash
     lspci | grep -i nvidia
     ```
     Cela liste le mat√©riel NVIDIA. Si rien n'appara√Æt, votre syst√®me peut ne pas avoir de GPU NVIDIA, et PyTorch n√©cessite un GPU NVIDIA pour la prise en charge CUDA.
   - **V√©rifiez l'installation du pilote NVIDIA** :
     Ex√©cutez :
     ```bash
     nvidia-smi
     ```
     Si install√©, cela affiche un tableau avec les d√©tails du GPU (par exemple, version du pilote, version CUDA). Sinon, installez le pilote NVIDIA :
     ```bash
     sudo apt-get update
     sudo apt-get install nvidia-driver-<version> nvidia-utils-<version> -y
     ```
     Remplacez `<version>` par le dernier pilote stable (par exemple, `535` ou `550`). Trouvez la version appropri√©e du pilote avec :
     ```bash
     ubuntu-drivers devices
     sudo ubuntu-drivers autoinstall
     ```
   - **V√©rifiez la version de CUDA** :
     PyTorch n√©cessite les biblioth√®ques CUDA. V√©rifiez la version de CUDA install√©e :
     ```bash
     nvcc --version
     ```
     Si non install√©, installez le CUDA Toolkit :
     ```bash
     sudo apt-get install nvidia-cuda-toolkit -y
     ```
     Alternativement, t√©l√©chargez le dernier CUDA Toolkit depuis le site web de NVIDIA (par exemple, CUDA 11.8 ou 12.1) et suivez leur guide d'installation.

#### 2. **V√©rifier l'installation de PyTorch**
   L'erreur sugg√®re que PyTorch est install√© mais ne peut pas utiliser le GPU. Assurez-vous d'avoir la bonne version de PyTorch avec la prise en charge CUDA.
   - **V√©rifiez l'installation de PyTorch** :
     Ex√©cutez :
     ```bash
     python3 -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"
     ```
     Le r√©sultat attendu devrait inclure une version de PyTorch (par exemple, `2.0.1`) et `True` pour `torch.cuda.is_available()`. Si `False`, PyTorch ne d√©tecte pas le GPU.
   - **R√©installez PyTorch avec la prise en charge CUDA** :
     Pour Python 3.10 et CUDA (par exemple, 11.8), installez PyTorch dans votre environnement Stable Diffusion :
     ```bash
     cd /home/lzw/Projects/stable-diffusion-webui
     source venv/bin/activate
     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
     ```
     Remplacez `cu118` par votre version de CUDA (par exemple, `cu121` pour CUDA 12.1). V√©rifiez les versions support√©es sur le site officiel de PyTorch.
   - **V√©rifiez apr√®s r√©installation** :
     Ex√©cutez √† nouveau la v√©rification :
     ```bash
     python3 -c "import torch; print(torch.cuda.is_available()); print(torch.cuda.get_device_name(0))"
     ```

#### 3. **Contourner la v√©rification CUDA (Solution temporaire)**
   Si vous voulez ex√©cuter Stable Diffusion sans prise en charge GPU (par exemple, pour tester sur CPU), contournez la v√©rification CUDA en ajoutant `--skip-torch-cuda-test` aux arguments de ligne de commande.
   - Modifiez `webui-user.sh` (ou cr√©ez-le s'il n'existe pas) :
     ```bash
     nano /home/lzw/Projects/stable-diffusion-webui/webui-user.sh
     ```
     Ajoutez ou modifiez la ligne `COMMANDLINE_ARGS` :
     ```bash
     export COMMANDLINE_ARGS="--skip-torch-cuda-test"
     ```
     Sauvegardez et quittez.
   - Ex√©cutez le script :
     ```bash
     ./webui.sh
     ```
     Cela permet √† Stable Diffusion de s'ex√©cuter sur CPU, mais les performances seront consid√©rablement plus lentes.

#### 4. **S'assurer que TCMalloc est correctement configur√©**
   Votre sortie montre que TCMalloc (`libtcmalloc_minimal.so.4`) est d√©tect√© et li√© avec `LD_PRELOAD`. Confirmez son fonctionnement :
   ```bash
   echo $LD_PRELOAD
   ```
   Si le r√©sultat est `/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4`, c'est bon. Sinon, d√©finissez-le manuellement :
   ```bash
   export LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
   ```
   Ou ajoutez-le √† `webui-user.sh` :
   ```bash
   export LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
   ```

#### 5. **V√©rifier les variables d'environnement et les chemins**
   Assurez-vous que votre environnement est correctement configur√© :
   - **V√©rifiez LD_LIBRARY_PATH** :
     Les biblioth√®ques CUDA doivent √™tre accessibles. Ajoutez-les si n√©cessaire :
     ```bash
     export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
     ```
     Ajoutez ceci √† `~/.bashrc` ou `webui-user.sh` pour la persistance.
   - **Activez l'environnement virtuel** :
     Activez toujours l'environnement virtuel Stable Diffusion avant l'ex√©cution :
     ```bash
     cd /home/lzw/Projects/stable-diffusion-webui
     source venv/bin/activate
     ```

#### 6. **Mettre √† jour Stable Diffusion WebUI**
   Votre version (`v1.10.1`, commit `82a973c`) peut avoir des probl√®mes de compatibilit√©. Mettez √† jour vers la derni√®re version :
   ```bash
   cd /home/lzw/Projects/stable-diffusion-webui
   git pull
   ```
   Puis, r√©installez les d√©pendances :
   ```bash
   ./webui.sh
   ```

#### 7. **D√©pannage**
   - **Si `nvidia-smi` √©choue** : R√©installez le pilote NVIDIA ou v√©rifiez les probl√®mes mat√©riels du GPU.
   - **Si PyTorch ne d√©tecte toujours pas le GPU** :
     - Assurez-vous que CUDA et cuDNN sont install√©s correctement. Installez cuDNN si manquant :
       ```bash
       sudo apt-get install libcudnn8
       ```
     - V√©rifiez la compatibilit√© de la version CUDA avec votre GPU et PyTorch. Par exemple, les anciens GPU (par exemple, s√©rie Kepler) peuvent ne pas supporter CUDA 12.
   - **Si les erreurs persistent** : V√©rifiez les logs de Stable Diffusion pour des erreurs d√©taill√©es :
     ```bash
     cat /home/lzw/Projects/stable-diffusion-webui/log/webui.log
     ```
     Partagez toute erreur sp√©cifique pour une assistance suppl√©mentaire.
   - **Limitations mat√©rielles** : Si votre GPU est trop ancien (par exemple, GPU NVIDIA d'avant 2016), il peut ne pas supporter les versions modernes de CUDA. Dans ce cas, utilisez `--skip-torch-cuda-test` ou mettez √† niveau votre GPU.

#### 8. **Ex√©cuter l'application**
   Apr√®s avoir appliqu√© les correctifs, ex√©cutez la WebUI :
   ```bash
   cd /home/lzw/Projects/stable-diffusion-webui
   ./webui.sh
   ```
   Si vous avez r√©solu le probl√®me GPU, l'erreur devrait dispara√Ætre. Si vous utilisez `--skip-torch-cuda-test`, elle s'ex√©cutera sur CPU.

### Notes
- **Informations syst√®me** : Votre configuration (glibc 2.35, Python 3.10.12, GCC 11.4.0) sugg√®re Ubuntu 22.04, qui est compatible avec CUDA 11.8 ou 12.1 et les versions r√©centes de PyTorch.
- **Performances** : L'ex√©cution sur CPU (avec `--skip-torch-cuda-test`) est une solution de repli mais sera lente. Il est recommand√© de corriger la prise en charge GPU pour Stable Diffusion.
- **TCMalloc** : Le probl√®me TCMalloc semble r√©solu sur base de votre sortie. Assurez-vous que `LD_PRELOAD` reste d√©fini si vous rencontrez des probl√®mes li√©s √† la m√©moire.

Si vous rencontrez toujours des probl√®mes ou avez besoin d'aide avec des messages d'erreur sp√©cifiques, veuillez fournir des d√©tails suppl√©mentaires (par exemple, mod√®le du GPU, version de CUDA, ou logs complets), et je peux affiner la solution !