---
audio: false
generated: true
image: false
lang: fr
layout: post
model: openai/gpt-5
title: Les LLM, le raisonnement en code et l'utilisation d'outils
translated: true
type: note
---

Excellente question ! Vous demandez essentiellement comment un mod√®le comme **Claude d'Anthropic (et d'autres LLM similaires)** g√®re en interne :

1.  **L'ex√©cution de code ou le raisonnement li√© au code**
2.  **La validation de sch√©mas JSON / la production de sorties structur√©es**
3.  **L'utilisation d'outils et l'acheminement entre eux**

Laissez-moi d√©tailler cela.

---

### 1. Raisonnement et ex√©cution de code
Claude (et les autres LLM de pointe) n'ex√©cutent pas r√©ellement de code directement √† l'int√©rieur du mod√®le ‚Äî ils **simulent un raisonnement de code** en pr√©disant des tokens de code ou des √©tapes logiques.

- En **mode texte normal**, Claude peut "√©crire" du code en poursuivant un motif, mais il ne l'ex√©cute pas en interne.
- Lorsqu'il est utilis√© avec un **backend (comme Anthropic's Workbench, ou l'Interpr√©teur de Code d'OpenAI)**, le syst√®me peut intercepter ces extraits de code et les *ex√©cuter* r√©ellement dans un environnement sandbox√©.
- Les r√©sultats peuvent ensuite √™tre renvoy√©s au mod√®le comme contexte, afin qu'il puisse encha√Æner son raisonnement comme suit :
  ‚Üí G√©n√©rer du code ‚Üí Ex√©cuter en externe ‚Üí Recevoir le r√©sultat ‚Üí D√©cider de l'√©tape suivante.

L'intelligence r√©side donc dans la boucle : le LLM g√©n√®re ‚Üí un ex√©cuteur externe ex√©cute ‚Üí le LLM interpr√®te les r√©sultats.

---

### 2. Validation de sch√©ma JSON
De nombreuses API (Claude, OpenAI, etc.) prennent d√©sormais en charge le **mode de sortie structur√©e**, o√π vous pouvez attacher un sch√©ma JSON. Voici comment cela fonctionne en interne :

- Vous transmettez une **d√©finition de sch√©ma JSON** avec votre requ√™te.
- Le LLM est guid√© pour produire **uniquement du JSON valide** qui y conforme.
- S'il tente de produire un JSON non valide, le syst√®me le d√©tecte (en utilisant un validateur comme [jsonschema](https://pypi.org/project/jsonschema/)) et demande au mod√®le de "corriger" la sortie.
- En arri√®re-plan, il s'agit souvent d'un m√©canisme de **d√©codage contraint** ou de **d√©codage bas√© sur une grammaire** ‚Äî cela restreint la g√©n√©ration de tokens pour que seuls les `"tokens valides suivants dans le sch√©ma"` soient autoris√©s.

Cela garantit que la sortie est un JSON syntaxiquement et s√©mantiquement correct, ce qui est crucial pour l'automatisation de l'utilisation d'outils.

---

### 3. Utilisation d'outils et acheminement
L'utilisation d'outils est g√©r√©e via une **couche de routage** entre le LLM et un environnement d'ex√©cution d'outils :

- **Logique de routage** : Le mod√®le est incit√© √† *d√©cider quel outil appeler* (ou √† r√©pondre directement).
- **Application du sch√©ma** : Chaque outil poss√®de un sch√©ma d'entr√©e. Le LLM doit produire un JSON valide pour cet outil.
- **Adaptateurs d'ex√©cution** : La couche d'orchestration (en dehors du mod√®le) prend le JSON du LLM, le valide par rapport au sch√©ma, ex√©cute l'outil, puis renvoie les r√©sultats dans le contexte.
- **Raisonnement encha√Æn√© (style ReAct)** : Le LLM "r√©fl√©chit √† haute voix" (peut produire des √©tapes de raisonnement cach√©es pour l'utilisateur), puis √©met des appels d'outils lorsque n√©cessaire, pour arriver progressivement √† une r√©ponse finale.

Par exemple :
```json
{
  "tool": "web_search",
  "query": "derni√®res recherches sur la correction d'erreurs quantiques"
}
```
‚Üí Le routeur voit `"tool": "web_search"`, valide le sch√©ma, ex√©cute la recherche web, replace les r√©sultats dans le contexte du mod√®le, et le mod√®le continue son raisonnement.

Claude d'Anthropic, les GPTs d'OpenAI, LangChain et d'autres prennent tous en charge ce mod√®le.

---

### üîë R√©sum√©
- **Code avec Claude** : N'ex√©cute pas de code en interne ; g√©n√®re du code ‚Üí un sandbox ex√©cute ‚Üí les r√©sultats sont renvoy√©s ‚Üí raisonnement it√©ratif.
- **Validation de sch√©ma JSON** : Utilise un d√©codage contraint / une validation de sch√©ma pour garantir une sortie structur√©e valide.
- **Routage d'utilisation d'outils** : Le LLM s√©lectionne des appels d'outils en JSON, le moteur d'orchestration les valide et les ex√©cute, et renvoie les r√©sultats dans la boucle.

---

üëâ Souhaitez-vous que je **dessine un diagramme** montrant le flux (LLM ‚Üî routeur d'outils ‚Üî validateur de sch√©ma ‚Üî moteur d'ex√©cution) pour une meilleure clart√© visuelle ?