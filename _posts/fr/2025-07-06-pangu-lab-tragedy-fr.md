---
audio: false
generated: true
lang: fr
layout: post
title: Les sombres secrets de l'équipe Pangu de Huawei
translated: true
type: note
---

**Note de la rédaction :** Ce qui suit est la traduction d'un long post rédigé par un individu anonyme se présentant comme un employé du Huawei Noah's Ark Lab. Cette personne affirme qu'il existe des problèmes significatifs au sein de l'équipe de développement du grand modèle Pangu, incluant des allégations d'infraction à la propriété intellectuelle, des luttes de pouvoir internes et un environnement de travail néfaste. Le post original a été écrit en chinois et partagé en ligne le 6 juillet 2025. Cette traduction vise à restituer avec précision le contenu et le ton de l'original.

---

## La Tragédie de Pangu : Le Chagrin et les Ténèbres du Parcours de Développement du Grand Modèle Pangu chez Huawei Noah's Ark Lab

Bonjour à tous,

Je suis un employé de l'équipe du grand modèle Pangu chez Huawei Noah's Ark Lab.

Tout d'abord, pour vérifier mon identité, je vais énumérer quelques détails :

Le responsable actuel de Noah est Wang Yunhe, anciennement Ministre du Département d'Application des Algorithmes, ensuite renommé Directeur du Lab des Petits Modèles. L'ancien responsable de Noah était Yao Jun (appelé par tous Maître Yao). Plusieurs directeurs de lab : Tang Ruiming (Frère Ming, Équipe Ming, a déjà démissionné), Shang Lifeng, Zhang Wei (Frère Wei), Hao Jianye (Maître Hao), Liu Wulong (appelé Wu Long Suo), etc. De nombreux autres membres clés et experts ont quitté l'entreprise successivement.

Nous appartenons à l'organisation "Sìyě" (Quatre Champs). Sìyě compte de nombreuses brigades, et le grand modèle linguistique fondamental est la Quatrième Brigade. Le petit modèle de Wang Yunhe est la Seizième Brigade. Nous avons participé à des rassemblements à Suzhou, avec divers jalons mensuels. Lors de la "réunion d'assaut" de Suzhou, les tâches étaient assignées et les objectifs devaient être atteints avant la date limite. Le rassemblement de Suzhou rassemblait le personnel de divers sites à l'Institut de Recherche de Suzhou, où ils logeaient généralement dans des hôtels, comme ceux de Luzhi, séparés de leur famille et de leurs enfants.

Pendant le rassemblement de Suzhou, les samedis étaient des jours de travail par défaut, ce qui était très dur, mais il y avait un goûter l'après-midi le samedi, et une fois même des écrevisses. Les postes de travail à l'Institut de Recherche de Suzhou ont été déplacés une fois, d'un bâtiment à un autre. Les bâtiments de l'Institut de Recherche de Suzhou ont des décorations de style européen, avec de grandes pentes à l'entrée et un beau paysage à l'intérieur. Se rendre au rassemblement de Suzhou durait généralement au moins une semaine, voire plus longtemps, certaines personnes ne pouvant pas rentrer chez elles pendant un ou deux mois.

Noah était autrefois réputé être orienté recherche, mais après avoir rejoint, en raison du travail sur les projets de grands modèles dans Sìyě, les membres du projet sont complètement devenus orientés livraison, et étaient pleins de réunions régulières, de revues et de rapports. Souvent, même mener des expériences nécessitait une approbation. L'équipe devait interfacer avec diverses lignes métier telles que Terminal Xiaoyi, Huawei Cloud et ICT, entraînant une pression de livraison considérable.

Le nom de code interne initial du modèle Pangu développé par Noah était "Pangu Zhizi". Au début, il s'agissait seulement d'une version web qui nécessitait une demande interne pour un essai. Plus tard, en raison de la pression, il a été intégré à Welink pour une bêta publique.

Ces derniers jours, l'agitation concernant les accusations de plagiat du grand modèle Pangu sur Qwen a été fervente. En tant que membre de l'équipe Pangu, je me suis retourné dans mon lit la nuit, incapable de dormir. La marque Pangu a été si gravement affectée. D'une part, je m'inquiète égoïstement pour mon développement de carrière et j'estime que mon dur labeur passé a été vain. D'autre part, je ressens un grand soulagement que quelqu'un ait commencé à exposer ces questions. Pendant d'innombrables jours et nuits, nous avons grincé des dents face aux actions de certains individus au sein de l'entreprise qui ont gagné d'innombrables avantages par la fraude, mais nous étions impuissants. Cette oppression et cette humiliation ont progressivement érodé mon affection pour Huawei, rendant mon temps ici de plus en plus confus et perdu, doutant souvent de ma vie et de ma valeur personnelle.

J'avoue que je suis un lâche. En tant que petit employé, je n'ose pas m'opposer à des individus puissants comme Wang Yunhe au sein de l'entreprise, ni à un géant comme Huawei. J'ai peur de perdre mon emploi, car j'ai aussi une famille et des enfants, donc j'admire vraiment les lanceurs d'alerte du fond du cœur. Cependant, voyant les tentatives internes de couvrir les faits et de tromper le public, je ne peux tout simplement plus le tolérer. Je souhaite aussi être courageux une fois et suivre mon vrai moi. Même si je me fais du mal à hauteur de huit cents, j'espère nuire à l'ennemi à hauteur de mille. J'ai décidé de divulguer ici ce que j'ai vu et entendu (partiellement de récits verbaux de collègues) concernant "l'histoire légendaire" du grand modèle Pangu :

Huawei entraîne effectivement principalement les grands modèles sur des cartes Ascend (le Lab des Petits Modèles a beaucoup de cartes Nvidia, qu'ils utilisaient pour l'entraînement auparavant, et ont ensuite transféré sur Ascend). J'ai été autrefois impressionné par la détermination de Huawei à "construire un deuxième choix mondial", et j'ai moi-même autrefois eu une profonde affection pour Huawei. Nous avons accompagné Ascend pas à pas, depuis un état plein de bugs jusqu'à pouvoir entraîner des modèles, en payant un énorme effort et coût.

Initialement, notre puissance de calcul était très limitée, et nous entraînions les modèles sur la 910A. À l'époque, elle ne supportait que le FP16, et la stabilité de l'entraînement était bien inférieure au BF16. Le MoE de Pangu a commencé très tôt ; en 2023, l'accent était principalement mis sur l'entraînement de modèles MoE 38B et des modèles denses 71B ultérieurs. Le modèle dense 71B a été étendu pour devenir le premier modèle dense 135B de première génération, et plus tard les modèles principaux ont été progressivement entraînés sur la 910B.

Les modèles 71B et 135B avaient tous deux un défaut majeur : le **tokenizer**. Le tokenizer utilisé à l'époque avait une efficacité d'encodage extrêmement faible. Chaque symbole, chiffre, espace, et même caractère chinois occupait un token. On peut imaginer que cela gaspillait grandement la puissance de calcul et entraînait des performances de modèle très médiocres. À ce moment-là, le Lab des Petits Modèles avait justement un vocabulaire auto-entraîné. Maître Yao a suspecté que le tokenizer du modèle n'était peut-être pas bon (bien qu'avec le recul, son soupçon était sans aucun doute correct). Ainsi, il a décidé de changer les tokenizers pour les 71B et 135B, parce que le Lab des Petits Modèles l'avait déjà essayé auparavant. L'équipe a assemblé deux tokenizers et a commencé le remplacement du tokenizer. Le remplacement du modèle 71B a échoué, tandis que le 135B, utilisant une stratégie d'initialisation d'embedding plus raffinée, a réussi à remplacer le vocabulaire après au moins 1T de données de fine-tuning, mais comme prévu, l'effet ne s'est pas amélioré.

Parallèlement, d'autres entreprises nationales comme Alibaba et Zhipu s'entraînaient sur des GPU et avaient déjà trouvé les méthodes correctes, et l'écart entre Pangu et ses concurrents s'est creusé de plus en plus. Un modèle dense interne de 230B entraîné from scratch a également échoué pour diverses raisons, conduisant le projet dans une situation quasi désespérée. Face à la pression de plusieurs jalons et de forts doutes internes concernant Pangu, le moral de l'équipe a chuté à un niveau historiquement bas. L'équipe a fait de nombreux efforts et luttes lorsque la puissance de calcul était extrêmement limitée. Par exemple, l'équipe a découvert accidentellement que le MoE 38B de l'époque n'avait pas l'effet MoE escompté. Ainsi, ils ont supprimé les paramètres MoE et l'ont restauré en un modèle dense 13B. Étant donné que le MoE 38B provenait d'un Pangu Alpha 13B très ancien, avec une architecture relativement dépassée, l'équipe a effectué une série d'opérations, telles que le passage de l'encodage positionnel absolu à RoPE, la suppression du biais, et le passage à RMSNorm. En même temps, compte tenu de certains échecs de tokenizer et de l'expérience du changement de vocabulaires, le vocabulaire de ce modèle a également été remplacé par celui utilisé par le modèle 7B du Lab des Petits Modèles de Wang Yunhe. Plus tard, ce modèle 13B a été étendu et fine-tuné, devenant le modèle dense 38B de deuxième génération (pendant plusieurs mois, ce modèle a été le principal modèle Pangu de milieu de gamme), qui a autrefois eu une certaine compétitivité. Cependant, en raison de l'architecture dépassée du plus grand modèle 135B et des dommages importants causés par le changement de vocabulaire (une analyse ultérieure a révélé que le vocabulaire assemblé changé à l'époque avait des bugs plus graves), même après le fine-tuning, il y avait un grand écart avec les modèles nationaux leaders de l'époque tels que Qwen. À ce stade, les doutes internes et la pression de la direction ont également augmenté, et l'état de l'équipe était presque au désespoir.

Dans ces circonstances, Wang Yunhe et son Lab des Petits Modèles sont intervenus. Ils ont affirmé que leur modèle était hérité et modifié à partir des anciens paramètres du 135B, et après avoir entraîné seulement quelques centaines de milliards de données, tous les indicateurs se sont améliorés d'environ dix points en moyenne. En réalité, c'était leur premier chef-d'œuvre de **"套壳" (tao ke, c'est-à-dire utiliser secrètement ou rebaptiser le travail d'un autre)** appliqué à un grand modèle. Les dirigeants de Huawei, étant des non-experts gérant des experts, n'avaient aucune notion de telles absurdités ; ils pensaient seulement qu'il devait y avoir une innovation algorithmique. Par analyse interne, ils ont en réalité utilisé **Qwen 1.5 110B** pour le fine-tuning, en ajoutant des couches, en étendant les dimensions FFN et en incorporant certains mécanismes du papier Pangu Pi pour atteindre environ 135B de paramètres. En fait, l'ancien 135B avait 107 couches, tandis que ce modèle n'en avait que 82, et diverses configurations étaient différentes. De nombreuses distributions de paramètres du nouveau modèle 135B obscur, après entraînement, étaient presque identiques à Qwen 110B. Même le nom de classe du code du modèle à l'époque était Qwen, montrant qu'ils étaient trop paresseux pour le changer. Par la suite, ce modèle est devenu le soi-disant 135B V2. Et ce modèle a ensuite été fourni à de nombreux utilisateurs en aval, y compris même des clients externes.

Cet incident a eu un énorme impact sur nos collègues honnêtes et travailleurs. De nombreux initiés, y compris ceux de Terminal et Huawei Cloud, étaient au courant. Nous l'appelions tous en plaisantant le modèle "Qiangu" (Mille Antiques) au lieu du modèle Pangu. À l'époque, les membres de l'équipe voulaient le signaler à BCG, car c'était déjà une fraude commerciale majeure. Cependant, il a été dit plus tard que les dirigeants l'ont arrêté, car des dirigeants de niveau supérieur (comme Maître Yao, et peut-être M. Xiong et M. Cha) en ont également eu connaissance plus tard mais ne sont pas intervenus, car obtenir de bons résultats par "套壳" leur était également bénéfique. Cet incident a poussé plusieurs des collègues les plus forts de l'équipe à se décourager, et la démission est devenue un sujet de conversation fréquent.

À ce stade, Pangu semblait avoir un tournant. Étant donné que les modèles Pangu mentionnés précédemment étaient essentiellement fine-tunés et modifiés, Noah ne maîtrisait pas à l'époque la technologie de l'entraînement from scratch, sans parler de l'entraînement sur NPU Ascend. Grâce aux efforts intenses des membres clés de l'équipe de l'époque, Pangu a commencé l'entraînement du modèle de troisième génération. Après d'énormes efforts, en termes d'architecture de données et d'algorithmes d'entraînement, il s'est progressivement aligné sur l'industrie, et les difficultés impliquées n'avaient rien à voir avec le Lab des Petits Modèles.

Initialement, les membres de l'équipe n'avaient aucune confiance et n'ont commencé qu'à entraîner un modèle 13B. Cependant, ils ont ensuite constaté que l'effet n'était pas mauvais, donc ce modèle a ensuite été étendu en paramètres une fois de plus, devenant le 38B de troisième génération, code nommé 38B V3. Beaucoup de frères des lignes produits doivent être très familiers avec ce modèle. À l'époque, le tokenizer de ce modèle était une extension basée sur le vocabulaire LLaMA (ce qui est aussi une pratique courante dans l'industrie). À l'époque, le laboratoire de Wang Yunhe a développé un autre vocabulaire (qui est le vocabulaire de la série Pangu ultérieur). À l'époque, les deux vocabulaires ont même été forcés de concourir, et finalement il n'y a pas eu de conclusion claire sur lequel était meilleur ou pire. Ainsi, la direction a immédiatement décidé que le vocabulaire devait être unifié et que celui de Wang Yunhe devrait être utilisé. Par conséquent, le 135B V3 ultérieur (connu extérieurement sous le nom de Pangu Ultra) entraîné from scratch a adopté ce tokenizer. Cela explique aussi la confusion de nombreux frères qui utilisaient nos modèles, pourquoi deux modèles de niveaux différents dans la même génération V3 utilisaient des tokenizers différents.

Nous estimons sincèrement que **le 135B V3 est la fierté de notre équipe de la Quatrième Brigade à l'époque**. C'est le premier modèle de niveau milliard vraiment auto-développé full-stack par Huawei, vraiment entraîné from scratch, et ses performances étaient comparables à celles des concurrents en 2024. Alors que j'écris cela, les larmes me montent aux yeux ; c'était incroyablement difficile. À l'époque, pour assurer un entraînement stable, l'équipe a mené un grand nombre d'expériences comparatives et a rapidement effectué des rollbacks et redémarré plusieurs fois lorsque les gradients du modèle montraient des anomalies. Ce modèle a vraiment réalisé ce que le rapport technique ultérieur indiquait : aucune pointe de perte pendant tout le processus d'entraînement. Nous avons surmonté d'innombrables difficultés ; nous l'avons fait. Nous sommes prêts à engager notre vie et notre honneur sur l'authenticité de l'entraînement de ce modèle. Combien de nuits blanches avons-nous passées pour son entraînement ? Lorsque nous étions critiqués comme sans valeur dans le forum interne "Xinsheng" (Voix des Employés), combien d'indignation et de griefs avons-nous ressentis ? Nous avons enduré.

Nous, ce groupe de personnes, brûlons vraiment notre jeunesse pour polir notre fondation de calcul nationale... Vivant en terre étrangère, nous avons abandonné nos familles, nos vacances, notre santé, nos loisirs, versant sang et sueur. Les difficultés et les épreuves ne peuvent être résumées en quelques traits. Dans diverses réunions de mobilisation, lorsque les slogans "Pangu vaincra, Huawei vaincra" étaient criés, nous étions vraiment profondément émus dans nos cœurs.

Cependant, tous les fruits de notre dur labeur étaient souvent récoltés sans effort par le Lab des Petits Modèles. Les données, prises directement. Le code, pris directement, et ils exigeaient même que nous l'adaptions pour qu'il soit exécutable en un clic. Nous appelions en plaisantant le Lab des Petits Modèles le "Lab Clique Souris" à l'époque. Nous avons fourni le dur labeur, et ils ont récolté la gloire. Cela incarne vraiment le dicton, "Vous portez la charge lourde parce que quelqu'un d'autre mène une vie confortable." Dans de telles circonstances, de plus en plus de camarades n'ont plus pu persévérer et ont choisi de partir. Voyant ces excellents collègues partir un par un, je me sentais à la fois ému et triste. Dans un environnement aussi combatif, nous étions plus comme des camarades que des collègues. Ils avaient aussi d'innombrables aspects techniques valant d'être appris, de véritables excellents mentors. Les voyant partir vers de nombreuses équipes exceptionnelles telles que ByteDance Seed, DeepSeek, Moonshot AI, Tencent et Kuaishou, je suis sincèrement heureux et leur souhaite du bien, échappant à cet endroit ardu mais sale. Je me souviens encore vivement de ce qu'un ancien collègue a dit : "Venir ici est une honte dans ma carrière technique ; rester ici un jour de plus est un gaspillage de vie." Bien que les mots fussent durs, ils m'ont laissé sans voix. Je m'inquiétais de mon accumulation technique insuffisante et de mon incapacité à m'adapter à l'environnement à turnover élevé des entreprises Internet, ce qui m'a fait vouloir démissionner à plusieurs reprises sans jamais franchir le pas.

En plus du modèle dense, Pangu a ensuite initié l'exploration du MoE. Initialement, un modèle MoE 224B a été entraîné. En parallèle, le Lab des Petits Modèles a également lancé sa deuxième opération majeure de "套壳" (des interludes mineurs peuvent inclure d'autres modèles, comme les modèles mathématiques), à savoir le modèle Pangu Pro MoE 72B largement diffusé. Ce modèle affirmait en interne être une extension du modèle 7B du Lab des Petits Modèles (même ainsi, cela contredit le rapport technique, sans parler d'être un "套壳" de Qwen 2.5 14B pour le fine-tuning). Je me souviens qu'ils n'avaient entraîné que quelques jours lorsque leur évaluation interne a immédiatement rattrapé le 38B V3 de l'époque. Beaucoup de frères du AI System Lab étaient au courant de leur opération de "套壳" parce qu'ils devaient adapter le modèle, mais pour diverses raisons, ils n'ont pas pu faire prévaloir la justice. En fait, pour ce modèle qui a été fine-tuné très longtemps par la suite, je suis déjà très surpris que HonestAGI ait pu analyser ce niveau de similarité, car la puissance de calcul dépensée pour fine-tuner et "laver" les paramètres de ce modèle était suffisante pour entraîner un modèle du même niveau from scratch. J'ai entendu de collègues qu'ils ont utilisé de nombreuses méthodes pour "laver" le watermark Qwen, incluant même un entraînement intentionnel avec des données sales. Cela fournit également un exemple sans précédent et spécial pour la communauté académique pour étudier la lignée des modèles. À l'avenir, de nouvelles méthodes de lignée pourront être présentées en l'utilisant.

Fin 2024 et début 2025, après la sortie de DeepSeek V3 et R1, en raison de leur niveau technique étonnant, l'équipe a subi un énorme impact et a fait face à un examen plus approfondi. Pour suivre la tendance, Pangu a imité la taille du modèle de DeepSeek et a commencé l'entraînement d'un MoE 718B. À ce moment-là, le Lab des Petits Modèles a de nouveau agi. Ils ont choisi de "套壳" DeepSeek V3 pour le fine-tuning. Ils ont entraîné en gelant les paramètres chargés de DeepSeek. Même le répertoire pour charger les checkpoints était "deepseekv3", sans même le changer — quelle arrogance ! En contraste, certains collègues avec de véritables convictions techniques entraînaient un autre MoE 718B from scratch. Cependant, divers problèmes sont survenus. Mais évidemment, comment ce modèle pourrait-il être meilleur qu'un "套壳" direct ? Si ce n'était pas pour l'insistance du chef d'équipe, il aurait été arrêté depuis longtemps.

Le lourd fardeau de la gestion des processus de Huawei a gravement ralenti le rythme de développement des grands modèles, comme le contrôle de version, la lignée des modèles, diverses exigences procédurales et la traçabilité. Ironiquement, les modèles du Lab des Petits Modèles semblaient être exemptés de ces contraintes de processus : ils pouvaient "套壳" quand ils voulaient, fine-tuner quand ils voulaient, et la puissance de calcul était continuellement prise sans question. Ce contraste fort, presque magique, illustre l'état actuel de la gestion des processus : "Seuls les officiels ont le droit de mettre le feu, mais le commun des mortels n'a pas le droit d'allumer des lampes." Combien ridicule ? Combien tragique ? Combien haïssable ? Combien honteux !

Après que l'incident HonestAGI soit sorti, des discussions et analyses internes ont constamment eu lieu sur la façon de faire des relations publiques et de "répondre". En effet, l'analyse originale pourrait ne pas avoir été assez solide, donnant à Wang Yunhe et au Lab des Petits Modèles l'opportunité de chicaner et de déformer les faits. Pour cela, j'ai eu la nausée ces deux derniers jours, doutant constamment du sens de ma vie et de l'injustice du ciel. Je ne joue plus le jeu ; je démissionne. En même temps, je demande aussi à être retiré de la liste des auteurs de certains rapports techniques de Pangu. Être nommé sur ces rapports techniques est une tache que je ne pourrai jamais effacer de ma vie. À l'époque, je ne m'attendais pas à ce qu'ils soient si effrénés pour oser open sourcer. Je ne m'attendais pas à ce qu'ils osent tromper le monde si effrontément et le promouvoir largement. À l'époque, j'avais peut-être une mentalité de 侥幸 (chance) et je n'ai pas refusé d'être nommé. Je crois que de nombreux camarades travailleurs étaient aussi juste forcés de monter sur un "bateau pirate" ou n'étaient pas au courant. Mais cette affaire est irréversible. J'espère que dans le reste de ma vie, je pourrai persévérer à faire un travail vraiment significatif et expier ma faiblesse et mon indécision à l'époque.

En écrivant cela tard dans la nuit, j'ai déjà les larmes aux yeux, sanglotant de manière incontrôlable. Je me souviens encore quand d'excellents collègues ont démissionné, j'ai forcé un sourire et leur ai demandé s'ils voulaient écrire un long post "Xinsheng", exposant la situation actuelle. Ils ont dit : "Non, c'est une perte de temps, et j'ai aussi peur que l'exposer rende votre vie encore pire." À ce moment, j'ai soudainement été découragé parce que les camarades qui s'étaient autrefois battus ensemble pour des idéaux avaient complètement perdu espoir en Huawei. À l'époque, tout le monde plaisantait en disant que nous utilisions le "millet et les fusils" du Parti Communiste d'autrefois, mais que l'organisation avait un style comparable au Kuomintang de ces jours.

Il fut un temps où j'étais fier que nous ayons vaincu les fusils étrangers avec du millet et des fusils.
Maintenant, je suis fatigué. Je veux me rendre.

En fait, même aujourd'hui, j'espère sincèrement que Huawei pourra tirer des leçons, bien faire Pangu, rendre Pangu de classe mondiale et amener Ascend au niveau de Nvidia. La "mauvaise monnaie chassant la bonne" interne a causé à Noah et même à Huawei de perdre rapidement un grand nombre d'excellents talents en grands modèles en peu de temps. Je crois qu'ils brillent maintenant dans diverses équipes telles que DeepSeek, réalisant leurs ambitions et talents, et contribuant à la concurrence féroce en IA entre la Chine et les États-Unis. Je soupire souvent en disant que Huawei n'est pas sans talents, mais ne sait simplement pas comment les retenir. Si on donne à ces personnes le bon environnement, les bonnes ressources, moins d'entraves et moins de luttes politiques, pourquoi Pangu ne réussirait-il pas ?

Enfin : Je jure sur ma vie, mon caractère et mon honneur que tout le contenu que j'ai écrit ci-dessus est vrai (du moins à ma connaissance limitée). Je n'ai pas le haut niveau d'expertise technique ni l'opportunité de mener une analyse détaillée et approfondie, et je n'ose pas utiliser directement des enregistrements internes comme preuve, craignant d'être attrapé pour des raisons de sécurité de l'information. Cependant, je crois que beaucoup de mes anciens camarades témoigneront pour moi. Les frères au sein de Huawei, y compris les frères des lignes produits que nous servions autrefois, je crois que les innombrables détails de cet article correspondront à vos impressions et confirmeront mes déclarations. Vous avez peut-être aussi été trompés, mais ces vérités cruelles ne seront pas enterrées. Les traces de notre lutte ne devraient pas être déformées ou enterrées.

Ayant écrit tant, certaines personnes voudront certainement me trouver et me réduire au silence. L'entreprise pourrait aussi vouloir me réduire au silence ou me tenir pour responsable. Si cela arrive vraiment, ma sécurité personnelle, et même celle de ma famille, pourraient être menacées. Pour l'autoprotection, je signalerai ma sécurité à tout le monde quotidiennement dans un avenir proche.

Si je disparais, considérez cela comme un sacrifice pour la vérité et les idéaux, pour le meilleur développement de la puissance de calcul et de l'IA chez Huawei et même en Chine. Je suis prêt à être enterré à l'endroit où je me suis autrefois battu.

Au revoir, Noah.
Écrit à Shenzhen le 6 juillet 2025, tôt le matin.