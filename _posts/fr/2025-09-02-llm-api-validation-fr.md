---
audio: false
generated: true
image: false
lang: fr
layout: post
title: Couches de Validation d'API LLM S√©curis√©e
translated: true
type: note
---

Lorsque vous construisez ou utilisez une **API LLM**, vous souhaitez g√©n√©ralement des garde-fous pour garantir que les r√©ponses sont s√ªres, valides et utiles. Voici les principales m√©thodes pour ajouter des v√©rifications :

---

### 1. **Validation des entr√©es**

* **V√©rifications de sch√©ma** : S'assurer que le JSON de la requ√™te suit le sch√©ma attendu avant de l'envoyer au LLM.
* **Assainissement du prompt** : Supprimer ou √©chapper les caract√®res ind√©sirables, les instructions malveillantes ou les tentatives d'injection.
* **V√©rifications de longueur** : Appliquer des limites maximales de tokens/caract√®res pour les entr√©es afin d'√©viter des co√ªts inutiles ou une troncation.

---

### 2. **Validation de la sortie**

* **Validation de sch√©ma JSON** : Si le LLM est cens√© renvoyer du JSON, l'ex√©cuter via `json.loads()` et le valider par rapport √† un sch√©ma (par exemple, avec `pydantic`, `jsonschema`).
* **V√©rifications par regex/format** : Pour les e-mails, les URLs ou les nombres, imposer des mod√®les.
* **V√©rification de type** : V√©rifier que les champs sont du bon type (cha√Æne, entier, liste, etc.).
* **V√©rifications de plage** : S'assurer que les valeurs num√©riques ou de date sont dans les limites attendues.

---

### 3. **V√©rifications de s√©curit√© et de contenu**

* **Filtres de toxicit√© ou de profanit√©** : Faire passer la sortie dans un classifieur (par exemple, Perspective API, OpenAI moderation API).
* **Filtres politiques** : D√©finir des r√®gles pour bloquer les r√©ponses contenant certains mots-cl√©s ou cat√©gories.
* **D√©tection d'hallucination** : Ajouter des √©tapes de v√©rification des faits (via des v√©rifications augment√©es par retrieval, une validation crois√©e par multiple mod√®les, ou des v√©rifications de coh√©rence bas√©es sur des r√®gles).

---

### 4. **Contraintes de logique m√©tier**

* **R√®gles de coh√©rence** : Si la r√©ponse doit correspondre aux donn√©es du syst√®me (par exemple, le solde de compte disponible, les valeurs de configuration), effectuer une contre-v√©rification avant de la renvoyer √† l'utilisateur.
* **Garde-fous** : Utiliser des biblioth√®ques comme **Guardrails AI**, **LMQL** ou **Instructor** pour imposer de mani√®re d√©clarative des sorties structur√©es et des contraintes.
* **Hooks de post-traitement** : Envelopper les r√©ponses du LLM avec une logique personnalis√©e (normaliser la casse, imposer des valeurs par d√©faut, rejeter des r√©ponses inattendues).

---

### 5. **Redondance et contre-v√©rification**

* **Prompts d'auto-v√©rification** : Demander au LLM de re-valider ou d'expliquer sa propre r√©ponse.
* **V√©rification par double mod√®le** : Utiliser un LLM plus petit/rapide pour v√©rifier la sortie du mod√®le principal (par exemple, "est-ce que cette r√©ponse est conforme au sch√©ma X ?").
* **Vote/consensus** : Ex√©cuter plusieurs appels et comparer les r√©ponses pour la stabilit√©.

---

### 6. **Sauvegardes op√©rationnelles**

* **Limites de d√©bit** : Emp√™cher l'abus de l'API.
* **D√©lais d'expiration** : Interrompre les requ√™tes qui pendent.
* **Journalisation et pistes d'audit** : Conserver un enregistrement des requ√™tes et des r√©ponses filtr√©es.
* **Solutions de repli** : Si la validation √©choue, soit r√©essayer avec un prompt ajust√©, soit renvoyer une valeur par d√©faut/erreur s√ªre.

---

üëâ En pratique, une bonne pile d'API LLM superpose ces √©l√©ments :

1. Valider l'entr√©e.
2. Appeler le LLM.
3. Valider la sortie par rapport au sch√©ma + r√®gles m√©tier.
4. Ex√©cuter les filtres de s√©curit√©/contenu.
5. Renvoyer uniquement si les v√©rifications passent (sinon r√©essayer/utiliser une solution de repli).

---

Souhaitez-vous que je vous montre un **exemple Python** o√π nous encapsulons un appel d'API LLM avec une validation de sch√©ma JSON et des v√©rifications de mod√©ration ?