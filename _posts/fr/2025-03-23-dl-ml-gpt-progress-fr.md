---
audio: false
generated: true
lang: fr
layout: post
title: Apprentissage profond, apprentissage automatique et progrès des GPT (2010-2025)
translated: true
type: note
---

Voici une chronologie détaillée des avancées majeures en apprentissage profond, en apprentissage automatique et dans le domaine des GPT, de 2010 jusqu'à ma date de coupure de connaissances en octobre 2024 :

## Début des années 2010 : Les Fondations

- **2012 : AlexNet** - L'architecture de réseau neuronal convolutif (CNN) de Krizhevsky, Sutskever et Hinton a remporté la compétition ImageNet, réduisant les taux d'erreur de 26 % à 15,3 %, déclenchant la révolution de l'apprentissage profond en vision par ordinateur.

- **2013 : Word2Vec** - Mikolov a introduit des techniques de plongement lexical (word embeddings) qui représentaient les mots sous forme de vecteurs basés sur le contexte, permettant une compréhension sémantique.

- **2014 : GANs (Generative Adversarial Networks)** - Goodfellow a introduit un cadre où les réseaux générateur et discriminateur sont en compétition, permettant la génération d'images réalistes.

- **2014 : Modèles Sequence-to-Sequence** - Sutskever, Vinyals et Le ont développé des modèles pour la traduction automatique pouvant mapper des séquences d'entrée vers des séquences de sortie.

## Milieu des années 2010 : Émergence des Modèles de Fondation

- **2015 : ResNet** - He et al. ont introduit les connexions résiduelles, permettant l'entraînement de réseaux beaucoup plus profonds (152+ couches) et remportant ImageNet avec un taux d'erreur de 3,57 %.

- **2015 : Normalisation par Lots (Batch Normalization)** - Ioffe et Szegedy ont développé une technique pour stabiliser et accélérer l'entraînement des réseaux neuronaux.

- **2015 : Mécanisme d'Attention** - Bahdanau a introduit l'attention pour la traduction automatique neuronale, permettant aux modèles de se concentrer sur les parties pertinentes des séquences d'entrée.

- **2016 : AlphaGo** - Le système de DeepMind a battu le champion du monde Lee Sedol au jeu de Go, combinant l'apprentissage par renforcement profond avec la recherche arborescente de Monte-Carlo.

## Fin des années 2010 : La Révolution des Transformers

- **2017 : Architecture Transformer** - Vaswani et al. ont introduit l'article "Attention is All You Need", remplaçant les RNN par des mécanismes d'auto-attention.

- **2018 : BERT** - Les Représentations de Codeur Bidirectionnel à partir de Transformers (Bidirectional Encoder Representations from Transformers) de Google ont atteint des résultats de pointe en compréhension du langage naturel.

- **2018 : GPT-1** - OpenAI a publié le premier Generative Pre-trained Transformer avec 117 millions de paramètres, entraîné sur BookCorpus.

- **2019 : GPT-2** - OpenAI a augmenté l'échelle à 1,5 milliard de paramètres, montrant des capacités surprenantes en zero-shot, mais en retenant initialement la publication complète en raison de préoccupations d'utilisation abusive.

## Début des années 2020 : Montée en Échelle et Multimodalité

- **2020 : GPT-3** - OpenAI a publié un modèle de 175 milliards de paramètres montrant des capacités remarquables de few-shot learning sur diverses tâches sans fine-tuning.

- **2021 : DALL-E** - OpenAI a démontré que les transformers pouvaient générer des images à partir de descriptions textuelles.

- **2021 : Codex** - Le modèle de génération de code d'OpenAI, alimentant GitHub Copilot, a montré des capacités en programmation.

- **2021 : Modèles de Diffusion** - GLIDE, DALL-E 2 et Stable Diffusion ont introduit une qualité de génération d'images supérieure.

- **2022 : ChatGPT** - L'interface conversationnelle d'OpenAI pour les modèles GPT a connu une adoption publique sans précédent (100 millions d'utilisateurs en 2 mois).

- **2022 : PaLM** - Le modèle de Google à 540 milliards de paramètres a démontré des capacités de raisonnement.

- **2022 : Chinchilla** - DeepMind a montré des lois d'échelle optimales suggérant que des modèles plus petits avec plus de données peuvent surpasser des modèles plus grands.

## 2023-2024 : LLMs Multimodaux et Raisonnement

- **2023 : GPT-4** - Le modèle multimodal d'OpenAI avec des capacités améliorées de raisonnement, de sécurité et de compréhension d'images.

- **2023 : Claude** - Anthropic a publié une IA constitutionnelle axée sur l'utilité, l'innocuité et l'honnêteté.

- **2023 : LLaMA** - Meta a publié des grands modèles de langage à poids ouvert (open-weight), stimulant l'innovation open-source.

- **2023 : Mixture-of-Experts (MoE)** - Des modèles comme Mixtral 8x7B ont montré des gains d'efficacité en n'activant que les parties pertinentes du réseau pour chaque entrée.

- **2023-2024 : Modèles Multimodaux** - GPT-4V, Gemini, Claude 3 et d'autres ont acquis des capacités à travers la vision, l'audio et le langage.

- **2024 : Sora** - Le modèle texte-vers-vidéo d'OpenAI a généré des vidéos photoréalistes de scènes complexes.

- **2024 : Améliorations du Raisonnement** - Les modèles ont acquis des capacités améliorées de Chaîne de Pensée (Chain-of-Thought), avec des modèles spécialisés pour les mathématiques, le codage et le raisonnement scientifique.

- **2024 : Cadres d'Agents** - Les systèmes incorporant la planification, l'utilisation d'outils et la mémoire ont permis aux modèles d'accomplir des tâches complexes en plusieurs étapes.

## Tendances Clés Tout au Long de Cette Période :

1. **Lois d'Échelle (Scaling Laws)** : Améliorations constantes des performances en augmentant la taille des modèles, la taille des jeux de données et la puissance de calcul.

2. **Capacités Émergentes** : Des capacités comme l'apprentissage en contexte (in-context learning) apparaissant de manière inattendue à certains seuils d'échelle.

3. **Multimodalité** : Intégration du texte, des images, de l'audio et de la vidéo dans des modèles unifiés.

4. **Apprentissage par Renforcement à partir des Retours Humains (RLHF)** : Alignement des modèles avec les préférences humaines.

5. **Démocratisation** : Croissance des modèles open-source et des frameworks accessibles abaissant les barrières au développement en ML.

Cette période représente peut-être le progrès technologique le plus rapide de l'histoire de l'humanité dans n'importe quel domaine, transformant le ML d'une discipline académique spécialisée en une technologie à usage général avec un impact mondial.