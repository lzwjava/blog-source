---
audio: false
generated: true
lang: fr
layout: post
title: Traitement d'image avec les CNN et les Vision Transformers (ViT)
translated: true
type: note
---

Voici des exemples de code d√©montrant comment les images sont trait√©es en utilisant les **Convolutional Neural Networks (CNNs)** et les **Vision Transformers (ViT)** en Python avec **PyTorch**.

---

## **1. Traitement d'image avec un CNN (Convolutional Neural Network)**
Les CNN sont largement utilis√©s pour la classification d'images, la d√©tection d'objets et l'extraction de caract√©ristiques.

### **Exemple : Utilisation d'un CNN pr√©-entra√Æn√© (ResNet)**
```python
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image

# Charger un mod√®le ResNet pr√©-entra√Æn√©
model = models.resnet18(pretrained=True)
model.eval()  # Passer en mode √©valuation

# D√©finir le pr√©traitement de l'image
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Charger et pr√©traiter une image
image = Image.open("example.jpg")  # Remplacer par le chemin de votre image
input_tensor = preprocess(image)
input_batch = input_tensor.unsqueeze(0)  # Ajouter une dimension de lot

# D√©placer sur le GPU si disponible
if torch.cuda.is_available():
    input_batch = input_batch.to('cuda')
    model.to('cuda')

# Extraire les caract√©ristiques (avant la couche de classification finale)
with torch.no_grad():
    features = model(input_batch)

print("Forme du vecteur de caract√©ristiques :", features.shape)  # ex: torch.Size([1, 1000])
```
**Explication** :
1. **ResNet18** est une architecture CNN pr√©-entra√Æn√©e sur ImageNet.
2. L'image est pr√©trait√©e (redimensionn√©e, normalis√©e).
3. Le mod√®le convertit l'image en un **vecteur de caract√©ristiques** (par exemple, de dimension 1000 pour ResNet18).

---

## **2. Traitement d'image avec un Vision Transformer (ViT)**
Les ViT traitent les images comme des s√©quences de patches et utilisent des m√©canismes d'auto-attention (comme en NLP).

### **Exemple : Utilisation d'un ViT pr√©-entra√Æn√© (Hugging Face)**
```python
from transformers import ViTFeatureExtractor, ViTModel
from PIL import Image
import torch

# Charger un Vision Transformer (ViT) pr√©-entra√Æn√©
model_name = "google/vit-base-patch16-224-in21k"
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)
model = ViTModel.from_pretrained(model_name)

# Charger une image
image = Image.open("example.jpg")  # Remplacer par le chemin de votre image

# Pr√©traiter l'image (convertir en patches)
inputs = feature_extractor(images=image, return_tensors="pt")

# Extraire les caract√©ristiques (token CLS ou embeddings des patches)
with torch.no_grad():
    outputs = model(**inputs)

# Obtenir le vecteur de caract√©ristiques (token CLS)
features = outputs.last_hidden_state[:, 0, :]  # Forme: [1, 768]

print("Forme du vecteur de caract√©ristiques :", features.shape)  # ex: torch.Size([1, 768])
```
**Explication** :
1. **ViT** d√©coupe l'image en **patches de 16x16** et les traite comme des tokens en NLP.
2. Le `token CLS` (premier token) repr√©sente le vecteur de caract√©ristiques de l'image enti√®re.
3. La sortie est un **vecteur de dimension 768** (pour `vit-base`).

---

## **3. Comparaison de l'extraction de caract√©ristiques : CNN vs. ViT**

| Mod√®le | Approche | Taille du vecteur de caract√©ristiques | Biblioth√®ques |
|-------|----------|---------------------|-----------|
| **CNN (ResNet18)** | Couches convolutionnelles + pooling | 1000 (classes ImageNet) | `torchvision` |
| **ViT (Google ViT-Base)** | Embeddings de patches + Transformer | 768 (dimension cach√©e) | `transformers` |

---

## **4. Applications des vecteurs de caract√©ristiques d'image**
- **Recherche d'image** : Comparer les vecteurs de caract√©ristiques (par exemple, similarit√© cosinus).
- **Transfer Learning** : Utiliser des caract√©ristiques pr√©-entra√Æn√©es pour des t√¢ches personnalis√©es.
- **D√©tection d'objets** : Extraire les r√©gions d'int√©r√™t (ROI) √† partir des caract√©ristiques.

```python
# Exemple : Calculer la similarit√© entre deux images
from sklearn.metrics.pairwise import cosine_similarity

# Supposons que features1 et features2 sont des vecteurs extraits
similarity = cosine_similarity(features1, features2)
print("Score de similarit√© :", similarity[0][0])
```

---

## **Points cl√©s √† retenir**
1. Les **CNN** (par exemple, ResNet) utilisent des **couches convolutionnelles** pour extraire des caract√©ristiques hi√©rarchiques.
2. Les **ViT** (par exemple, ViT de Google) traitent les images comme des **s√©quences de patches** et utilisent l'**auto-attention**.
3. Les deux convertissent les images en **vecteurs de caract√©ristiques** pour des t√¢ches en aval.

Souhaitez-vous un exemple sur **l'entra√Ænement d'un CNN/ViT personnalis√©** √† partir de z√©ro ? Faites-le moi savoir ! üöÄ