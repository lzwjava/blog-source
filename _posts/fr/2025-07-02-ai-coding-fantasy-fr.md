---
audio: false
generated: true
lang: fr
layout: post
title: L'IA ne peut remplacer les compétences en programmation
translated: true
type: note
---

https://weibo.com/6347862377/5183583601819943

---

Il y a tellement de désinformation en ligne ces jours-ci, prétendant que l'IA (LLM) est incroyablement compétente en programmation, capable de terminer des projets sans écrire une seule ligne de code. D'après ma vaste expérience pratique avec ChatGPT, Claude, Copilot, et récemment Cursor, c'est presque un fantasme de penser que quelqu'un qui ne sait pas programmer peut réussir à terminer un projet en utilisant l'IA.

Même ceux qui savent programmer mais qui manquent d'une compréhension profonde de l'informatique et de la capacité à écrire des programmes extrêmement simples et logiquement précis sont peu susceptibles de produire du code de "niveau Wang Yin" avec l'IA. Certains sont surpris que Wang Yin utilise aussi l'IA ? Bien sûr, pourquoi pas moi ? Je l'utilise pas mal et plus efficacement que la plupart des gens. Pendant les dernières étapes de la cinquième session du cours sur les bases de l'informatique l'année dernière, j'ai démontré aux étudiants comment utiliser Copilot pour compléter du code. Cependant, je ne recommande pas aux étudiants de la classe d'utiliser ces outils parce qu'ils n'ont pas la capacité de discerner la qualité du code généré, et utiliser l'IA entraverait clairement leur réflexion et leur progression. Mais moi, je peux la contrôler, donc je peux l'utiliser.

Au cours du dernier mois, Cursor a généré plus de 60 000 lignes de code pour moi. Devinez combien de lignes j'ai acceptées ? Moins de 5 000. Il part souvent dans la mauvaise direction, répète la même logique sans comprendre l'abstraction, et corrige même des parties que j'avais ajustées manuellement, revenant sur des erreurs précédemment corrigées. Il écrit beaucoup de tests complexes qu'il ne peut pas lui-même comprendre, échouant finalement à comprendre pourquoi les tests "ne passent pas..."

Il y a quelques jours, j'ai créé un nouveau projet qui a consommé plus de 20 heures de mes "explications" à l'IA, resulting en la génération de plus de 20 000 lignes de code. Finalement, c'est devenu si complexe que c'était irréparable, et j'ai dû décider de recommencer complètement. L'IA a même applaudi : "Succès !" et a listé point par point les "réalisations", ignorant complètement les erreurs fondamentales qui n'avaient aucun sens. J'ai pointé les problèmes à plusieurs reprises, mais elle n'arrêtait pas de répondre par "Oh, je vois !" et "Cette fois, j'ai trouvé la racine du problème !" mais ce n'était que du vent... Parce que cela ne pouvait pas être corrigé, elle ne pouvait que se tromper elle-même ?

Le modèle que j'utilisais était le dernier Claude 4 sonnet. GPT 4.1 est encore pire et presque inutilisable pour la modification de code. Claude opus est trop cher et lent, et d'après ce que j'ai essayé, il ne semble pas être bien meilleur que sonnet. Certaines personnes fournissent des "guides" de configuration pour Cursor, disant qu'il suffit d'écrire cela dans .cursorrules. Bien sûr, j'ai essayé, mais c'est inutile. Cela ne satisfait pas ce que vous demandez ; même les exigences que je viens de proposer peuvent parfois être ignorées. Les gens pensent que l'IA peut comprendre une grande quantité de code complexe, mais maintes et maintes fois, l'expérience m'a appris qu'elle ne le peut pas.

Personne ne peut comprendre le code désordonné, pas même Wang Yin. Si vous donnez des instructions à l'IA plusieurs fois et que le code généré est combiné, il commence à se répéter et à devenir désordonné. L'IA ne peut pas comprendre les modèles et les similarités dans ce code ; il se peut même qu'elle n'ait pas regardé une partie du code. Donc, elle ne peut pas simplifier un tel code ni même voir où il peut être simplifié. À plusieurs reprises, j'ai explicitement marqué les numéros de ligne et j'ai pointé : "Cette partie peut être simplifiée." Elle a répondu : "Oui ! Je vais vous aider à la simplifier !" Mais à la fin, sa compréhension était complètement différente ; elle est allée corriger des parties qui étaient correctes à l'origine, et le code n'était pas du tout simplifié.

Ne vous méprenez pas, utiliser l'IA pour faire des choses n'est pas toujours un échec ; en fait, c'est souvent un succès à petite échelle. Parfois, elle peut vraiment faire avancer les choses, mais il faut savoir la contrôler. Je donne cet exemple juste pour montrer que même Wang Yin échoue souvent en utilisant l'IA pour écrire du code. Ce n'est clairement pas comme annoncé, où il suffit de lui dire quoi faire. Je l'ai décrit avec beaucoup de détails, et cela ne fonctionne toujours pas bien. À quel point les descriptions de Wang Yin peuvent-elles être détaillées ? Il suffit de regarder les articles de Wang Yin, et vous saurez.

Certains disent de ne pas fixer d'objectifs trop élevés ou trop rapides et d'avoir une stratégie. Bien sûr, je le sais ; je suis très stratégique. Pensez-vous que mes projets réussis précédents auraient pu être accomplis sans sagesse et sans stratégie ? La stratégie consiste à savoir quoi faire en premier, quoi faire plus tard, ce qui devrait être fait, ce qui ne devrait pas être fait, et ce qui ne devrait pas être fait pour le moment. Je peux dire que je suis un maître dans ce genre de stratégie. Très peu de gens savent comment je fais les choses ; ils ne connaissent que le résultat final.

Après que j'ai fait PySonar, une équipe chez Google a passé deux ans à essayer de créer un projet qui surpasserait PySonar, mais à la fin, ils n'ont rien accompli. Pourquoi ? Parce que leur stratégie était erronée dès le début. Ils voulaient utiliser un langage de programmation logique comme Prolog pour implémenter l'inférence de types. Dès que j'ai entendu cela, j'ai su que c'était voué à l'échec. Comment le savais-je ? Parce que je l'avais déjà essayé, et je connaissais les limites du système Hindley-Milner et de Prolog. Savoir ce qu'il ne faut pas faire et ce qui est voué à l'échec est en fait une sagesse et une stratégie très importantes. Beaucoup de gens manquent de cette sagesse.

Je m'égare. Bref, j'ai découvert plus tard que mes stratégies de programmation habituelles peuvent être utilisées pour guider l'IA dans l'écriture de code, comme commencer par les petites fonctions les plus basiques et progresser graduellement. Peut-elle bien faire si elle est guidée ainsi ? J'ai constaté qu'elle ne peut même pas bien écrire de petits morceaux de code. Certaines petites fonctions de quelques lignes seulement nécessitent que je les corrige plusieurs fois avant qu'elle ne les obtienne correctement. Et puis, qui sait quand elle pourrait les corriger à nouveau incorrectement, donc vous devez vérifier chaque endroit qu'elle a modifié. Vous devez savoir à quoi ressemble un bon code et ce qui est de la camelote. En d'autres termes, vous devez réviser presque chaque ligne de code qu'elle écrit, sinon, il est facile de perdre le contrôle.

Si vous ne savez pas écrire du code, comment pouvez-vous réviser le code de quelqu'un d'autre ? Savoir à quoi ressemble un code bon et correct est la chose la plus difficile. Sans recherche approfondie et beaucoup d'expérience, il est impossible de discerner. Oui, l'IA est maintenant devenue un codeur, et je suis devenu un VP. Mais à quoi peut servir un VP qui ne comprend pas l'informatique et qui dirige un groupe de codeurs écrivant du code spaghetti ? Héhé, je comprends des phénomènes similaires dans de nombreuses entreprises. Ils ne savent pas ce que font leurs subordonnés, qui a raison, ou quelle devrait être la prochaine étape. Je sais combien de VPs tâtonnent dans le noir, trompant et trichant.

Ainsi, les personnes sans capacité ne peuvent toujours rien faire avec l'IA parce qu'elles ne peuvent pas la contrôler. Ils ne sont pas qualifiés pour être VPs. Parce que la plupart du code dans le monde est écrit par des programmeurs médiocres de code spaghetti, et les données d'entraînement sont comme ça, il est attendu que l'IA puisse difficilement écrire du code de "niveau Wang Yin". J'ai constaté qu'en donnant mon code bien écrit à l'IA, elle peut effectivement effectuer quelques analyses et améliorations utiles. Mais si elle commence à écrire à partir de zéro, l'IA a vraiment du mal. Presque chaque petite fonction nécessite que je la corrige plusieurs fois pour atteindre la simplicité et la compréhensibilité que j'attends.

Le code dans mon cours d'informatique est extrêmement profond, complètement différent du code d'entreprise et des projets open source. Ainsi, les étudiants qui suivent mon cours ont peu d'espoir d'utiliser l'IA pour terminer leurs exercices. Parce que le volume de données est trop faible, il n'y a pas de données d'entraînement, donc l'IA pourrait ne jamais atteindre ce niveau de profondeur. Bien sûr, après l'obtention de leur diplôme, le niveau des étudiants dépasse de loin celui de l'IA et de ces programmeurs médiocres qui sont la source des données d'entraînement de l'IA. C'est pourquoi mon cours s'appelle "Informatique" et non "Programmation". Il y a une énorme différence entre les informaticiens et les programmeurs/ingénieurs logiciels.

L'IA pourrait peut-être remplacer les programmeurs ordinaires, mais elle ne pourra jamais remplacer les informaticiens. Elle ne peut être utilisée par les informaticiens que comme un outil. Ne vous méprenez pas, je pense en fait que l'IA est une grande chose et une invention vraiment géniale. J'ai constaté que le LLM peut vraiment comprendre le langage humain et semble avoir un niveau profond de "pensée", ce qui est déjà une réalisation remarquable. Mes évaluations précédentes de l'IA étaient pour la plupart correctes, comme la prédiction que les "voitures autonomes" sont vouées à l'échec. C'est juste que les capacités du LLM ont quelque peu dépassé mes attentes.

Cependant, le niveau de programmation actuel du LLM est clairement bien inférieur au mien. En utilisant l'IA, j'ai constaté que la vitesse de résolution des problèmes a beaucoup augmenté parce que de nombreuses tâches fastidieuses ne nécessitent pas mon attention personnelle, me permettant de me concentrer davantage sur les parties centrales. Bref, je l'utilise pour faire le "sale boulot" que je ne veux pas faire, et elle ne se plaint pas. C'est pourquoi, après tant d'échecs, je continue à les utiliser et même à payer pour les utiliser. Parce qu'il y a trop de sale boulot dans ce monde, trop de documents complexes et mal conçus, et j'ai besoin d'un tel outil pour m'aider à les traiter. Mais les idées centrales doivent toujours venir de moi ; l'IA est impuissante à cet égard.