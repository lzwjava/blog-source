---
audio: false
generated: false
lang: fr
layout: post
title: Introduction au Cloud Computing et au Big Data
translated: true
---

Cette le√ßon couvre les sujets suivants :

* Spark
* Hadoop
* Kubernetes
* Docker
* Flink
* MongoDB

Lorsqu'on parle de cloud computing, il semble difficile de ne pas mentionner de nombreux outils tels que Hadoop, Hive, Hbase, ZooKeeper, Docker, Kubernetes, Spark, Kafka, MongoDB, Flink, Druid, Presto, Kylin, et Elastic Search. Les avez-vous tous entendus ? Certains de ces outils, je les ai d√©couverts dans les descriptions de postes d'`ing√©nieur en big data` et d'`ing√©nieur back-end distribu√©`. Ce sont des postes bien r√©mun√©r√©s. Essayons de les installer tous et de les manipuler un peu.
## Premi√®re exploration de Spark

Le site officiel indique que `Spark` est un moteur d'analyse pour le traitement de donn√©es √† grande √©chelle. `Spark` est essentiellement une biblioth√®que. Contrairement √† `Redis`, il ne semble pas √™tre divis√© en un serveur et un client. `Spark` est uniquement utilis√© c√¥t√© client. J'ai t√©l√©charg√© la derni√®re version depuis le site officiel, `spark-3.1.1-bin-hadoop3.2.tar`.

```shell
$ tree . -L 1
.
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ NOTICE
‚îú‚îÄ‚îÄ R
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ RELEASE
‚îú‚îÄ‚îÄ bin
‚îú‚îÄ‚îÄ conf
‚îú‚îÄ‚îÄ data
‚îú‚îÄ‚îÄ examples
‚îú‚îÄ‚îÄ jars
‚îú‚îÄ‚îÄ kubernetes
‚îú‚îÄ‚îÄ licenses
‚îú‚îÄ‚îÄ python
‚îú‚îÄ‚îÄ sbin
‚îî‚îÄ‚îÄ yarn
```

11 r√©pertoires, 4 fichiers
```

Il semble qu'il s'agisse principalement de biblioth√®ques d'analyse √©crites dans diff√©rents langages.

En m√™me temps, le site officiel indique que vous pouvez installer directement les d√©pendances sur Python. `pip install pyspark`

```shell
$ pip install pyspark
Collecting pyspark
  T√©l√©chargement de pyspark-3.1.1.tar.gz (212,3 Mo)
     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 212,3 Mo 14 ko/s
Collecting py4j==0.10.9
  T√©l√©chargement de py4j-0.10.9-py2.py3-none-any.whl (198 ko)
     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198 ko 145 ko/s
Construction des roues pour les paquets collect√©s : pyspark
  Construction de la roue pour pyspark (setup.py) ... termin√©
  Roue cr√©√©e pour pyspark : nom=pyspark-3.1.1-py2.py3-none-any.whl taille=212767604 sha256=0b8079e82f3a5bcadad99179902d8c8ff9f8eccad928a469c11b97abdc960b72
  Stock√© dans le r√©pertoire : /Users/lzw/Library/Caches/pip/wheels/23/bf/e9/9f3500437422e2ab82246f25a51ee480a44d4efc6c27e50d33
pyspark construit avec succ√®s
Installation des paquets collect√©s : py4j, pyspark
py4j-0.10.9 et pyspark-3.1.1 install√©s avec succ√®s
```

Install√©.

Je regarde le site officiel, il y a quelques exemples.

```shell
./bin/run-example SparkPi 10
```

Ah, donc on peut ex√©cuter le programme contenu dans le package d'installation que l'on vient de t√©l√©charger. Mais il y a une erreur.

```shell
$ ./bin/run-example SparkPi 10
21/03/11 00:06:15 WARN NativeCodeLoader: Impossible de charger la biblioth√®que native-hadoop pour votre plateforme... utilisation des classes Java int√©gr√©es l√† o√π c'est applicable
21/03/11 00:06:16 INFO ResourceUtils: Aucune ressource personnalis√©e configur√©e pour spark.driver.
21/03/11 00:06:16 WARN Utils: Le service 'sparkDriver' n'a pas pu se lier sur un port libre al√©atoire. Vous pouvez v√©rifier si une adresse de liaison appropri√©e est configur√©e.
```

> Spark est un moteur de traitement rapide et g√©n√©ral compatible avec les donn√©es Hadoop. Il peut fonctionner dans des clusters Hadoop via YARN ou en mode autonome de Spark, et il peut traiter des donn√©es dans HDFS, HBase, Cassandra, Hive et tout format d'entr√©e Hadoop. Il est con√ßu pour effectuer √† la fois du traitement par lots (similaire √† MapReduce) et de nouvelles charges de travail comme le streaming, les requ√™tes interactives et l'apprentissage automatique.

Le terme `hadoop` est apparu plusieurs fois. Apr√®s avoir cherch√© sur Google `spark depends hadoop`, j'ai trouv√© ce passage. Il semble que cela d√©pende des donn√©es au format `Hadoop`. Commen√ßons par √©tudier `Hadoop`.

## Hadoop

Apr√®s avoir rapidement parcouru le site officiel, passons √† l'installation.

```shell
brew install hadoop
```

Pendant l'installation, prenons le temps de comprendre.

> La biblioth√®que logicielle Apache Hadoop est un framework qui permet le traitement distribu√© de grands ensembles de donn√©es √† travers des clusters d'ordinateurs en utilisant des mod√®les de programmation simples. Il est con√ßu pour √©voluer d'un seul serveur √† des milliers de machines, chacune offrant des capacit√©s de calcul et de stockage locales. Plut√¥t que de d√©pendre du mat√©riel pour assurer une haute disponibilit√©, la biblioth√®que elle-m√™me est con√ßue pour d√©tecter et g√©rer les d√©faillances au niveau de la couche application, offrant ainsi un service hautement disponible sur un cluster d'ordinateurs, dont chacun peut √™tre sujet √† des pannes.

En d'autres termes, Hadoop est un ensemble de frameworks con√ßu pour traiter des ensembles de donn√©es distribu√©s. Ces ensembles de donn√©es peuvent √™tre r√©partis sur de nombreux ordinateurs. Il utilise un mod√®le de programmation tr√®s simple pour les traiter. Il est con√ßu pour passer d'un seul serveur √† des milliers de machines. Plut√¥t que de d√©pendre de la haute disponibilit√© du mat√©riel, cette biblioth√®que est con√ßue pour d√©tecter et g√©rer les erreurs au niveau de la couche application. Ainsi, elle permet de d√©ployer des services hautement disponibles sur un cluster, m√™me si chaque ordinateur du cluster est susceptible de tomber en panne.

```shell
$ brew install hadoop
Erreur :
  homebrew-core est un clone superficiel.
  homebrew-cask est un clone superficiel.
Pour effectuer `brew update`, ex√©cutez d'abord :
  git -C /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core fetch --unshallow
  git -C /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask fetch --unshallow
Ces commandes peuvent prendre quelques minutes √† s'ex√©cuter en raison de la taille importante des d√©p√¥ts.
Cette restriction a √©t√© impos√©e √† la demande de GitHub car la mise √† jour de clones superficiels
est une op√©ration extr√™mement co√ªteuse en raison de la structure de l'arborescence et du trafic des
d√©p√¥ts Homebrew/homebrew-core et Homebrew/homebrew-cask. Nous ne le faisons pas automatiquement
pour vous afin d'√©viter de r√©p√©ter une op√©ration co√ªteuse de d√©superficialisation dans les syst√®mes CI
(qui devraient plut√¥t √™tre corrig√©s pour ne pas utiliser de clones superficiels). Nous nous excusons pour
le d√©sagr√©ment !
==> T√©l√©chargement de https://homebrew.bintray.com/bottles/openjdk-15.0.1.big_sur.bottle.tar.gz
D√©j√† t√©l√©charg√© : /Users/lzw/Library/Caches/Homebrew/downloads/d1e3ece4af1d225bc2607eaa4ce85a873d2c6d43757ae4415d195751bc431962--openjdk-15.0.1.big_sur.bottle.tar.gz
==> T√©l√©chargement de https://www.apache.org/dyn/closer.lua?path=hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
D√©j√† t√©l√©charg√© : /Users/lzw/Library/Caches/Homebrew/downloads/764c6a0ea7352bb8bb505989feee1b36dc628c2dcd6b93fef1ca829d191b4e1e--hadoop-3.3.0.tar.gz
==> Installation des d√©pendances pour hadoop : openjdk
==> Installation de la d√©pendance hadoop : openjdk
==> D√©versement de openjdk-15.0.1.big_sur.bottle.tar.gz
==> Avertissements
Pour que les wrappers Java du syst√®me trouvent ce JDK, cr√©ez un lien symbolique avec
  sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk
```

openjdk est keg-only, ce qui signifie qu'il n'a pas √©t√© li√© symboliquement dans /usr/local,
car il masque le wrapper `java` de macOS.

Si vous devez avoir openjdk en premier dans votre PATH, ex√©cutez :
  ```bash
  echo 'export PATH="/usr/local/opt/openjdk/bin:$PATH"' >> /Users/lzw/.bash_profile
  ```

Pour que les compilateurs trouvent openjdk, vous devrez peut-√™tre d√©finir :
  ```bash
  export CPPFLAGS="-I/usr/local/opt/openjdk/include"
  ```

==> R√©sum√©
üç∫  /usr/local/Cellar/openjdk/15.0.1: 614 fichiers, 324,9 Mo
==> Installation de hadoop
üç∫  /usr/local/Cellar/hadoop/3.3.0: 21 819 fichiers, 954,7 Mo, construit en 2 minutes 15 secondes
==> Mise √† jour de 1 d√©pendance :
maven 3.3.3 -> 3.6.3_1
==> Mise √† jour de maven 3.3.3 -> 3.6.3_1
==> T√©l√©chargement de https://www.apache.org/dyn/closer.lua?path=maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
==> T√©l√©chargement depuis https://mirror.olnevhost.net/pub/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
######################################################################## 100,0%
Erreur : L'√©tape `brew link` ne s'est pas termin√©e avec succ√®s
La formule a √©t√© construite, mais n'est pas li√©e symboliquement dans /usr/local
Impossible de cr√©er un lien symbolique pour bin/mvn
La cible /usr/local/bin/mvn
est un lien symbolique appartenant √† maven. Vous pouvez le supprimer :
  brew unlink maven

Pour forcer le lien et √©craser tous les fichiers en conflit :
  brew link --overwrite maven

Pour lister tous les fichiers qui seraient supprim√©s :
  brew link --overwrite --dry-run maven

Les fichiers potentiellement en conflit sont :
/usr/local/bin/mvn -> /usr/local/Cellar/maven/3.3.3/bin/mvn
/usr/local/bin/mvnDebug -> /usr/local/Cellar/maven/3.3.3/bin/mvnDebug
/usr/local/bin/mvnyjp -> /usr/local/Cellar/maven/3.3.3/bin/mvnyjp
==> R√©sum√©
üç∫  /usr/local/Cellar/maven/3.6.3_1: 87 fichiers, 10.7MB, construit en 7 secondes
Suppression : /usr/local/Cellar/maven/3.3.3... (92 fichiers, 9MB)
==> V√©rification des d√©pendants des formules mises √† niveau...
==> Aucun d√©pendant cass√© trouv√© !
==> Avertissements
==> openjdk
Pour que les wrappers Java du syst√®me trouvent ce JDK, cr√©ez un lien symbolique avec
  sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk

openjdk est keg-only, ce qui signifie qu'il n'a pas √©t√© li√© symboliquement dans /usr/local,
car il masque le wrapper `java` de macOS.

Si vous devez avoir openjdk en premier dans votre PATH, ex√©cutez :
  ```bash
  echo 'export PATH="/usr/local/opt/openjdk/bin:$PATH"' >> /Users/lzw/.bash_profile
  ```

Pour que les compilateurs trouvent openjdk, vous devrez peut-√™tre d√©finir :
  export CPPFLAGS="-I/usr/local/opt/openjdk/include"
```

J'ai remarqu√© dans les logs de sortie de `brew` que `maven` n'√©tait pas correctement li√©. Ensuite, j'ai proc√©d√© √† un lien forc√© vers la version `3.6.3_1`.

```shell
  brew link --overwrite maven
```

`Hadoop` est maintenant install√© avec succ√®s.

> ## Modules
>
> Le projet inclut les modules suivants :
>
> - **Hadoop Common** : Les utilitaires communs qui prennent en charge les autres modules Hadoop.
> - **Hadoop Distributed File System (HDFS‚Ñ¢)** : Un syst√®me de fichiers distribu√© qui offre un acc√®s √† haut d√©bit aux donn√©es des applications.
> - **Hadoop YARN** : Un framework pour la planification des t√¢ches et la gestion des ressources du cluster.
> - **Hadoop MapReduce** : Un syst√®me bas√© sur YARN pour le traitement parall√®le de grands ensembles de donn√©es.
> - **Hadoop Ozone** : Un magasin d'objets pour Hadoop.

Il dit qu'il y a ces modules. Cela a tap√© `hadoop` et voici ce qui est apparu :

```shell
$ hadoop
Usage : hadoop [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]
 ou     hadoop [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]
  o√π CLASSNAME est une classe Java fournie par l'utilisateur
```

OPTIONS peut √™tre `none` ou l'une des options suivantes :

--config dir                     R√©pertoire de configuration Hadoop
--debug                          activer le mode de d√©bogage du script shell
--help                           informations sur l'utilisation
buildpaths                       tenter d'ajouter des fichiers de classe depuis l'arborescence de construction
hostnames list[,of,host,names]   h√¥tes √† utiliser en mode esclave
hosts filename                   liste des h√¥tes √† utiliser en mode esclave
loglevel level                   d√©finir le niveau log4j pour cette commande
workers                          activer le mode travailleur

  SUBCOMMAND est l'un des :
    Commandes Administrateur :

daemonlog     obtenir/d√©finir le niveau de journalisation pour chaque d√©mon

    Commandes Client :

archive       cr√©er une archive Hadoop
checknative   v√©rifier la disponibilit√© des biblioth√®ques natives Hadoop et de compression
classpath     affiche le chemin de classe n√©cessaire pour obtenir le fichier jar Hadoop et les biblioth√®ques requises
conftest      valider les fichiers de configuration XML
credential    interagir avec les fournisseurs d'identifiants
distch        changeur de m√©tadonn√©es distribu√©
distcp        copier un fichier ou des r√©pertoires de mani√®re r√©cursive
dtutil        op√©rations li√©es aux jetons de d√©l√©gation
envvars       afficher les variables d'environnement Hadoop calcul√©es
fs            ex√©cuter un client utilisateur g√©n√©rique de syst√®me de fichiers
gridmix       soumettre un m√©lange de travaux synth√©tiques, mod√©lisant une charge de production profil√©e
jar <jar>     ex√©cuter un fichier jar. REMARQUE : veuillez utiliser "yarn jar" pour lancer des applications YARN, pas cette commande.
jnipath       affiche le java.library.path
kdiag         diagnostiquer les probl√®mes Kerberos
kerbname      montrer la conversion du principal auth_to_local
key           g√©rer les cl√©s via le KeyProvider
rumenfolder   mettre √† l'√©chelle une trace d'entr√©e rumen
rumentrace    convertir des journaux en une trace rumen
s3guard       g√©rer les m√©tadonn√©es sur S3
trace         afficher et modifier les param√®tres de tra√ßage Hadoop
version       afficher la version

    Commandes Daemon :

kms           ex√©cuter KMS, le serveur de gestion des cl√©s
registrydns   ex√©cuter le serveur DNS du registre

SUBCOMMAND peut afficher l'aide lorsqu'il est invoqu√© sans param√®tres ou avec -h.
```

Le site officiel fournit quelques exemples.

```shell
  $ mkdir input
  $ cp etc/hadoop/*.xml input
  $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'
  $ cat output/*
```

On remarque la pr√©sence de `share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar`. Cela signifie qu'il y a peut-√™tre des fichiers d'exemple que nous n'avons pas obtenus. On suppose que l'installation via `Homebrew` ne fournit pas ces fichiers. Nous avons donc t√©l√©charg√© le package d'installation depuis le site officiel.

```shell
$ tree . -L 1
.
‚îú‚îÄ‚îÄ LICENSE-binary
‚îú‚îÄ‚îÄ LICENSE.txt
‚îú‚îÄ‚îÄ NOTICE-binary
‚îú‚îÄ‚îÄ NOTICE.txt
‚îú‚îÄ‚îÄ README.txt
‚îú‚îÄ‚îÄ bin
‚îú‚îÄ‚îÄ etc
‚îú‚îÄ‚îÄ include
‚îú‚îÄ‚îÄ lib
‚îú‚îÄ‚îÄ libexec
‚îú‚îÄ‚îÄ licenses-binary
‚îú‚îÄ‚îÄ sbin
‚îî‚îÄ‚îÄ share
```

Le r√©pertoire `share` est apparu. Cependant, est-ce que `Homebrew` n'a vraiment pas ces fichiers suppl√©mentaires ? Trouvez le r√©pertoire d'installation de `Homebrew`.

```shell
$ type hadoop
hadoop est /usr/local/bin/hadoop
$ ls -alrt /usr/local/bin/hadoop
lrwxr-xr-x  1 lzw  admin  33 Mar 11 00:48 /usr/local/bin/hadoop -> ../Cellar/hadoop/3.3.0/bin/hadoop
$ cd /usr/local/Cellar/hadoop/3.3.0
```

Voici l'arborescence des r√©pertoires imprim√©e sous `/usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop` :

```shell
$ tree . -L 2
.
‚îú‚îÄ‚îÄ client
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-client-api-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-client-minicluster-3.3.0.jar
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ hadoop-client-runtime-3.3.0.jar
‚îú‚îÄ‚îÄ common
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-common-3.3.0-tests.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-common-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-kms-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-nfs-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-registry-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ jdiff
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ lib
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sources
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ webapps
‚îú‚îÄ‚îÄ hdfs
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-hdfs-3.3.0-tests.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-hdfs-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-hdfs-client-3.3.0-tests.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-hdfs-client-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-hdfs-httpfs-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-hdfs-native-client-3.3.0-tests.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-hdfs-native-client-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-hdfs-nfs-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-hdfs-rbf-3.3.0-tests.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-hdfs-rbf-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ jdiff
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ lib
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sources
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ webapps
‚îú‚îÄ‚îÄ mapreduce
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-mapreduce-client-app-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-mapreduce-client-common-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-mapreduce-client-core-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-mapreduce-client-hs-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-mapreduce-client-hs-plugins-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-mapreduce-client-jobclient-3.3.0-tests.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-mapreduce-client-jobclient-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-mapreduce-client-nativetask-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-mapreduce-client-shuffle-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-mapreduce-client-uploader-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hadoop-mapreduce-examples-3.3.0.jar
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ jdiff
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ lib-examples
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sources
‚îú‚îÄ‚îÄ tools
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ dynamometer
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ lib
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ resourceestimator
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sls
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sources
‚îî‚îÄ‚îÄ yarn
    ‚îú‚îÄ‚îÄ csi
    ‚îú‚îÄ‚îÄ hadoop-yarn-api-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-applications-catalog-webapp-3.3.0.war
    ‚îú‚îÄ‚îÄ hadoop-yarn-applications-distributedshell-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-applications-mawo-core-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-client-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-common-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-registry-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-server-applicationhistoryservice-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-server-common-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-server-nodemanager-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-server-resourcemanager-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-server-router-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-server-sharedcachemanager-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-server-tests-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-server-timeline-pluginstorage-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-server-web-proxy-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-services-api-3.3.0.jar
    ‚îú‚îÄ‚îÄ hadoop-yarn-services-core-3.3.0.jar
    ‚îú‚îÄ‚îÄ lib
    ‚îú‚îÄ‚îÄ sources
    ‚îú‚îÄ‚îÄ test
    ‚îú‚îÄ‚îÄ timelineservice
    ‚îú‚îÄ‚îÄ webapps
    ‚îî‚îÄ‚îÄ yarn-service-examples
```

Vous pouvez voir qu'il y a de nombreux fichiers `jar`.

```shell
$ mkdir input
$ ls
bin			hadoop-config.sh	hdfs-config.sh		libexec			sbin			yarn-config.sh
etc			hadoop-functions.sh	input			mapred-config.sh	share
$ cp etc/hadoop/*.xml input
$ cd input/
$ ls
capacity-scheduler.xml	hadoop-policy.xml	hdfs-site.xml		kms-acls.xml		mapred-site.xml
core-site.xml		hdfs-rbf-site.xml	httpfs-site.xml		kms-site.xml		yarn-site.xml
$ cd ..
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'
Le fichier JAR n'existe pas ou n'est pas un fichier normal : /usr/local/Cellar/hadoop/3.3.0/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar
$
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar grep input output 'dfs[a-z.]+'
2021-03-11 01:54:30,791 WARN util.NativeCodeLoader: Impossible de charger la biblioth√®que native-hadoop pour votre plateforme... utilisation des classes Java int√©gr√©es l√† o√π applicable
2021-03-11 01:54:31,115 INFO impl.MetricsConfig: Propri√©t√©s charg√©es depuis hadoop-metrics2.properties
2021-03-11 01:54:31,232 INFO impl.MetricsSystemImpl: P√©riode de capture des m√©triques planifi√©e √† 10 seconde(s).
...
```

En suivant l'exemple du site officiel, on remarque la commande `bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input`. Ici, le fichier `jar` est pr√©c√©d√© d'un num√©ro de version. Il faut donc le remplacer par notre version `3.3.0`.

Fin du journal :

```shell
2021-03-11 01:54:35,374 INFO mapreduce.Job:  map 100% reduce 100%
2021-03-11 01:54:35,374 INFO mapreduce.Job: Job job_local2087514596_0002 termin√© avec succ√®s
2021-03-11 01:54:35,377 INFO mapreduce.Job: Compteurs : 30
	Compteurs du syst√®me de fichiers
		FILE: Nombre d'octets lus=1204316
		FILE: Nombre d'octets √©crits=3565480
		FILE: Nombre d'op√©rations de lecture=0
		FILE: Nombre de grandes op√©rations de lecture=0
		FILE: Nombre d'op√©rations d'√©criture=0
	Framework Map-Reduce
		Enregistrements d'entr√©e de map=1
		Enregistrements de sortie de map=1
		Octets de sortie de map=17
		Octets mat√©rialis√©s de sortie de map=25
		Octets de split d'entr√©e=141
		Enregistrements d'entr√©e de combine=0
		Enregistrements de sortie de combine=0
		Groupes d'entr√©e de reduce=1
		Octets de shuffle de reduce=25
		Enregistrements d'entr√©e de reduce=1
		Enregistrements de sortie de reduce=1
		Enregistrements d√©vers√©s=2
		Maps m√©lang√©s=1
		Shuffles √©chou√©s=0
		Sorties de map fusionn√©es=1
		Temps √©coul√© GC (ms)=57
		Utilisation totale du tas engag√© (octets)=772800512
	Erreurs de Shuffle
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	Compteurs du format d'entr√©e de fichier
		Octets lus=123
	Compteurs du format de sortie de fichier
		Octets √©crits=23
```

Continuons √† regarder.

```shell
$ cat output/*
1	dfsadmin
```

Qu'est-ce que cela signifie exactement ? Peu importe, en tout cas, nous avons r√©ussi √† d√©marrer `Hadoop`. Et nous avons ex√©cut√© notre premier exemple de calcul en mode standalone.

## Spark

Revenons √† Spark. Prenons un exemple.

```python
text_file = sc.textFile("hdfs://...")
counts = text_file.flatMap(lambda line: line.split(" ")) \
             .map(lambda word: (word, 1)) \
             .reduceByKey(lambda a, b: a + b)
counts.saveAsTextFile("hdfs://...")
```

Un fichier `hdfs` est apparu ici. Apr√®s avoir effectu√© des recherches, j'ai d√©couvert qu'il est possible de cr√©er un fichier `hdfs` de cette mani√®re :

```shell
hdfs dfs -mkdir /test
```

Voyons la commande `hdfs`.

```shell
$ hdfs
Usage : hdfs [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]
```

OPTIONS est soit `none`, soit l'une des options suivantes :

--buildpaths                       tenter d'ajouter des fichiers de classe √† partir de l'arborescence de construction
--config dir                       r√©pertoire de configuration Hadoop
--daemon (start|status|stop)       op√©rer sur un d√©mon
--debug                            activer le mode de d√©bogage des scripts shell
--help                             informations d'utilisation
--hostnames list[,of,host,names]   h√¥tes √† utiliser en mode worker
--hosts filename                   liste des h√¥tes √† utiliser en mode worker
--loglevel level                   d√©finir le niveau log4j pour cette commande
--workers                          activer le mode worker

  SUBCOMMAND est l'un des :
    Commandes d'administration :

cacheadmin           configurer le cache HDFS
crypto               configurer les zones de chiffrement HDFS
debug                ex√©cuter un Debug Admin pour ex√©cuter des commandes de d√©bogage HDFS
dfsadmin             ex√©cuter un client admin DFS
dfsrouteradmin       g√©rer la f√©d√©ration bas√©e sur Router
ec                   ex√©cuter une CLI de codage d'effacement HDFS
fsck                 ex√©cuter un utilitaire de v√©rification du syst√®me de fichiers DFS
haadmin              ex√©cuter un client admin DFS HA
jmxget               obtenir les valeurs JMX export√©es depuis NameNode ou DataNode
oev                  appliquer le visualiseur de modifications hors ligne √† un fichier d'√©ditions
oiv                  appliquer le visualiseur d'image de syst√®me de fichiers hors ligne √† une image de syst√®me de fichiers
oiv_legacy           appliquer le visualiseur d'image de syst√®me de fichiers hors ligne √† une image de syst√®me de fichiers h√©rit√©e
storagepolicies      lister/obtenir/d√©finir/satisfaire les politiques de stockage des blocs

    Commandes client :

classpath            affiche le chemin de classe n√©cessaire pour obtenir le fichier JAR Hadoop et les biblioth√®ques requises
dfs                  ex√©cute une commande de syst√®me de fichiers sur le syst√®me de fichiers
envvars              affiche les variables d'environnement Hadoop calcul√©es
fetchdt              r√©cup√®re un jeton de d√©l√©gation depuis le NameNode
getconf              obtient les valeurs de configuration √† partir de la configuration
groups               obtient les groupes auxquels les utilisateurs appartiennent
lsSnapshottableDir   liste tous les r√©pertoires pouvant √™tre snapshot√©s appartenant √† l'utilisateur actuel
snapshotDiff         compare deux snapshots d'un r√©pertoire ou compare le contenu actuel du r√©pertoire avec un snapshot
version              affiche la version

    Commandes Daemon :

balancer             ex√©cuter un utilitaire d'√©quilibrage de cluster  
datanode             ex√©cuter un datanode DFS  
dfsrouter            ex√©cuter le routeur DFS  
diskbalancer         r√©partir les donn√©es de mani√®re uniforme entre les disques d'un n≈ìud donn√©  
httpfs               ex√©cuter le serveur HttpFS, la passerelle HTTP HDFS  
journalnode          ex√©cuter le journalnode DFS  
mover                ex√©cuter un utilitaire pour d√©placer les r√©plicas de blocs entre les types de stockage  
namenode             ex√©cuter le namenode DFS  
nfs3                 ex√©cuter une passerelle NFS version 3  
portmap              ex√©cuter un service portmap  
secondarynamenode    ex√©cuter le namenode secondaire DFS  
sps                  ex√©cuter le satisfacteur de politique de stockage externe  
zkfc                 ex√©cuter le d√©mon ZK Failover Controller

SUBCOMMAND peut afficher l'aide lorsqu'il est invoqu√© sans param√®tres ou avec -h.
```

Continuer √† modifier le code.

```python
from pyspark.sql import SparkSession
```

```python
spark = SparkSession.builder.master("local[*]")\
           .config('spark.driver.bindAddress', '127.0.0.1')\
           .getOrCreate()
sc = spark.sparkContext
```

```python
text_file = sc.textFile("a.txt")
counts = text_file.flatMap(lambda line: line.split(" ")) \
             .map(lambda word: (word, 1)) \
             .reduceByKey(lambda a, b: a + b)
counts.saveAsTextFile("b.txt")
```

Il est important de noter `.config('spark.driver.bindAddress', '127.0.0.1')`. Sinon, vous pourriez rencontrer l'erreur suivante : `Service 'sparkDriver' could not bind on a random free port. You may check whether configuring an appropriate binding address`.

Cependant, une erreur est survenue √† ce moment-l√†.

```shell
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py", line 473, in main
    raise Exception(("Python in worker has different version %s than that in " +
Exception: Python dans le worker a une version diff√©rente 3.8 de celle du driver 3.9, PySpark ne peut pas fonctionner avec des versions mineures diff√©rentes. Veuillez v√©rifier que les variables d'environnement PYSPARK_PYTHON et PYSPARK_DRIVER_PYTHON sont correctement configur√©es.
```

Cela indique que diff√©rentes versions de `Python` ont √©t√© ex√©cut√©es.

Modifier le fichier `.bash_profile` :

```shell
PYSPARK_PYTHON=/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
PYSPARK_DRIVER_PYTHON=/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3
```

Cependant, l'erreur persiste. Apr√®s quelques recherches, il semble que cela pourrait √™tre d√ª au fait que `spark` ne charge pas cette variable d'environnement lors de son ex√©cution, et n'utilise donc pas les variables d'environnement par d√©faut du terminal.

Vous devez configurer dans le code :

```python
import os
```

# Configurer les environnements Spark
```python
os.environ['PYSPARK_PYTHON'] = '/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'
os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3'
```

Cela fonctionnera.

```shell
$ python sc.py
21/03/11 02:54:52 WARN NativeCodeLoader: Impossible de charger la biblioth√®que native-hadoop pour votre plateforme... utilisation des classes Java int√©gr√©es l√† o√π applicable
Utilisation du profil log4j par d√©faut de Spark : org/apache/spark/log4j-defaults.properties
D√©finition du niveau de journalisation par d√©faut √† "WARN".
Pour ajuster le niveau de journalisation, utilisez sc.setLogLevel(newLevel). Pour SparkR, utilisez setLogLevel(newLevel).
PythonRDD[6] √† RDD √† PythonRDD.scala:53
```

√Ä ce moment, le fichier `b.txt` a √©t√© g√©n√©r√©.

```shell
‚îú‚îÄ‚îÄ b.txt
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ _SUCCESS
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ part-00000
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ part-00001
```

Ouvrez-le.

```shell
$ cat b.txt/part-00000
('college', 1)
('two', 1)
('things', 2)
('worked', 1)
('on,', 1)
('of', 8)
('school,', 2)
('writing', 2)
('programming.', 1)
("didn't", 4)
('then,', 1)
('probably', 1)
('are:', 1)
('short', 1)
('awful.', 1)
('They', 1)
('plot,', 1)
('just', 1)
('characters', 1)
('them', 2)
...
```

√áa a march√© ! Cela ne vous semble-t-il pas familier ? C'est comme dans l'exemple avec `Hadoop`.

```shell
$ cat output/*
1	dfsadmin
```

Ces fichiers sont appel√©s `HDFS`. On peut voir ici que `Spark` est utilis√© pour compter les mots. En quelques lignes seulement, cela semble tr√®s pratique.

## Kubernetes

Passons maintenant √† `Kubernetes`, √©galement appel√© `k8s`, o√π le "8" repr√©sente les 8 lettres omises entre le "K" et le "s". Il s'agit d'un syst√®me open-source con√ßu pour automatiser le d√©ploiement, la mise √† l'√©chelle et la gestion des applications conteneuris√©es.

L'outil en ligne de commande `kubectl` est utilis√© pour ex√©cuter des commandes sur un cluster Kubernetes (k8s). Il permet de d√©ployer des applications, de visualiser et de g√©rer les ressources du cluster, ainsi que de consulter les journaux.

Il est √©galement possible d'installer via Homebrew.

```shell
brew install kubectl
```

Journalisation des sorties :

```shell
==> T√©l√©chargement de https://homebrew.bintray.com/bottles/kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
==> T√©l√©chargement depuis https://d29vzk4ow07wi7.cloudfront.net/0b4f08bd1d47cb913d7cd4571e3394c6747dfbad7ff114c5589c8396c1085ecf?response-content-disposition=a
######################################################################## 100.0%
==> Extraction de kubernetes-cli-1.20.1.big_sur.bottle.tar.gz
==> Avertissements
La compl√©tion Bash a √©t√© install√©e dans :
  /usr/local/etc/bash_completion.d
==> R√©sum√©
üç∫  /usr/local/Cellar/kubernetes-cli/1.20.1: 246 fichiers, 46.1 Mo
```

Installation termin√©e.

```shell
$ kubectl version --client
Client Version: version.Info{Major:"1", Minor:"20", GitVersion:"v1.20.1", GitCommit:"c4d752765b3bbac2237bf87cf0b1c2e307844666", GitTreeState:"clean", BuildDate:"2020-12-19T08:38:20Z", GoVersion:"go1.15.5", Compiler:"gc", Platform:"darwin/amd64"}
```

```shell
$ kubectl
kubectl contr√¥le le gestionnaire de cluster Kubernetes.
```

Pour plus d'informations, consultez : https://kubernetes.io/docs/reference/kubectl/overview/

Commandes de base (D√©butant) :
  create        Cr√©er une ressource √† partir d'un fichier ou de stdin.
  expose        Prendre un contr√¥leur de r√©plication, un service, un d√©ploiement ou un pod et l'exposer en tant que nouveau service Kubernetes
  run           Ex√©cuter une image sp√©cifique sur le cluster
  set           D√©finir des fonctionnalit√©s sp√©cifiques sur des objets

Commandes de base (interm√©diaires) :
  explain       Documentation des ressources
  get           Afficher une ou plusieurs ressources
  edit          Modifier une ressource sur le serveur
  delete        Supprimer des ressources par fichiers, stdin, ressources et noms, ou par ressources et s√©lecteur de label

Commandes de d√©ploiement :
  rollout       G√©rer le d√©ploiement d'une ressource
  scale         D√©finir une nouvelle taille pour un Deployment, ReplicaSet ou Replication Controller
  autoscale     Mettre √† l'√©chelle automatiquement un Deployment, ReplicaSet ou ReplicationController

Commandes de gestion de cluster :
  certificate   Modifier les ressources de certificat.
  cluster-info  Afficher les informations du cluster.
  top           Afficher l'utilisation des ressources (CPU/M√©moire/Stockage).
  cordon        Marquer un n≈ìud comme non planifiable.
  uncordon      Marquer un n≈ìud comme planifiable.
  drain         Vider un n≈ìud en pr√©paration √† une maintenance.
  taint         Mettre √† jour les taints sur un ou plusieurs n≈ìuds.

Commandes de d√©pannage et de d√©bogage :
  describe      Afficher les d√©tails d'une ressource sp√©cifique ou d'un groupe de ressources
  logs          Afficher les logs d'un conteneur dans un pod
  attach        Se connecter √† un conteneur en cours d'ex√©cution
  exec          Ex√©cuter une commande dans un conteneur
  port-forward  Rediriger un ou plusieurs ports locaux vers un pod
  proxy         Lancer un proxy vers le serveur API Kubernetes
  cp            Copier des fichiers et r√©pertoires vers et depuis des conteneurs
  auth          Inspecter les autorisations
  debug         Cr√©er des sessions de d√©bogage pour le d√©pannage des charges de travail et des n≈ìuds

Commandes avanc√©es :
  diff          Comparer la version en direct avec la version qui serait appliqu√©e
  apply         Appliquer une configuration √† une ressource par nom de fichier ou stdin
  patch         Mettre √† jour un ou plusieurs champs d'une ressource
  replace       Remplacer une ressource par nom de fichier ou stdin
  wait          Exp√©rimental : Attendre une condition sp√©cifique sur une ou plusieurs ressources.
  kustomize     Construire une cible de kustomization √† partir d'un r√©pertoire ou d'une URL distante.

Commandes de configuration :
  label         Mettre √† jour les √©tiquettes sur une ressource
  annotate      Mettre √† jour les annotations sur une ressource
  completion    G√©n√©rer le code de compl√©tion pour le shell sp√©cifi√© (bash ou zsh)

Autres Commandes :
  api-resources Affiche les ressources API prises en charge sur le serveur
  api-versions  Affiche les versions API prises en charge sur le serveur, sous la forme "groupe/version"
  config        Modifie les fichiers kubeconfig
  plugin        Fournit des utilitaires pour interagir avec les plugins.
  version       Affiche les informations de version du client et du serveur

Utilisation :
  kubectl [flags] [options]

Utilisez "kubectl <commande> --help" pour obtenir plus d'informations sur une commande donn√©e.
Utilisez "kubectl options" pour obtenir une liste des options globales de ligne de commande (s'applique √† toutes les commandes).
```

Cr√©ons un fichier de configuration.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  minReadySeconds: 5
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

```

```shell
$ kubectl apply -f simple_deployment.yaml
La connexion au serveur localhost:8080 a √©t√© refus√©e - avez-vous sp√©cifi√© le bon h√¥te ou port ?
```

```shell
$ kubectl cluster-info
```

Pour d√©boguer et diagnostiquer davantage les probl√®mes du cluster, utilisez `kubectl cluster-info dump`.
La connexion au serveur localhost:8080 a √©t√© refus√©e - avez-vous sp√©cifi√© le bon h√¥te ou port ?
```

Lorsque vous essayez de l'ex√©cuter dans le terminal du site officiel.

```shell
$ start.sh
D√©marrage de Kubernetes...version de minikube : v1.8.1
commit : cbda04cf6bbe65e987ae52bb393c10099ab62014
* minikube v1.8.1 sur Ubuntu 18.04
* Utilisation du pilote none bas√© sur la configuration utilisateur
* Ex√©cution sur localhost (CPU=2, M√©moire=2460MB, Disque=145651MB) ...
* La version du syst√®me d'exploitation est Ubuntu 18.04.4 LTS
```

* Pr√©paration de Kubernetes v1.17.3 sur Docker 19.03.6 ...
  - kubelet.resolv-conf=/run/systemd/resolve/resolv.conf
* Lancement de Kubernetes ... 
* Activation des modules compl√©mentaires : default-storageclass, storage-provisioner
* Configuration de l'environnement local ...
* Termin√© ! kubectl est maintenant configur√© pour utiliser "minikube"
* Le module compl√©mentaire 'dashboard' est activ√©
Kubernetes d√©marr√©
```

Revenons √† notre terminal.

```shell
$ kubectl version --client
Client Version: version.Info{Major:"1", Minor:"20", GitVersion:"v1.20.1", GitCommit:"c4d752765b3bbac2237bf87cf0b1c2e307844666", GitTreeState:"clean", BuildDate:"2020-12-19T08:38:20Z", GoVersion:"go1.15.5", Compiler:"gc", Platform:"darwin/amd64"}
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"20", GitVersion:"v1.20.1", GitCommit:"c4d752765b3bbac2237bf87cf0b1c2e307844666", GitTreeState:"clean", BuildDate:"2020-12-19T08:38:20Z", GoVersion:"go1.15.5", Compiler:"gc", Platform:"darwin/amd64"}
La connexion au serveur localhost:8080 a √©t√© refus√©e - avez-vous sp√©cifi√© le bon h√¥te ou port ?
```

Il est int√©ressant de noter que l'ajout de l'option `--client` n'a pas g√©n√©r√© d'erreur.

La documentation indique qu'il faut d'abord installer `Minikube`.

```shell
$ brew install minikube
==> T√©l√©chargement de https://homebrew.bintray.com/bottles/minikube-1.16.0.big_sur.bottle.tar.gz
==> T√©l√©chargement depuis https://d29vzk4ow07wi7.cloudfront.net/1b6d7d1b97b11b6b07e4fa531c2dc21770da290da9b2816f360fd923e00c85fc?response-content-disposition=a
######################################################################## 100.0%
==> Extraction de minikube-1.16.0.big_sur.bottle.tar.gz
==> Notes
La compl√©tion Bash a √©t√© install√©e dans :
  /usr/local/etc/bash_completion.d
==> R√©sum√©
üç∫  /usr/local/Cellar/minikube/1.16.0: 8 fichiers, 64,6 Mo
```

```shell
$ minikube start
üòÑ  minikube v1.16.0 sur Darwin 11.2.2
üéâ  minikube 1.18.1 est disponible ! T√©l√©chargez-le : https://github.com/kubernetes/minikube/releases/tag/v1.18.1
üí°  Pour d√©sactiver cette notification, ex√©cutez : 'minikube config set WantUpdateNotification false'
```

‚ú®  S√©lection automatique du pilote virtualbox
üíø  T√©l√©chargement de l'image de d√©marrage de la VM ...
    > minikube-v1.16.0.iso.sha256: 65 B / 65 B [-------------] 100.00% ? p/s 0s
    > minikube-v1.16.0.iso: 212.62 MiB / 212.62 MiB [] 100.00% 5.32 MiB p/s 40s
üëç  D√©marrage du n≈ìud de contr√¥le plane minikube dans le cluster minikube
üíæ  T√©l√©chargement de Kubernetes v1.20.0 preload ...
    > preloaded-images-k8s-v8-v1....: 491.00 MiB / 491.00 MiB  100.00% 7.52 MiB
üî•  Cr√©ation de la VM virtualbox (CPU=2, M√©moire=4000MB, Disque=20000MB) ...
‚ùó  Cette VM rencontre des difficult√©s pour acc√©der √† https://k8s.gcr.io
üí°  Pour t√©l√©charger de nouvelles images externes, vous devrez peut-√™tre configurer un proxy : https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
üê≥  Pr√©paration de Kubernetes v1.20.0 sur Docker 20.10.0 ...
    ‚ñ™ G√©n√©ration des certificats et cl√©s ...
    ‚ñ™ D√©marrage du contr√¥le plane ...
    ‚ñ™ Configuration des r√®gles RBAC ...
üîé  V√©rification des composants Kubernetes...
üåü  Modules compl√©mentaires activ√©s : storage-provisioner, default-storageclass
üèÑ  Termin√© ! kubectl est maintenant configur√© pour utiliser le cluster "minikube" et l'espace de noms "default" par d√©faut
```

Ensuite, acc√©dez √† ce cluster.

```shell
$ kubectl get po -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   coredns-74ff55c5b-ndbcr            1/1     Running   0          60s
kube-system   etcd-minikube                      0/1     Running   0          74s
kube-system   kube-apiserver-minikube            1/1     Running   0          74s
kube-system   kube-controller-manager-minikube   1/1     Running   0          74s
kube-system   kube-proxy-g2296                   1/1     Running   0          60s
kube-system   kube-scheduler-minikube            0/1     Running   0          74s
kube-system   storage-provisioner                1/1     Running   1          74s
```

Pour ouvrir le tableau de bord de `minikube`, utilisez la commande suivante :

```bash
minikube dashboard
```

Cela ouvrira le tableau de bord de Kubernetes dans votre navigateur par d√©faut.

```shell
$ minikube dashboard
üîå  Activation du tableau de bord ...
ü§î  V√©rification de l'√©tat du tableau de bord ...
üöÄ  Lancement du proxy ...
ü§î  V√©rification de l'√©tat du proxy ...
üéâ  Ouverture de http://127.0.0.1:50030/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ dans votre navigateur par d√©faut...
```

![k8s](assets/images/distributed/k8s.png)

Comment l'√©teindre ?

```shell
$ minikube
minikube provisionne et g√®re des clusters Kubernetes locaux optimis√©s pour les flux de travail de d√©veloppement.
```

Commandes de base :
  start          D√©marre un cluster Kubernetes local
  status         Obtient le statut d'un cluster Kubernetes local
  stop           Arr√™te un cluster Kubernetes en cours d'ex√©cution
  delete         Supprime un cluster Kubernetes local
  dashboard      Acc√®de au tableau de bord Kubernetes en cours d'ex√©cution dans le cluster minikube
  pause          Met Kubernetes en pause
  unpause        Reprend Kubernetes apr√®s une pause

Commandes pour les images :
  docker-env     Configurer l'environnement pour utiliser le d√©mon Docker de minikube
  podman-env     Configurer l'environnement pour utiliser le service Podman de minikube
  cache          Ajouter, supprimer ou pousser une image locale dans minikube

Commandes de configuration et de gestion :
  addons         Activer ou d√©sactiver un module compl√©mentaire de minikube
  config         Modifier les valeurs de configuration persistantes
  profile        Obtenir ou lister les profils actuels (clusters)
  update-context Mettre √† jour kubeconfig en cas de changement d'adresse IP ou de port

Commandes de r√©seau et de connectivit√© :
  service        Retourne une URL pour se connecter √† un service
  tunnel         Se connecter aux services LoadBalancer

Commandes avanc√©es :
  mount          Monte le r√©pertoire sp√©cifi√© dans minikube
  ssh            Se connecter √† l'environnement minikube (pour le d√©bogage)
  kubectl        Ex√©cute une version de kubectl correspondant √† la version du cluster
  node           Ajouter, supprimer ou lister des n≈ìuds suppl√©mentaires

Commandes de d√©pannage :
  ssh-key        R√©cup√®re le chemin de la cl√© d'identit√© SSH du n≈ìud sp√©cifi√©
  ssh-host       R√©cup√®re la cl√© h√¥te SSH du n≈ìud sp√©cifi√©
  ip             R√©cup√®re l'adresse IP du n≈ìud sp√©cifi√©
  logs           Retourne les journaux pour d√©boguer un cluster Kubernetes local
  update-check   Affiche les num√©ros de version actuelle et la plus r√©cente
  version        Affiche la version de minikube

Autres commandes :
  completion     G√©n√©rer la compl√©tion de commande pour un shell

Utilisez "minikube <commande> --help" pour obtenir plus d'informations sur une commande donn√©e.
```

Il semble que ce soit `minikube stop`.

Revenons √† `kubernetes`, maintenant tout fonctionne correctement.

```shell
$ kubectl cluster-info
Le plan de contr√¥le de Kubernetes est en cours d'ex√©cution √† l'adresse https://192.168.99.100:8443
KubeDNS est en cours d'ex√©cution √† l'adresse https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
```

Pour d√©boguer et diagnostiquer davantage les probl√®mes du cluster, utilisez `kubectl cluster-info dump`.
```

Lorsque nous ouvrons `https://192.168.99.100:8443`, le navigateur affiche :

```json
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "√âchec",
  "message": "interdit : L'utilisateur \"system:anonymous\" ne peut pas acc√©der au chemin \"/\"",
  "reason": "Interdit",
  "details": {
    
  },
  "code": 403
}
```

Acc√©dez √† `https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy` :

```json
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "√âchec",
  "message": "services \"kube-dns:dns\" est interdit : L'utilisateur \"system:anonymous\" ne peut pas acc√©der √† la ressource \"services/proxy\" dans le groupe d'API \"\" dans l'espace de noms \"kube-system\"",
  "reason": "Interdit",
  "details": {
    "name": "kube-dns:dns",
    "kind": "services"
  },
  "code": 403
}
```

Essayons la configuration que nous venons de voir.

```shell
$ kubectl apply -f simple_deployment.yaml
deployment.apps/nginx-deployment cr√©√©
```

Il y a un petit probl√®me. Cependant, jusqu'√† pr√©sent, nous avons r√©ussi √† faire fonctionner `kubernetes`. Terminons cela pour l'instant. Nous y reviendrons plus tard.

```shell
$ minikube stop
‚úã  Arr√™t du n≈ìud "minikube"  ...
üõë  1 n≈ìud arr√™t√©.
```

V√©rifiez si c'est termin√©.

```shell
w$ minikube dashboard
ü§∑  Le n≈ìud du plan de contr√¥le doit √™tre en cours d'ex√©cution pour cette commande
üëâ  Pour d√©marrer un cluster, ex√©cutez : "minikube start"
```

## Docker

`Docker` est √©galement une plateforme de conteneurs qui aide √† acc√©l√©rer la cr√©ation, le partage et l'ex√©cution d'applications modernes. T√©l√©chargez l'application depuis le site officiel.

![docker](assets/images/distributed/docker.png)

L'utilisation du client est un peu lente. Utilisons la ligne de commande.

```docker
$ docker
```

Utilisation : docker [OPTIONS] COMMANDE

Un runtime autonome pour les conteneurs

Options :
      --config string      Emplacement des fichiers de configuration du client (par d√©faut "/Users/lzw/.docker")
  -c, --context string     Nom du contexte √† utiliser pour se connecter au d√©mon (remplace la variable d'environnement DOCKER_HOST et le contexte par d√©faut d√©fini avec "docker context use")
  -D, --debug              Activer le mode d√©bogage
  -H, --host list          Socket(s) du d√©mon au(x)quel(s) se connecter
  -l, --log-level string   D√©finir le niveau de journalisation ("debug"|"info"|"warn"|"error"|"fatal") (par d√©faut "info")
      --tls                Utiliser TLS ; implicite avec --tlsverify
      --tlscacert string   Faire confiance uniquement aux certificats sign√©s par cette CA (par d√©faut "/Users/lzw/.docker/ca.pem")
      --tlscert string     Chemin vers le fichier de certificat TLS (par d√©faut "/Users/lzw/.docker/cert.pem")
      --tlskey string      Chemin vers le fichier de cl√© TLS (par d√©faut "/Users/lzw/.docker/key.pem")
      --tlsverify          Utiliser TLS et v√©rifier le serveur distant
  -v, --version            Afficher les informations de version et quitter

Commandes de gestion :
  app*        Docker App (Docker Inc., v0.9.1-beta3)
  builder     G√©rer les builds
  buildx*     Construire avec BuildKit (Docker Inc., v0.5.1-docker)
  config      G√©rer les configurations Docker
  container   G√©rer les conteneurs
  context     G√©rer les contextes
  image       G√©rer les images
  manifest    G√©rer les manifestes d'images Docker et les listes de manifestes
  network     G√©rer les r√©seaux
  node        G√©rer les n≈ìuds Swarm
  plugin      G√©rer les plugins
  scan*       Docker Scan (Docker Inc., v0.5.0)
  secret      G√©rer les secrets Docker
  service     G√©rer les services
  stack       G√©rer les stacks Docker
  swarm       G√©rer Swarm
  system      G√©rer Docker
  trust       G√©rer la confiance sur les images Docker
  volume      G√©rer les volumes

Commandes :
  attach      Attacher les flux d'entr√©e, de sortie et d'erreur standard locaux √† un conteneur en cours d'ex√©cution
  build       Construire une image √† partir d'un Dockerfile
  commit      Cr√©er une nouvelle image √† partir des modifications d'un conteneur
  cp          Copier des fichiers/dossiers entre un conteneur et le syst√®me de fichiers local
  create      Cr√©er un nouveau conteneur
  diff        Inspecter les modifications apport√©es aux fichiers ou r√©pertoires sur le syst√®me de fichiers d'un conteneur
  events      Obtenir des √©v√©nements en temps r√©el depuis le serveur
  exec        Ex√©cuter une commande dans un conteneur en cours d'ex√©cution
  export      Exporter le syst√®me de fichiers d'un conteneur sous forme d'archive tar
  history     Afficher l'historique d'une image
  images      Lister les images
  import      Importer le contenu d'une archive tar pour cr√©er une image de syst√®me de fichiers
  info        Afficher des informations syst√®me globales
  inspect     Retourner des informations de bas niveau sur les objets Docker
  kill        Tuer un ou plusieurs conteneurs en cours d'ex√©cution
  load        Charger une image √† partir d'une archive tar ou de STDIN
  login       Se connecter √† un registre Docker
  logout      Se d√©connecter d'un registre Docker
  logs        R√©cup√©rer les logs d'un conteneur
  pause       Suspendre tous les processus dans un ou plusieurs conteneurs
  port        Lister les mappages de ports ou un mappage sp√©cifique pour le conteneur
  ps          Lister les conteneurs
  pull        T√©l√©charger une image ou un d√©p√¥t depuis un registre
  push        Envoyer une image ou un d√©p√¥t vers un registre
  rename      Renommer un conteneur
  restart     Red√©marrer un ou plusieurs conteneurs
  rm          Supprimer un ou plusieurs conteneurs
  rmi         Supprimer une ou plusieurs images
  run         Ex√©cuter une commande dans un nouveau conteneur
  save        Sauvegarder une ou plusieurs images dans une archive tar (stream√©e vers STDOUT par d√©faut)
  search      Rechercher des images sur Docker Hub
  start       D√©marrer un ou plusieurs conteneurs arr√™t√©s
  stats       Afficher un flux en direct des statistiques d'utilisation des ressources des conteneurs
  stop        Arr√™ter un ou plusieurs conteneurs en cours d'ex√©cution
  tag         Cr√©er une balise TARGET_IMAGE qui fait r√©f√©rence √† SOURCE_IMAGE
  top         Afficher les processus en cours d'ex√©cution d'un conteneur
  unpause     Reprendre tous les processus dans un ou plusieurs conteneurs
  update      Mettre √† jour la configuration d'un ou plusieurs conteneurs
  version     Afficher les informations de version de Docker
  wait        Bloquer jusqu'√† ce qu'un ou plusieurs conteneurs s'arr√™tent, puis afficher leurs codes de sortie

Ex√©cutez 'docker COMMANDE --help' pour obtenir plus d'informations sur une commande.

Pour obtenir plus d'aide sur Docker, consultez nos guides sur https://docs.docker.com/go/guides/
```

Suivons le tutoriel pour essayer.

```shell
$ docker run -d -p 80:80 docker/getting-started
Unable to find image 'docker/getting-started:latest' locally
latest: Pulling from docker/getting-started
aad63a933944: Pull complete
b14da7a62044: Pull complete
343784d40d66: Pull complete
6f617e610986: Pull complete
Digest: sha256:d2c4fb0641519ea208f20ab03dc40ec2a5a53fdfbccca90bef14f870158ed577
Status: Downloaded newer image for docker/getting-started:latest
815f13fc8f99f6185257980f74c349e182842ca572fe60ff62cbb15641199eaf
docker: Error response from daemon: Les ports ne sont pas disponibles : √©coute tcp 0.0.0.0:80: bind: adresse d√©j√† utilis√©e.
```

Changez le port.

```shell
$ docker run -d -p 8080:80 docker/getting-started
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
```

![docker_run](assets/images/distributed/docker_run.png)

Ouvrez votre navigateur, cela signifie que nous avons r√©ussi √† faire fonctionner `docker`.

![navigateur](assets/images/distributed/browser.png)

Arr√™tez le conteneur. Utilisez l'`ID` retourn√© pr√©c√©demment.

```shell
$ docker stop 45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
45bb95fa1ae80adc05cc498a1f4f339c45c51f7a8ae1be17f5b704853a5513a5
```

√Ä ce moment-l√†, le site web √©tait d√©j√† inaccessible.

Cela montre que `docker` ressemble √† une machine virtuelle.

## Flink

Ouvrez le site officiel.

![flink-home-graphic](assets/images/distributed/flink-home-graphic.png)

`Flink` est un calcul `Stateful` des flux de donn√©es. Mais qu'est-ce que signifie `Stateful` ? Pour l'instant, je ne comprends pas encore. Cependant, le sch√©ma ci-dessus est tr√®s int√©ressant. Essayons de l'explorer.

Il est dit qu'un environnement Java est n√©cessaire.

```shell
$ java -version
java version "1.8.0_151"
Java(TM) SE Runtime Environment (build 1.8.0_151-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode)
```

T√©l√©chargez la derni√®re version `flink-1.12.2-bin-scala_2.11.tar` depuis le site officiel.

```shell
$ ./bin/start-cluster.sh
D√©marrage du cluster.
D√©marrage du d√©mon standalonesession sur l'h√¥te lzwjava.
D√©marrage du d√©mon taskexecutor sur l'h√¥te lzwjava.
```

```shell
$ ./bin/flink run examples/streaming/WordCount.jar
Ex√©cution de l'exemple WordCount avec le jeu de donn√©es d'entr√©e par d√©faut.
Utilisez --input pour sp√©cifier un fichier d'entr√©e.
Affichage du r√©sultat sur stdout. Utilisez --output pour sp√©cifier le chemin de sortie.
Le job a √©t√© soumis avec l'ID de job 60f37647c20c2a6654359bd34edab807
L'ex√©cution du programme est termin√©e
Le job avec l'ID 60f37647c20c2a6654359bd34edab807 est termin√©.
Temps d'ex√©cution du job : 757 ms
```

```shell
$ tail log/flink-*-taskexecutor-*.out
(nymph,1)
(in,3)
(thy,1)
(orisons,1)
(be,4)
(all,2)
(my,1)
(sins,1)
(remember,1)
(d,4)
```

```shell
$ ./bin/stop-cluster.sh
Arr√™t du d√©mon taskexecutor (pid : 41812) sur l'h√¥te lzwjava.
```

Oui, c'est parti. On voit que c'est tr√®s similaire √† `Spark`.

## Kylin

Acc√©dez au site officiel.

> Apache Kylin‚Ñ¢ est un entrep√¥t de donn√©es analytiques distribu√© et open source con√ßu pour le Big Data. Il a √©t√© cr√©√© pour offrir des capacit√©s OLAP (Traitement Analytique en Ligne) √† l'√®re du Big Data. En r√©inventant la technologie des cubes multidimensionnels et du pr√©calcul sur Hadoop et Spark, Kylin est capable d'atteindre une vitesse de requ√™te quasi constante, quelle que soit la croissance du volume de donn√©es. En r√©duisant la latence des requ√™tes de plusieurs minutes √† moins d'une seconde, Kylin ram√®ne l'analyse en ligne au c≈ìur du Big Data.

> Apache Kylin‚Ñ¢ vous permet d'interroger des milliards de lignes avec une latence inf√©rieure √† la seconde en 3 √©tapes.
>
> 1. Identifiez un sch√©ma en √©toile ou en flocon de neige sur Hadoop.
> 2. Construisez un Cube √† partir des tables identifi√©es.
> 3. Interrogez en utilisant ANSI-SQL et obtenez des r√©sultats en moins d'une seconde, via ODBC, JDBC ou une API RESTful.

![kylin_diagram](assets/images/distributed/kylin_diagram.png)

Cela fait essentiellement partie de l'analyse des big data. On peut l'utiliser pour effectuer des recherches tr√®s rapidement. Il sert de pont.

Malheureusement, pour le moment, cela ne fonctionne que dans un environnement `Linux`. Je reviendrai bricoler cela plus tard.

## MongoDB

C'est aussi une base de donn√©es. Essayez de l'installer.

```shell
$ brew tap mongodb/brew
==> Tapping mongodb/brew
Clonage dans '/usr/local/Homebrew/Library/Taps/mongodb/homebrew-brew'...
remote: √ânum√©ration des objets: 63, fait.
remote: Comptage des objets: 100% (63/63), fait.
remote: Compression des objets: 100% (62/62), fait.
remote: Total 566 (delta 21), r√©utilis√©s 6 (delta 1), r√©utilis√©s du pack 503
R√©ception des objets: 100% (566/566), 121.78 KiB | 335.00 KiB/s, fait.
R√©solution des deltas: 100% (259/259), fait.
11 formules ajout√©es (39 fichiers, 196.2KB).
```

```shell
$ brew install mongodb-community@4.4
==> Installation de mongodb-community depuis mongodb/brew
==> T√©l√©chargement de https://fastdl.mongodb.org/tools/db/mongodb-database-tools-macos-x86_64-100.3.0.zip
######################################################################## 100.0%
==> T√©l√©chargement de https://fastdl.mongodb.org/osx/mongodb-macos-x86_64-4.4.3.tgz
######################################################################## 100.0%
==> Installation des d√©pendances pour mongodb/brew/mongodb-community: mongodb-database-tools
==> Installation de la d√©pendance mongodb/brew/mongodb-community: mongodb-database-tools
Erreur : L'√©tape `brew link` ne s'est pas termin√©e avec succ√®s
La formule a √©t√© construite, mais n'est pas li√©e symboliquement dans /usr/local
Impossible de cr√©er un lien symbolique pour bin/bsondump
La cible /usr/local/bin/bsondump
est un lien symbolique appartenant √† mongodb. Vous pouvez le d√©lier :
  brew unlink mongodb
```

Pour forcer le lien et √©craser tous les fichiers en conflit :
  brew link --overwrite mongodb-database-tools

Pour lister tous les fichiers qui seraient supprim√©s :
  brew link --overwrite --dry-run mongodb-database-tools

Les fichiers potentiellement en conflit sont :
/usr/local/bin/bsondump -> /usr/local/Cellar/mongodb/3.0.7/bin/bsondump
/usr/local/bin/mongodump -> /usr/local/Cellar/mongodb/3.0.7/bin/mongodump
/usr/local/bin/mongoexport -> /usr/local/Cellar/mongodb/3.0.7/bin/mongoexport
/usr/local/bin/mongofiles -> /usr/local/Cellar/mongodb/3.0.7/bin/mongofiles
/usr/local/bin/mongoimport -> /usr/local/Cellar/mongodb/3.0.7/bin/mongoimport
/usr/local/bin/mongorestore -> /usr/local/Cellar/mongodb/3.0.7/bin/mongorestore
/usr/local/bin/mongostat -> /usr/local/Cellar/mongodb/3.0.7/bin/mongostat
/usr/local/bin/mongotop -> /usr/local/Cellar/mongodb/3.0.7/bin/mongotop
==> R√©sum√©
üç∫  /usr/local/Cellar/mongodb-database-tools/100.3.0: 13 fichiers, 154 Mo, construit en 11 secondes
==> Installation de mongodb/brew/mongodb-community
Erreur : L'√©tape `brew link` ne s'est pas termin√©e avec succ√®s
La formule a √©t√© construite, mais n'est pas li√©e symboliquement dans /usr/local
Impossible de cr√©er un lien symbolique pour bin/mongo
La cible /usr/local/bin/mongo
est un lien symbolique appartenant √† mongodb. Vous pouvez le dissocier :
  brew unlink mongodb

Pour forcer le lien et √©craser tous les fichiers en conflit :
  brew link --overwrite mongodb-community

Pour lister tous les fichiers qui seraient supprim√©s :
  brew link --overwrite --dry-run mongodb-community

Les fichiers potentiellement en conflit sont :
/usr/local/bin/mongo -> /usr/local/Cellar/mongodb/3.0.7/bin/mongo
/usr/local/bin/mongod -> /usr/local/Cellar/mongodb/3.0.7/bin/mongod
/usr/local/bin/mongos -> /usr/local/Cellar/mongodb/3.0.7/bin/mongos
==> Avertissements
Pour d√©marrer mongodb/brew/mongodb-community avec launchd maintenant et red√©marrer √† la connexion :
  brew services start mongodb/brew/mongodb-community
Ou, si vous ne voulez/pas besoin d'un service en arri√®re-plan, vous pouvez simplement ex√©cuter :
  mongod --config /usr/local/etc/mongod.conf
==> R√©sum√©
üç∫  /usr/local/Cellar/mongodb-community/4.4.3: 11 fichiers, 156,8 Mo, construit en 10 secondes
==> Avertissements
==> mongodb-community
Pour d√©marrer mongodb/brew/mongodb-community avec launchd maintenant et red√©marrer √† la connexion :
  brew services start mongodb/brew/mongodb-community
Ou, si vous ne voulez/pas besoin d'un service en arri√®re-plan, vous pouvez simplement ex√©cuter :
  mongod --config /usr/local/etc/mongod.conf
```

J'avais pr√©c√©demment install√© une ancienne version. Je vais supprimer les liens.

```shell
$ brew unlink mongodb
D√©liaison de /usr/local/Cellar/mongodb/3.0.7... 11 liens symboliques supprim√©s
```

```shell
$ mongod --version
db version v4.4.3
Build Info: {
    "version": "4.4.3",
    "gitVersion": "913d6b62acfbb344dde1b116f4161360acd8fd13",
    "modules": [],
    "allocator": "system",
    "environment": {
        "distarch": "x86_64",
        "target_arch": "x86_64"
    }
}
```

Ensuite, ex√©cutez `mongod` pour d√©marrer le serveur de base de donn√©es MongoDB. Cependant, lors du premier d√©marrage, il a indiqu√© que `/data/db` n'existait pas. Nous avons donc cr√©√© un r√©pertoire, `~/mongodb`, pour y stocker les fichiers de la base de donn√©es.

```shell
$ mongod --dbpath ~/mongodb
```

Sortie :

```json
{"t":{"$date":"2021-03-11T18:17:32.838+08:00"},"s":"I",  "c":"CONTROL",  "id":23285,   "ctx":"main","msg":"D√©sactivation automatique de TLS 1.0, pour forcer l'activation de TLS 1.0, sp√©cifiez --sslDisabledProtocols 'none'"}
{"t":{"$date":"2021-03-11T18:17:32.842+08:00"},"s":"W",  "c":"ASIO",     "id":22601,   "ctx":"main","msg":"Aucune couche de transport configur√©e lors du d√©marrage de l'interface r√©seau"}
{"t":{"$date":"2021-03-11T18:17:32.842+08:00"},"s":"I",  "c":"NETWORK",  "id":4648602, "ctx":"main","msg":"Utilisation implicite de TCP FastOpen."}
{"t":{"$date":"2021-03-11T18:17:32.842+08:00"},"s":"I",  "c":"STORAGE",  "id":4615611, "ctx":"initandlisten","msg":"D√©marrage de MongoDB","attr":{"pid":46256,"port":27017,"dbPath":"/Users/lzw/mongodb","architecture":"64-bit","host":"lzwjava"}}
{"t":{"$date":"2021-03-11T18:17:32.842+08:00"},"s":"I",  "c":"CONTROL",  "id":23403,   "ctx":"initandlisten","msg":"Informations de construction","attr":{"buildInfo":{"version":"4.4.3","gitVersion":"913d6b62acfbb344dde1b116f4161360acd8fd13","modules":[],"allocator":"system","environment":{"distarch":"x86_64","target_arch":"x86_64"}}}}
{"t":{"$date":"2021-03-11T18:17:32.843+08:00"},"s":"I",  "c":"CONTROL",  "id":51765,   "ctx":"initandlisten","msg":"Syst√®me d'exploitation","attr":{"os":{"name":"Mac OS X","version":"20.3.0"}}}
...
```

On peut voir que tout est au format `JSON`. MongoDB enregistre tous les fichiers de donn√©es au format `JSON`. Ensuite, ouvrez un autre onglet de terminal.

```shell
$ mongo
MongoDB shell version v4.4.3
connexion √† : mongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb
Session implicite : session { "id" : UUID("4f55c561-70d3-4289-938d-4b90a284891f") }
Version du serveur MongoDB : 4.4.3
---
Le serveur a g√©n√©r√© ces avertissements de d√©marrage lors du d√©marrage :
        2021-03-11T18:17:33.743+08:00 : Le contr√¥le d'acc√®s n'est pas activ√© pour la base de donn√©es. L'acc√®s en lecture et en √©criture aux donn√©es et √† la configuration est illimit√©.
        2021-03-11T18:17:33.743+08:00 : Ce serveur est li√© √† localhost. Les syst√®mes distants ne pourront pas se connecter √† ce serveur. D√©marrez le serveur avec --bind_ip <adresse> pour sp√©cifier les adresses IP auxquelles il doit r√©pondre, ou avec --bind_ip_all pour le lier √† toutes les interfaces. Si ce comportement est souhait√©, d√©marrez le serveur avec --bind_ip 127.0.0.1 pour d√©sactiver cet avertissement.
        2021-03-11T18:17:33.743+08:00 : Les limites de ressources (soft rlimits) sont trop basses.
        2021-03-11T18:17:33.743+08:00 :         valeur actuelle : 4864
        2021-03-11T18:17:33.743+08:00 :         minimum recommand√© : 64000
---
---
        Activez le service de surveillance cloud gratuit de MongoDB, qui recevra et affichera
        des m√©triques sur votre d√©ploiement (utilisation du disque, CPU, statistiques des op√©rations, etc.).
```

Les donn√©es de surveillance seront disponibles sur un site web MongoDB avec une URL unique accessible √† vous et √† toute personne avec qui vous partagez l'URL. MongoDB peut utiliser ces informations pour am√©liorer ses produits et vous sugg√©rer des produits MongoDB ainsi que des options de d√©ploiement.

Pour activer la surveillance gratuite, ex√©cutez la commande suivante : `db.enableFreeMonitoring()`  
Pour d√©sactiver d√©finitivement ce rappel, ex√©cutez la commande suivante : `db.disableFreeMonitoring()`  
```

Ensuite, vous pouvez essayer d'ins√©rer des donn√©es et de les interroger.

```shell
> db.inventory.insertOne(
...    { item: "canvas", qty: 100, tags: ["cotton"], size: { h: 28, w: 35.5, uom: "cm" } }
... )
{
	"acknowledged" : true,
	"insertedId" : ObjectId("6049ef91b653541cf355facb")
}
>
> db.inventory.find()
{ "_id" : ObjectId("6049ef91b653541cf355facb"), "item" : "canvas", "qty" : 100, "tags" : [ "cotton" ], "size" : { "h" : 28, "w" : 35.5, "uom" : "cm" } }
```

## Enfin

Arr√™tons-nous ici pour le moment. Nous aborderons d'autres outils par la suite. Quelle est la signification de tout cela ? Il s'agit probablement de tracer d'abord une ligne directrice. Le d√©but est toujours difficile, mais nous avons d√©j√† parcouru tout cela d'un seul coup. Cela nous donne confiance, et maintenant, il ne reste plus qu'√† explorer davantage ces logiciels.

## Exercice

* Les √©tudiants explorent de mani√®re similaire comme ci-dessus.