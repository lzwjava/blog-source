---
audio: false
generated: false
image: false
lang: fr
layout: post
title: Introduction au Machine Learning - PyTorch
translated: true
type: post
---

Ce post a été initialement rédigé en chinois. Il a été traduit en anglais pour faciliter les traductions ultérieures dans d'autres langues.

---

## PyTorch

Installons-le. Cela prend en charge la version Python `3.9`.

```shell
$ pip install torch torchvision
Collecting torch
  Downloading torch-1.8.0-cp39-none-macosx_10_9_x86_64.whl (120.6 MB)
     |████████████████████████████████| 120.6 MB 224 kB/s
Collecting torchvision
  Downloading torchvision-0.9.0-cp39-cp39-macosx_10_9_x86_64.whl (13.1 MB)
     |████████████████████████████████| 13.1 MB 549 kB/s
Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from torch) (1.20.1)
Collecting typing-extensions
  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)
Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.9/site-packages (from torchvision) (8.0.1)
Installing collected packages: typing-extensions, torch, torchvision
Successfully installed torch-1.8.0 torchvision-0.9.0 typing-extensions-3.7.4.3
```

Vérifions-le.

```python
import torch
x = torch.rand(5, 3)
print(x)
```

Une erreur est survenue.

```shell
Traceback (most recent call last):
  File "torch.py", line 1, in <module>
    import torch
  File "torch.py", line 2, in <module>
    x = torch.rand(5, 3)
AttributeError: partially initialized module 'torch' has no attribute 'rand' (most likely due to a circular import)
```

Après avoir recherché ce message d'erreur, il s'avère que notre fichier s'appelait aussi `torch`, ce qui a causé un conflit de noms. Après l'avoir renommé, cela fonctionne correctement.

```shell
tensor([[0.5520, 0.9446, 0.5543],
        [0.6192, 0.0908, 0.8726],
        [0.0223, 0.7685, 0.9814],
        [0.4019, 0.5406, 0.3861],
        [0.5485, 0.6040, 0.2387]])
```

Trouvons un exemple.

```python
# -*- coding: utf-8 -*-

import torch
import math
dtype = torch.float
device = torch.device("cpu")
# device = torch.device("cuda:0") # Décommentez cette ligne pour exécuter sur GPU

# Créer des données d'entrée et de sortie aléatoires
x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)
y = torch.sin(x)

# Initialiser aléatoirement les poids
a = torch.randn((), device=device, dtype=dtype)
b = torch.randn((), device=device, dtype=dtype)
c = torch.randn((), device=device, dtype=dtype)
d = torch.randn((), device=device, dtype=dtype)

learning_rate = 1e-6
for t in range(2000):
    # Passe avant : calculer la prédiction y
    y_pred = a + b * x + c * x ** 2 + d * x ** 3

    # Calculer et afficher la perte
    loss = (y_pred - y).pow(2).sum().item()
    if t % 100 == 99:
        print(t, loss)

    # Rétropropagation pour calculer les gradients de a, b, c, d par rapport à la perte
    grad_y_pred = 2.0 * (y_pred - y)
    grad_a = grad_y_pred.sum()
    grad_b = (grad_y_pred * x).sum()
    grad_c = (grad_y_pred * x ** 2).sum()
    grad_d = (grad_y_pred * x ** 3).sum()

    # Mettre à jour les poids en utilisant la descente de gradient
    a -= learning_rate * grad_a
    b -= learning_rate * grad_b
    c -= learning_rate * grad_c
    d -= learning_rate * grad_d
print(f'Résultat : y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')
```

Exécutons-le.

```shell
99 1273.537353515625
199 849.24853515625
299 567.4786987304688
399 380.30291748046875
499 255.92752075195312
599 173.2559814453125
699 118.2861328125
799 81.72274780273438
899 57.39331817626953
999 41.198158264160156
1099 30.41307830810547
1199 23.227672576904297
1299 18.438262939453125
1399 15.244369506835938
1499 13.113286972045898
1599 11.690631866455078
1699 10.740333557128906
1799 10.105220794677734
1899 9.6804780960083
1999 9.39621353149414
Résultat : y = -0.011828352697193623 + 0.8360244631767273 x + 0.002040589228272438 x^2 + -0.09038365632295609 x^3
```

Regardons un code utilisant uniquement la bibliothèque `numpy`.

```python
# -*- coding: utf-8 -*-
import numpy as np
import math

# Créer des données d'entrée et de sortie aléatoires
x = np.linspace(-math.pi, math.pi, 2000)
y = np.sin(x)

# Initialiser aléatoirement les poids
a = np.random.randn()
b = np.random.randn()
c = np.random.randn()
d = np.random.randn()

learning_rate = 1e-6
for t in range(2000):
    # Passe avant : calculer la prédiction y
    # y = a + b x + c x^2 + d x^3
    y_pred = a + b * x + c * x ** 2 + d * x ** 3

    # Calculer et afficher la perte
    loss = np.square(y_pred - y).sum()
    if t % 100 == 99:
        print(t, loss)

    # Rétropropagation pour calculer les gradients de a, b, c, d par rapport à la perte
    grad_y_pred = 2.0 * (y_pred - y)
    grad_a = grad_y_pred.sum()
    grad_b = (grad_y_pred * x).sum()
    grad_c = (grad_y_pred * x ** 2).sum()
    grad_d = (grad_y_pred * x ** 3).sum()

    # Mettre à jour les poids
    a -= learning_rate * grad_a
    b -= learning_rate * grad_b
    c -= learning_rate * grad_c
    d -= learning_rate * grad_d

print(f'Résultat : y = {a} + {b} x + {c} x^2 + {d} x^3')
```

Remarquez que ce sont deux méthodes différentes pour effectuer des calculs.

Dans ces exemples, un ensemble de valeurs x et y est d'abord généré. Ensuite, il est supposé être une équation cubique. Puis, certaines méthodes sont utilisées pour calculer itérativement les coefficients. Quels sont ces algorithmes ? Notez qu'il boucle `2000` fois, devenant plus précis à chaque itération. Nous n'entrerons pas dans les détails ici.

## Enfin

Actuellement, nous ne comprenons pas comment fonctionnent les calculs d'apprentissage automatique en arrière-plan. Cependant, ce n'est pas important pour le moment. Avec les connaissances ci-dessus, nous pouvons déjà faire beaucoup de choses. L'apprentissage automatique peut également être utilisé pour traiter du texte, de l'audio et bien plus encore. Après avoir exploré des dizaines d'exemples, il ne sera pas trop tard pour apprendre la théorie.

## Exercices

* Les étudiants doivent explorer comme indiqué ci-dessus.