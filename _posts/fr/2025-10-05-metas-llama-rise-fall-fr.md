---
audio: false
generated: true
image: false
lang: fr
layout: post
model: x-ai/grok-4-fast
title: L'ascension et la chute de Llama de Meta
translated: true
type: note
---

### Le parcours de Llama chez Meta : de la percée de 2023 aux difficultés de 2025

En 2023, Meta a fait une entrée remarquée sur la scène de l'IA avec Llama 1 et 2, salués comme des modèles de référence—des alternatives open-source qui rivalisaient en capacités avec des systèmes fermés comme GPT-3.5, tout en favorisant une communauté de développeurs massive. Cette initiative a positionné Meta comme un leader dans la démocratisation de l'IA, attirant les talents et les investissements. Cependant, dès 2025, Llama était distancé par des concurrents comme Google (Gemini), OpenAI (série GPT), et même par des acteurs open-source plus agiles comme Mistral et DeepSeek. Ce retard découle d'un mélange d'erreurs internes, de pressions externes et de pivots stratégiques qui ont érodé l'élan initial.

#### 1. **Une hémorragie massive de talents**
L'équipe originale de Llama chez Meta, créditée dans l'article de recherche de 2023, a été décimée. Sur les 14 auteurs clés, seulement trois restaient à la mi-2025, 11 étant partis en deux ans—beaucoup pour fonder ou rejoindre des rivaux comme Mistral AI (co-fondé par d'anciens chercheurs de Meta, Guillaume Lample et Timothée Lacroix). Cette exode, représentant en moyenne plus de cinq ans d'ancienneté par départ, a laissé des lacunes en expertise pour le scaling et l'innovation. Des initiés ont cité l'épuisement dû à des délais agressifs, des politiques internes et de meilleures opportunités dans des startups ou chez d'autres géants technologiques offrant plus d'autonomie et de ressources.

#### 2. **Obstacles au développement et sorties précipitées**
Le passage du laboratoire de recherche fondamentale en IA (FAIR) de Meta—berceau des premiers Llama—à des équipes GenAI axées sur les produits a perturbé les flux de travail. FAIR a perdu la priorité sur les ressources de calcul, ralentissant le travail exploratoire, tandis que les équipes produits poussaient pour des victoires rapides. Cela a entraîné des retards, comme la mise en suspens du modèle massif "Behemoth" en raison de benchmarks internes décevants, et un lancement de Llama 4 mal calibré (publié un week-end sans toutes ses variantes, incluant un modèle dédié au raisonnement). Les critiques ont pointé des tests incomplets et un manque d'itération systématique, contrastant avec les déploiements soignés des concurrents.

#### 3. **Écarts de performance et mécontentement de la communauté**
Llama 4, malgré ses fonctionnalités multimodales et son énorme fenêtre de contexte de 10 millions de tokens, a sous-performé sur des benchmarks clés comme la récupération en contexte long et le raisonnement à plusieurs étapes—des domaines où DeepSeek R1 (un modèle chinois à faible coût) et les mises à jour de Mistral ont pris de l'avance. Les développeurs sur des plateformes comme Hugging Face ont déplacé leurs téléchargements vers des alternatives à l'évolution plus rapide, érodant l'adoption de Llama. Des accusations de métriques gonflées (utilisant des versions personnalisées pour les classements) et d'opacité ont encore endommagé la confiance, avec un faible trafic quotidien et des statistiques de rétention soulignant le retard de Meta en matière d'engagement utilisateur par rapport à ChatGPT ou Gemini.

#### 4. **Désalignements stratégiques**
Meta a doublé la mise sur l'open-source comme sa "voie à suivre", mais n'a pas pu suivre le rythme des leaders des modèles fermés ou des rivaux open-source agiles. La volonté de Zuckerberg de scaling rapide a heurté les réalités du développement de l'IA, conduisant à des réallocations de ressources vers les produits commerciaux au détriment de la recherche fondamentale. D'ici 2025, cela s'est manifesté par la "mort lente" de FAIR (selon des initiés), des remaniements de leadership (par exemple, le départ de Joelle Pineau), et des rumeurs de pivot vers des modèles fermés pour éviter l'embarras. Pendant ce temps, des concurrents comme Google ont capitalisé sur les faux pas de Meta avec des versions écrasant les benchmarks et une meilleure tarification.

En substance, le succès de Meta en 2023 était alimenté par une ouverture audacieuse et une équipe star, mais 2025 a exposé les risques : fuite des talents, priorités en silos et fatigue de l'innovation dans un domaine hyper-compétitif. La société recrute maintenant agressivement pour un "laboratoire de superintelligence" pour rebondir, mais pour combler son retard, il faudra reconstruire cette magie perdue.

### Références
- [Meta’s Llama Troubles](https://medium.com/predict/metas-llama-troubles-f637f21a82dd)
- [Meta's Llama AI team has been bleeding talent](https://www.businessinsider.com/meta-llama-ai-talent-mistral-2025-5)
- [Google Leads With LLMs, Meta and OpenAI Struggle](https://spectrum.ieee.org/large-language-models-2025)
- [Meta’s AI research lab is ‘dying a slow death’](https://fortune.com/2025/04/10/meta-ai-research-lab-fair-questions-departures-future-yann-lecun-new-beginning/)
- [Meta Is Delaying the Rollout of Its 'Behemoth' AI Model](https://www.wsj.com/tech/ai/meta-is-delaying-the-rollout-of-its-flagship-ai-model-f4b105f7)
- [Statistics Reveal How Far Behind Meta Is Against Top AI Competitors](https://seekingalpha.com/article/4774647-statistics-reveal-how-far-behind-meta-is-against-top-ai-competitors-its-not-even-close)