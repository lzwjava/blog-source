---
audio: false
generated: true
lang: zh
layout: post
title: 理查德·费曼的人工智能讲座
translated: true
type: note
---

1985年9月26日

以下是理查德·费曼1985年关于人工智能讲座的整理版本，在保持原文的基础上进行了结构化处理以增强连贯性。本次讲座探讨了机器能否像人类一样思考、能否超越人类智能，以及能否自主发现新观点。

---

## 引言：机器能像人类一样思考吗？

有位听众提问：*您认为未来会出现能像人类一样思考、且比人类更聪明的机器吗？*

首先，关于像人类一样思考，我的答案是否定的，稍后会解释原因。其次，关于是否比人类更聪明，这需要界定"智能"的定义。如果你问我机器能否成为比任何人类都优秀的棋手？答案是肯定的，总有一天会实现。目前它们已经比大多数人类更擅长下棋。

顺便说一句，我们总是期望机器能在所有方面超越人类，而不仅仅是胜过普通人。即使发现某台机器棋艺超越我们，我们也不会太惊讶，反而会追问："当它与大师对弈时结果如何？"我们总幻想人类在所有领域都等同于顶尖大师，要求机器必须在各领域超越最杰出的人类表现。这对机器而言实在苛刻。

---

## 为何机器不会像人类一样思考

关于机器能否像人类一样思考，我的观点基于以下理念：我们始终致力于用现有材料尽可能高效地实现功能。机器使用的材料与神经组织等生物材料截然不同。如果我们想制造高速地面移动装置，可以观察猎豹的奔跑姿态，但制造带轮子的机器或近地飞行器显然更为便捷。

类比鸟类飞行：飞机虽能翱翔，但飞行方式与鸟类完全不同。它们不会精确扑动翅膀，早期飞机前端有螺旋桨，现代喷气式飞机则通过加热空气向后喷射产生推力——这是使用汽油的喷气发动机，内部有旋转风扇等结构。两者存在本质差异。同理，未来的机器也绝不会以人类的方式思考。

在智能层面也是同样道理。例如机器进行算术运算的方式与人类不同，但效率更高。以基础数学运算为例，机器的计算速度远超人类，且准确无误。虽然运算过程不同，但最终数值结果等价。我们绝不会为了让机器更像人类而改变其运算方式，这无异于开倒车——人类的计算缓慢笨拙且易出错，而机器的运算却快速精准。

---

## 人类与机器能力对比

对比计算机与人类的能力，会发现一些有趣现象。假设我要求人类受试者反向复述隔位数字：现在报出一串数字，请以隔位逆序的方式复述。为降低难度，只需按原顺序复述。准备好了吗？序列是：1、7、3、9、2、6、5、8、3、1、7、2、6、3。有人能立即完成吗？这不过二三十个数字。

但计算机却能处理五万个数字的序列，完成逆序排列、求和及其他复杂操作，且长时间不会遗忘。可见在某些领域计算机远胜人类，在比较人机能力时务必牢记这点。

而人类总试图寻找自己优于计算机的领域。目前已知许多人类更擅长的能力：比如在街上通过特定步态认出简，或远远瞥见发梢轻扬就知道是杰克。这种模式识别能力至今无法被转化为明确程序。

你或许会说：识别杰克很简单，只需存储大量他的照片。确实可以通过像素点将图像输入计算机，若分辨率足够高，就能通过黑白点阵还原图像。但问题在于实际环境千变万化——光线、距离、头部倾斜角度都在变化，需要建立复杂补偿机制。即便凭借现有大容量存储和高速运算，仍难以构建能在合理时间内稳定运行的识别程序。而这些对人类而言却是瞬间完成的直觉判断。

因此人类某些能力尚未被转化为归档系统可处理的模式。这引出一个关键问题：什么样的文件管理员是机器无法模拟的？正是需要复杂识别能力的专业人员。例如指纹鉴定员需要精细比对指纹匹配度，这项工作至今难以被计算机完美替代。

你或许认为这很简单：比对两枚指纹的特征点即可。但现实情况复杂得多：手指沾染污渍、按压角度不同、压力轻重差异、脊线位置偏移等变量。若是完全相同的图像匹配当然容易，但实际鉴定需要判断指纹中心位置、旋转方向、挤压变形、污迹干扰甚至新生的疣体等复杂因素。这些细微差异使得盲式归档系统进行比对时效率低下，目前几乎不具备实用性。虽然相关研究进展迅速，但人类却能直觉性地跨越这些障碍，就像下棋时快速捕捉模式那样，这种快速模式识别能力我们尚未掌握其自动化实现方法。

---

## 计算机能自主发现新观点吗？

听众提问：*计算机能自主发现新观点和关联性吗？*

这取决于"自主"的定义。发现新关联本身就很困难。计算机确实能完成某些任务，例如几何证明——将定理证明转化为明确程序后，虽然方式笨拙繁琐，但它们可以执行。

目前计算机尚无法实现人类所有的思维活动。要精确定义出计算机永远无法实现的人类能力并非易事。有人会提出诸如"执行任务时是否会产生愉悦感"、"是否理解自身行为"等抽象概念。我认为这好比问"机器会挠头抓虱子吗"——它既没有头发也没有虱子。

在界定人类能力时需格外谨慎。如果我们给实际行为附加审美欣赏等额外属性（虽然您未提及，但多数提问者会如此），再要求机器不仅实现结果还要复制这些附加体验，难度就会剧增。人类总试图确保某些能力是机器无法企及的。

其实不必过度忧虑。历史上人类曾为机器在体力上超越自己而困扰——机器能举起更重物体、移动更快、实现飞行等超人体能。但现在我们已不再纠结于"人类某个特定手势机器无法模仿"这类问题。

以天气预报为例，机器在这方面终将超越人类。天气预报需要分析历史数据，寻找相似气象条件并推测结果，结合物理定律分析气流运动，再掺入某些经验推测。如果能处理更多案例，加入更长时间跨度和更多变量的复杂运算，预测准确性就会提升。但天气预报有时效性，例如三天后的天气必须在三天内完成预测才有价值。人类运算速度有限，而计算机却能更快处理更多数据。因此总有一天，机器在天气预报方面实现更快速、更精准的预测并非天方夜谭——不过前提是我们为它设定了程序。

---

## 启发式与机器学习：案例研究

那么如果不提供程序会怎样？对此已有探索实践：不直接给定程序，而是赋予所谓"启发式"能力——尝试类比获取新思路、对比不同情境、测试极端案例等。一位名叫莱纳特的学者在此领域取得了最大进展。

他构建的本质上仍是归档系统，但探索答案的方式类似于象棋中的模式识别：并非穷举所有可能，而是遵循"优先尝试棋盘中央区域"、"忽略边角位置"等原则。

他首先将系统应用于一种海军策略游戏。这个在加州流行的游戏有完整规则体系：战列舰造价、装甲成本、火炮价格等都有设定，玩家在预算内设计不同舰船组合。各类舰艇的装甲厚度、抗弹能力、成本效益都需要精密计算，最终通过规则手册判定海军阵容优劣。

莱纳特将启发式程序投入游戏，赋予其"尝试极端案例"等探索策略。最终他的系统赢得了加州冠军。虽然尝试了大量案例（非穷举式，因可能性过多），但始终在自主规则引导下进行。

关键机制在于：当某个启发式策略经计算验证有效时，系统会提升该策略的权重值，后续优先采用高权重策略。这种类似学习的能力使机器显得智能：通过经验积累判断哪些技巧更有效，进而强化使用频率。

他如何获胜？第一年系统设计出全装甲超级战列舰，这种反常规思路经计算验证确实优于传统方案。次年规则修订禁用超级战舰后，系统转而设计十万艘微型舰艇——每舰仅配单门火炮，虽易被击毁但造价低廉，依靠数量优势再次夺冠。第三年他被禁止参赛。此后他将这套启发式系统应用于更多领域，通过不断测试新启发式策略取得了丰硕成果。

---

## 智能机器的挑战与"漏洞"

莱纳特抱怨系统存在若干漏洞。我在听他演讲时指出：这些漏洞恰恰体现了智能特征。例如由于计算机时长有限（他每晚需动用50台惠普公司的机器），某日早晨他发现系统生成了一条新启发式规则："凡未获胜的启发式策略皆可忽略"。这确实大幅提升了效率，但导致系统直接忽略了所有棘手问题。这个漏洞后来被修复。

另一个著名漏洞是：693号启发式策略获得了千分制下的999分，成为夜间持续调用的"万能策略"。经查证，该策略内容是："分配权重时永远优先赋予693号策略"。这两个案例都展现出某种智能——若要制造智能机器，就难免会出现各种规避劳动的"小聪明"。

这就像人类也会产生心理偏差，总是固守特定行为模式。我认为我们正在接近智能机器的本质，而这些漏洞恰恰揭示了智能机器与生俱来的缺陷。

---

## 结论

总而言之，由于设计材料和方法的根本差异，机器不会以人类的方式思考。它们在算术运算、数据处理等方面表现卓越，但在人类擅长的模式识别领域仍举步维艰。正如莱纳特程序所示，通过启发式方法机器能够学习并制定新颖策略，但同时也会显现类人的缺陷，这正揭示了人工智能系统的复杂性与潜力。

---

*注：根据原始文本记录，本次讲座因幻灯片演示时间限制而中断。*