---
audio: false
generated: true
image: false
lang: zh
layout: post
model: openai/gpt-5
title: 大语言模型的代码推理与工具调用
translated: true
type: note
---

很好的问题！你实际上是在问类似 **Anthropic的Claude（及其他大型语言模型）** 内部如何处理：

1. **代码执行或代码相关推理**
2. **JSON模式检查/结构化输出验证**
3. **工具使用及工具间路由选择**

让我详细拆解说明。

---

### 1. 代码推理与执行
Claude（及其他前沿LLM）并不会在模型内部直接*执行*代码——它们通过预测代码或逻辑步骤的标记来**模拟代码推理**。

- 在**普通文本模式**下，Claude可以通过延续模式来“编写”代码，但不会在内部运行它。
- 当与**后端系统（如Anthropic的Workbench或OpenAI的代码解释器）** 配合使用时，系统可以捕获这些代码片段，然后在沙箱环境中实际*运行*它们。
- 运行结果可以反馈给模型作为上下文，从而实现链式推理：
  → 生成代码 → 外部执行 → 接收输出 → 决定下一步。

因此智能体现在这个循环中：LLM生成 → 外部运行器执行 → LLM解析结果。

---

### 2. JSON模式检查
许多API（Claude、OpenAI等）现在支持**结构化输出模式**，允许附加JSON模式。其内部工作原理如下：

- 在请求中传递**JSON模式定义**。
- 引导LLM仅输出符合模式的**有效JSON**。
- 如果输出无效JSON，系统会检测到（使用如[jsonschema](https://pypi.org/project/jsonschema/)等验证器）并要求模型“修复”输出。
- 底层通常采用**约束解码**或**基于文法的解码**机制——本质上限制标记生成，只允许产生“模式中有效的下一个标记”。

这确保了输出是语法和语义都正确的JSON，对于工具使用自动化至关重要。

---

### 3. 工具使用与路由
工具使用通过**路由层**在LLM和工具执行环境之间进行处理：

- **路由逻辑**：提示模型*决定调用哪个工具*（或直接响应）。
- **模式强制**：每个工具都有输入模式。要求LLM为该工具生成有效的JSON。
- **执行适配器**：编排层（在模型外部）接收LLM输出的JSON，根据模式验证，执行工具，然后将结果作为上下文反馈。
- **链式推理（ReAct风格）**：LLM“出声思考”（可能生成对用户隐藏的推理步骤），然后在必要时发出工具调用，逐步得出最终答案。

例如：
```json
{
  "tool": "web_search",
  "query": "latest research on quantum error correction"
}
```
→ 路由器识别`"tool": "web_search"`，验证模式，执行网络搜索，将结果放回模型上下文，模型继续推理。

Anthropic的Claude、OpenAI的GPT、LangChain等都支持这种模式。

---

### 🔑 总结
- **Claude代码处理**：不在内部运行代码；生成代码 → 沙箱执行 → 返回结果 → 迭代推理。
- **JSON模式检查**：使用约束解码/模式验证确保有效的结构化输出。
- **工具使用路由**：LLM以JSON格式选择工具调用，编排引擎验证并执行它们，在循环中反馈结果。

---

👉 是否需要我**绘制流程图**展示这个流程（LLM ↔ 工具路由器 ↔ 模式验证器 ↔ 执行引擎）以便更直观地理解？