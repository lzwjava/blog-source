---
audio: false
generated: true
image: false
lang: zh
layout: post
model: x-ai/grok-4-fast
title: 2025年ImageNet分类新进展
translated: true
type: note
---

自2012年取得突破性进展以来，ImageNet（特指ImageNet-1K图像分类验证集）上的顶尖技术水准持续稳步提升。截至2025年11月，领先模型的Top-1准确率已达91%左右，对应Top-1错误率约9%。Top-5准确率更高，普遍超过99%，对应Top-5错误率低于1%。

### 关键SOTA模型（基于Papers With Code排行榜前五）
以下为当前顶尖模型（基于ImageNet-1K微调）的Top-1准确率快照。由于这些高性能模型的Top-5准确率已接近饱和完美水平，通常不会专门重报，但参照近期类似架构可知所有模型的Top-5错误率均低于1%：

| 排名 | 模型 | Top-1准确率 | 预估Top-5准确率 | 参数量 | 备注 |
|------|------|-------------|-----------------|---------|------|
| 1 | CoCa（微调版） | 91.0%（错误率9.0%） | ~99.5%（错误率<0.5%） | 21亿 | 多模态图文模型；零样本（86.3% Top-1）与冻结编码器（90.6% Top-1）场景表现卓越 |
| 2 | Model Soups（BASIC-L） | 90.98%（错误率9.02%） | ~99.4%（错误率<0.6%） | ~10亿 | 通过微调模型集成平均提升鲁棒性 |
| 3 | Model Soups（ViT-G/14） | 90.94%（错误率9.06%） | ~99.4%（错误率<0.6%） | 18亿 | 基于ViT架构；对分布外数据具有强泛化能力 |
| 4 | DaViT-Giant | 90.4%（错误率9.6%） | ~99.3%（错误率<0.7%） | 14亿 | 双注意力ViT；基于15亿图文对训练 |
| 5 | ConvNeXt V2-Huge | 88.9%（错误率11.1%） | ~99.0%（错误率~1.0%） | 6.6亿 | 采用掩码自编码预训练的CNN复兴架构；适用于边缘设备 |

### 关于“当今<3%”的说明
- 此指标指**Top-5错误率**而非Top-1。2012年前的基线方法（如SVM）的Top-5错误率约为25%。到2017年（SENet），该指标降至约2.3%。现代SOTA模型已将其压缩至1%以下，使得Top-5预测在多数实际应用场景中基本可靠。
- Top-1错误率仍较高（约9%），因其要求模型必须给出完全匹配的顶级预测，这对模糊图像等边缘案例的判定更为严苛。

由于数据集趋于饱和，近年进展有所放缓——当前提升主要来自海量预训练（如ImageNet-21K或网络规模数据）以及模型集成/蒸馏等技术。人类专家在该基准上的预估表现约为5%的Top-1错误率（或2-12%的Top-5错误率，因研究而异），意味着AI在此基准上已超越人类水平。

[ImageNet基准（Papers With Code）](https://paperswithcode.com/sota/image-classification-on-imagenet)  
[2025年图像分类顶尖模型综述（HiringNet）](https://hiringnet.com/image-classification-state-of-the-art-models-in-2025)  
[CoCa：对比式描述模型作为图文基础模型（arXiv）](https://arxiv.org/abs/2205.01917)