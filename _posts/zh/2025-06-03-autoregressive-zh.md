---
audio: false
generated: true
lang: zh
layout: post
title: 自回归模型生成
translated: true
type: note
---

在GPT（生成式预训练变换器）这类模型中，“自回归”一词特指模型生成输出序列的方式。具体而言，它表示模型逐个生成序列中的每个单元，并将先前的输出作为生成后续单元的附加输入上下文。

以下是此类模型中自回归过程的工作原理详解：

1. **序列化生成**：模型以序列化方式生成文本。从初始输入（通常称为提示）开始，每次生成一个标记（可以是单词、词段或字符）。

2. **对前序标记的依赖**：在生成每个新标记时，模型会考量所有已生成的标记。这意味着每一步的输出都依赖于之前所有步骤的输出。

3. **反馈循环**：模型采用反馈循环机制，将第\\( t \\)个时间步的输出作为第\\( t+1 \\)个时间步的输入。这种机制使模型能够维持长序列的连贯性和上下文关联。

4. **概率分布**：在每个时间步，模型会生成可能的下一个标记的概率分布，并基于该分布选择标记（通常采用采样或选择最高概率标记等技术）。

总而言之，在GPT及类似模型的语境中，“自回归”意味着模型通过逐步生成序列的方式运作，每个步骤都依赖于前序步骤，从而能够生成连贯且符合语境的文本。