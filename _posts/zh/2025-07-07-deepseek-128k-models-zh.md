---
audio: false
generated: true
lang: zh
layout: post
title: DeepSeek的128K令牌模型在2025年
translated: true
type: note
---

截至2025年6月，DeepSeek已推出一系列具备出色上下文长度的模型，通常采用混合专家架构以提升效率。具体如下：

* **DeepSeek-R1**：该模型于2025年1月发布，以支持**128,000 tokens**的上下文长度著称（部分基准测试中为131,072 tokens）。凭借强化学习后训练技术，在数学、编程和结构化推理领域表现尤为突出。
* **DeepSeek-V3**：2024年12月发布的DeepSeek-V3及其基础模型同样支持**128,000 tokens**的上下文长度。作为强大的混合专家模型，其总参数量达6710亿（单次查询激活370亿参数）。
* **DeepSeek-Coder-V2**：这款专注于代码生成的混合专家模型于2024年7月发布，拥有**128,000 tokens**的大容量上下文窗口，支持338种编程语言。
* **DeepSeek-V2**：2024年5月推出的DeepSeek-V2具备**128,000 tokens**上下文长度，该混合专家模型致力于实现经济高效的训练与推理。
* **DeepSeek-V2.5**：2024年9月发布的该模型融合通用能力与编程专长，同样支持**128,000 tokens**的上下文窗口。

**重要注意事项：**

* **原生上下文长度与API限制**：虽然部分DeepSeek模型原生支持最高163,840 tokens的上下文长度，但DeepSeek API可能对特定模型设有限制（例如当前通过API使用的“deepseek-chat”和“deepseek-reasoner”上下文上限为64K）。如需使用完整上下文长度，可能需要本地部署模型或选择支持更长上下文的API服务商。
* **性能衰减现象**：与其他大语言模型类似，当触及标称的最大上下文窗口极限时，模型性能可能出现衰减。例如DeepSeek R2模型正是为了改善R1在128,000 tokens极限上下文场景下出现的15%性能下降问题而研发。

总体而言，DeepSeek在长上下文大模型领域表现强劲，截至2025年6月已有多个模型提供128K tokens的上下文窗口，使其能够胜任大规模输入处理和复杂任务挑战。