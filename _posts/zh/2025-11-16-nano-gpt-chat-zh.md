---
audio: false
generated: true
image: false
lang: zh
layout: post
model: x-ai/grok-4-fast
title: 卡帕西的nanoGPT与nanochat
translated: true
type: note
---

### 概述
nanoGPT 和 nanochat 均为 Andrej Karpathy 创建的开源项目，旨在降低大语言模型（LLM）训练门槛并兼具教育意义。nanoGPT（2023年发布）专注于从零开始训练 GPT 风格模型的基础原理，而 nanochat（2025年10月发布）则在其基础上构建了更全面的"全栈"流程，用于创建类 ChatGPT 聊天机器人。两者的核心差异在于项目范围、训练阶段、代码库复杂度及端到端可用性——nanochat 本质上将 nanoGPT 演进为适用于对话式 AI 的完整生产级系统。

### 训练代码核心差异
nanochat 的训练代码在继承 nanoGPT 方法的基础上进行了扩展和优化，并针对聊天应用整合了额外阶段与增强功能。具体对比如下：

| 维度                  | nanoGPT                                                                 | nanochat                                                                 |
|-----------------------|-------------------------------------------------------------------------|--------------------------------------------------------------------------|
| **核心目标**          | 基于原始文本数据（如 OpenWebText 或莎士比亚文集）预训练 Transformer 架构的 GPT 模型。重点传授分词、模型架构和基础训练循环等核心概念。 | 全流程覆盖：预训练 + 中期训练（对话/多选题） + 监督微调（SFT） + 可选强化学习（基于 GRPO 的 RLHF） + 评估 + 推理。构建可部署的聊天机器人。 |
| **训练阶段**          | - 单阶段预训练<br>- 基础评估（如困惑度） | - **预训练**：类似 nanoGPT，但使用 FineWeb 数据集<br>- **中期训练**：基于 SmolTalk（用户-助手对话）、多选题及工具调用数据<br>- **监督微调**：针对对话对齐进行微调，在 MMLU、ARC-E/C、GSM8K（数学）、HumanEval（代码）等基准测试中评估<br>- **强化学习**：在 GSM8K 上实施可选 RLHF 以实现偏好对齐<br>- 自动生成评估报告（含 CORE 分数等指标） |
| **代码库规模与结构**  | 总计约 600 行（如 `train.py` 约 300 行，`model.py` 约 300 行）。极简可 hack 的 PyTorch 实现，优先考虑简洁性而非完整性。目前已弃用，推荐使用 nanochat。 | 约 8,000 行整洁模块化 PyTorch 代码。包含基于 Rust 的分词器、高效推理引擎（KV 缓存、预填充/解码机制）、工具集成（如 Python 沙箱）及 Web 界面。更具系统性且仍支持分支改造。 |
| **优化器与超参数**    | 标准 AdamW；学习率针对中等规模模型（如 1.24 亿参数的 GPT-2）调优。 | Muon + AdamW 混合优化器（受 modded-nanoGPT 启发）；自适应学习率（如对小数据集采用更低学习率防止过拟合）。通过 `--depth` 参数实现模型规模扩展。 |
| **数据处理**          | 原始文本语料库；基础 BPE 分词器训练。 | 增强流程：训练自定义分词器（词表量约 6.5 万）；使用 Hugging Face 数据集（预训练用 FineWeb，对话训练用 SmolTalk）。支持合成数据注入个性特征。 |
| **训练时间与成本**    | 8×A100 训练约 4 天达到 GPT-2 等效水平（约 500+ 美元）。侧重教育性实验。 | 8×H100 训练 4 小时可完成 5.6 亿参数基础模型（约 100 美元）；12 小时即可超越 GPT-2；扩展至更强模型约需 1,000 美元（如 24 小时训练后 MMLU 达 40%）。 |
| **推理与部署**        | 基础文本生成；无内置聊天功能或用户界面。 | 优化推理引擎（含 KV 缓存）；命令行聊天界面；类 ChatGPT 的 Web 界面；工具调用（如代码执行）。小规模模型虽"天真笨拙"但颇具趣味性。 |
| **教育目标**          | 构建语言模型的"核心大脑"。适合初学者探索架构调整。 | 构建完整 ChatGPT 复刻版（从大脑到交互界面）。作为 LLM101n 等进阶课程的结业项目，兼具潜在研究基准价值。 |

### 使用场景选择
- **选择 nanoGPT**：如果您是 LLM 初学者，希望通过轻量级项目入门预训练（如调整架构或数据集）。该方案简洁但仅支持非对话模型。
- **选择 nanochat**：用于端到端聊天机器人开发。在对话任务上表现优于 nanoGPT（部分 RLHF 测试提升 58%），且包含从数据到可运行界面的完整工具链。

两者均强调可 hack 性——例如 nanochat 支持轻松调整模型规模（修改深度参数）或个性化定制（通过合成数据注入特征）。nanochat 甚至赋予模型自我认知能力（如知晓自身规模与局限性）。

实践探索推荐：
- [nanoGitHub 仓库](https://github.com/karpathy/nanoGPT)
- [nanochat GitHub 仓库](https://github.com/karpathy/nanochat)

如需运行建议，可在 Lambda Labs 等云 GPU 平台上从 nanochat 的 `speedrun.sh` 脚本开始体验完整流程。