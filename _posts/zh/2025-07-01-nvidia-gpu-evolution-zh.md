---
audio: false
generated: true
lang: zh
layout: post
title: 英伟达的AI与GPU革命
translated: true
type: note
---

过去十年间，NVIDIA彻底改变了计算行业格局，从一家主营游戏显卡的公司转型为加速计算领域的领军者，尤其在人工智能和高性能计算领域表现卓越。

### NVIDIA GPU发展简史（近十年篇）

近十年来，NVIDIA GPU实现了跨越式发展，从传统图形渲染延伸至数据中心和人工智能领域的关键支柱。重要里程碑包括：

* **帕斯卡架构（2016年左右）**：随GeForce GTX 10系列显卡问世，在提升游戏性能的同时，通过Tesla P100展现了NVIDIA在深度学习领域的战略布局
* **伏特架构（2017年）**：成为AI领域的革命性突破。基于该架构的Tesla V100首次搭载张量核心，这种专用处理单元极大加速了深度学习训练与推理所需的矩阵运算，奠定了NVIDIA在AI硬件领域的统治地位
* **图灵架构（2018年）**：通过GeForce RTX 20系列将实时光线追踪和DLSS（深度学习超采样）技术引入消费级GPU，依托张量核心与新增的RT核心实现更逼真图形效果
* **安培架构（2020年）**：GeForce RTX 30系列与面向数据中心的A100 GPU将该架构推向新高度。A100在V100基础上显著提升AI算力，提供更高吞吐量与内存带宽，成为众多AI研发项目的核心算力引擎
* **艾达·洛夫莱斯架构（2022年）**：该架构驱动着GeForce RTX 40系列（含旗舰RTX 4090），通过第四代张量核心与第三代RT核心实现性能、能效与AI能力的全面提升，进一步优化光线追踪与DLSS 3技术
* **霍珀架构（2022年）**：H100 GPU作为该代旗舰产品，专为大规模AI与HPC设计。在安培架构基础上强化张量核心性能，新增面向大语言模型的Transformer引擎，并通过NVLink交换系统实现大规模扩展
* **布莱克威尔架构（2024年发布）**：NVIDIA最新架构有望成为AI领域下一里程碑，B200与GB200（融合Grace CPU与布莱克威尔GPU）旨在为未来大语言模型提供前所未有的训练推理性能

### 明星产品：H100与RTX 4090

* **NVIDIA H100张量核心GPU**：基于霍珀架构的现役顶级数据中心GPU，专为AI与HPC工作负载设计，特别适配大语言模型。相较前代A100实现数量级性能飞跃，配备先进张量核心、Transformer引擎及HBM3/HBM3e高速显存，可通过NVLink交换系统组建大规模计算集群
* **NVIDIA GeForce RTX 4090**：艾达·洛夫莱斯架构的消费级旗舰游戏GPU。除了为游戏提供极致性能（支持光线追踪与DLSS 3的超高清画质），其底层架构与强大算力也使其成为需要本地GPU加速的创作者、AI开发者及研究人员的理想选择，配备24GB GDDR6X显存及海量CUDA核心、RT核心与张量核心

### 科技巨头的近年选择

科技巨头是NVIDIA高端数据中心GPU（特别是A100与H100）的主要需求驱动力。在竞相构建更复杂AI模型的过程中，NVIDIA GPU提供了不可或缺的计算支撑：

* **微软**：通过Azure云服务及自有AI研发（含大语言模型）大量采购NVIDIA GPU
* **谷歌**：在Google Cloud Platform及AI研究（如Gemini模型训练）中广泛使用NVIDIA GPU。尽管自研TPU芯片，仍深度依赖NVIDIA构建AI基础设施
* **亚马逊（AWS）**：作为重要客户，在云服务中部署NVIDIA GPU为各类客户提供AI与HPC服务
* **Meta**：重金投入NVIDIA GPU以推动AI战略，包括为旗下平台训练大语言模型
* **甲骨文**：积极采购NVIDIA高端GPU以增强云服务能力

这些企业常以数万张GPU规模构建AI超算集群，同时通过云服务向客户提供GPU算力租赁。

### 云平台解决方案

主流云服务商提供丰富的NVIDIA GPU即服务，帮助企业与研究者以按需付费模式获取强大算力：

* **亚马逊云科技（AWS）**：提供包括NVIDIA A100/H100（如p5实例）及A10等多代GPU方案
* **谷歌云平台（GCP）**：覆盖L4（适配生成式AI）、H100、A100、T4、V100等全系NVIDIA GPU，通常能快速部署最新硬件
* **微软Azure**：配备NVIDIA A100、H100及A10等GPU，支持各类机器学习与HPC工作负载
* **甲骨文云基础设施（OCI）**：持续增强H100等高端GPU服务能力
* **专业GPU云服务商**：CoreWeave、Lambda、Paperspace、DigitalOcean、E2E Cloud等专精于GPU加速计算，以灵活定价提供H100、A100及RTX A6000/RTX 6000 Ada等最新显卡

这些云平台通过弹性伸缩的计算资源，使高性能NVIDIA GPU能够惠及更广泛的用户群体。