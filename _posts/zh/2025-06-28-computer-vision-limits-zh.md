---
audio: false
generated: true
lang: zh
layout: post
title: 计算机视觉尚不及人类水平
translated: true
type: note
---

王垠的博客文章指出，即便是2019年的先进计算机视觉系统，也远未达到人类水平。文章认为这些系统在基础物体识别（如识别汽车）方面存在困难，且容易受到对抗样本或细微图像修改的干扰，而人类却能轻松识别物体。王垠提出该领域过度夸大进展，由于系统处理和理解图像的根本性局限，真正的人类级计算机视觉仍然难以实现。

### 事实果真如此吗？
截至2019年10月文章发表时，王垠的论点基于当时计算机视觉的发展状况是成立的：

- **泛化能力有限**：卷积神经网络等计算机视觉模型严重依赖训练数据中的模式匹配。正如王垠所述，它们往往难以泛化到新场景或妥善处理边缘案例。例如当光照、角度或背景发生显著变化时，模型可能错误分类物体。

- **对抗性攻击脆弱性**：关于经过细微修改就能误导模型的对抗样本，王垠的观点是准确的。Goodfellow等人（2014）的研究表明，微小且难以察觉的扰动就能导致模型以高置信度误判图像，这凸显了人类与机器视觉间的差距。

- **过度宣传质疑**：文章批评了计算机视觉领域的夸大宣传。2019年，虽然ResNet、YOLO及早期Transformer等模型在ImageNet等基准测试中表现亮眼，但这些均属受控数据集。自动驾驶、人脸识别等实际应用常暴露出系统缺陷。

但文章语气过于绝对，声称“根本不存在人类级别的计算机视觉”，这忽略了特定任务取得的进展：
- **专项任务成功**：截至2019年，在糖尿病视网膜病变检测等医疗影像分类任务中，计算机视觉系统已超越人类表现。
- **2019年后的进展**：到2025年，视觉Transformer、CLIP等视觉模型以及GPT-4o、DALL·E 3等多模态模型显著缩小了差距。这些模型能处理更复杂的输入，提升跨场景泛化能力，并通过语言-视觉融合增强推理能力。不过仍未能完全复现人类视觉的鲁棒性、情境意识和直觉理解。

### 关键评估
王垠的核心主张——2019年的计算机视觉未达人类水平——基本符合事实。当时的模型确实缺乏人类视觉的泛化能力、鲁棒性和直觉理解。但其对技术进步的否定可能过于悲观：
- **情境推理**：人类能轻松融合感官数据与世界知识，机器则难以实现
- **边缘案例**：面对罕见或全新场景时，模型容易失效而人类能快速适应
- **能效比**：人类视觉的能效远高于计算模型

这篇文章作为对AI能力过度宣传的批判至今仍具参考价值，但未充分考量该领域的飞速发展。截至2025年，虽无单一信源确认已实现“人类级”视觉，但两者间的差距已显著缩小。[](https://yinwang0.wordpress.com/2019/10/20/human-level-computer-vision/)