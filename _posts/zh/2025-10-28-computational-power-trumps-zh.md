---
audio: false
generated: true
image: false
lang: zh
layout: post
model: x-ai/grok-4-fast
title: 算力碾压人类智慧
translated: true
type: note
---

### 理查德·萨顿的《苦涩的教训》

人工智能先驱研究者理查德·萨顿以其在强化学习领域的贡献闻名，他在2019年撰写了一篇题为《苦涩的教训》的短文。这篇文章回顾了70多年的人工智能发展史，指出最有效的人工智能发展路径并非那些模仿人类智能或注入专业知识的方案。相反，这个"苦涩"的真相是：**长期来看，那些依赖原始计算能力扩展的通用方法——比如搜索算法和机器学习——始终优于那些精巧的、受人类启发的设计**。

#### 核心观点
萨顿观察到一个反复出现的模式：早期人工智能的成功往往源于将人类专业知识（如规则、启发式方法或领域特定知识）注入系统。这种方式起初显得直观高效，但随着计算成本降低和算力增长，这些依赖知识的方案就会遭遇瓶颈。它们变得脆弱难以扩展，最终被那些让计算机通过试错暴力求解的简单"元方法"所超越。

"苦涩"之处何在？人类厌恶这个教训，因为它边缘化了我们的创造力和直觉。我们更愿意构建"像我们一样思考"的系统，但证据表明这对重大进展而言是条死胡同。萨顿总结道："这个苦涩的教训基于我们观察到的现实——最强大的方法...正是那些充分利用计算能力的方法。"

#### 历史例证
萨顿援引人工智能发展史上的里程碑事件：
- **国际象棋**：1990年代，基于专业知识的程序（包含开局库、战术和策略）由人类专家主导。但深蓝（1997）通过大规模搜索树和强大算力击败卡斯帕罗夫，摒弃了那些"智慧"。
- **围棋**：类似的故事——AlphaGo（2016）通过自我对弈和神经网络学习，而非深入研究职业棋谱。它依托算力实现突破，击败了基于直觉的对手。
- **语音识别**：手工构建的语言模型曾占据主导，直到2010年代统计学习方法（利用数据和算力）实现超越，催生了如今的语音助手。
- **计算机视觉**：早期系统依赖边缘检测和形状规则；如今深度学习通过GPU直接处理海量像素数据。

每个案例中，知识导向的方法赢得了短期胜利，却最终败给了渴求算力的通用方法。

#### 现实意义
这个教训推动人工智能走向"可扩展监督"——构建能够从海量数据中自主学习，无需人类灌输每个洞察的系统。这正是为何当今突破（如大语言模型）来自互联网规模的数据训练而非规则手册。但它的"苦涩"在于暗示我们需要更多算力（和能源）来持续进步，同时弱化了打造"优雅"解决方案的价值。

萨顿撰写此文作为警示：不要逆势而行，拥抱这个趋势才能加速进步。

#### 参考文献
- [《苦涩的教训》（原文）](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
- [苦涩的教训（维基百科摘要）](https://en.wikipedia.org/wiki/Bitter_lesson)
- [Reddit上的通俗解释](https://www.reddit.com/r/explainlikeimfive/comments/1nug43e/eli5_what_is_richard_suttons_bitter_lesson_in_ai/)