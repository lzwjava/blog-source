---
audio: false
generated: true
image: false
lang: zh
layout: post
model: x-ai/grok-4-fast
title: 优化多服务等级目标的大语言模型服务
translated: true
type: note
---

### 概述
论文《SLOs-Serve：多服务等级目标大语言模型的优化服务》介绍了SLOs-Serve系统，该系统专为多阶段应用场景中的大语言模型服务优化设计。在这些场景中，每个处理阶段（如输入处理的预填充阶段、令牌生成的解码阶段）和具体应用（如聊天机器人、编程助手）都有特定的服务等级目标。这些SLOs能确保面向用户环节的低延迟，例如预填充阶段的首令牌响应时间和解码阶段的令牌输出间隔时间。传统服务系统（如vLLM或Sarathi-Serve）以吞吐量为优先考量，但在共享资源环境下（特别是在突发流量或混合工作负载时）经常违反这些细粒度SLOs。

### 核心挑战与创新贡献
作者指出了多SLO服务中的关键挑战：
- **多阶段请求**：推理类LLM（"思考"阶段需严格SLOs）或工具调用智能体（包含严格预填充/解码的循环流程）需要阶段级保障
- **资源竞争**：共享GPU资源在协同部署或分离式架构中易导致SLO违规
- **突发流量**：流量骤增会击穿调度系统防线

SLOs-Serve的核心创新包括：
- 基于动态规划的调度器，通过优化令牌分配（预填充预算、批处理大小）在满足SLOs的同时最大化吞吐量
- 支持分块预填充、SLO自适应推测解码（按SLO层级定制推测长度）和软性准入控制（保障已接纳请求的SLOs，延迟处理其他请求）
- 基于vLLM批处理引擎和Ray编排框架的分布式架构，具备多副本路由和突发流量抵御能力

| 应用场景     | 预填充SLO要求 | 解码SLO要求     | 典型示例         |
|--------------|---------------|-----------------|------------------|
| 文本摘要     | 严格（3倍延迟上限） | 宽松（100ms TPOT） | 文档处理         |
| 代码生成     | 宽松          | 严格（50ms TPOT）  | 编程辅助         |
| 聊天机器人   | 宽松          | 宽松            | 交互式问答       |
| 工具调用     | 严格（循环中） | 严格（循环中）/宽松（最终输出） | 智能体工作流   |
| 逻辑推理     | 严格（思考阶段） | 严格（思考阶段）/宽松（响应阶段） | 思维链推理     |

### 系统设计
- **调度器（算法1）**：采用动态规划进行请求准入与批处理规划，通过受Roofline模型启发的预测器（预测精度R²>0.8）建模执行时间。状态机跟踪内存、预填充预算和已接纳请求，状态转移优先处理紧急截止时间和SLO达标需求
- **批处理构建**：基于最严格TPOT动态调整批处理规模（最高支持512+令牌），在避免SLO违规的前提下实现高吞吐量
- **推测解码**：按SLO层级自适应调整推测长度（1-10个令牌）以提升预填充预算，通过枚举求解实现预填充与解码的最优平衡
- **多副本与突发处理**：集中式控制器主动路由请求，不可达请求转入尽力而为队列，必要时实施抢占机制

该设计深入探索了系统权衡，例如扩大批处理规模可提升吞吐量但会增加延迟风险（通过SLO可行区域可视化图表呈现）

### 性能评估
在6类场景（聊天机器人、代码生成、文本摘要、混合负载、工具调用、逻辑推理）中采用真实流量轨迹（Azure LLM工作负载）和数据集（ShareGPT、HumanEval等）进行测试。模型选用OPT-7B/13B/30B、ToolLlama-7B，硬件配置以4×A100为主，最高扩展至8×H100

- **容量提升**：相较vLLM/Sarathi-Serve/DistServe实现2.2倍平均提升（跨场景几何平均），其中推理场景达2.4倍，突发代码生成场景达2.1倍
- **扩展能力**：通过路由机制实现副本级超线性扩展（工具调用场景突发流量下最高达6.2倍）
- **消融实验**：推测解码贡献1.66倍增益，路由机制贡献1.19倍，突发处理贡献1.34倍
- **系统开销**：单次调度耗时低于10毫秒

实验图表显示，在流量峰值期间SLOs-Serve能保持p99延迟接近目标值，而基线系统性能明显劣化

### 结论
SLOs-Serve通过保障多样化突发环境中的多SLOs，将服务效率提升2倍以上，推动LLM服务技术发展。未来工作可延伸至未知解码长度或更多阶段场景。该系统证明基于SLO的定制化调度是实现生产级LLM部署的关键。

[SLOs-Serve：多服务等级目标大语言模型的优化服务](https://arxiv.org/abs/2504.08784)