---
audio: false
generated: true
image: false
lang: zh
layout: post
model: x-ai/grok-4-fast
title: 高效大语言模型的4位量化技术
translated: true
type: note
---

### 什么是4位量化（在QLoRA或GPTQ语境下）？

4位量化是一种通过仅使用4比特存储每个权重（而非通常的16位FP16/BF16或32位FP32精度）来大幅减少大语言模型内存占用的技术。

常规（全精度）模型：
- FP32：每个参数4字节 → 70亿参数模型 ≈ 28 GB
- FP16/BF16：每个参数2字节 → 70亿参数模型 ≈ 14 GB

4位量化：
- 每个参数约0.5字节 → 70亿参数模型 ≈ 3.5–4 GB（根据具体方法不同，约为原始大小的1/4至1/8）

目前常见的两种主流4位量化方法：

| 方法    | 全称                       | 主要论文/年份     | 典型应用场景                     | 核心特性                                                                             |
|---------|----------------------------|-------------------|----------------------------------|-------------------------------------------------------------------------------------|
| GPTQ    | GPTQ                       | 2023              | 训练后量化（仅推理）             | 一次性量化，精度极高，无需重新训练。在训练后将权重舍入至4位。                         |
| QLoRA   | 量化低秩适配                 | 2023年6月         | 高效微调/指令调优                | 结合4位存储+LoRA适配器+分页优化器。支持在单张24-48GB GPU上微调650亿+参数模型。        |

#### 深入解析QLoRA（通常人们所说的“4位QLoRA”）
QLoRA同步实现了四项创新：

1. 4位正态浮点（NF4）量化  
   - 专为服从正态分布的权重优化的特殊4位数据类型（多数LLM权重训练后近似高斯分布）
   - 优于普通INT4；对正态分布数据具有理论最优性

2. 双重量化  
   - 将量化常数（缩放因子）从FP16进一步量化为8位，额外节省数MB内存

3. 分页优化器  
   - 优化器状态（AdamW动量值）存储于CPU内存，通过NVIDIA统一内存分页传输至GPU，防止训练过程中的内存溢出

4. LoRA适配器  
   - 仅训练小型低秩矩阵（秩≤64），基础4位模型保持冻结状态

成果：使用QLoRA可在单张48GB RTX A6000上完整微调650亿参数Llama/Mistral模型，甚至可在单张80GB A100上微调700亿参数模型，而传统全参数微调需要8张以上A100显卡。

#### GPTQ（专注推理的量化方法）
- 在训练完成后执行
- 利用二阶（海森矩阵）信息最小化权重压缩至4位时的舍入误差
- 精度极高——相比FP16通常 perplexity 损失小于0.1
- 已集成于AutoGPTQ、ExLlama、vLLM和llama.cpp等工具（GGUF格式也支持GPTQ模式）

### 梯度检查点（又称“激活检查点”）

一种在训练过程中使用的独立内存优化技术。

工作原理：
- 正常情况下，反向传播需要存储前向传播的所有中间激活值 → 内存消耗随模型深度/批次大小/序列长度线性增长
- 梯度检查点通过牺牲计算资源换取内存空间：
  - 前向传播时仅保存部分“检查点”激活值
  - 反向传播时实时重新计算缺失的激活值

典型内存节省：激活内存的50–80%，代价是训练速度降低约20–30%

该技术常与QLoRA或任何大模型微调结合使用，因为即使采用4位权重，激活值仍会耗尽GPU内存。

### 核心要点总结

“4位量化（QLoRA风格或GPTQ）+ 梯度检查点”是现代大模型运行的黄金组合，助力实现：

- 在消费级或单张企业级GPU上运行或微调巨型模型（330亿/700亿/4050亿参数）
- QLoRA风格4位量化 → 极低GPU内存下的微调
- GPTQ风格4位量化 → 极低GPU内存下的高速推理
- 梯度检查点 → 支持长序列反向传播而不内存溢出

正是这些技术的结合，使得如今在单张RTX 3090/4090上微调Llama-3-700亿参数模型成为可能。