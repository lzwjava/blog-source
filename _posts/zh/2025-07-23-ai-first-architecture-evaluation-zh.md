---
audio: false
generated: true
lang: zh
layout: post
title: 现代开发的AI优先架构
translated: true
type: note
---

这篇文章是在 Grok 的协助下完成的，但观点均为原创。

---

### 对您观点的评估

我将逐一分析您的观点，结合当前软件工程趋势、AI/LLM集成（例如 GitHub Copilot、Cursor 或自定义 LLM 代理等工具）以及实际应用进行评估。您触及了一个关键洞察：随着 AI 成为开发工作流程中不可或缺的一部分，架构设计必须在以人为本的同时，优先考虑对 AI 的友好性。然而，并非所有想法都普遍适用——具体情境很重要，需要在简洁性和可扩展性之间取得平衡。我将概述赞同、反对之处以及关键细节。

#### 1. 传统银行架构有其优点，但新项目应优先考虑 AI/LLM 优化：聚焦于上下文工程、清晰分离和 AI 优先设计
理论上您的观点是正确的。传统架构（例如银行业中假设提及的单体或分层企业系统）在可靠性、安全性和人工可维护性方面表现出色。然而，随着 AI/LLM 代理驱动代码生成、调试和重构，“AI 优先”的思维方式越来越重要。这涉及为 LLM 的约束条件（例如 GPT-4o 中 128k token 的有限上下文窗口）进行设计，通过模块化代码确保关键细节能适配这些边界。

- **优势**：清晰的关注点分离（例如，不同的数据流、提示或 API 边界）使 AI 能够更有效地进行推理。例如，像 LangChain 或自定义代理这样的 AI 工具在处理定义明确、隔离的上下文时表现更佳，而非纠缠不清的逻辑。
- **细节**：以人为本的设计仍然至关重要——在金融等复杂领域，监管合规性和安全性至关重要，AI 仍然需要人工监督。混合模式可能是最优选择：对重复性任务进行 AI 优化，对关键逻辑进行人工优化。
- **总体评价**：基本同意；这一趋势在 AI 驱动的微服务和无服务器架构中显而易见。

#### 2. Spring 提供了强大的抽象，但对 AI/LLM 的理解构成了挑战
您这一点说得很对。Spring（以及类似的 Java 框架，如 Micronaut）非常适合具有依赖注入、AOP 和分层抽象（例如，控制器 -> 服务 -> 仓库）功能的企业环境。虽然这些对于人工管理的大型团队来说非常出色，但由于间接性和样板代码，它们可能会让 LLM 不堪重负。

- **优势**：LLM 通常难以处理深度调用栈或隐式行为（例如 @Autowired 注解），导致产生幻觉或不完整的分析。关于 AI 代码生成的研究表明，在过度抽象的代码库中错误率更高。
- **细节**：并非所有抽象都是有害的——例如，接口增强了可测试性，间接帮助了 AI 完成诸如模拟生成等任务。然而，过多的层级会膨胀上下文，使 LLM 的逻辑跟踪复杂化。
- **总体评价**：非常同意；正在向更轻量级的框架（例如 Quarkus）或最小化框架方法转变，以提高 AI 兼容性。

#### 3. 倾向于扁平化结构，类似于扁平化组织：限制在 2 个层级，第一级调用第二级，避免具有 50 个层级的深度堆栈
这是一个引人注目的简化思路，但并非普遍理想。扁平化结构（例如，一个顶层编排器调用多个小函数）减少了嵌套，有助于 LLM 避免在复杂调用栈上出现推理错误。这类似于 Python 脚本中常见的简单函数链式调用。

- **优势**：扁平化代码降低了 AI 的认知负荷——LLM 在线性或并行推理方面比在深度递归上表现更好。“扁平化组织”的类比成立：就像初创公司一样，扁平化代码更易于 AI 修改适应。
- **细节**：从单一点调用大量函数，如果没有规范的组织（例如清晰的命名或模块化），可能会产生“意大利面条式”代码。在大型系统中，最少层级的层次结构（3-4 层）可以防止混乱。虽然像 Devin 这样的 AI 代理能很好地处理扁平结构，但如果没有适当的编排，可能会出现性能问题。
- **总体评价**：部分同意；在可行的情况下，扁平化是有益的，但必须测试其可扩展性。这与 AI 驱动开发中的函数式编程趋势一致。

#### 4. AI/LLM 难以处理复杂的嵌套结构，擅长处理小函数（100-200 行）；Python 的调用和导入系统支持这一点
关于 LLM 的能力，您说得非常准确。当前的模型（例如 Claude 3.5, GPT-4）擅长处理集中的、自包含的任务，但在复杂性面前表现不佳——由于 token 限制和注意力分散，在超过约 500 行上下文后错误率会上升。

- **优势**：小函数（100-200 行）对 AI 来说是最优的：易于提示、生成或重构。Python 的导入系统（例如 `from module import func`）促进了模块化，使其比 Java 以类为中心的结构更 AI 友好。
- **细节**：虽然 LLM 在不断进步（例如通过思维链提示），但嵌套逻辑仍然是一个挑战。Python 的灵活性有所帮助，但静态类型（例如 TypeScript）也可以通过提供明确的线索来辅助 AI。
- **总体评价**：非常同意；这解释了为什么 ML/AI 生态系统（例如 Hugging Face 库）通常采用 Python 的模块化风格。

#### 5. 将 Java 大文件拆分为更多函数的更小文件，以便于测试/验证；Java 项目应效仿 Python 的结构
这是一个实用的方向。庞大、单体的 Java 类（例如 1000+ 行）对人类和 AI 都具有挑战性，而拆分成更小的文件/函数可以提高粒度。

- **优势**：更小的单元简化了单元测试（例如使用 JUnit）和验证（AI 可以一次专注于一个函数），反映了 Python 的“每个功能一个模块”的方法。像 Maven/Gradle 这样的构建工具可以无缝适应这一点。
- **细节**：Java 的包系统已经支持这一点，但需要从 OOP 单体结构进行文化转变。并非所有 Java 项目都应该模仿 Python——性能关键型应用程序可能受益于一定程度的整合。
- **总体评价**：同意；现代 Java（例如在 Java 21+ 中使用记录类和密封类）正朝着这个方向发展。

#### 6. 在 AI/LLM 时代，过程式编程可能超越 OOP
这是一个大胆但在特定情境下有效的观点。过程式（或函数式）方法强调直接的流程和纯函数，这与 LLM 的优势相符——生成线性代码比处理 OOP 的状态、继承和多态更简单。

- **优势**：像深度继承这样的 OOP 抽象常常混淆 LLM，导致生成的代码出错。过程式代码更具可预测性，适合 AI 的模式匹配特性。像 Rust（具有过程式特质）和 Go（强调简单性）这样的语言反映了这一趋势。
- **细节**：OOP 并未过时——它在建模复杂领域（例如金融实体）方面仍然有效。混合方法（过程式核心加上 OOP 包装器）可能是理想的。通过定制的提示，LLM 可以管理 OOP，但过程式减少了摩擦。
- **总体评价**：部分同意；过程式/函数式风格在 AI 工作流程中越来越受欢迎，但 OOP 在大型系统的长期可维护性方面仍具有价值。

#### 7. 像 VSCode 或 IntelliJ IDEA 这样的 IDE 应该提供用于 AI 辅助函数/方法编辑的快捷方式
您说得对，这将简化工作流程。虽然当前的 IDE 提供了部分支持（例如 VSCode 的“转到定义”或 Copilot 的内联建议），但专用的 AI 编辑快捷方式正变得越来越普遍。

- **优势**：选择一个函数/方法并提示 AI（例如“重构这个”）将提高效率。像 Cursor（基于 VSCode 构建）这样的工具已经支持针对特定区域的 AI 编辑。
- **细节**：IntelliJ IDEA 提供了“提取方法”和 AI 助手（通过 JetBrains AI），而 VSCode 扩展如 GitHub Copilot Chat 支持基于选择的查询。尽管如此，原生的“AI 编辑此函数”快捷方式将是一个有价值的补充——很可能在未来的更新中出现。
- **总体评价**：同意；这符合 AI 优先工具日益增长的趋势。

### 总结
您的见解大体上是准确的：采用 AI 优化的架构（扁平化、模块化、小单元）解决了 LLM 的实际局限性，并能加速开发。然而，极端做法，如完全过程式或过度扁平化的设计，可能会损害长期可维护性——平衡至关重要。在金融等领域，安全性和合规性可能需要某些抽象。您的观点与 AI 辅助编码中新兴的最佳实践相一致，即简洁性对人类和机器都有利。

如果您有具体的代码示例或想探索 AI 优先的重新设计，请随时提问！