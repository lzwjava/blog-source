---
audio: false
generated: true
image: false
lang: zh
layout: post
title: 安全LLM API验证层
translated: true
type: note
---

当你构建或使用 **LLM API** 时，通常需要设置防护措施来确保响应是安全、有效且有用的。以下是添加检查的主要方式：

---

### 1. **输入验证**

* **模式检查**：在发送给 LLM 前，确保请求 JSON 符合预期模式
* **提示词净化**：剥离或转义非常规字符、恶意指令或注入攻击内容
* **长度检查**：强制实施最大令牌数/字符数限制，避免不必要成本或被截断

---

### 2. **输出验证**

* **JSON模式验证**：若 LLM 需返回 JSON，通过 `json.loads()` 解析并用模式验证（如使用 `pydantic`、`jsonschema`）
* **正则/格式检查**：对邮箱、URL或数字等数据实施格式匹配
* **类型检查**：验证字段类型是否正确（字符串、整型、列表等）
* **范围检查**：确保数值或日期在预期范围内

---

### 3. **安全与内容检查**

* **毒性/违禁词过滤**：通过分类器处理输出（如 Perspective API、OpenAI 审核接口）
* **策略过滤器**：设定规则拦截含特定关键词或类别的回复
* **幻觉检测**：添加事实核查步骤（通过检索增强检查、多模型交叉验证或基于规则的合理性检查）

---

### 4. **业务逻辑约束**

* **一致性规则**：若响应需匹配系统数据（如可用账户余额、配置值），返回用户前进行交叉验证
* **防护栏**：使用 **Guardrails AI**、**LMQL** 或 **Instructor** 等库声明式强化结构化输出与约束
* **后处理钩子**：用自定义逻辑包装LLM响应（规范化大小写、强制默认值、拒绝意外答案）

---

### 5. **冗余与交叉验证**

* **自检提示**：要求LLM重新验证或解释自身答案
* **双模型校验**：使用更轻量/更快的LLM验证主模型输出（如“该响应是否符合X模式？”）
* **投票/共识机制**：运行多次调用并比对答案稳定性

---

### 6. **运行防护**

* **频率限制**：防止API滥用
* **超时控制**：中止挂起的请求
* **日志与审计追踪**：记录请求与被过滤的响应
* **降级方案**：验证失败时，可调整提示词重试或返回安全默认值/错误

---

👉 实践中，优秀的LLM API架构会分层实施：

1. 验证输入
2. 调用LLM
3. 根据模式和业务规则验证输出
4. 运行安全/内容过滤器
5. 仅当检查通过时返回（否则重试/启用降级方案）

---

需要为您展示**Python示例**吗？我们将通过JSON模式验证和内容审核检查来封装LLM API调用。