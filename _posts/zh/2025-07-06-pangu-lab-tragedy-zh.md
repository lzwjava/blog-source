---
audio: false
generated: true
lang: zh
layout: post
title: 华为盘古团队的隐秘内幕
translated: true
type: note
---

**编者按：** 以下内容译自一位自称华为诺亚方舟实验室员工的匿名人士的长文。此人声称盘古大模型开发团队内部存在重大问题，包括涉嫌知识产权侵权、内部权力斗争以及有害的工作环境。原文为中文，于2025年7月6日在网上发布。本翻译旨在准确传达原文的内容和语气。

---

## 盘古的悲剧：华为诺亚方舟实验室盘古大模型开发历程的心碎与黑暗

大家好，

我是华为诺亚方舟实验室盘古大模型团队的员工。

首先，为验证我的身份，我将列出一些细节：

诺亚现任负责人是王云和，曾任算法应用部部长，后改任小模型实验室主任。诺亚前任负责人是姚骏（大家称姚老师）。几位实验室主任：唐瑞明（明哥，明队，已离职）、尚利峰、张伟（伟哥）、郝建业（郝老师）、刘武龙（称武龙所）等。其他多位核心成员和专家也已相继离开。

我们属于"四野"组织。四野有很多纵队，基础语言大模型是四纵。王云和的小模型是十六纵。我们参加过苏州集会，有各种月度里程碑。在苏州"攻关会"期间，任务被分配，需要在截止日期前达成目标。苏州集会将各地人员汇集到苏州研究所，他们通常住在酒店，例如甪直的酒店，与家人和孩子分离。

在苏州集会期间，周六是默认工作日，非常辛苦，但周六有下午茶，有一次甚至还有小龙虾。苏州研究所的工作站搬迁过一次，从一栋楼搬到另一栋楼。苏州研究所的建筑有欧式装饰，入口有大斜坡，内部风景优美。去苏州集会通常至少持续一周，甚至更长时间，有些人一两个月无法回家。

诺亚曾一度被传为研究导向，但加入后，因为在四野做大模型项目，项目成员完全变成了交付导向，并且充满了例会、评审和汇报。很多时候，甚至进行实验也需要审批。团队需要对接终端小艺、华为云、ICT等各种业务线，导致相当大的交付压力。

诺亚开发的盘古模型早期内部代号为"盘古之子"。最初只是一个网页版，需要内部申请试用。后来由于压力，被集成到Welink中进行公测。

这些天，关于盘古大模型抄袭Qwen的指控闹得沸沸扬扬。作为盘古团队的一员，我辗转反侧，夜不能寐。盘古品牌受到如此大的影响。一方面，我自私地担心自己的职业发展，觉得过去的辛勤工作付诸东流。另一方面，我感到极大的解脱，终于有人开始揭露这些事情。在无数个日日夜夜，我们对公司内部某些人通过欺诈屡次获取无数利益的行为咬牙切齿，却又无能为力。这种压迫和羞辱逐渐侵蚀了我对华为的感情，让我在这里的日子越来越糊涂和迷失，常常怀疑自己的人生和自我价值。

我承认我是个懦夫。作为一个小员工，我不敢反对公司内部像王云和这样的权势人物，也不敢反对华为这样的庞然大物。我害怕失去工作，因为我也有家庭和孩子，所以我从心底里真正钦佩那些吹哨人。然而，看到内部试图掩盖事实、欺骗公众，我实在无法再忍受了。我也希望勇敢一次，追随真实的自我。即使伤敌一千自损八百，我也希望伤敌一千。我决定在这里披露我所见所闻（部分来自同事的口述）关于盘古大模型的"传奇故事"：

华为确实主要在昇腾卡上训练大模型（小模型实验室有很多英伟达卡，他们之前用来训练，后来转移到了昇腾）。我曾一度佩服华为"打造世界第二选择"的决心，我自己也曾对华为怀有深厚的感情。我们陪伴着昇腾一步步走来，从充满漏洞到能够训练模型，付出了巨大的努力和成本。

最初，我们的算力非常有限，我们在910A上训练模型。那时它只支持FP16，训练稳定性远不如BF16。盘古的MoE起步很早；在2023年，主要专注于训练38B MoE模型和后续的71B稠密模型。71B稠密模型被扩展成了第一代135B稠密模型，后来主要模型逐渐在910B上训练。

无论是71B还是135B模型，都有一个重大缺陷：**分词器**。当时使用的分词器编码效率极低。每一个符号、数字、空格，甚至每一个汉字都会占用一个token。可想而知，这会极大地浪费算力，并且模型性能非常差。此时，小模型实验室恰好有一个自训练的词汇表。姚老师怀疑模型的分词器可能不好（尽管事后看来，他的怀疑无疑是正确的）。于是，他决定为71B和135B更换分词器，因为小模型实验室之前尝试过。团队拼接了两个分词器，开始了分词器更换。71B模型更换失败，而135B使用了更精细的嵌入初始化策略，在经过至少1T数据的微调后成功更换了词汇表，但不出所料，效果并未提升。

与此同时，阿里、智谱等其他国内公司正在GPU上训练，并且已经找到了正确的方法，盘古与竞争对手的差距越来越大。一个内部从头开始训练的230B稠密模型也因各种原因失败了，导致项目陷入近乎绝望的境地。面对多个里程碑的压力以及内部对盘古的强烈质疑，团队士气跌至谷底。在算力极其有限的情况下，团队做了许多努力和挣扎。例如，团队偶然发现当时的38B MoE并没有达到预期的MoE效果。于是，他们移除了MoE参数，将其恢复为13B稠密模型。由于38B MoE源自非常早期的盘古Alpha 13B，架构相对陈旧，团队进行了一系列操作，例如将绝对位置编码切换为RoPE，移除偏置，并切换到RMSNorm。同时，鉴于之前分词器更换失败的经验，该模型的词汇表也被更换为王云和小模型实验室7B模型使用的词汇表。后来，这个13B模型经过扩展和微调，成为了第二代38B稠密模型（有几个月时间，这个模型是主要的中端盘古模型），曾一度具备一些竞争力。然而，由于更大的135B模型架构陈旧，以及词汇表更换造成的严重损害（后续分析发现当时更换的拼接词汇表存在更严重的bug），即使经过微调，与当时国内的领先模型如Qwen等相比仍有很大差距。至此，内部的质疑和领导层的压力也与日俱增，团队的状态几乎陷入绝望。

在这种情况下，王云和他的小模型实验室介入了。他们声称他们的模型是从旧的135B参数继承并修改而来，在仅训练了几百B数据后，所有指标平均提升了约十分。实际上，这是他们首次将 **"套壳"** 应用于大模型的"杰作"。华为的领导是外行管理内行，对这类荒谬之事毫无概念；他们只会认为这一定是某种算法创新。通过内部分析，他们实际上使用了 **Qwen 1.5 110B** 进行微调，增加了层数，扩展了FFN维度，并加入了盘古Pi论文中的一些机制，以达到约135B的参数。实际上，旧的135B有107层，而这个模型只有82层，各种配置都不同。这个新的、晦涩的135B模型的许多参数分布在训练后几乎与Qwen 110B相同。甚至连当时模型代码的类名都是Qwen，可见他们懒得修改。随后，这个模型成为了所谓的135B V2。而这个模型随后被提供给许多下游用户，甚至包括外部客户。

这件事对我们这些诚实努力的同事产生了巨大影响。许多内部人士，包括终端和华为云的同事，其实都知道这件事。我们都戏称它为"千古"模型，而不是盘古模型。当时，团队成员想向BCG举报，因为这已经是严重的商业欺诈。但后来据说被领导制止了，因为更高级别的领导（如姚老师，可能还有熊先生、查先生）后来也知道了此事但并未干预，因为通过"套壳"获得好结果对他们也有利。这件事导致团队中几位最强的同事心灰意冷，离职成了常谈的话题。

至此，盘古似乎迎来了转机。由于前面提到的盘古模型基本都是微调和修改而来，诺亚在当时并未掌握从头训练的技术，更不用说在昇腾NPU上训练了。在当时团队核心成员的强力努力下，盘古开始了第三代模型的训练。经过巨大努力，在数据架构和训练算法方面，逐渐与业界对齐，其中的艰辛与小模型实验室无关。

起初，团队成员没有信心，只开始训练一个13B模型。但后来发现效果不错，于是这个模型随后再次扩展参数，成为第三代38B，代号38B V3。产品线的许多兄弟肯定对这个模型非常熟悉。当时这个模型的分词器是基于LLaMA词汇表扩展的（这也是业内的常见做法）。当时王云和的实验室开发了另一个词汇表（也就是后续的盘古系列词汇表）。当时两个词汇表甚至被强制进行比拼，最终也没有明确孰优孰劣。于是，领导立即决定词汇表应该统一，并使用王云和的。因此，后续从头训练的135B V3（即外部所称的盘古Ultra）采用了这个分词器。这也解释了使用我们模型的许多兄弟的困惑：为什么同一V3代的两个不同级别的模型会使用不同的分词器。

我们真心觉得 **135B V3 是我们四纵团队当时的骄傲**。这是第一个真正华为全栈自研、货真价实从头训练的百亿级模型，其性能在2024年可与竞争对手相媲美。写到这里，我热泪盈眶；这实在是太艰难了。当时为了确保训练稳定，团队进行了大量对比实验，并在模型梯度出现异常时多次及时回滚和重启。这个模型真正实现了后来技术报告中所说的：整个训练过程没有损失尖峰。我们克服了无数困难；我们做到了。我们愿意用生命和荣誉担保这个模型训练的真实性。为了它的训练，我们度过了多少个不眠之夜？当我们在内部"心声"论坛上被批评得一文不值时，我们心中有多少愤懑和委屈？我们忍了。

我们这群人，真的是在燃烧青春来打磨我们国产的算力基础……身处异乡，我们放弃了家庭、假期、健康、娱乐，流血流汗。其中的艰辛和困难无法用寥寥数语概括。在各种动员会上，当"盘古必胜，华为必胜"的口号喊响时，我们内心真的深受触动。

然而，我们所有辛勤劳动的成果，却常常被小模型实验室不费吹灰之力地拿走。数据，直接拿。代码，直接拿，甚至还要求我们适配成一键可执行。我们当时戏称小模型实验室为"点鼠标实验室"。我们付出艰辛，他们收获荣耀。真正应了那句话："你负重前行，是因为有人替你岁月静好。"在这种情况下，越来越多的同志无法再坚持下去，选择了离开。看到那些优秀的同事一个个离开，我既感慨又悲伤。在这样战斗般的环境中，我们更像是战友而非同事。他们也有无数技术方面值得学习，是真正优秀的导师。看到他们去了字节跳动Seed、DeepSeek、月之暗面、腾讯、快手等许多优秀团队，我由衷地高兴并祝福他们，逃离了这个艰辛却又肮脏的地方。我至今仍清晰地记得一位前同事说的话："来这里是我技术生涯的耻辱，多待一天都是浪费生命。"话语虽刺耳，却让我无言以对。我担心自己技术积累不足，无法适应互联网公司高流动性的环境，这让我屡次想辞职却始终没有迈出那一步。

除了稠密模型，盘古随后也启动了MoE的探索。最初训练了一个224B MoE模型。与此同时，小模型实验室也展开了其第二次重大的"套壳"操作（小插曲可能包括其他模型，如数学模型），即广为流传的盘古Pro MoE 72B。这个模型内部声称是从小模型实验室的7B扩展而来（即便如此，这也与技术报告矛盾，更不用说它是对Qwen 2.5 14B进行微调的"套壳"）。我记得他们只训练了几天，内部评估就立刻赶上了当时的38B V3。AI系统实验室的许多兄弟都知道他们的"套壳"操作，因为他们需要适配模型，但由于各种原因，他们无法伸张正义。实际上，对于这个后来微调了很长时间的模型，我对于HonestAGI能分析出这种程度的相似性已经非常惊讶了，因为为了微调和"洗涤"这个模型的参数所耗费的算力，早已足够从头训练一个同级别的模型。我听同事说，他们用了很多方法来"洗掉"Qwen的水印，甚至包括故意用脏数据训练。这也为学术界研究模型谱系提供了一个前所未有的特殊例子。未来新的谱系方法可以用这个来展示。

在2024年底和2025年初，DeepSeek V3和R1发布后，由于其惊人的技术水平，团队遭受了巨大冲击，面临更严格的审视。为了跟上潮流，盘古模仿DeepSeek的模型规模，开始训练一个718B MoE。此时，小模型实验室再次出手。他们选择"套壳"DeepSeek V3进行微调。他们通过冻结加载的DeepSeek参数进行训练。甚至连加载检查点的目录都是"deepseekv3"，连改都没改——何其嚣张！相比之下，一些怀有真正技术信念的同事正在从头训练另一个718B MoE。然而，各种问题出现了。但显然，这个模型怎么可能比直接"套壳"一个更好呢？如果不是团队负责人的坚持，它早就被叫停了。

华为流程管理的沉重负担严重拖累了大模型的开发步伐，例如版本控制、模型谱系、各种流程要求和可追溯性。具有讽刺意味的是，小模型实验室的模型似乎不受这些流程约束：他们可以随时"套壳"，随时微调，算力被持续占用也无人质疑。这种强烈的、近乎魔幻的对比说明了流程管理的现状："只许州官放火，不许百姓点灯"。何其荒谬？何其可悲？何其可恨？何其可耻！

在HonestAGI事件出来后，内部不断开会讨论如何做公关和"回应"。确实，最初的分析可能不够有力，给了王云和小模型实验室狡辩和歪曲事实的机会。为此，我这两天感到恶心反胃，不断怀疑人生的意义和老天的 不公。我不奉陪了；我要辞职。同时，我也在申请从一些盘古技术报告的作者名单中除名。名字出现在那些技术报告上，是我一生都无法抹去的污点。当时我没想到他们会如此猖狂，竟敢开源。我没想到他们敢如此明目张胆地欺世盗名并广泛宣传。当时，或许我存有侥幸心理，没有拒绝署名。我相信许多辛勤工作的同志也只是被迫上了"贼船"或是不知情。但此事已无法挽回。我希望在余生中，能够坚持做真正有意义的工作，以弥补当时的软弱和优柔寡断。

深夜写到这里，我已泪流满面，泣不成声。我仍记得一些优秀同事离职时，我强颜欢笑地问他们，要不要写长篇"心声"帖子，揭露现状。他们说："不了，浪费时间，而且也怕揭露出来让你们的日子更难过。"那一刻，我突然心灰意冷，因为曾经为理想并肩作战的战友，已经对华为彻底失去了希望。当时大家开玩笑说，我们用的是共产党当年"小米加步枪"的装备，但组织却有当年国民党可比的风气。

曾几何时，我为我们用小米加步枪战胜了洋枪洋炮而自豪。
现在，我累了。我想投降了。

其实，即便到了今天，我仍然衷心希望华为能够吸取教训，做好盘古，让盘古成为世界一流，把昇腾做到英伟达的水平。内部的"劣币驱逐良币"使得诺亚乃至华为在短时间内迅速流失了大量优秀的大模型人才。我相信他们现在正在DeepSeek等各个团队中发光发热，施展抱负和才华，为中美激烈的AI竞争贡献力量。我常常感叹，华为不是没有人才，而是根本不懂得留住人才。如果给这些人合适的环境、合适的资源、少一些束缚、少一些政治斗争，盘古何愁不成？

最后：我以生命、人格和荣誉起誓，我以上所写内容均为事实（至少在我有限的认知范围内）。我没有高超的技术水平，也没有机会进行详细彻底的分析，更不敢直接使用内部记录作为证据，担心因信息安全而被查到。但我相信，我昔日的许多战友会为我作证。华为内部的兄弟们，包括我们曾经服务过的产品线兄弟，我相信文中的无数细节会与你们的印象吻合，印证我的说法。你们可能也被欺骗了，但这些残酷的真相不会被埋没。我们奋斗过的痕迹不应被扭曲或掩埋。

写了这么多，某些人肯定想找到我，让我闭嘴。公司可能也想让我闭嘴或追究我的责任。如果真到了那一步，我的人身安全，甚至我家人的安全，都可能受到威胁。为了自我保护，我将在近期每日向各位汇报我的安全状况。

如果我消失了，就当是为了真理和理想，为了华为乃至中国算力和AI更好地发展而牺牲吧。我愿意埋骨于我曾经战斗过的地方。

再见，诺亚。
写于2025年7月6日凌晨，深圳。