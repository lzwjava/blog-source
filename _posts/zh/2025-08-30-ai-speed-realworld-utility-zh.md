---
audio: false
generated: true
image: false
lang: zh
layout: post
title: AI速度与现实效用的完美融合
translated: true
type: note
---

以下是该论文的**核心要点**：

---

### 核心理念

* **传统AI基准测试**主要关注准确性/质量，但忽略了**处理速度**——这在现实世界的时间敏感应用中至关重要（例如自动驾驶、客户服务）。
* 现有的速度指标（TTFT、TPS）是**以令牌为中心的**，不足以应对多模态AI的未来。
* **提出的新指标**：**智能带宽**——AI在单位时间内能产生的有用信息量。

---

### 智能带宽的近似方法

1. **单位时间基准得分**

   * 使用标准化基准性能除以所用时间。
   * 对于实际任务而言，比令牌/秒更具信息量。

2. **信息论方法**

   * 通过概率分布测量输出信息内容。
   * 局限性在于信息≠实用性，且需要访问概率向量。

3. **原始输出比特/秒**

   * 最简单，与模态无关。
   * 测量AI输出（文本、图像、视频）的比特/秒。
   * 不直接衡量实用性，但若仅应用于顶级模型则有效。

---

### 历史背景

* 速度此前被忽视，因为：

  1. AI尚未先进到需要关注速度。
  2. 应用领域狭窄且任务特定。
* 随着**大语言模型**和**多模态AI**的出现，**统一的速度指标**变得必要。

---

### 人机交互的影响

* 类似于**摩尔定律**和**尼尔森定律**，该指标可以揭示增长趋势。
* **阈值概念**：一旦AI输出速度超过人类感知速度（例如阅读或听力），实时交互就成为可能。
* AI已经超过人类的阅读和听力速度；下一个前沿是**实时图像和视频集成**。
* 未来：AI可能支持**实时视觉推理、白板式设计和沉浸式虚拟环境**。

---

### 实验与数据

* 使用**原始输出比特/秒**对历史大语言模型、图像和视频生成器进行测量。
* **观察结果**：

  * 大语言模型：0–3 KB/秒。
  * 图像生成器：呈指数级增长。
  * 视频生成器：目前滞后但预计将加速。
  * **Gemini 2.5 Flash**是一个例外（针对低延迟优化）。

---

### Jin定律

* **表述**：*最佳公开托管AI模型的智能带宽每年翻一番。*
* 目前由**图像生成器**领先；随着服务改进，视频预计将占据主导地位。
* **预测**：

  1. **图像集成到AI聊天**将在1年内成为标准。
  2. **实时视频交互**约3年内可行（需要约8倍速度提升）。

---

### 局限性

* 定义**“有用信息”**仍未解决。
* 当前数据稀疏，因此一年翻倍的估计不确定。
* 增长可能受能源/经济限制，而不仅仅是技术进步。

---

### 总结

* AI评估必须同时考虑**正确性和速度**，这与人类智能评估方式一致。
* **智能带宽**为AI的未来提供了一个预测框架，特别是对于**实时、多模态交互**。

---

您是否希望我也创建一个**Jin定律预测的可视化时间线**（文本→图像→视频→沉浸式环境），以便一目了然？