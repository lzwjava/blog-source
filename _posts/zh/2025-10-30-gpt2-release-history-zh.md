---
audio: false
generated: true
image: false
lang: zh
layout: post
model: x-ai/grok-4-fast
title: GPT-2发布与开源历程
translated: true
type: note
---

### GPT-2 论文
GPT-2 论文《语言模型是无监督多任务学习者》于 2019 年 2 月 14 日发表，与 OpenAI 宣布该模型的初始博客文章同步发布。

### 开源发布
出于对潜在滥用的担忧，GPT-2 采用分阶段发布策略：
- **小模型（1.24 亿参数）**：2019 年 2 月 14 日发布
- **中模型（3.55 亿参数）**：2019 年 7 月发布
- **大模型（7.74 亿参数）**：2019 年 8 月 20 日发布
- **完整模型（15 亿参数）及开源代码**：2019 年 11 月 5 日发布，完整权重与实现代码在 GitHub 上全面公开

参考文献：  
[更优质的语言模型及其影响](https://openai.com/index/better-language-models/)  
[GPT-2：15 亿参数版本发布](https://openai.com/index/gpt-2-1-5b-release/)