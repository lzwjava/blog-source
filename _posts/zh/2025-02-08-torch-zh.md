---
audio: false
lang: zh
layout: post
title: PyTorch
translated: true
type: note
---

### torch 函数

*   `torch.Tensor`：包含单一数据类型元素的多维数组。
*   `torch.tensor`：通过数据和属性构造张量。
*   `torch.zeros`：返回填充零值的张量。
*   `torch.ones`：返回填充单位值的张量。
*   `torch.arange`：返回等间距数值的一维张量。
*   `torch.linspace`：返回指定区间内等间距数值的一维张量。
*   `torch.rand`：返回从区间 [0,1) 均匀分布中抽取随机数填充的张量。
*   `torch.randn`：返回从均值为 0、方差为 1 的正态分布中抽取随机数填充的张量。
*   `torch.empty`：返回包含未初始化数据的张量。
*   `torch.full`：创建指定尺寸并填充特定值的张量。
*   `torch.eye`：返回对角线为 1、其他位置为 0 的二维张量。

### 张量运算

*   `torch.add`：逐元素相加两个张量。
*   `torch.sub`：逐元素相减两个张量。
*   `torch.mul`：逐元素相乘两个张量。
*   `torch.div`：逐元素相除两个张量。
*   `torch.matmul`：执行矩阵乘法。
*   `torch.pow`：对张量每个元素进行幂运算。
*   `torch.exp`：计算张量每个元素的指数。
*   `torch.log`：计算张量每个元素的自然对数。
*   `torch.sqrt`：计算张量每个元素的平方根。
*   `torch.abs`：计算张量每个元素的绝对值。
*   `torch.neg`：对张量每个元素取负。
*   `torch.round`：将张量每个元素四舍五入到最接近的整数。
*   `torch.floor`：返回张量每个元素的向下取整值。
*   `torch.ceil`：返回张量每个元素的向上取整值。
*   `torch.clamp`：将输入的所有元素限制在 [min, max] 范围内。
*   `torch.sum`：返回输入张量所有元素的和。
*   `torch.mean`：返回输入张量所有元素的平均值。
*   `torch.std`：返回输入张量所有元素的标准差。
*   `torch.var`：返回输入张量所有元素的方差。
*   `torch.max`：返回输入张量所有元素的最大值。
*   `torch.min`：返回输入张量所有元素的最小值。
*   `torch.argmax`：返回输入张量所有元素最大值的索引。
*   `torch.argmin`：返回输入张量所有元素最小值的索引。
*   `torch.sort`：沿给定维度对输入张量元素进行排序。
*   `torch.topk`：返回输入张量沿给定维度的 k 个最大元素。
*   `torch.reshape`：返回与输入数据相同、元素数量相同但形状指定的张量。
*   `torch.transpose`：返回输入张量维度交换后的视图。
*   `torch.squeeze`：返回移除输入张量所有尺寸为 1 的维度后的张量。
*   `torch.unsqueeze`：返回在指定位置插入尺寸为 1 的新维度的张量。
*   `torch.cat`：在给定维度上连接给定张量。
*   `torch.stack`：沿新维度连接一系列张量。
*   `torch.chunk`：将张量分割为特定数量的块。
*   `torch.split`：将张量分割为特定尺寸的块。

### 神经网络模块

*   `torch.nn.Module`：所有神经网络模块的基类。
*   `torch.nn.Linear`：对输入数据应用线性变换。
*   `torch.nn.Conv2d`：对由多个输入平面组成的输入信号应用二维卷积。
*   `torch.nn.MaxPool2d`：对输入信号应用二维最大池化。
*   `torch.nn.ReLU`：逐元素应用修正线性单元函数。
*   `torch.nn.Sigmoid`：逐元素应用 S 型函数。
*   `torch.nn.Tanh`：逐元素应用双曲正切函数。
*   `torch.nn.BatchNorm2d`：对四维输入应用批量归一化。
*   `torch.nn.Dropout`：在训练期间，以概率 p 随机将输入张量的部分元素置零。
*   `torch.nn.Embedding`：存储固定词典和尺寸嵌入向量的简单查找表。

### 损失函数

*   `torch.nn.MSELoss`：创建衡量输入与目标每个元素间均方误差（L2 范数平方）的准则。
*   `torch.nn.CrossEntropyLoss`：该准则计算输入与目标之间的交叉熵损失。
*   `torch.nn.BCELoss`：创建衡量目标与输出间二元交叉熵的准则。
*   `torch.nn.L1Loss`：创建衡量输入与目标每个元素间平均绝对误差（MAE）的准则。

### 优化器

*   `torch.optim.SGD`：实现随机梯度下降（可选带动量）。
*   `torch.optim.Adam`：实现 Adam 算法。
*   `torch.optim.RMSprop`：实现 RMSprop 算法。

### 自动求导

*   `torch.autograd.grad`：计算并返回输出相对于输入的梯度之和。

### 工具函数

*   `torch.device`：表示 torch.Tensor 已分配或将要分配的设备。
*   `torch.cuda.is_available`：若 CUDA 可用则返回 True。
*   `torch.save`：将张量保存至磁盘。
*   `torch.load`：从磁盘加载张量。

### 其他

*   `torch.no_grad`：禁用梯度计算的上下文管理器。
*   `torch.set_grad_enabled`：根据参数启用或禁用梯度计算。