---
audio: true
lang: zh
layout: post
title: 人工智能思考
translated: true
---

- 萨特亚·纳德拉提到了詹逊悖论。值得学习。

- 王颖：在人工智能中没有“智能”，在神经网络中没有“神经”，在机器学习中没有“学习”，在深度学习中没有“深度”。这领域真正有效的是被称为“微积分”的东西。所以我更喜欢把这个领域称为“可求导计算”，建模过程称为“可求导编程”。

- 王颖：机器学习实际上非常有用，甚至可以说是美丽的理论，因为它只是微积分的化妆品！它是牛顿、劳斯莱尼的老而伟大的理论，以简单、优雅和强大的形式重新表现出来。机器学习基本上是使用微积分来导出并拟合一些函数，深度学习是拟合更复杂的函数。

- 目前，大语言模型无法按文件语言如YAML或Python进行过滤。但是，现实世界中的大部分信息是以这种方式组织的。这意味着我们可以使用文件训练大语言模型。

- 训练大语言模型时，我们可以开发一个系统来查找精确匹配。也许可以将KMP（诺斯-莫里斯-普拉特）搜索算法与变压器架构结合，以增强搜索能力。

- 没有技术秘密。开源会揭示所有紧密保守的秘密。