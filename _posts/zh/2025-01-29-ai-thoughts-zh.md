---
audio: false
lang: zh
layout: post
title: 人工智能思考
translated: true
---

- 薩特亞·納德拉提到了傑文斯悖論。值得一學。

- 尹王：人工智慧中沒有「智慧」，神經網絡中沒有「神經」，機器學習中沒有「學習」，深度學習中沒有「深度」。這個領域真正有效的部分被稱為「微分學」。因此，我更喜歡把這個領域稱為「可微分計算」，建模過程稱為「可微分編程」。

- 尹王：機器學習真的很有用，甚至可以說它是美麗的理論，因為它只是微分學的改版！它是牛頓、列宾兹那古老而伟大的理論的簡單、優雅且強大的形式。機器學習基本上是使用微分學來推導和適應一些函數，而深度學習是適應更複雜的函數。

- 目前，大型語言模型無法根據文件語言（如YAML或Python）進行過濾。然而，現實世界中大量信息是這樣組織的。這意味著我們可以使用文件來訓練大型語言模型。

- 在訓練大型語言模型時，我們可以開發一個系統來找到精確匹配。也許我們可以將KMP（諾斯-莫里斯-普拉特）搜索算法與轉換器架構結合起來，以增強搜索能力。

- 沒有技術秘密。開源會揭示所有那些緊密保護的秘密。

- [由AI工作流驅動的新平台](./ai-workflow-en)

- [AI代碼編輯器的下一步方向](./ai-code-en)

- [在AI和區塊鏈時代的生活方式](./ai-blockchain-en)