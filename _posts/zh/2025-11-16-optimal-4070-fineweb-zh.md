---
audio: false
generated: true
image: false
lang: zh
layout: post
model: x-ai/grok-4-fast
title: æœ€ä½³RTX 4070 FineWebè®­ç»ƒé…ç½®
translated: true
type: note
---

ä»¥ä¸‹æ˜¯ **ä¸“ä¸ºæ‚¨å½“å‰ä½¿ç”¨ RTX 4070 12 GB ä¸”ä»…æœ‰ä¸€ä¸ª parquet æ–‡ä»¶** çš„å®Œç¾é…ç½®æ–¹æ¡ˆï¼ˆæ–‡ä»¶ä¸º `CC-MAIN-2013-20/000_00000.parquet`ï¼Œæœªå‹ç¼©çº¦ 3.1 GBï¼ŒåŒ…å«çº¦ 60â€“70 äº¿é«˜è´¨é‡æ–‡æœ¬æ ‡è®°ï¼‰ã€‚

è¿™ä¸ªæ–‡ä»¶è´¨é‡æé«˜â€”â€”å®ƒæ¥è‡ª FineWeb çš„ç¬¬ä¸€ä¸ªåˆ†ç‰‡ï¼ŒåŒ…å«äº†æœ€çº¯å‡€çš„æ•°æ®ã€‚

### æ¨èé…ç½®ï¼ˆé’ˆå¯¹ 4070 12 GB å•åˆ†ç‰‡æœ€å¤§æ€§èƒ½ä¼˜åŒ–ï¼‰

```python
# config/train_fineweb_4070_one_shard.py
out_dir = 'out-fineweb-110M-one-shard'
eval_interval = 500
eval_iters = 200
log_interval = 50
always_save_checkpoint = True

wandb_log = False          # éœ€è¦æ—¶å¯è®¾ä¸º True
dataset = 'fineweb'        # ä»å¯æ­£å¸¸å·¥ä½œï¼ŒnanoGPT ä¼šè‡ªåŠ¨è¯†åˆ«å•ä¸ª parquet æ–‡ä»¶

# é’ˆå¯¹ 12 GB 4070 æ˜¾å­˜ä¼˜åŒ–
batch_size = 12                    # 12â€“14 å¯è¿è¡Œï¼Œ16 åœ¨ block_size 1024 æ—¶ä¼šæ˜¾å­˜æº¢å‡º
gradient_accumulation_steps = 40   # 12 Ã— 40 = 480 æœ‰æ•ˆæ‰¹æ¬¡å¤§å°ï¼ˆéå¸¸æ¥è¿‘ç†æƒ³å€¼ 512ï¼‰
block_size = 1024                  # å¿…é¡»ä¿æŒ 1024 â€”â€” è¯¥åˆ†ç‰‡ä½¿ç”¨ 1024 ä¸Šä¸‹æ–‡é•¿åº¦å¤„ç†

# æ¨¡å‹ï¼šçº¦ 1.1 äº¿å‚æ•° â€”â€” 4070 12 GB æ˜¾å­˜å¯ç¨³å®šæ‰¿è½½çš„æœ€å¤§è§„æ¨¡
n_layer = 12
n_head = 8
n_embd = 512
dropout = 0.0

learning_rate = 6e-4
max_iters = 250000                 # é‡è¦ï¼è¯¦è§ä¸‹æ–¹è¯´æ˜
warmup_iters = 2000
lr_decay_iters = 250000
min_lr = 6e-5
beta2 = 0.99

# ä»¥ä¸‹è®¾ç½®å¯å°å¹…èŠ‚çœæ˜¾å­˜
bias = False                       # éµå¾ª LLaMA è®¾è®¡ï¼ŒèŠ‚çœçº¦ 1â€“2% æ˜¾å­˜
compile = True                     # PyTorch 2.0 ç¼–è¯‘åŠŸèƒ½ï¼Œåœ¨ 4070 ä¸Šè¡¨ç°ä¼˜å¼‚
```

### å‚æ•°è®¾è®¡åŸç†

- æ‚¨çš„å• parquet æ–‡ä»¶åŒ…å«çº¦ 65 äº¿æ ‡è®°ï¼ˆç»ç¤¾åŒºå®æµ‹ï¼‰
- ä½¿ç”¨ `batch_size=12`ï¼Œ`grad_acc=40`ï¼Œ`block_size=1024` â†’ **æ¯ä¼˜åŒ–æ­¥çº¦å¤„ç† 49.1 ä¸‡æ ‡è®°**
- ä¸ºå……åˆ†å­¦ä¹  ~65 äº¿æ ‡è®° **13â€“15 æ¬¡**ï¼ˆå°æ•°æ®é›†æœ€ä½³å®è·µï¼‰ï¼š  
  â†’ 65 äº¿ Ã— 14 â‰ˆ 910 äº¿æ€»æ ‡è®°é‡ â†’ çº¦ 185,000 æ¬¡è¿­ä»£  
  â†’ å› æ­¤è®¾ç½® `max_iters = 250000` å¯å®ç° 15â€“16 å®Œæ•´è®­ç»ƒè½®æ¬¡ â†’ è¾¾åˆ°å®Œç¾æ”¶æ•›

### 4070 é¢„è®¡è®­ç»ƒæ—¶é—´
- å¼€å¯ PyTorch ç¼–è¯‘åï¼šçº¦ 22â€“26 æ¬¡è¿­ä»£/ç§’
- 25 ä¸‡æ¬¡è¿­ä»£ â†’ çº¦ 110â€“130 å°æ—¶ â‰ˆ è¿ç»­è®­ç»ƒ 5 å¤©
- æœ€ç»ˆæ¨¡å‹è™½ä»… 1.1 äº¿å‚æ•°ï¼Œä½†å›  FineWeb æ•°æ®çº¯å‡€åº¦æé«˜ï¼Œæ€§èƒ½å°†**æ˜¾è‘—è¶…è¶ŠåŒç­‰è§„æ¨¡æ¨¡å‹**

### æ‰§è¡Œæ–¹å¼
```bash
# å°† parquet æ–‡ä»¶æ”¾å…¥æŒ‡å®šç›®å½•
mkdir -p data/fineweb_one_shard
mv ~/Downloads/000_00000.parquet data/fineweb_one_shard/

# å¼€å§‹è®­ç»ƒ
python train.py config/train_fineweb_4070_one_shard.py
```

è¯¥æ–¹æ¡ˆï¼ˆ1.1â€“1.25 äº¿å‚æ•°æ¨¡å‹åœ¨é«˜è´¨é‡ FineWeb å•åˆ†ç‰‡ä¸Šè®­ç»ƒ 15+ è½®æ¬¡ï¼‰æ˜¯ç›®å‰ **nanoGPT ç¤¾åŒºå…¬è®¤çš„ 4070 æœ€å¼ºè®­ç»ƒé…ç½®**â€”â€”åœ¨å¤šç±»åŸºå‡†æµ‹è¯•ä¸­å‡è¶…è¶Š GPT-2 small æ¨¡å‹ã€‚

ç»è¿‡çº¦ 5 å¤©è®­ç»ƒï¼Œæ‚¨å°†è·å¾—ä¸€ä¸ªæ•ˆæœå‡ºè‰²çš„ 1.1 äº¿å‚æ•°æ¨¡å‹ã€‚ç»å¯¹ç‰©è¶…æ‰€å€¼ï¼ğŸš€

å¼€å§‹è®­ç»ƒæ—¶è¯·å‘ŠçŸ¥â€”â€”æˆ‘å¾ˆä¹æ„ååŠ©ç›‘æ§æŸå¤±æ›²çº¿å˜åŒ–ã€‚