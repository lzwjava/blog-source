---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: рдлрд╛рдЗрдирд╡реЗрдм рдиреИрдиреЛрдЬреАрдкреАрдЯреА рдЬреАрдкреАрдпреВ рдореЗрдореЛрд░реА рдЧрд╛рдЗрдб
translated: true
type: note
---

рдЖрдк рдПрдХ рдЫреЛрдЯрд╛ GPT (nanoGPT-рд╢реИрд▓реА рдХрд╛) **FineWeb** рдбреЗрдЯрд╛рд╕реЗрдЯ рдкрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рджреЗ рд░рд╣реЗ рд╣реИрдВ (Common Crawl рдХрд╛ 100B-рдЯреЛрдХрди рд╕рд╛рдл рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╕рдВрд╕реНрдХрд░рдг рдЬрд┐рд╕рд╕реЗ LLaMA, Mistral рдЖрджрд┐ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛), рд▓реЗрдХрд┐рди рдЖрдк рд╕реАрдорд┐рдд GPU рдореЗрдореЛрд░реА (рд╢рд╛рдпрдж 16тАУ24 GB, рдЬреИрд╕реЗ RTX 3090/4090 рдпрд╛ A6000) рдХреЗ рд╕рд╛рде рдРрд╕рд╛ рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВред

рдЖрдкрдХреА рд╡рд░реНрддрдорд╛рди рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рдкрд╣рд▓реЗ рд╕реЗ рд╣реА рдХрд╛рдлреА рд░реВрдврд╝рд┐рд╡рд╛рджреА рдФрд░ рдПрдХрд▓ рдЙрдкрднреЛрдХреНрддрд╛ GPU рдХреЗ рд▓рд┐рдП рдЕрдЪреНрдЫреА рд╣реИ, рд▓реЗрдХрд┐рди рдпрд╣рд╛рдВ **nanoGPT рдХреЗ рд▓рд┐рдП FineWeb рдкрд░ рд╕рд░реНрд╡реЛрддреНрддрдо рдкреИрд░рд╛рдореАрдЯрд░ рдХреИрд╕реЗ рдЪреБрдиреЗрдВ** рдЗрд╕ рдкрд░ рдПрдХ рд╡рд┐рд╕реНрддреГрдд рдорд╛рд░реНрдЧрджрд░реНрд╢рд┐рдХрд╛ рджреА рдЧрдИ рд╣реИ, рдЬреЛ рдорд╣рддреНрд╡ рдФрд░ рдореЗрдореЛрд░реА рдкреНрд░рднрд╛рд╡ рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдХреНрд░рдордмрджреНрдз рд╣реИред

### GPU рдореЗрдореЛрд░реА рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдЕрдиреБрд╢рдВрд╕рд┐рдд рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди

| GPU VRAM       | рдореЙрдбрд▓ рдЖрдХрд╛рд░ (рдкреИрд░рд╛рдореАрдЯрд░) | n_layer | n_head | n_embd | batch_size | grad_acc | рдкреНрд░рднрд╛рд╡реА BS | block_size | рдЯрд┐рдкреНрдкрдгрд┐рдпрд╛рдБ |
|----------------|---------------------|---------|--------|--------|------------|----------|--------------|------------|-------|
| 80 GB (A100/H100) | ~350M              | 12      | 12     | 768    | 64         | 8        | 512          | 1024       | рдореВрд▓ GPT-2 рдореАрдбрд┐рдпрдо рдХреЗ рдХрд░реАрдм, рдЕрдЪреНрдЫрд╛ рдкреНрд░рд╢рд┐рдХреНрд╖рдг |
| 48 GB (A6000/3090) | ~250тАУ300M         | 12      | 12     | 672    | 32         | 16       | 512          | 1024       | рдмрд╣реБрдд рдЕрдЪреНрдЫрд╛ рд╕рдордЭреМрддрд╛ |
| 24 GB (4090/3090) | ~160тАУ200M          | 10      | 10     | 640    | 32         | 12тАУ16    | 384тАУ512      | 1024       | рдЖрдкрдХрд╛ рд╕реНрд╡реАрдЯ рд╕реНрдкреЙрдЯ |
| 16тАУ20 GB (4080, 3090 Ti) | ~125M        | 8       | 8      | 512    | 32         | 12       | 384          | 1024       | рд╕реНрдерд┐рд░ |
| <16 GB (4070 Ti, рдЖрджрд┐) | ~84M           | 6       | 6      | 384    | 16тАУ32      | 16тАУ24    | 256тАУ512      | 512тАУ1024   | рдЖрдкрдХреА рд╡рд░реНрддрдорд╛рди рдХреЙрдиреНрдлрд╝рд┐рдЧ |

рдЖрдкрдХреА рд╡рд░реНрддрдорд╛рди рдХреЙрдиреНрдлрд╝рд┐рдЧ (`6L 6H 384embd`) рд╕реБрд░рдХреНрд╖рд┐рдд рд╣реИ рд▓реЗрдХрд┐рди рдереЛрдбрд╝реА рдЫреЛрдЯреА рд╣реИред рдЖрдк рдмрдбрд╝рд╛ рдЬрд╛ рд╕рдХрддреЗ рд╣реИрдВред

### 24 GB GPU (RTX 4090 / 3090) рдХреЗ рд▓рд┐рдП рд╕рд░реНрд╡реЛрддреНрддрдо рдХреЙрдиреНрдлрд╝рд┐рдЧ FineWeb рдкрд░
рдпрд╣ рдЕрднреА nanoGPT рдХрдореНрдпреБрдирд┐рдЯреА рдореЗрдВ рд╕рдмрд╕реЗ рд▓реЛрдХрдкреНрд░рд┐рдп рд╕реЗрдЯрдЕрдк рд╣реИ:

```python
out_dir = 'out-fineweb-160M'
eval_interval = 1000
eval_iters = 200
log_interval = 100
always_save_checkpoint = True

wandb_log = True
wandb_project = 'fineweb'
wandb_run_name = '160M-fineweb'

dataset = 'fineweb'
gradient_accumulation_steps = 16   # 32 * 16 = 512 рдкреНрд░рднрд╛рд╡реА рдмреИрдЪ рдЖрдХрд╛рд░
batch_size = 32
block_size = 1024                  # рдорд╣рддреНрд╡рдкреВрд░реНрдг: FineWeb рдХреЛ 1024+ рдХреЗ рд╕рд╛рде рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛

n_layer = 10
n_head = 10
n_embd = 640
dropout = 0.0                      # рдмрд╛рдж рдореЗрдВ 0.1 рдЖрдЬрд╝рдорд╛ рд╕рдХрддреЗ рд╣реИрдВ
learning_rate = 6e-4               # рдЫреЛрдЯреЗ рдореЙрдбрд▓реЛрдВ рдХреЗ рд▓рд┐рдП рдереЛрдбрд╝рд╛ рдЕрдзрд┐рдХ
max_iters = 50000                  # ~50тАУ100B рдХреБрд▓ рдЯреЛрдХрди рдЖрджрд░реНрд╢ рд╣реИ
warmup_iters = 2000
lr_decay_iters = 50000
min_lr = 6e-5
beta2 = 0.99
```

тЖТ рдпрд╣ ~160M рдкреИрд░рд╛рдореАрдЯрд░ рд╣реИ, рдПрдХ 4090 рдкрд░ рдЖрд░рд╛рдо рд╕реЗ рдЪрд▓рддрд╛ рд╣реИ рдЬрд┐рд╕рдореЗрдВ ~20тАУ22 GB VRAM рдЙрдкрдпреЛрдЧ рд╣реЛрддрд╛ рд╣реИред

### рдФрд░ рднреА рдмреЗрд╣рддрд░: 200M+ рдореЙрдбрд▓ (рдпрджрд┐ рдЖрдкрдХреЗ рдкрд╛рд╕ 24 GB+ рд╣реИ)
```python
n_layer = 12
n_head = 12
n_embd = 768    # тЖТ ~350M рдкреИрд░рд╛рдореАрдЯрд░ (рдореВрд▓ GPT-2 рдореАрдбрд┐рдпрдо рдЖрдХрд╛рд░)
batch_size = 32
gradient_accumulation_steps = 16   # рдкреНрд░рднрд╛рд╡реА BS 512
block_size = 1024
learning_rate = 5e-4
max_iters = 60000
```
рдмрд╣реБрдд рд╕реЗ рд▓реЛрдЧ рдЗрд╕реЗ рдПрдХрд▓ 4090 рдкрд░ рд╕рдлрд▓рддрд╛рдкреВрд░реНрд╡рдХ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рддреЗ рд╣реИрдВред

### FineWeb + nanoGPT рдХреЗ рд▓рд┐рдП рдореБрдЦреНрдп рдЕрдиреБрдорд╛рдирд┐рдд рдирд┐рдпрдо

1. **block_size = 1024** рджреГрдврд╝рддрд╛ рд╕реЗ рдЕрдиреБрд╢рдВрд╕рд┐рдд рд╣реИ  
   FineWeb рдХреЛ 1024 рдХреЙрдиреНрдЯреЗрдХреНрд╕реНрдЯ рдХреЗ рд╕рд╛рде рдлрд╝рд┐рд▓реНрдЯрд░ рдФрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛ред 512 рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рд╕реЗ рдкрд░реНрдкреНрд▓реЗрдХреНрд╕рд┐рдЯреА рдЖрдкрдХреЗ рд╕реЛрдЪрдиреЗ рд╕реЗ рдЕрдзрд┐рдХ рдкреНрд░рднрд╛рд╡рд┐рдд рд╣реЛрддреА рд╣реИред

2. **рдкреНрд░рднрд╛рд╡реА рдмреИрдЪ рдЖрдХрд╛рд░ тЙИ 512** рд╕реНрд╡реАрдЯ рд╕реНрдкреЙрдЯ рд╣реИ  
   рдореВрд▓ LLaMA рдиреЗ ~4M рдЯреЛрдХрди рдкреНрд░рддрд┐ рдмреИрдЪ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ред nanoGPT рдХреЗ рд▓рд┐рдП, 512 рдЕрдиреБрдХреНрд░рдо ├Ч 1024 рдЯреЛрдХрди = ~0.5M рдЯреЛрдХрди/рдмреИрдЪ тЖТ рд╕реНрдХреЗрд▓рд┐рдВрдЧ рд▓реЙ рдХреЗ рд▓рд┐рдП рдХрд╛рдлреА рдХрд░реАрдмред

3. **рд▓рд░реНрдирд┐рдВрдЧ рд░реЗрдЯ**  
   - ~100M рдкреИрд░рд╛рдореАрдЯрд░: 6eтАУ8e-4  
   - ~350M рдкреИрд░рд╛рдореАрдЯрд░: 5eтАУ6e-4  
   - ~770M рдкреИрд░рд╛рдореАрдЯрд░: 3e-4  

4. **рдХрдо рд╕реЗ рдХрдо 50B рдЯреЛрдХрди рдХреЗ рд▓рд┐рдП рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░реЗрдВ** (100B+ рдмреЗрд╣рддрд░)  
   160M рдореЙрдбрд▓ рдХреЗ рд╕рд╛рде:  
   - 50k iters ├Ч 32 ├Ч 16 ├Ч 1024 рдЯреЛрдХрди = ~83B рдЯреЛрдХрди  
   рдЕрдЪреНрдЫрд╛ рдХрдиреНрд╡рд░реНрдЬреЗрдВрд╕ред

5. **рдЖрдзрд┐рдХрд╛рд░рд┐рдХ FineWeb рдбреЗрдЯрд╛рд╕реЗрдЯ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ (openwebtext рдирд╣реАрдВ)**  
   рдЖрдкрдХреА рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдкрд╣рд▓реЗ рд╕реЗ рд╣реА рд╕рд╣реА рд╣реИ:  
   рдЧреБрдгрд╡рддреНрддрд╛ рдореЗрдВ FineWeb >> OpenWebTextред  
   100B рд╕рдмрд╕реЗрдЯ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ: `fineweb100B` рдпрд╛ рдкреВрд░реНрдг `fineweb` (рдЖрдкрдХреА рдбрд┐рд╕реНрдХ рддрдХ рдЫреЛрдЯрд╛ рдХрд┐рдпрд╛ рдЧрдпрд╛)ред

6. **рд╡реИрдХрд▓реНрдкрд┐рдХ рд▓реЗрдХрд┐рди рд╕рд╣рд╛рдпрдХ**
```python
compile = True          # PyTorch 2.0 рдХрдВрдкрд╛рдЗрд▓, ~20тАУ30% рддреЗрдЬрд╝
bias = False            # Linear рд▓реЗрдпрд░реНрд╕ рдореЗрдВ рдХреЛрдИ рдмрд╛рдпрд╕ рдирд╣реАрдВ (LLaMA рдХреА рддрд░рд╣)
weight_decay = 0.1
```

### FineWeb (100B рд╕рдВрд╕реНрдХрд░рдг) рдбрд╛рдЙрдирд▓реЛрдб рдХрд░рдиреЗ рдХрд╛ рддреНрд╡рд░рд┐рдд рдХрдорд╛рдВрдб
```bash
pip install datasets
python -c "
from datasets import load_dataset
ds = load_dataset('HuggingFaceFW/fineweb', name='sample-100BT', split='train')
ds.save_to_disk('data/fineweb100B')
"
```
рдлрд┐рд░ nanoGPT рдХреЛ рдЙрд╕ рдлрд╝реЛрд▓реНрдбрд░ рдХреА рдУрд░ рдЗрдВрдЧрд┐рдд рдХрд░реЗрдВред

### рд╕рд╛рд░рд╛рдВрд╢: рдЕрдкрдиреА рд╡рд░реНрддрдорд╛рди рдХреЙрдиреНрдлрд╝рд┐рдЧ рдХреЛ рдЕрдкрдЧреНрд░реЗрдб рдХрд░реЗрдВ
рдЕрдкрдиреЗ рд╡рд░реНрддрдорд╛рди рдореЙрдбрд▓ рднрд╛рдЧ рдХреЛ рдЗрд╕рдХреЗ рд╕рд╛рде рдмрджрд▓реЗрдВ (24 GB GPU рдХреЗ рд▓рд┐рдП):

```python
n_layer = 10
n_head = 10
n_embd = 640
batch_size = 32
gradient_accumulation_steps = 16
block_size = 1024
learning_rate = 6e-4
max_iters = 50000
```

рдЖрдкрдХреЛ рд▓рдЧрднрдЧ рдХреЛрдИ рдЕрддрд┐рд░рд┐рдХреНрдд рд▓рд╛рдЧрдд рдирд╣реАрдВ рд▓рдЧрд╛рдХрд░ рдПрдХ рдмрд╣реБрдд рдордЬрдмреВрдд рдореЙрдбрд▓ рдорд┐рд▓реЗрдЧрд╛ред

рд▓реЛрдЧ рдЗрди рд╕реЗрдЯрд┐рдВрдЧреНрд╕ рдХреЗ рд╕рд╛рде FineWeb рдкрд░ **рдмрд╣реБрдд рдЕрдЪреНрдЫреЗ 160MтАУ350M рдореЙрдбрд▓** рдкреНрд░рд╛рдкреНрдд рдХрд░ рд░рд╣реЗ рд╣реИрдВ тАФ рдЬреЛ рдЕрдХреНрд╕рд░ рдореВрд▓ GPT-2 рдкреНрд░рджрд░реНрд╢рди рдХреЛ рдкрд╛рд░ рдХрд░ рдЬрд╛рддреЗ рд╣реИрдВред

рдореБрдЭреЗ рдЕрдкрдирд╛ рд╕рдЯреАрдХ GPU рдмрддрд╛рдПрдВ рдФрд░ рдореИрдВ рдЖрдкрдХреЛ рдЗрд╖реНрдЯрддрдо рдХреЙрдиреНрдлрд╝рд┐рдЧ рджреЗ рд╕рдХрддрд╛ рд╣реВрдВ! ЁЯЪА