---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: गणनात्मक शक्ति मानव सूझबूझ पर भारी पड़ती है
translated: true
type: note
---

### रिचर्ड सटन द्वारा "द बिटर लेसन"

रिचर्ड सटन, जो रीइनफोर्समेंट लर्निंग में अपने काम के लिए जाने जाने वाले एक अग्रणी AI शोधकर्ता हैं, ने 2019 में "द बिटर लेसन" शीर्षक से एक लघु निबंध लिखा। यह AI के 70 वर्षों के इतिहास पर एक विचार है, जिसमें तर्क दिया गया है कि AI प्रगति के सबसे प्रभावी रास्ते वे नहीं हैं जो मानव बुद्धिमत्ता की नकल करते हैं या विशेषज्ञ ज्ञान से भरे होते हैं। बल्कि, "कड़वा" सच यह है कि **सामान्य-उद्देश्य वाली विधियाँ जो कच्ची कम्प्यूटेशनल शक्ति के साथ स्केल करती हैं—जैसे सर्च अल्गोरिदम और मशीन लर्निंग—लंबे समय में चतुर, मानव-प्रेरित डिजाइनों को लगातार पछाड़ देती हैं**।

#### मुख्य विचार
सटन एक आवर्ती पैटर्न का अवलोकन करते हैं: AI की शुरुआती सफलताएं अक्सर मानव विशेषज्ञता (जैसे, नियम, ह्यूरिस्टिक्स, या डोमेन-विशिष्ट ज्ञान) को सिस्टम में डालने से आती हैं। यह पहले-पहल सहज और कुशल लगता है, लेकिन जैसे-जैसे कम्प्यूटेशन सस्ता और प्रचुर मात्रा में होता जाता है, ये ज्ञान-केंद्रित दृष्टिकोण दीवार से टकरा जाते हैं। वे नाजुक, स्केल करने में मुश्किल हो जाते हैं, और सरल "मेटा-मेथड्स" से पिछड़ जाते हैं जो कम्प्यूटरों को ट्रायल और एरर के जरिए समाधान ढूंढने देते हैं।

"कड़वे" हिस्से की बात? हम मनुष्यों को यह सबक पसंद नहीं है क्योंकि यह हमारी सरलता और अंतर्ज्ञान को गौण कर देता है। हम ऐसी प्रणालियाँ बनाना पसंद करते हैं जो "हमारी तरह सोचें," लेकिन सबूत बताते हैं कि बड़ी प्रगति के लिए यह एक बंद गली है। सटन इसका सारांश देते हैं: "कड़वा सबक इस अवलोकन पर आधारित है कि हमारे द्वारा विकसित सबसे शक्तिशाली तरीके... वे हैं जो कम्प्यूटेशन का लाभ उठाते हैं।"

#### ऐतिहासिक उदाहरण
सटन उदाहरण देने के लिए AI के मील के पत्थरों से सबक लेते हैं:
- **शतरंज**: 1990 के दशक में, मानव विशेषज्ञ ज्ञान-आधारित प्रोग्रामों (जिनमें ओपनिंग, टैक्टिक्स और स्ट्रैटेजी को एनकोड किया जाता था) के साथ हावी रहे। लेकिन डीप ब्लू (1997) ने बड़े पैमाने पर सर्च ट्री और कम्प्यूटेशन का उपयोग करके कास्परोव को हरा दिया, उस "ज्ञान" की अधिकांश को नजरअंदाज करते हुए।
- **गो**: इसी तरह की कहानी—अल्फागो (2016) ने सेल्फ-प्ले और न्यूरल नेटवर्क के माध्यम से सीखा, पेशेवर खेलों का गहन अध्ययन करके नहीं। यह कम्प्यूट शक्ति के साथ स्केल हुआ और अंतर्ज्ञान-आधारित प्रतिद्वंद्वियों को हराया।
- **स्पीच रिकग्निशन**: हैंड-क्राफ्टेड भाषाई मॉडल तब तक हावी रहे जब तक कि सांख्यिकीय लर्निंग (डेटा और कम्प्यूटेशन का लाभ उठाते हुए) ने 2010 के दशक में अधिकार नहीं कर लिया, जिससे आज के वॉइस असिस्टेंट का मार्ग प्रशस्त हुआ।
- **कम्प्यूटर विजन**: शुरुआती सिस्टम एज डिटेक्शन और शेप नियमों पर निर्भर थे; अब, डीप लर्निंग GPU के साथ पिक्सेल्स को प्रोसेस करती है।

प्रत्येक मामले में, ज्ञान-केंद्रित दृष्टिकोण ने अल्पकालिक लड़ाइयाँ तो जीत लीं, लेकिन युद्ध कम्प्यूटेशन-भूखी सामान्यता से हार गया।

#### यह महत्वपूर्ण क्यों है
यह सबक AI को "स्केलेबल ओवरसाइट" की ओर धकेलता है—ऐसी प्रणालियाँ बनाना जो विशाल डेटा से सीख सकें बिना इसके कि हमें हर अंतर्दृष्टि चम्मच से खिलानी पड़े। यही कारण है कि आज की क्रांतिकारी उपलब्धियाँ (जैसे लार्ज लैंग्वेज मॉडल) रूलबुक के बजाय इंटरनेट-स्केल डेटा पर ट्रेनिंग से आती हैं। लेकिन यह "कड़वा" है क्योंकि इसका तात्पर्य है कि हमें आगे बढ़ते रहने के लिए और अधिक कम्प्यूटेशन (और ऊर्जा) की आवश्यकता होगी, और यह "सुरुचिपूर्ण" समाधान तैयार करने पर जोर कम कर देता है।

सटन ने इसे एक चेतावनी के रूप में लिखा था: इस प्रवृत्ति से न लड़ें; तेज प्रगति के लिए इसे अपनाएं।

#### संदर्भ
- [द बिटर लेसन (मूल निबंध)](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
- [बिटर लेसन (विकिपीडिया सारांश)](https://en.wikipedia.org/wiki/Bitter_lesson)
- [रेडिट पर ELI5 व्याख्या](https://www.reddit.com/r/explainlikeimfive/comments/1nug43e/eli5_what_is_richard_suttons_bitter_lesson_in_ai/)