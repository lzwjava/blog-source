---
audio: false
generated: true
image: false
lang: hi
layout: post
title: एलएलएम टोकन्स की सरल व्याख्या
translated: true
type: note
---

बढ़िया सवाल — LLM APIs में टोकन्स पहली बार में थोड़े भ्रमित करने वाले लग सकते हैं। मैं इसे स्पष्ट रूप से समझाता हूं।

---

## टोकन क्या होते हैं

* एक **टोकन** टेक्स्ट की सबसे छोटी इकाई है जिसे मॉडल प्रोसेस करता है।
* यह **ठीक एक शब्द नहीं है**। टोकन आमतौर पर शब्दों के टुकड़े, पूरे शब्द, विराम चिह्न, या भाषा और टोकनाइज़र के आधार पर रिक्त स्थान भी हो सकते हैं।
* LLM (जैसे OpenAI GPT मॉडल) एक पूर्वनिर्धारित **टोकनाइज़र** का उपयोग करके टेक्स्ट को टोकन में विभाजित करते हैं।

उदाहरण के लिए:

* `"cat"` → 1 टोकन
* `"cats"` → संभवतः `"cat"` + `"s"` के रूप में विभाजित → 2 टोकन
* `"You're handsome."` → कुछ इस तरह विभाजित होता है: `"You"`, `"'re"`, `" handsome"`, `"."` → **4 टोकन**

तो टोकन **सबवर्ड यूनिट्स** हैं, जिन्हें इस तरह अनुकूलित किया गया है कि मॉडल कई भाषाओं और दुर्लभ शब्दों को कुशलतापूर्वक हैंडल कर सके।

---

## APIs में टोकन क्यों महत्वपूर्ण हैं

1.  **बिलिंग** – अधिकांश LLM APIs टोकन (इनपुट + आउटपुट) के हिसाब से चार्ज करती हैं।
2.  **सीमाएं** – मॉडलों की अधिकतम टोकन सीमा होती है (उदा., GPT-4 Turbo 128k का मतलब है इनपुट + आउटपुट के लिए कुल 128,000 टोकन तक)।
3.  **दक्षता** – आप लागत कम करने और सीमा के भीतर रहने के लिए प्रॉम्प्ट भेजते समय टोकन को कम से कम करना चाहते हैं।

---

## व्यवहार में टोकन को हैंडल करना

* **टोकन का अनुमान लगाएं**: एक सामान्य नियम है अंग्रेजी में प्रति टोकन लगभग 4 वर्ण। तो एक 1,000-शब्दों वाला अंग्रेजी निबंध (≈5,000 वर्ण) लगभग 1,200–1,300 टोकन का होता है।
* **टोकनों को सटीक रूप से जांचें**: अधिकांश SDKs (जैसे OpenAI के लिए Python में `tiktoken`) आपको भेजने से पहले टोकन गिनने देते हैं।
* **प्रॉम्प्ट्स को अनुकूलित करें**:

  * अनावश्यक रिक्त स्थान/शब्द हटाएं।
  * संक्षिप्त निर्देशों का उपयोग करें।
  * रॉ टेक्स्ट डंप करने के बजाय संदर्भ को सारांशित करें।

---

## उदाहरण

```python
import tiktoken

enc = tiktoken.get_encoding("cl100k_base")
text = "You're handsome."
tokens = enc.encode(text)
print(tokens)        # टोकन IDs की सूची
print(len(tokens))   # टोकनों की संख्या
```

यह कुछ इस तरह आउटपुट करेगा `[9125, 3938, 13]` → 3 टोकन (सटीक टोकनाइज़र वर्जन पर निर्भर करता है)।

---

✅ तो: **टोकन ≠ शब्द**। वे मूलभूत बिल्डिंग ब्लॉक्स हैं जिन्हें LLM देखता है। `"You're handsome."` लगभग 3–4 टोकन है, न कि 2 शब्द।

---

क्या आप चाहते हैं कि में आपको दिखाऊं **अपने स्वयं के टेक्स्ट (जैसे ट्रांस्क्रिप्ट्स, निबंध, कोड) के साथ टोकन कैसे गिनें** ताकि आप API को कॉल करने से पहले लागत/सीमा देख सकें?