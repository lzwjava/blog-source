---
audio: false
generated: false
lang: hi
layout: post
title: मशीन लर्निंग का परिचय
translated: true
---

चूंकि हम `Python` सीख रहे हैं, तो मशीन लर्निंग के बारे में भी जरूर बात करेंगे। क्योंकि इसके कई लाइब्रेरीज़ Python में लिखे गए हैं। शुरुआत में उन्हें इंस्टॉल करके थोड़ा सा खेलेंगे।

## Tensorflow

इसे इंस्टॉल करें।

```shell
$ pip install tensorflow
ERROR: Could not find a version that satisfies the requirement tensorflow
ERROR: No matching distribution found for tensorflow
```

(यह त्रुटि संदेश बताता है कि TensorFlow का कोई संगत संस्करण नहीं मिला है।)

```shell
$ type python
python को `/usr/local/Cellar/python@3.9/3.9.1_6/bin/python3' के रूप में एलियास किया गया है
```

हालांकि, `Tensorflow 2` केवल `Python 3.5–3.8` को सपोर्ट करता है। हम `3.9` का उपयोग कर रहे हैं।

```shell
 % type python3
python3 /usr/bin/python3 में है
% python3 -V
Python 3.8.2
```

मैंने देखा कि मेरे सिस्टम में `python3` का संस्करण `3.8.2` है। यह Python संस्करण के लिए `pip` कहाँ स्थापित है?

```shell
% python3 -m pip -V
pip 21.0.1 from /Users/lzw/Library/Python/3.8/lib/python/site-packages/pip (python 3.8)
```

संबंधित `pip` यहाँ है। तो मैं `.zprofile` फ़ाइल में थोड़ा बदलाव करूँगा। हाल ही में मैंने अपना `shell` बदला है। `.zprofile` पहले के `.bash_profile` के समान है। इसमें एक लाइन जोड़ दें।

```shell
alias pip3=/Users/lzw/Library/Python/3.8/bin/pip3
```

(यह कोड ब्लॉक है, इसे अनुवादित नहीं किया जाना चाहिए।)

इस तरह, हम `Tensorflow` को खेलने के लिए `python3` और `pip3` का उपयोग करते हैं।

```shell
% pip3 install tensorflow
...
सफलतापूर्वक स्थापित किया गया absl-py-0.12.0 astunparse-1.6.3 cachetools-4.2.1 certifi-2020.12.5 chardet-4.0.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.27.1 google-auth-oauthlib-0.4.3 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 idna-2.10 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.15.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.3 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1
```

बहुत सारे लाइब्रेरी इंस्टॉल किए। वेबसाइट के एक उदाहरण का उपयोग किया।

```python
import tensorflow as tf
```

```python
mnist = tf.keras.datasets.mnist
```

```python
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
```

यह कोड MNIST डेटासेट को लोड करता है और ट्रेनिंग और टेस्टिंग डेटा को 0 से 1 के बीच स्केल करता है। `x_train` और `x_test` में इमेज डेटा होता है, जबकि `y_train` और `y_test` में उनके संबंधित लेबल होते हैं। इमेज डेटा को 255.0 से विभाजित करके, पिक्सेल मान 0 से 1 के बीच स्केल हो जाते हैं, जो न्यूरल नेटवर्क के लिए अधिक उपयुक्त होता है।

```python
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])
```

यह कोड TensorFlow के `Sequential` मॉडल का उपयोग करके एक न्यूरल नेटवर्क बनाता है। यह मॉडल 28x28 आकार के इनपुट डेटा को समतल (Flatten) करता है, फिर 128 न्यूरॉन्स वाला एक घना (Dense) लेयर जोड़ता है जिसमें ReLU एक्टिवेशन फंक्शन का उपयोग किया जाता है। इसके बाद, 20% ड्रॉपआउट लेयर जोड़ा जाता है, और अंत में 10 न्यूरॉन्स वाला एक और घना लेयर जोड़ा जाता है।

```python
predictions = model(x_train[:1]).numpy()
print(predictions)
```

यह कोड मॉडल का उपयोग करके `x_train` डेटासेट के पहले नमूने के लिए भविष्यवाणियाँ (predictions) करता है और उन्हें NumPy ऐरे के रूप में प्रिंट करता है।

```

चलाएं।

```shell
$ /usr/bin/python3 tf.py
डेटा डाउनलोड हो रहा है https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz से
11493376/11490434 [==============================] - 10s 1us/step
[[ 0.15477428 -0.3877643   0.0994779   0.07474922 -0.26219758 -0.03550266
   0.32226565 -0.37141111  0.10925996 -0.0115255 ]]
```

डेटासेट डाउनलोड हो गया है, और फिर परिणाम प्रदर्शित किया गया है।

अगले चरण में, चित्र वर्गीकरण के उदाहरण पर नजर डालते हैं।

```python
# TensorFlow और tf.keras
import tensorflow as tf
```

# सहायक लाइब्रेरीज़
import numpy as np
import matplotlib.pyplot as plt

```python
print(tf.__version__)
```

त्रुटि।

```shell
ModuleNotFoundError: 'matplotlib' नामक कोई मॉड्यूल नहीं मिला
```

इसे इंस्टॉल करें।

```shell
% pip3 install matplotlib
```

ठीक है।

```shell
$ /usr/bin/python3 image.py
2.4.1
```

कॉपी और पेस्ट उदाहरण कोड।

```python
# TensorFlow और tf.keras
import tensorflow as tf
```

# सहायक लाइब्रेरीज़
import numpy as np
import matplotlib.pyplot as plt

```python
fashion_mnist = tf.keras.datasets.fashion_mnist
```

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

```python
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
print(train_images.shape)
print(len(train_labels))
```

यहाँ परिणाम प्रदर्शित किया गया है। ध्यान दें कि यहाँ `train_images`, `train_labels`, `test_images`, `test_labels` हैं। यह डेटा को प्रशिक्षण डेटासेट और परीक्षण डेटासेट में विभाजित करता है।

```shell
(60000, 28, 28)
60000
```

यह कोड ब्लॉक एक NumPy ऐरे के आकार को दर्शाता है। पहली लाइन `(60000, 28, 28)` एक 3D ऐरे का आकार दिखाती है, जिसमें 60,000 इमेज हैं और प्रत्येक इमेज का आकार 28x28 पिक्सेल है। दूसरी लाइन `60000` सिर्फ 60,000 का मान दिखाती है, जो संभवतः ऐरे में इमेज की कुल संख्या है।

अब चलिए, छवि को प्रिंट करने का प्रयास करते हैं।

```python
print(train_images[0])
```

परिणाम देखें।

```shell
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0
    0   1   4   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62
   54   0   0   0   1   3   4   0   0   3]
 [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134
  144 123  23   0   0   0   0  12  10   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178
  107 156 161 109  64  23  77 130  72  15]
 [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216
  216 163 127 121 122 146 141  88 172  66]]
  ....
```

यहां कुछ परिणामों का अंश दिया गया है।

```python
print(len(train_images[0][0]))
```

यह कोड Python में लिखा गया है और यह `train_images` नामक सूची के पहले तत्व के पहले तत्व की लंबाई (length) प्रिंट करता है। यह कोड हिंदी में अनुवाद नहीं किया जा सकता क्योंकि यह एक प्रोग्रामिंग भाषा का कोड है और इसे समझने के लिए Python की समझ आवश्यक है।

आउटपुट `28` है। तो यह स्पष्ट है कि यह एक 28 की चौड़ाई वाला मैट्रिक्स है। प्रिंट करना जारी रखें।

```python
    print(len(train_images[0][0][0])
TypeError: 'numpy.uint8' प्रकार की वस्तु में len() नहीं है
```

तो यह बहुत स्पष्ट है। प्रत्येक छवि एक `28*28*3` का सरणी है। अंतिम आयाम सरणी में rgb मान संग्रहीत होते हैं। हालांकि, हमें पता चला कि हमारा विचार गलत हो सकता है।

```python
print(train_images[0][1][20])
```

(नोट: कोड ब्लॉक को अनुवादित नहीं किया जाता है, क्योंकि यह प्रोग्रामिंग कोड है और इसे हिंदी में अनुवादित करने की आवश्यकता नहीं है।)

```shell
0
```

```python
print(train_images[0][1])
```

(यह कोड ब्लॉक को हिंदी में अनुवाद करने की आवश्यकता नहीं है क्योंकि यह एक प्रोग्रामिंग कोड है और इसे अपरिवर्तित छोड़ दिया जाना चाहिए।)

```shell
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
```

प्रत्येक छवि 28*28 के सरणी (array) के रूप में है। कुछ समय तक प्रयास करने के बाद, हमने अंततः रहस्य जान लिया।

पहले आउटपुट ग्राफ़ को देखें।

```python
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()
```

(यह कोड ब्लॉक को हिंदी में अनुवाद करने की आवश्यकता नहीं है क्योंकि यह प्रोग्रामिंग कोड है और इसे अपरिवर्तित छोड़ा जाना चाहिए।)

<img src="/assets/images/ml/tf.png" alt="tf" style="zoom:30%;" />

क्या आप दाईं ओर के रंग बार को देख रहे हैं? `0` से `250` तक। यह वास्तव में दो रंगों के बीच का ग्रेडिएंट है। लेकिन यह कैसे जानता है कि ये दो रंग कौन से हैं? हमने इसे कहाँ बताया है?

फिर हम दूसरी छवि को भी प्रिंट करते हैं।

```python
plt.imshow(train_images[1])
```

(यह कोड ब्लॉक में है और इसे अनुवादित नहीं किया जाना चाहिए। यह Python कोड है जो `train_images` सूची में दूसरी इमेज को प्रदर्शित करता है।)

<img src="/assets/images/ml/plt.png" alt="plt" style="zoom:30%;" />

बहुत दिलचस्प है। क्या यह `pyplot` डिपेंडेंसी लाइब्रेरी का डिफ़ॉल्ट व्यवहार है? चलिए, अब ऑफिशियल वेबसाइट द्वारा प्रदान किए गए कोड को चलाते हैं।

```python
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()
```

यह कोड एक 5x5 ग्रिड में 25 छवियों को प्रदर्शित करता है। प्रत्येक छवि के नीचे उसकी संबंधित लेबल (श्रेणी का नाम) दिखाया जाता है। `plt.xticks([])` और `plt.yticks([])` का उपयोग करके x और y अक्ष के टिक्स को हटा दिया जाता है, और `plt.grid(False)` का उपयोग करके ग्रिड को अक्षम किया जाता है। `plt.imshow()` का उपयोग करके छवि को दिखाया जाता है, और `plt.xlabel()` का उपयोग करके छवि के नीचे लेबल जोड़ा जाता है। अंत में, `plt.show()` का उपयोग करके प्लॉट को प्रदर्शित किया जाता है।

<img src="/assets/images/ml/tf2.png" alt="tf2" style="zoom:20%;" />

यहाँ ध्यान दें कि चित्र और उनके वर्गीकरण दिखाए गए हैं। अंत में हमें `cmp` पैरामीटर के बारे में पता चला। यदि `cmp` में कुछ नहीं लिखा जाए, तो यह निश्चित रूप से हमारे द्वारा देखे गए रंग का होगा। वास्तव में।

```shell
    plt.imshow(train_images[i])
```

<img src="/assets/images/ml/cmap.png" alt="cmap" style="zoom:20%;" />

इस बार हम `pyplot cmap` को खोजते हैं। कुछ संसाधन मिलते हैं।

```shell
    plt.imshow(train_images[i], cmap=plt.cm.PiYG)
```

<img src="/assets/images/ml/cmap1.png" alt="cmap1" style="zoom:20%;" />

कोड को संशोधित करें।
```python
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)   ## इस लाइन को बदलें
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.Blues)
    plt.xlabel(class_names[train_labels[i]])
plt.show()
```

हालांकि, एक त्रुटि आई।

```shell
ValueError: num 1 <= num <= 10 के बीच होना चाहिए, 11 नहीं
```

यह क्या मतलब है। पहले का `5,5,i+1` आखिर क्या मतलब है। इसे `2` क्यों नहीं बदला जा सकता। हालांकि हम सहज रूप से जानते हैं कि यह शायद 5 पंक्तियों और 5 स्तंभों का मतलब है। लेकिन यह त्रुटि क्यों आई। `11` की गणना कैसे की गई। `num` का क्या मतलब है। `10` का क्या मतलब है। ध्यान दें कि `2*5=10`। तो शायद जब `i=11` होता है तो त्रुटि होती है। जब इसे `for i in range(10):` में बदला गया, तो निम्नलिखित परिणाम प्राप्त हुए।

<img src="/assets/images/ml/plot3.png" alt="plot3" style="zoom:20%;" />

यहां हम थोड़ा सा दस्तावेज़ीकरण देखेंगे और पता चलेगा कि `subplot(nrows, ncols, index, **kwargs)` है। हां, यहां तक हमें बहुत स्पष्ट हो गया है।

```python
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    # plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.Blues)
    plt.xlabel(class_names[train_labels[i]])
plt.show()
```

(यह कोड ब्लॉक को हिंदी में अनुवाद करने की आवश्यकता नहीं है क्योंकि यह प्रोग्रामिंग कोड है और इसे अपरिवर्तित छोड़ दिया जाना चाहिए।)

<img src="/assets/images/ml/plot_xticks.png" alt="plot_xticks" style="zoom:30%;" />

ध्यान दें कि `0 25` जैसे नंबरों को `xticks` कहा जाता है। जब हम इस बॉक्स को ज़ूम इन या ज़ूम आउट करते हैं, तो यह अलग-अलग तरीके से दिखाई देता है।

![plot_scale](assets/images/ml/plot_scale.png)

ध्यान दें कि जब आप ज़ूम इन और ज़ूम आउट करते हैं, तो `xticks` और `xlabels` अलग-अलग तरीके से प्रदर्शित हो सकते हैं।

```python
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])
```

```python
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

यह कोड TensorFlow के मॉडल को कंपाइल करने के लिए उपयोग किया जाता है। इसमें:

- `optimizer='adam'` का उपयोग करके Adam ऑप्टिमाइज़र को सेट किया गया है।
- `loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)` का उपयोग करके स्पार्स कैटेगोरिकल क्रॉसएन्ट्रॉपी लॉस फ़ंक्शन को सेट किया गया है, जो लॉगिट्स से सीधे काम करता है।
- `metrics=['accuracy']` का उपयोग करके मॉडल की परफॉर्मेंस को मापने के लिए एक्यूरेसी मेट्रिक को सेट किया गया है।

model.fit(train_images, train_labels, epochs=10)

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)

```python
print('\nटेस्ट सटीकता:', test_acc)
```

यहाँ मॉडल को परिभाषित करने के लिए `Sequential` क्लास का उपयोग किया गया है। इन पैरामीटर्स पर ध्यान दें: `28,28`, `128`, `relu`, `10`। ध्यान दें कि `compile` और `fit` की आवश्यकता है। `fit` का अर्थ है फिट करना। ध्यान दें कि `28,28` इमेज का आकार है।

```shell
Epoch 1/10
1875/1875 [==============================] - 2s 928us/step - loss: 0.6331 - accuracy: 0.7769
Epoch 2/10
1875/1875 [==============================] - 2s 961us/step - loss: 0.3860 - accuracy: 0.8615
Epoch 3/10
1875/1875 [==============================] - 2s 930us/step - loss: 0.3395 - accuracy: 0.8755
Epoch 4/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.3071 - accuracy: 0.8890
Epoch 5/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2964 - accuracy: 0.8927
Epoch 6/10
1875/1875 [==============================] - 2s 985us/step - loss: 0.2764 - accuracy: 0.8955
Epoch 7/10
1875/1875 [==============================] - 2s 961us/step - loss: 0.2653 - accuracy: 0.8996
Epoch 8/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2549 - accuracy: 0.9052
Epoch 9/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2416 - accuracy: 0.9090
Epoch 10/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2372 - accuracy: 0.9086
313/313 - 0s - loss: 0.3422 - accuracy: 0.8798
```

टेस्ट सटीकता: 0.879800021648407
```

मॉडल को प्रशिक्षित कर लिया गया है। अब पैरामीटर्स को बदलने का समय है।

```shell
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(28, activation='relu'),    # 128 -> 28
    tf.keras.layers.Dense(10)
])
```

`Dense` के पहले पैरामीटर को संशोधित करें।

```shell
Epoch 1/10
1875/1875 [==============================] - 2s 714us/step - loss: 6.9774 - accuracy: 0.3294
Epoch 2/10
1875/1875 [==============================] - 1s 715us/step - loss: 1.3038 - accuracy: 0.4831
Epoch 3/10
1875/1875 [==============================] - 1s 747us/step - loss: 1.0160 - accuracy: 0.6197
Epoch 4/10
1875/1875 [==============================] - 1s 800us/step - loss: 0.7963 - accuracy: 0.6939
Epoch 5/10
1875/1875 [==============================] - 2s 893us/step - loss: 0.7006 - accuracy: 0.7183
Epoch 6/10
1875/1875 [==============================] - 1s 747us/step - loss: 0.6675 - accuracy: 0.7299
Epoch 7/10
1875/1875 [==============================] - 1s 694us/step - loss: 0.6681 - accuracy: 0.7330
Epoch 8/10
1875/1875 [==============================] - 1s 702us/step - loss: 0.6675 - accuracy: 0.7356
Epoch 9/10
1875/1875 [==============================] - 1s 778us/step - loss: 0.6508 - accuracy: 0.7363
Epoch 10/10
1875/1875 [==============================] - 1s 732us/step - loss: 0.6532 - accuracy: 0.7350
313/313 - 0s - loss: 0.6816 - accuracy: 0.7230
```

टेस्ट सटीकता: 0.7229999899864197
```

ध्यान दें कि `Test accuracy` में पहले और बाद में परिवर्तन हुआ है। `Epoch` जैसी चीज़ें `fit` फ़ंक्शन द्वारा आउटपुट किए गए लॉग हैं। ध्यान दें कि जब `128` था, तो `accuracy` `0.7769` से `0.9086` तक बदल गई। और जब `28` था, तो `accuracy` `0.3294` से `0.7350` तक बदल गई। यह ध्यान देने योग्य है कि हम पहले ट्रेनिंग डेटासेट का उपयोग करके `loss` और `accuracy` को ऑप्टिमाइज़ करते हैं। फिर टेस्ट डेटासेट का उपयोग करके टेस्ट करते हैं। पहले `train_labels` को देखते हैं।

```python
print(train_labels)
[9 0 0 ... 3 0 5]
print(len(train_labels))
60000
```

यह कोड `train_labels` को प्रिंट करता है, जो एक सरणी है जिसमें संख्याएँ हैं। यह सरणी प्रशिक्षण डेटा के लेबल को दर्शाती है। दूसरी लाइन में, `len(train_labels)` का उपयोग करके `train_labels` सरणी की लंबाई प्रिंट की जाती है, जो 60000 है।

इसका मतलब है कि इन श्रेणियों को `0 से 9` तक के नंबरों से दर्शाया जाएगा। संयोग से `class_names` में भी 10 आइटम हैं।

```shell
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
```

फिर से इसे संशोधित करें।

```python
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(28, activation='relu'),
    tf.keras.layers.Dense(5)   # 10 -> 5
])
```

यह कोड TensorFlow के `tf.keras` API का उपयोग करके एक सरल न्यूरल नेटवर्क मॉडल बनाता है। मॉडल में तीन लेयर्स हैं:

1. **Flatten Layer**: यह लेयर 28x28 आकार के इनपुट डेटा को एक सपाट (flatten) वेक्टर में बदल देती है, जिसका आकार 784 होगा।
2. **Dense Layer**: यह एक पूरी तरह से जुड़ी हुई (fully connected) लेयर है जिसमें 28 न्यूरॉन्स हैं और यह ReLU एक्टिवेशन फंक्शन का उपयोग करती है।
3. **Dense Layer**: यह दूसरी पूरी तरह से जुड़ी हुई लेयर है जिसमें 5 न्यूरॉन्स हैं। यह लेयर किसी भी एक्टिवेशन फंक्शन का उपयोग नहीं करती है, जिसका अर्थ है कि यह रैखिक (linear) आउटपुट प्रदान करती है।

मॉडल का आउटपुट 5 क्लासेस के लिए होगा, जो पहले के 10 क्लासेस से बदलकर 5 कर दिया गया है।

```python
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

यह कोड TensorFlow के मॉडल को कंपाइल करने के लिए है। इसमें `adam` ऑप्टिमाइज़र का उपयोग किया गया है, जो मॉडल को ट्रेन करने के लिए एक लोकप्रिय ऑप्टिमाइज़र है। `loss` फ़ंक्शन के रूप में `SparseCategoricalCrossentropy` का उपयोग किया गया है, जो क्लासिफिकेशन प्रॉब्लम्स के लिए उपयुक्त है, और `from_logits=True` सेट किया गया है क्योंकि मॉडल के आउटपुट लॉगिट्स हैं। `metrics` में `accuracy` का उपयोग किया गया है, जो मॉडल के प्रदर्शन को मापने के लिए एक सामान्य मीट्रिक है।

```python
model.fit(train_images, train_labels, epochs=10)
```

यह कोड TensorFlow या Keras में एक मॉडल को प्रशिक्षित करने के लिए उपयोग किया जाता है। यह `train_images` और `train_labels` डेटा का उपयोग करके मॉडल को 10 epochs (युग) तक प्रशिक्षित करता है। प्रत्येक epoch में, मॉडल पूरे प्रशिक्षण डेटा पर एक बार पास करता है और अपने वजन (weights) को अपडेट करता है।

गलती हो गई।

```shell
tensorflow.python.framework.errors_impl.InvalidArgumentError:  लेबल का मान 9 प्राप्त हुआ है जो [0, 5) के वैध सीमा से बाहर है।  लेबल मान: 4 3 2 9 4 1 6 0 7 9 1 6 5 2 3 8 6 3 8 0 3 5 6 1 2 6 3 6 8 4 8 4
         [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at /curiosity-courses/ml/tf/image.py:53) ]] [Op:__inference_train_function_538]
```

फ़ंक्शन कॉल स्टैक:
train_function
```

`Sequential` के तीसरे पैरामीटर `Dense` का पैरामीटर `15` में बदल दें। परिणाम में ज्यादा अंतर नहीं होगा। `Epoch` को बदलकर देखें।

```python
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(28, activation='relu'),
    tf.keras.layers.Dense(15)
])
```

यह कोड TensorFlow के `tf.keras` API का उपयोग करके एक सरल न्यूरल नेटवर्क मॉडल बनाता है। इस मॉडल में तीन लेयर्स हैं:

1. **Flatten Layer**: यह लेयर 28x28 आकार के इनपुट डेटा को एक 784-आयामी वेक्टर में समतल (flatten) करती है।
2. **Dense Layer (28 न्यूरॉन्स)**: यह एक घनी (dense) लेयर है जिसमें 28 न्यूरॉन्स हैं और 'relu' एक्टिवेशन फंक्शन का उपयोग किया गया है।
3. **Dense Layer (15 न्यूरॉन्स)**: यह एक और घनी लेयर है जिसमें 15 न्यूरॉन्स हैं। इस लेयर में कोई एक्टिवेशन फंक्शन नहीं है, जिसका अर्थ है कि यह रैखिक (linear) आउटपुट देगी।

यह मॉडल आमतौर पर छवि वर्गीकरण (image classification) जैसे कार्यों के लिए उपयोग किया जाता है।

```python
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

यह कोड TensorFlow के मॉडल को कंपाइल करने के लिए उपयोग किया जाता है। इसमें:

- **optimizer='adam'**: मॉडल को ट्रेन करने के लिए Adam ऑप्टिमाइज़र का उपयोग किया जाता है।
- **loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)**: लॉस फ़ंक्शन के रूप में Sparse Categorical Crossentropy का उपयोग किया जाता है, जो लॉगिट्स से सीधे काम करता है।
- **metrics=['accuracy']**: मॉडल के प्रदर्शन को मापने के लिए सटीकता (accuracy) मेट्रिक का उपयोग किया जाता है।

```python
model.fit(train_images, train_labels, epochs=15)  # 10 -> 15
```

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)

```python
print('\nपरीक्षण सटीकता:', test_acc)
```

```shell
Epoch 1/15
1875/1875 [==============================] - 2s 892us/step - loss: 6.5778 - accuracy: 0.3771
Epoch 2/15
1875/1875 [==============================] - 2s 872us/step - loss: 1.3121 - accuracy: 0.4910
Epoch 3/15
1875/1875 [==============================] - 2s 909us/step - loss: 1.0900 - accuracy: 0.5389
Epoch 4/15
1875/1875 [==============================] - 1s 730us/step - loss: 1.0422 - accuracy: 0.5577
Epoch 5/15
1875/1875 [==============================] - 1s 709us/step - loss: 0.9529 - accuracy: 0.5952
Epoch 6/15
1875/1875 [==============================] - 1s 714us/step - loss: 0.9888 - accuracy: 0.5950
Epoch 7/15
1875/1875 [==============================] - 1s 767us/step - loss: 0.8678 - accuracy: 0.6355
Epoch 8/15
1875/1875 [==============================] - 1s 715us/step - loss: 0.8247 - accuracy: 0.6611
Epoch 9/15
1875/1875 [==============================] - 1s 721us/step - loss: 0.8011 - accuracy: 0.6626
Epoch 10/15
1875/1875 [==============================] - 1s 711us/step - loss: 0.8024 - accuracy: 0.6622
Epoch 11/15
1875/1875 [==============================] - 1s 781us/step - loss: 0.7777 - accuracy: 0.6696
Epoch 12/15
1875/1875 [==============================] - 1s 724us/step - loss: 0.7764 - accuracy: 0.6728
Epoch 13/15
1875/1875 [==============================] - 1s 731us/step - loss: 0.7688 - accuracy: 0.6767
Epoch 14/15
1875/1875 [==============================] - 1s 715us/step - loss: 0.7592 - accuracy: 0.6793
Epoch 15/15
1875/1875 [==============================] - 1s 786us/step - loss: 0.7526 - accuracy: 0.6792
313/313 - 0s - loss: 0.8555 - accuracy: 0.6418
```

टेस्ट सटीकता: 0.6417999863624573
```

ध्यान दें कि इसे 15 में बदल दिया गया है। अंतर भी ज्यादा नहीं है। `tf.keras.layers.Dense(88, activation='relu'),` महत्वपूर्ण है। 128 को 88 में बदलने का प्रयास करें। `Test accuracy: 0.824999988079071` प्राप्त हुआ। 128 पर, यह `0.879800021648407` था। 28 पर, यह `0.7229999899864197` था। क्या यह जितना बड़ा होगा उतना ही बेहतर होगा, हालांकि जब इसे `256` में बदला गया, तो यह `Test accuracy: 0.8409000039100647` था। यह हमें `loss` और `accuracy` के अर्थ के बारे में सोचने पर मजबूर करता है।

```python
probability_model = tf.keras.Sequential([model, 
                                         tf.keras.layers.Softmax()])
```

(यह कोड ब्लॉक है, इसे अनुवादित नहीं किया जाना चाहिए।)

अगला, भविष्यवाणी करते हैं। ध्यान दें कि `Sequential` ऊपर की तरह ही है। पैरामीटर `model` और `tf.keras.layers.Softmax()` पर ध्यान दें।

```python
probability_model = tf.keras.Sequential([model, 
                                         tf.keras.layers.Softmax()])
predictions = probability_model.predict(test_images)
```

इस कोड को हिंदी में समझाएं:

- `probability_model` एक `tf.keras.Sequential` मॉडल है जो दो लेयर्स से बना है: पहले मॉडल (`model`) और उसके बाद एक `Softmax` लेयर।
- `Softmax` लेयर का उपयोग मॉडल के आउटपुट को प्रोबेबिलिटी (संभावना) में बदलने के लिए किया जाता है।
- `predictions` वेरिएबल में `test_images` के लिए मॉडल की प्रेडिक्शन्स स्टोर की जाती हैं। ये प्रेडिक्शन्स प्रोबेबिलिटी के रूप में होती हैं, जो यह बताती हैं कि प्रत्येक इमेज किस क्लास से संबंधित होने की संभावना है।

```python
def plot_image(i, predictions_array, true_label, img):
  true_label, img = true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
```

यह कोड एक फ़ंक्शन `plot_image` को परिभाषित करता है जो एक छवि (image) को प्लॉट करने के लिए उपयोग किया जाता है। यह फ़ंक्शन चार पैरामीटर लेता है:

1. `i`: इंडेक्स जो बताता है कि कौन सी छवि और लेबल को प्लॉट करना है।
2. `predictions_array`: एक ऐरे जिसमें मॉडल द्वारा की गई भविष्यवाणियाँ होती हैं।
3. `true_label`: एक ऐरे जिसमें छवियों के सही लेबल होते हैं।
4. `img`: एक ऐरे जिसमें छवियाँ होती हैं।

फ़ंक्शन के अंदर:
- `true_label` और `img` को इंडेक्स `i` के आधार पर चुना जाता है।
- `plt.grid(False)` ग्रिड को हटा देता है।
- `plt.xticks([])` और `plt.yticks([])` x और y अक्ष पर टिक्स को हटा देते हैं।

इस फ़ंक्शन का उपयोग छवि को बिना किसी ग्रिड या अक्ष लेबल के प्लॉट करने के लिए किया जाता है।

```python
plt.imshow(img, cmap=plt.cm.binary)
```

```python
predicted_label = np.argmax(predictions_array)
if predicted_label == true_label:
    color = 'blue'
else:
    color = 'red'
```

  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

इस कोड को हिंदी में अनुवाद करने की आवश्यकता नहीं है क्योंकि यह एक प्रोग्रामिंग कोड है और इसे मूल रूप में ही रखना चाहिए।

```python
def plot_value_array(i, predictions_array, true_label):
  true_label = true_label[i]
  plt.grid(False)
  plt.xticks(range(10))
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)
```

यह फ़ंक्शन `plot_value_array` एक बार ग्राफ़ बनाता है जो किसी विशेष इमेज के लिए मॉडल की भविष्यवाणियों (predictions) को दर्शाता है। यह ग्राफ़ 10 संभावित क्लासेस (0 से 9 तक) के लिए प्रायिकता (probability) दिखाता है। 

- `true_label` वास्तविक लेबल को दर्शाता है।
- `plt.grid(False)` ग्रिड को हटा देता है।
- `plt.xticks(range(10))` x-अक्ष पर 0 से 9 तक के नंबर दिखाता है।
- `plt.yticks([])` y-अक्ष पर कोई टिक नहीं दिखाता है।
- `plt.bar(range(10), predictions_array, color="#777777")` बार ग्राफ़ बनाता है जहां हर बार एक क्लास की प्रायिकता को दर्शाता है।
- `plt.ylim([0, 1])` y-अक्ष की सीमा को 0 से 1 तक सेट करता है।
- `predicted_label = np.argmax(predictions_array)` सबसे अधिक प्रायिकता वाले क्लास को चुनता है।

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')

```python
i = 0
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions[i], test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions[i],  test_labels)
plt.show()
```

<img src="/assets/images/ml/pred.png" alt="pred" style="zoom:50%;" />

यह दर्शाता है कि इस चित्र की 99% संभावना है कि यह `Ankle boot` है। ध्यान दें कि `plot_image` बाईं ओर का चित्र दिखाता है। `plot_value_array` दाईं ओर का चित्र प्रदर्शित करता है।

```python
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions[i], test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions[i], test_labels)
plt.tight_layout()
plt.show()
```

(यह कोड ब्लॉक को हिंदी में अनुवाद करने की आवश्यकता नहीं है क्योंकि यह प्रोग्रामिंग कोड है और इसे मूल रूप में ही रखना चाहिए।)

<img src="/assets/images/ml/pred1.png" alt="pred1" style="zoom:50%;" />

ध्यान दें कि यहां केवल अधिक परीक्षण परिणाम प्रदर्शित किए गए हैं। इसलिए उपयोग प्रक्रिया हमें काफी स्पष्ट है। इसलिए हम अभी तक नहीं जानते कि पीछे की गणना कैसे की जाती है। लेकिन हम जानते हैं कि उनका उपयोग कैसे करना है। उनके पीछे कैलकुलस है। कैलकुलस को कैसे समझें?

मान लीजिए कि एक संख्या है, 1 से 100 के बीच, और आपको उसे अनुमान लगाना है। हर बार जब आप अनुमान लगाते हैं, मैं आपको बताऊंगा कि आपका अनुमान छोटा है या बड़ा। 

- आपने 50 का अनुमान लगाया। मैंने कहा, "छोटा है।"
- आपने 80 का अनुमान लगाया। मैंने कहा, "बड़ा है।"
- आपने 65 का अनुमान लगाया। मैंने कहा, "बड़ा है।"
- आपने 55 का अनुमान लगाया। मैंने कहा, "छोटा है।"
- आपने 58 का अनुमान लगाया। मैंने कहा, "हां, सही अनुमान लगाया।"

मशीन लर्निंग, इस प्रक्रिया को पीछे से अनुकरण करने का एक तरीका है। हालांकि, यह थोड़ा जटिल होता है। इसमें कई `1 से 100` तक की संख्याएं हो सकती हैं, और कई संख्याओं का अनुमान लगाना पड़ सकता है। साथ ही, हर बार अनुमान लगाने के लिए कई गणनाएं करनी पड़ती हैं। और हर बार यह जांचने के लिए कि अनुमान बड़ा है या छोटा, कई गणनाएं करनी पड़ती हैं।



## PyTorch

इसे इंस्टॉल करें। यह `3.9` वर्जन के Python को सपोर्ट करता है।

```shell
$ pip install torch torchvision
Collecting torch
  Downloading torch-1.8.0-cp39-none-macosx_10_9_x86_64.whl (120.6 MB)
     |████████████████████████████████| 120.6 MB 224 kB/s
Collecting torchvision
  Downloading torchvision-0.9.0-cp39-cp39-macosx_10_9_x86_64.whl (13.1 MB)
     |████████████████████████████████| 13.1 MB 549 kB/s
Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from torch) (1.20.1)
Collecting typing-extensions
  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)
Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.9/site-packages (from torchvision) (8.0.1)
Installing collected packages: typing-extensions, torch, torchvision
Successfully installed torch-1.8.0 torchvision-0.9.0 typing-extensions-3.7.4.3
```

जाँच करें।

```python
import torch
x = torch.rand(5, 3)
print(x)
```

(यह कोड ब्लॉक को अनुवादित नहीं किया गया है क्योंकि यह प्रोग्रामिंग कोड है और इसे हिंदी में अनुवादित करने की आवश्यकता नहीं है।)

गलती हो गई।

```shell
Traceback (most recent call last):
  File "torch.py", line 1, in <module>
    import torch
  File "torch.py", line 2, in <module>
    x = torch.rand(5, 3)
AttributeError: आंशिक रूप से आरंभिक मॉड्यूल 'torch' में 'rand' विशेषता नहीं है (संभवतः एक चक्रीय आयात के कारण)
```

इस त्रुटि संदेश को Google पर खोजें। पता चला कि यह समस्या इसलिए हो रही थी क्योंकि हमारी फ़ाइल का नाम भी `torch` था। नाम टकरा रहा था। फ़ाइल का नाम बदलने के बाद सब ठीक हो गया।

```shell
tensor([[0.5520, 0.9446, 0.5543],
        [0.6192, 0.0908, 0.8726],
        [0.0223, 0.7685, 0.9814],
        [0.4019, 0.5406, 0.3861],
        [0.5485, 0.6040, 0.2387]])
```

एक उदाहरण ढूंढें।

```python
# -*- coding: utf-8 -*-
```

```python
import torch
import math
dtype = torch.float
device = torch.device("cpu")
# device = torch.device("cuda:0") # इसे GPU पर चलाने के लिए अनकमेंट करें
```

# यादृच्छिक इनपुट और आउटपुट डेटा बनाएं
x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)
y = torch.sin(x)

# वज़न को यादृच्छिक रूप से प्रारंभ करें
a = torch.randn((), device=device, dtype=dtype)
b = torch.randn((), device=device, dtype=dtype)
c = torch.randn((), device=device, dtype=dtype)
d = torch.randn((), device=device, dtype=dtype)

```python
learning_rate = 1e-6
for t in range(2000):
    # फॉरवर्ड पास: y का अनुमानित मान गणना करें
    y_pred = a + b * x + c * x ** 2 + d * x ** 3
```

    # हानि की गणना और प्रिंट करें
    loss = (y_pred - y).pow(2).sum().item()
    if t % 100 == 99:
        print(t, loss)

    # हानि के संबंध में a, b, c, d के ग्रेडिएंट्स की गणना करने के लिए बैकप्रॉप
    grad_y_pred = 2.0 * (y_pred - y)
    grad_a = grad_y_pred.sum()
    grad_b = (grad_y_pred * x).sum()
    grad_c = (grad_y_pred * x ** 2).sum()
    grad_d = (grad_y_pred * x ** 3).sum()

    # ग्रेडिएंट डिसेंट का उपयोग करके वज़न अपडेट करें
    a -= learning_rate * grad_a
    b -= learning_rate * grad_b
    c -= learning_rate * grad_c
    d -= learning_rate * grad_d
print(f'परिणाम: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')
```

चलाएं।

```shell
99 1273.537353515625
199 849.24853515625
299 567.4786987304688
399 380.30291748046875
499 255.92752075195312
599 173.2559814453125
699 118.2861328125
799 81.72274780273438
899 57.39331817626953
999 41.198158264160156
1099 30.41307830810547
1199 23.227672576904297
1299 18.438262939453125
1399 15.244369506835938
1499 13.113286972045898
1599 11.690631866455078
1699 10.740333557128906
1799 10.105220794677734
1899 9.6804780960083
1999 9.39621353149414
परिणाम: y = -0.011828352697193623 + 0.8360244631767273 x + 0.002040589228272438 x^2 + -0.09038365632295609 x^3
```

`numpy` लाइब्रेरी का उपयोग करके कोड देखें।

```python
# -*- coding: utf-8 -*-
import numpy as np
import math
```

# यादृच्छिक इनपुट और आउटपुट डेटा बनाएं
x = np.linspace(-math.pi, math.pi, 2000)
y = np.sin(x)

# वज़नों को यादृच्छिक रूप से प्रारंभ करें
a = np.random.randn()
b = np.random.randn()
c = np.random.randn()
d = np.random.randn()

```python
learning_rate = 1e-6
for t in range(2000):
    # फॉरवर्ड पास: y का अनुमानित मान गणना करें
    # y = a + b x + c x^2 + d x^3
    y_pred = a + b * x + c * x ** 2 + d * x ** 3
```

    # हानि की गणना और प्रिंट करें
    loss = np.square(y_pred - y).sum()
    if t % 100 == 99:
        print(t, loss)

    # Backprop का उपयोग करके loss के संबंध में a, b, c, d के gradients की गणना करें
    grad_y_pred = 2.0 * (y_pred - y)
    grad_a = grad_y_pred.sum()
    grad_b = (grad_y_pred * x).sum()
    grad_c = (grad_y_pred * x ** 2).sum()
    grad_d = (grad_y_pred * x ** 3).sum()

    # वज़न अपडेट करें
    a -= learning_rate * grad_a
    b -= learning_rate * grad_b
    c -= learning_rate * grad_c
    d -= learning_rate * grad_d

print(f'परिणाम: y = {a} + {b} x + {c} x^2 + {d} x^3')
```

ध्यान दें कि यह दो तरीके हैं जिनसे गणना की जा सकती है।

ये दो उदाहरण हैं, जहां पहले x और y का एक समूह बनाया गया है। फिर यह माना गया है कि यह एक तीसरी डिग्री का समीकरण (क्यूबिक इक्वेशन) है। इसके बाद कुछ विधियों का उपयोग करके गुणांकों (coefficients) को पुनरावृत्ति (iteration) के माध्यम से गणना की गई है। ये एल्गोरिदम कैसे काम करते हैं? ध्यान दें कि यहां 2000 बार लूप चलाया गया है, और हर बार फिटिंग थोड़ी और सटीक होती जाती है। यहां हम इसके विस्तार में नहीं जाएंगे।

## अंत में

अभी हमें मशीन लर्निंग के पीछे की गणना कैसे होती है, यह समझ में नहीं आता है। हालांकि, फिलहाल यह महत्वपूर्ण नहीं है। हम ऊपर दिए गए ज्ञान के समान ज्ञान का उपयोग करके बहुत सारे काम कर सकते हैं। हम मशीन लर्निंग का उपयोग टेक्स्ट, ऑडियो आदि को प्रोसेस करने के लिए भी कर सकते हैं। जब हम कुछ दर्जन उदाहरणों का परीक्षण कर लेंगे, तब सिद्धांत सीखना भी देर नहीं होगा।

## अभ्यास

* छात्र ऊपर दिए गए तरीके से एक्सप्लोर करें।