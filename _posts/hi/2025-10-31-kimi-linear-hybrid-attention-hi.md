---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: किमी रैखिक संकर ध्यान वास्तुकला
translated: true
type: note
---

### किमी लीनियर क्या है?

किमी लीनियर मूनशॉट एआई द्वारा विकसित एक प्रायोगिक मिश्रण-विशेषज्ञ (Mixture-of-Experts - MoE) भाषा मॉडल आर्किटेक्चर है, जो अक्टूबर 2025 के अंत में जारी किया गया। इसे अत्यधिक लंबे कॉन्टेक्स्ट (1 मिलियन टोकन तक) को उच्च दक्षता के साथ हैंडल करने के लिए डिज़ाइन किया गया है, जो इसे विस्तृत तर्क, लंबे फॉर्म जनरेशन और रीइन्फोर्समेंट लर्निंग (RL) परिदृश्यों वाले टास्क्स के लिए विशेष रूप से उपयुक्त बनाता है। यह आर्किटेक्चर MIT लाइसेंस के तहत ओपन-सोर्स किया गया है और Hugging Face पर Kimi-Linear-48B-A3B-Instruct जैसे मॉडल के रूप में उपलब्ध है।

इसके मूल में, किमी लीनियर एक **हाइब्रिड अटेंशन मैकेनिज्म** का उपयोग करता है जो इन्हें जोड़ता है:
- **किमी डेल्टा अटेंशन (KDA)**: एक लीनियर अटेंशन वेरिएंट जो गेटेड डेल्टानेट का परिष्कृत संस्करण है। KDA फाइनाइट-स्टेट RNN मेमोरी पर एक अधिक कुशल गेटिंग मैकेनिज्म का उपयोग करता है, जो कम्प्यूटेशनल ओवरहेड को काफी कम करते हुए फुल अटेंशन का अनुमान लगाने की अनुमति देता है। यह इसे जटिलता में "रैखिक" (O(N) बनाता है, जबकि सीक्वेंस लंबाई N के लिए पारंपरिक अटेंशन O(N²) होती है)।
- **मल्टीहेड लेटेंट अटेंशन (MLA)**: जटिल निर्भरताओं के बेहतर मॉडलिंग के लिए 3:1 के अनुपात (3 भाग KDA, 1 भाग MLA) में वैश्विक रूप से एकीकृत।

मॉडल में कुल 48 बिलियन पैरामीटर हैं लेकिन प्रति फॉरवर्ड पास केवल 3 बिलियन सक्रिय होते हैं (MoE डिजाइन के लिए विशिष्ट), जिन्हें 5.7 ट्रिलियन टोकन पर प्रशिक्षित किया गया है। मुख्य लाभों में शामिल हैं:
- KV कैश मेमोरी उपयोग में 75% तक की कमी।
- लंबे कॉन्टेक्स्ट के लिए डिकोडिंग थ्रूपुट में 6x तक तेजी।
- शॉर्ट-कॉन्टेक्स्ट टास्क्स, लॉन्ग-कॉन्टेक्स्ट रिट्रीवल और RL स्केलिंग लॉज के बेंचमार्क में श्रेष्ठ प्रदर्शन।

KDA कर्नेल को ओपन-सोर्स FLA लाइब्रेरी में लागू किया गया है, जिससे llama.cpp या exLlama जैसे इन्फरेंस इंजन में आसानी से एकीकृत किया जा सकता है।

### यह MLA और अन्य अटेंशन मैकेनिज्म की तुलना में कैसा है?

किमी लीनियर MLA का सीधा प्रतिस्थापन नहीं है बल्कि एक हाइब्रिड के रूप में इस पर निर्मित है, जो अल्ट्रा-लॉन्ग कॉन्टेक्स्ट में MLA की कुछ सीमाओं को संबोधित करता है। यहां एक विवरण दिया गया है:

| पहलू                     | किमी लीनियर (हाइब्रिड KDA + MLA) | MLA (मल्टीहेड लेटेंट अटेंशन) | पारंपरिक फुल अटेंशन (जैसे, MHA) |
|-------------------------|--------------------------------|----------------------------------|---------------------------------------|
| **जटिलता**         | अधिकांश लेयर्स के लिए रैखिक (O(N)); विरल वैश्विक MLA के साथ हाइब्रिड | उप-द्विघात (लेटेंट कम्प्रेशन के माध्यम से प्रभावी O(N log N)) | द्विघात (O(N²)) – लंबाई के साथ खराब स्केल करती है |
| **दक्षता (मेमोरी/थ्रूपुट)** | उत्कृष्ट: 75% कम KV कैश, 1M टोकन पर 6x तेज; कम बिट-पर-वेट पर सिंगल 24GB GPU पर फिट होता है | अच्छी: शेयर्ड लेटेंट्स के माध्यम से पैरामीटर कम करती है; किमी K2 (1T पैरामीटर) और DeepSeek-V3 में उपयोग की जाती है | खराब: लंबे सीक्वेंस के लिए मेमोरी विस्फोट; भारी ऑप्टिमाइजेशन की आवश्यकता होती है |
| **प्रदर्शन**        | शॉर्ट/लॉन्ग/RL शासनों में फुल अटेंशन से बेहतर; एजेंटिक/कोडिंग टास्क्स में मजबूत | घने मॉडलिंग में मजबूत (जैसे, पर्प्लेक्सिटी में MHA से बेहतर); मिड-रेंज कॉन्टेक्स्ट में उत्कृष्ट | बेसलाइन: सबसे अच्छी कच्ची गुणवत्ता लेकिन अक्षम; स्केलिंग में पिछड़ जाती है |
| **उपयोग के मामले**          | लॉन्ग-कॉन्टेक्स्ट (1M+ टोकन), RL, कुशल इन्फरेंस | पैरामीटर दक्षता वाले सामान्य-उद्देश्य वाले LLM (जैसे, MoE मॉडल जैसे किमी K2) | शॉर्ट कॉन्टेक्स्ट; GPT-3 जैसे लीगेसी मॉडल |
| **कमियां**          | नई आर्किटेक्चर – प्रारंभ में सीमित टूलिंग/समर्थन | हाइब्रिड्स के बिना अत्यधिक लंबाई के लिए कम इष्टतम | उच्च कम्प्यूट लागत; ट्रिक्स के बिना 1M+ टोकन के लिए व्यवहार्य नहीं |

- **MLA बनाम**: MLA (जो मूनशॉट के किमी K2 और DeepSeek-V3 में देखी गई है) क्वेरीज़/कीज़ को दक्षता के लिए लो-रैंक लेटेंट में संपीड़ित करती है, लेकिन अवशिष्ट द्विघात तत्वों के कारण यह अभी भी बहुत लंबे सीक्वेंस पर बॉटलनेक हो सकती है। किमी लीनियर अटेंशन हेड्स के 75% के लिए लीनियर KDA को शामिल करके इसे कम करता है, MLA के ग्लोबल डिपेंडेंसी मॉडलिंग को संरक्षित रखते हुए मेमोरी को कम करता है। बेंचमार्क में, हाइब्रिड लॉन्ग-कॉन्टेक्स्ट नीडल-इन-ए-हायस्टैक टास्क्स और RL ट्रेनिंग दक्षता में शुद्ध MLA सेटअप को पछाड़ता है।

- **अन्य बनाम (जैसे, MHA, RWKV जैसे लीनियर वेरिएंट)**: यह गति और पैमाने में मानक मल्टी-हेड अटेंशन (MHA) से गुणवत्ता हानि के बिना आगे निकल जाता है। शुद्ध लीनियर अटेंशन (जैसे, RWKV या बेसिक डेल्टानेट) की तुलना में, किमी लीनियर की गेटिंग परिष्कार और MLA हाइब्रिड इसे सूक्ष्म टास्क्स के लिए अधिक अभिव्यंजक बनाता है, पूरी तरह से रिकरंट लीनियर्स की "भुलक्कड़पन" से बचाता है।

कुल मिलाकर, किमी लीनियर "हाइब्रिड" अटेंशन्स की ओर एक विकास का प्रतिनिधित्व करता है, जो नेक्स्ट-जेन लॉन्ग-कॉन्टेक्स्ट मॉडल्स के लिए लीनियर स्केलेबिलिटी को लेटेंट कम्प्रेशन के साथ मिलाता है। यह विशेष रूप से ओपन-सोर्स डिप्लॉयमेंट के लिए आशाजनक है जहां हार्डवेयर बाधाएं मायने रखती हैं।

**संदर्भ**  
- [Hugging Face पर Kimi-Linear कलेक्शन](https://huggingface.co/collections/moonshotai/kimi-linear)  
- [Reddit पर Kimi Linear रिलीज पर चर्चा](https://www.reddit.com/r/LocalLLaMA/comments/1ojzekg/moonshotaikimilinear48ba3binstruct_hugging_face/)  
- [गेटेड डेल्टानेट पेपर (KDA आधार)](https://arxiv.org/abs/2412.06464)