---
audio: false
generated: true
lang: hi
layout: post
title: जॉर्जी गेर्गनोव
translated: true
type: note
---

जॉर्जी गेरगनोव, एक बल्गेरियाई डेवलपर जिनकी पृष्ठभूमि मेडिकल फिजिक्स में है, एआई को लोकतांत्रिक बनाने में एक प्रमुख व्यक्ति के रूप में उभरे हैं। उन्होंने **llama.cpp** बनाया, जो मेटा एआई के LLaMA जैसे बड़े भाषा मॉडल (एलएलएम) चलाने के लिए एक अत्यधिक कुशल C/C++ लाइब्रेरी है। उनकी यात्रा तंत्रिका नेटवर्क के बारे में संदेह के साथ शुरू हुई, लेकिन उनकी तकनीकी जिज्ञासा और अनुकूलन की कुशलता ने ऑन-डिवाइस एआई इनफेरेंस में अभूतपूर्व योगदान दिया।

### पृष्ठभूमि और प्रारंभिक कार्य
- **शिक्षा और उपलब्धियाँ**: गेरगनोव ने सोफिया विश्वविद्यालय के भौतिकी संकाय में अध्ययन किया, जहाँ उन्होंने मेडिकल फिजिक्स में विशेषज्ञता हासिल की। उन्होंने 2006 के अंतर्राष्ट्रीय भौतिकी ओलंपियाड में रजत पदक और बल्गेरियाई सॉफ्टवेयर कंपनियों के संघ द्वारा आयोजित 2008 की एक प्रोग्रामिंग प्रतियोगिता जीतकर अपनी प्रारंभिक प्रतिभा का प्रदर्शन किया।
- **एआई के प्रारंभिक संदेह**: 2022 से पहले, गेरगनोव स्व-वर्णित "गैर-एआई-विश्वासी" थे, जो तकनीक के प्रति रूढ़िवादी दृष्टिकोण को तरजीह देते हुए, तंत्रिका नेटवर्क की क्षमता के बारे में संदेहास्पद थे।
- **Whisper.cpp**: उनकी पहली बड़ी एआई परियोजना **whisper.cpp** (2022) थी, जो ओपनएआई के व्हिस्पर, एक स्पीच-टू-टेक्स्ट मॉडल का एक C/C++ पोर्ट था। यह परियोजना, अच्छे समय और भाग्य से प्रेरित होकर, व्हिस्पर को सीपीयू पर चलाने के लिए अनुकूलित की गई, जिससे यह जीपीयू के बिना डिवाइस, जैसे लैपटॉप या यहाँ तक कि स्मार्टफोन पर भी सुलभ हो गई। यह कुशल ऑडियो ट्रांसक्रिप्शन और अनुवाद सक्षम करने के लिए लोकप्रिय हुई।

### llama.cpp का जन्म
- **संदर्भ**: फरवरी 2023 में, मेटा एआई ने LLaMA जारी किया, शोध के लिए कुशल एलएलएम (7B से 65B पैरामीटर) का एक परिवार, लेकिन उन्हें चलाने के लिए महत्वपूर्ण कम्प्यूटेशनल संसाधनों, आमतौर पर जीपीयू की आवश्यकता होती थी।
- **चुनौती**: whisper.cpp की सफलता से प्रेरित होकर, गेरगनोव ने LLaMA को उपभोक्ता हार्डवेयर, विशेष रूप से एक MacBook पर चलाने का लक्ष्य रखा, "सिर्फ मजे के लिए"। मार्च 2023 में, उन्होंने **llama.cpp** विकसित किया, जो LLaMA के इनफेरेंस कोड का एक न्यूनतम C/C++ कार्यान्वयन था, जिसमें कोई बाहरी निर्भरताएँ नहीं थीं।
- **मुख्य नवाचार**: गेरगनोव ने अपनी **GGML** (जॉर्जी गेरगनोव मॉडल लैंग्वेज) लाइब्रेरी का लाभ उठाया, जो एक C-आधारित टेंसर बीजगणित फ्रेमवर्क था जिसकी शुरुआत उन्होंने सितंबर 2022 में फैब्रिस बेलार्ड के LibNC से प्रेरित होकर की थी। GGML ने सख्त मेमोरी प्रबंधन और मल्टी-थ्रेडिंग पर जोर दिया, जिससे कुशल CPU-आधारित इनफेरेंस सक्षम हुआ।
- **क्वांटिज़ेशन सफलता**: llama.cpp का एक मुख्य फीचर 4-बिट क्वांटिज़ेशन था, जो मेमोरी उपयोग को कम करने और इनफेरेंस की गति बढ़ाने के लिए मॉडल वेट को संपीड़ित करता है, जिससे सटीकता में न्यूनतम हानि (जैसे, 4-बिट पर केवल 4% पर्प्लेक्सिटी वृद्धि) होती है। इसने 7B LLaMA मॉडल को 4GB रैम जितने कम वाले डिवाइस, जिनमें Android फोन और Raspberry Pi शामिल हैं, पर चलाना संभव बना दिया।

### प्रभाव और विकास
- **सुलभता**: llama.cpp ने एलएलएम को विशेष हार्डवेयर के बिना शौकीनों और डेवलपर्स के लिए सुलभ बना दिया। यह MacBooks, Pixel फोन, और यहाँ तक कि Raspberry Pi 4s पर भी चल सकता था (हालाँकि धीमी गति से, ~1 टोकन/सेकंड)। इसने प्रयोगों की एक लहर शुरू कर दी, जहाँ हैकर्स और शोधकर्ताओं ने LLaMA को विविध प्लेटफॉर्म पर चलाया।
- **समुदाय और पैमाना**: इस परियोजना ने जबरदस्त लोकप्रियता हासिल की, जिसने 69,000 से अधिक GitHub सितारे, 2,600+ रिलीज़, और 900+ योगदानकर्ता जुटाए। इसके ओपन-सोर्स स्वभाव और सरलता (जैसे, एक सिंगल C++ फाइल में CUDA बैकेंड) ने सहयोग को बढ़ावा दिया, जिसमें AMD डिवाइस के लिए ROCm सपोर्ट और MPI के माध्यम से वितरित इनफेरेंस जैसी सुविधाएँ शामिल हैं।
- **GGUF फॉर्मेट**: अगस्त 2023 में, गेरगनोव ने **GGUF** (GGML यूनिवर्सल फाइल) फॉर्मेट पेश किया, जो GGML का उत्तराधिकारी था। GGUF ने मॉडल वेट, मेटाडेटा, और टोकन को एक सिंगल बाइनरी फाइल में समेकित किया, जो 2-बिट से 8-बिट क्वांटिज़ेशन का समर्थन करता है और पिछड़े संगतता सुनिश्चित करता है। इसने मॉडल स्टोरेज और लोडिंग को और अनुकूलित किया।
- **मल्टीमॉडल सपोर्ट**: अक्टूबर 2023 तक, llama.cpp ने LLaVA जैसे मल्टीमॉडल मॉडल के लिए सपोर्ट जोड़ा, जिससे इसका दायरा टेक्स्ट से आगे विजन-आधारित कार्यों तक विस्तृत हो गया।

### तकनीकी योगदान
- **अनुकूलन तकनीकें**: गेरगनोव द्वारा SIMD वेक्टर निर्देशों (जैसे, AVX2/AVX-512) के उपयोग ने मैट्रिक्स ऑपरेशन के लिए सीपीयू को "मिनी-जीपीयू" में बदल दिया, जिससे प्रदर्शन बढ़ा। एप्पल सिलिकॉन पर उनके बेंचमार्क ने एलएलएम इनफेरेंस के लिए इसके मेमोरी बैंडविड्थ लाभों को उजागर किया।
- **दार्शनिक बदलाव**: Llama.cpp ने एआई प्रतिस्पर्धा को कच्चे मॉडल प्रदर्शन से हटाकर अनुकूलन और सुलभता की ओर मोड़ दिया, जिससे स्थानीय इनफेरेंस सक्षम हुआ और क्लाउड-आधारित जीपीयू पर निर्भरता कम हुई।
- **एज एआई**: यह परियोजना ऑन-डिवाइस एआई के विजन के साथ संरेखित हुई, जहाँ छह Raspberry Pi पर वितरित 65B LLaMA इनफेरेंस जैसे प्रयोगों ने कम लागत वाले, विकेंद्रीकृत एआई के लिए इसकी क्षमता प्रदर्शित की।

### व्यापक प्रभाव
- **ggml.ai**: गेरगनोव ने GGML और llama.cpp के विकास का समर्थन करने के लिए नैट फ्रीडमैन और डैनियल ग्रॉस द्वारा समर्थित **ggml.ai** की स्थापना की। कंपनी ऑन-डिवाइस इनफेरेंस को आगे बढ़ाने के लिए योगदानकर्ताओं को नियुक्त करती है।
- **सांस्कृतिक प्रभाव**: एक्स पर "यूरोपीय अल्फा कोडर" कहलाने वाले गेरगनोव के तेजी से विकास (जैसे, एक शाम में llama.cpp को हैक करना) और ओपन-सोर्स आचार-विचार ने उन्हें एआई समुदाय में एक लोक नायक बना दिया। उनके काम ने स्टेबल डिफ्यूजन के ओपन रिलीज़ के साथ तुलना को प्रेरित किया, जिसने एलएलएम के लिए एक "स्टेबल डिफ्यूजन मोमेंट" चिह्नित किया।
- **लोकतंत्रीकरण**: उपभोक्ता डिवाइस पर एलएलएम चलाना संभव बनाकर, llama.cpp ने एआई प्रयोग के लिए बाधाओं को कम किया, जिससे एज एआई में नवाचार को बढ़ावा मिला और जीपीयू-केंद्रित फ्रेमवर्क के वर्चस्व को चुनौती दी गई।

### संक्षेप में कहानी
जॉर्जी गेरगनोव की llama.cpp के साथ कहानी तकनीकी सरलता और अनुकूल समय का लाभ उठाने की है। एक एआई संशयवादी के रूप में शुरुआत करते हुए, उन्होंने उस समय का लाभ उठाया जब LLaMA जारी किया गया था, और C/C++ और टेंसर अनुकूलन में अपनी विशेषज्ञता को लागू करके अत्याधुनिक एलएलएम को रोजमर्रा के हार्डवेयर पर चलाना संभव बनाया। llama.cpp के माध्यम से, उन्होंने न केवल एक तकनीकी चुनौती का समाधान किया बल्कि सुलभ, स्थानीय एआई की ओर एक आंदोलन को भी उत्प्रेरित किया, यह साबित करते हुए कि बुल्गारिया का एक एकल डेवलपर एआई परिदृश्य को फिर से आकार दे सकता है। उनका कार्य विकसित होता रहता है, और llama.cpp ओपन-सोर्स नवाचार की शक्ति के प्रमाण के रूप में खड़ा है।