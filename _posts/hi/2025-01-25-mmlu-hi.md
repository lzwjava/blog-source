---
audio: false
lang: hi
layout: post
title: मूल्यांकन मापदंड
translated: true
---

## अभिव्यक्ति

यह पोस्ट MMLU (Massive Multitask Language Understanding) बेनचमार्क का उपयोग करके एक भाषा मॉडल का मूल्यांकन करता है।

MMLU बेनचमार्क एक मॉडल की विभिन्न कार्यों को करने की क्षमता का एक सम्पूर्ण परीक्षण है, जो विभिन्न विषयों के वैविध्य के बीच फैला हुआ है। इसमें विभिन्न क्षेत्रों जैसे गणित, इतिहास, कानून और चिकित्सा पर बहुविकल्पीय प्रश्न शामिल हैं।

**डेटासेट लिंक्स:**

*   [Papers with Code](https://paperswithcode.com/dataset/mmlu)
*   [Hugging Face Datasets](https://huggingface.co/datasets/cais/mmlu)

## llama-server

llama-server चलाने के लिए:

```bash
build/bin/llama-server -m models/7B/mistral-7b-instruct-v0.2.Q4_K_M.gguf --port 8080
```

## MMLU बेनचमार्क

इस स्क्रिप्ट MMLU बेनचमार्क का तीन अलग-अलग बैकएंड्स का उपयोग करके मूल्यांकन करता है: `ollama`, `llama-server`, और `deepseek`.

MMLU बेनचमार्क कोड चलाने के लिए:

```python
import torch
from datasets import load_dataset
import requests
import json
from tqdm import tqdm
import argparse
import os
from openai import OpenAI
from dotenv import load_dotenv
import time
import random

load_dotenv()

# तर्क विन्यास का सेटअप करें
parser = argparse.ArgumentParser(description="बहुविध डेटासेट को विभिन्न बैकएंड्स के साथ मूल्यांकन करें।")
parser.add_argument("--type", type=str, default="ollama", choices=["ollama", "llama", "deepseek", "gemini", "mistral"], help="बैकएंड प्रकार: ollama, llama, deepseek, gemini या mistral")
parser.add_argument("--model", type=str, default="", help="मॉडल का नाम")

args = parser.parse_args()

# MMLU डेटासेट लोड करें
subject = "college_computer_science"  # अपना विषय चुनें
dataset = load_dataset("cais/mmlu", subject, split="test")

# एक एकल-शॉट उदाहरण के साथ प्रॉम्प्ट का फॉर्मेट करें
def format_mmlu_prompt(example):
    prompt = f"प्रश्न: {example['question']}\n"
    prompt += "विकल्प:\n"
    for i, choice in enumerate(example['choices']):
        prompt += f"{chr(ord('A') + i)}. {choice}\n"
    prompt += "अपना उत्तर दीजिए. केवल विकल्प दीजिए.\n"
    return prompt

# यदि आवश्यक हो, DeepSeek क्लाइंट को प्रारंभ करें
def initialize_deepseek_client():
    api_key = os.environ.get("DEEPSEEK_API_KEY")
    if not api_key:
        print("त्रुटि: DEEPSEEK_API_KEY पर्यावरण चर नहीं सेट है।")
        exit()
    return OpenAI(api_key=api_key, base_url="https://api.deepseek.com")

def call_gemini_api(prompt, retries=3, backoff_factor=1):
    gemini_api_key = os.environ.get("GEMINI_API_KEY")
    if not gemini_api_key:
        print("त्रुटि: GEMINI_API_KEY पर्यावरण चर नहीं सेट है।")
        exit()
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"
    params = {"key": gemini_api_key}
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    print(f"Gemini API में इनपुट: {payload}")

    for attempt in range(retries):
        response = requests.post(url, json=payload, params=params)
        response_json = response.json()
        print(response_json)
        if response.status_code == 200:
            return response_json
        elif response.status_code == 429:
            time.sleep(backoff_factor * (2 ** attempt))  # Exponential backoff
        else:
            raise Exception(f"Gemini API Error: {response.status_code} - {response_json}")
    return None

def call_mistral_api(prompt, model="mistral-small-2501", process_response=True):
    api_key = os.environ.get("MISTRAL_API_KEY")
    if not api_key:
        print("त्रुटि: MISTRAL_API_KEY पर्यावरण चर नहीं सेट है।")
        return None

    url = "https://api.mistral.ai/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    data = {
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ]
    }
    print(f"Mistral API में इनपुट: {data}")
    print(f"Mistral API URL: {url}")
    print(f"Mistral API Headers: {headers}")
    try:
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        response_json = response.json()
        print(response_json)
        if response_json and response_json['choices']:
            content = response_json['choices'][0]['message']['content']
            if process_response:
                return process_mistral_response(content)
            else:
                return content
        else:
            print(f"Mistral API Error: Invalid response format: {response_json}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"Mistral API Error: {e}")
        stre = f"{e}"
        if '429' in  stre:
            print("बहुत ज्यादा अनुरोध, 10 सेकंड सोते हुए और फिर से प्रयास")
            time.sleep(10)
            return call_mistral_api(prompt, model, process_response)

        raise e

import re

def process_ollama_response(response):
    if response.status_code == 200:
        print(f"API से आउटपुट: {response.json()}")
        output_text = response.json()["choices"][0]["message"]["content"]
        match = re.search(r"Answer:\s*([A-D])", output_text, re.IGNORECASE)
        if not match:
            match = re.search(r"\*\*Answer\*\*:\s*([A-D])", output_text, re.IGNORECASE)
        if not match:
            match = re.search(r"The correct answer is\s*([A-D])", output_text, re.IGNORECASE)
        if not match:
            match = re.search(r"The correct choice is\s*([A-D])", output_text, re.IGNORECASE)
        if not match:
            match = re.search(r"The correct choice would be\s*([A-D])", output_text, re.IGNORECASE)
        if not match:
            match = re.search(r"The answer is\s*([A-D])", output_text, re.IGNORECASE)
        if not match:
            match = re.search(r"The answer appears to be\s*([A-D])", output_text, re.IGNORECASE)
        if not match:
            match = re.search(r"The correct answer should be\s*([A-D])", output_text, re.IGNORECASE)
        if not match:
            match = re.search(r"The correct answer would be\s*([A-D])", output_text, re.IGNORECASE)
        if match:
            predicted_answer = match.group(1).upper()
        else:
            stripped_output = output_text.strip()
            if len(stripped_output) > 0:
                first_word = stripped_output.split(" ")[0]
                if len(first_word) == 1:
                    predicted_answer = first_word
                else:
                    first_word_comma = stripped_output.split(",")[0]
                    if len(first_word_comma) == 1:
                        predicted_answer = first_word_comma
                    else:
                        first_word_period = stripped_output.split(".")[0]
                        if len(first_word_period) == 1:
                            predicted_answer = first_word_period
                        else:
                            print(f"आउटपुट से एक अक्षर उत्तर निकालने में असमर्थ: {output_text}, रैंडम उत्तर वापस कर रहा है")
                            predicted_answer = random.choice(["A", "B", "C", "D"])
            else:
                predicted_answer = ""

        return predicted_answer
    else:
        print(f"त्रुटि: {response.status_code} - {response.text}")
        return ""

def process_llama_response(response):
    if response.status_code == 200:
        output_text = response.json()["choices"][0]["message"]["content"]
        predicted_answer = output_text.strip()[0] if len(output_text.strip()) > 0 else ""
        print(f"API से आउटपुट: {output_text}")
        return predicted_answer
    else:
        print(f"त्रुटि: {response.status_code} - {response.text}")
        return ""

def process_deepseek_response(client, prompt, model="deepseek-chat", retries=3, backoff_factor=1):
    print(f"Deepseek API में इनपुट: {prompt}")
    for attempt in range(retries):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=100
            )
            if response and response.choices:
                output_text = response.choices[0].message.content.strip()
                predicted_answer = output_text.strip()[0] if len(output_text.strip()) > 0 else ""
                print(f"API से आउटपुट: {output_text}")
                return predicted_answer
            else:
                print("त्रुटि: API से कोई उत्तर नहीं मिला।")
                return ""
        except Exception as e:
            if "502" in str(e):
                print(f"API कोल से बैंड गेटवे त्रुटि (502), {backoff_factor * (2 ** attempt)} सेकंड में फिर से प्रयास...")