---
audio: true
lang: hi
layout: post
title: एमएमएलयू बेंचमार्क
translated: true
---

यह पोस्ट MMLU (मासिव मल्टीटास्क लैंग्वेज अंडरस्टैंडिंग) बेंचमार्क पर एक भाषा मॉडल का मूल्यांकन करती है।

MMLU बेंचमार्क एक व्यापक परीक्षण है जो मॉडल की विभिन्न विषयों पर कार्य करने की क्षमता का मूल्यांकन करता है। इसमें गणित, इतिहास, कानून, और चिकित्सा जैसे विविध क्षेत्रों को कवर करने वाले बहुविकल्पीय प्रश्न शामिल हैं।

**डेटासेट लिंक:**

*   [Papers with Code](https://paperswithcode.com/dataset/mmlu)
*   [Hugging Face Datasets](https://huggingface.co/datasets/cais/mmlu)

```python
import torch
from datasets import load_dataset
import requests
import json

# MMLU डेटासेट लोड करें
subject = "abstract_algebra"  # अपना विषय चुनें
dataset = load_dataset("cais/mmlu", subject, split="test")

# कुछ उदाहरणों के साथ प्रॉम्प्ट को फॉर्मेट करें
def format_mmlu_prompt(example, few_shot_examples=5):
    prompt = "निम्नलिखित {} के बारे में बहुविकल्पीय प्रश्न (उत्तरों के साथ) हैं।\n\n".format(subject.replace("_", " "))
    
    # कुछ उदाहरण जोड़ें
    few_shot_dataset = load_dataset("cais/mmlu", subject, split="validation")
    for i in range(few_shot_examples):
        ex = few_shot_dataset[i]
        prompt += f"प्रश्न: {ex['question']}\n"
        prompt += "विकल्प:\nA. {}\nB. {}\nC. {}\nD. {}\n".format(*ex['choices'])
        prompt += f"उत्तर: {ex['answer']}\n\n"
    
    # वर्तमान प्रश्न जोड़ें
    prompt += f"प्रश्न: {example['question']}\n"
    prompt += "विकल्प:\nA. {}\nB. {}\nC. {}\nD. {}\n".format(*example['choices'])
    prompt += "उत्तर:"
    return prompt

# मूल्यांकन लूप
correct = 0
total = 0

for example in dataset:
    prompt = format_mmlu_prompt(example)
    
    # llama-server को अनुरोध भेजें
    url = "http://localhost:8080/v1/chat/completions"
    headers = {"Content-Type": "application/json"}
    data = {
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 5,
        "temperature": 0,
    }
    
    response = requests.post(url, headers=headers, data=json.dumps(data))
    
    if response.status_code == 200:
        output_text = response.json()["choices"][0]["message"]["content"]
        predicted_answer = output_text.strip()[0] if len(output_text.strip()) > 0 else ""
    else:
        predicted_answer = ""
        print(f"त्रुटि: {response.status_code} - {response.text}")
    
    # ग्राउंड ट्रुथ के साथ तुलना करें
    if predicted_answer.upper() == example["answer"]:
        correct += 1
    total += 1

# सटीकता की गणना करें
accuracy = correct / total
print(f"विषय: {subject}")
print(f"सटीकता: {accuracy:.2%} ({correct}/{total})")
```