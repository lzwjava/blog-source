---
audio: true
lang: hi
layout: post
title: '# MMLU बेंचमार्क'
translated: true
---

## प्रस्तावना

यह पोस्ट MMLU (मासिव मल्टीटास्क लैंग्वेज अंडरस्टैंडिंग) बेंचमार्क का उपयोग करके एक भाषा मॉडल का मूल्यांकन करती है।

MMLU बेंचमार्क एक व्यापक परीक्षण है जो मॉडल की विभिन्न विषयों पर कार्य करने की क्षमता का मूल्यांकन करता है। इसमें गणित, इतिहास, कानून, और चिकित्सा जैसे विविध क्षेत्रों को कवर करने वाले बहुविकल्पीय प्रश्न शामिल हैं।

**डेटासेट लिंक:**

*   [Papers with Code](https://paperswithcode.com/dataset/mmlu)
*   [Hugging Face Datasets](https://huggingface.co/datasets/cais/mmlu)

## llama-server

llama-server चलाने के लिए:

```bash
build/bin/llama-server -m models/7B/mistral-7b-instruct-v0.2.Q4_K_M.gguf --port 8080
```

## MMLU बेंचमार्क

MMLU बेंचमार्क कोड चलाने के लिए:

```python
import torch
from datasets import load_dataset
import requests
import json
from tqdm import tqdm

# MMLU डेटासेट लोड करें
subject = "college_computer_science"  # अपना विषय चुनें
dataset = load_dataset("cais/mmlu", subject, split="test")

# फ्यू-शॉट उदाहरणों के बिना प्रॉम्प्ट फॉर्मेट करें
def format_mmlu_prompt(example):
    prompt = "The following are multiple-choice questions about {}".format(subject.replace("_", " "))
    prompt += ". Please answer with the letter of the correct choice (A, B, C, or D) only."
    prompt += " Answer the letter only. No explanation is needed."
    
    # वर्तमान प्रश्न जोड़ें
    prompt += f"Question: {example['question']}\n"
    prompt += "Choices:\nA. {}\nB. {}\nC. {}\nD. {}\n".format(*example['choices'])
    return prompt

# मूल्यांकन लूप
correct = 0
total = 0

for i, example in tqdm(enumerate(dataset), total=len(dataset), desc="Evaluating"):
    prompt = format_mmlu_prompt(example)
    
    # llama-server को अनुरोध भेजें
    url = "http://localhost:8080/v1/chat/completions"
    headers = {"Content-Type": "application/json"}
    data = {
        "messages": [{"role": "user", "content": prompt}]
    }
    
    print(f"Input to API: {data}")
    response = requests.post(url, headers=headers, data=json.dumps(data))
    
    if response.status_code == 200:
        output_text = response.json()["choices"][0]["message"]["content"]
        predicted_answer = output_text.strip()[0] if len(output_text.strip()) > 0 else ""
        print(f"Output from API: {output_text}")
    else:
        predicted_answer = ""
        print(f"Error: {response.status_code} - {response.text}")
    
    # ग्राउंड ट्रुथ के साथ तुलना करें
    
    answer_map = {0: "A", 1: "B", 2: "C", 3: "D"}
    ground_truth_answer = answer_map.get(example["answer"], "")
    is_correct = predicted_answer.upper() == ground_truth_answer
    if is_correct:
        correct += 1
    total += 1
    
    print(f"Question: {example['question']}")
    print(f"Choices: A. {example['choices'][0]}, B. {example['choices'][1]}, C. {example['choices'][2]}, D. {example['choices'][3]}")
    print(f"Predicted Answer: {predicted_answer}, Ground Truth: {ground_truth_answer}, Correct: {is_correct}")
    print("-" * 30)

    if (i+1) % 10 == 0:
        accuracy = correct / total
        print(f"Processed {i+1}/{len(dataset)}. Current Accuracy: {accuracy:.2%} ({correct}/{total})")


# सटीकता की गणना करें
accuracy = correct / total
print(f"Subject: {subject}")
print(f"Accuracy: {accuracy:.2%} ({correct}/{total})")
```

लॉग:

```bash
% python scripts/mmlu.py

Evaluating:   9%| 9/100 [01:31<15:19, 10.10s/it]Processed 10/100. Current Accuracy: 0.00% (0/10)
Evaluating:  19%| 19/100 [03:14<12:47,  9.47s/it]Processed 20/100. Current Accuracy: 0.00% (0/20)
Evaluating:  26%| 26/100 [04:30<13:44, 11.14s/it]

...

Processed 100/100. Current Accuracy: 40.00% (40/100)
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [15:15<00:00,  9.16s/it]
Subject: college_computer_science
Accuracy: 40.00% (40/100)
```

## ollama

```bash
Processed 100/100. Current Accuracy: 40.00% (40/100)
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:18<00:00,  1.39s/it]
Subject: college_computer_science
Accuracy: 40.00% (40/100)
```

ollama प्रोग्राम llama-server की तुलना में बहुत तेज लगता है। 

ollama के लिए, यह निम्नलिखित पैरामीटर्स का उपयोग करता है।

```bash
/Applications/Ollama.app/Contents/Resources/ollama runner --model /Users/lzwjava/.ollama/models/blobs/sha256-ff82381e2bea77d91c1b824c7afb83f6fb73e9f7de9dda631bcdbca564aa5435 --ctx-size 8192 --batch-size 512 --n-gpu-layers 33 --threads 4 --parallel 4 --port 51151
```

## Deepseek

Deepseek का बेंचमार्क।

```python
import torch
from datasets import load_dataset
import requests
import json
from tqdm import tqdm
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# MMLU डेटासेट लोड करें
subject = "college_computer_science"  # अपना विषय चुनें
dataset = load_dataset("cais/mmlu", subject, split="test")

# फ्यू-शॉट उदाहरणों के बिना प्रॉम्प्ट फॉर्मेट करें
def format_mmlu_prompt(example):
    prompt = "The following are multiple-choice questions about {}".format(subject.replace("_", " "))
    prompt += ". Please answer with the letter of the correct choice (A, B, C, or D) only."
    prompt += " Answer the letter only. Do not need Explanation."
    
    # वर्तमान प्रश्न जोड़ें
    prompt += f"Question: {example['question']}\n"
    prompt += "Choices:\nA. {}\nB. {}\nC. {}\nD. {}\n".format(*example['choices'])
    return prompt

# मूल्यांकन लूप
correct = 0
total = 0

# DeepSeek क्लाइंट इनिशियलाइज़ करें
api_key = os.environ.get("DEEPSEEK_API_KEY")
if not api_key:
    print("Error: DEEPSEEK_API_KEY environment variable not set.")
    exit()
client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")


for i, example in tqdm(enumerate(dataset), total=len(dataset), desc="Evaluating"):
    prompt = format_mmlu_prompt(example)
    
    # DeepSeek API को अनुरोध भेजें
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "user", "content": prompt}
            ],
            max_tokens=100
        )
        if response and response.choices:
            output_text = response.choices[0].message.content.strip()
            predicted_answer = output_text.strip()[0] if len(output_text.strip()) > 0 else ""
            print(f"Output from API: {output_text}")
        else:
            predicted_answer = ""
            print("Error: No response from the API.")
    except Exception as e:
        predicted_answer = ""
        print(f"Error during API call: {e}")
    
    # ग्राउंड ट्रुथ के साथ तुलना करें
    
    answer_map = {0: "A", 1: "B", 2: "C", 3: "D"}
    ground_truth_answer = answer_map.get(example["answer"], "")
    is_correct = predicted_answer.upper() == ground_truth_answer
    if is_correct:
        correct += 1
    total += 1
    
    print(f"Question: {example['question']}")
    print(f"Choices: A. {example['choices'][0]}, B. {example['choices'][1]}, C. {example['choices'][2]}, D. {example['choices'][3]}")
    print(f"Predicted Answer: {predicted_answer}, Ground Truth: {ground_truth_answer}, Correct: {is_correct}")
    print("-" * 30)

    if (i+1) % 10 == 0:
        accuracy = correct / total
        print(f"Processed {i+1}/{len(dataset)}. Current Accuracy: {accuracy:.2%} ({correct}/{total})")


# सटीकता की गणना करें
accuracy = correct / total
print(f"Subject: {subject}")
print(f"Accuracy: {accuracy:.2%} ({correct}/{total})")
```

परिणाम:

```bash
Processed 100/100. Current Accuracy: 78.00% (78/100)
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:44<00:00,  2.24s/it]
Subject: college_computer_science
Accuracy: 78.00% (78/100)
```