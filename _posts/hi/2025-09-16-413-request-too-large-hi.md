---
audio: false
generated: true
image: false
lang: hi
layout: post
model: openai/gpt-oss-120b
title: ४१३ अनुरोध बहुत बड़ा त्रुटि समाधान
translated: true
type: note
---

## त्रुटि का क्या अर्थ है

- **413 Request Too Large** एक HTTP स्थिति कोड है जो इंगित करता है कि सर्वर ने अनुरोध को संसाधित करने से इनकार कर दिया क्योंकि पेलोड स्वीकृत आकार से अधिक है। OpenAI की inference सेवा के संदर्भ में, "पेलोड" एक ही अनुरोध में भेजे गए टोकनों (इनपुट + आउटपुट) की कुल संख्या होती है। [1]

- **टोकन-प्रति-मिनट (TPM) सीमा**: `openai/gpt‑oss‑120b` मॉडल ऑन-डिमांड सेवा टियर के लिए अधिकतम **8,000 TPM** के साथ कॉन्फ़िगर किया गया है। आपके द्वारा भेजे गए अनुरोध में **13,701 टोकन** थे, जो सीमा से **5,701 टोकन अधिक** है। [1]

- **यह त्रुटि क्यों होती है**:
  1. **बड़ा प्रॉम्प्ट** – इनपुट टेक्स्ट (जिसमें सिस्टम निर्देश, उपयोगकर्ता संदेश और कोई भी जोड़ा गया डेटा शामिल है) बहुत लंबा हो सकता है।
  2. **उच्च max‑tokens सेटिंग** – यदि अनुरोध मॉडल से एक लंबा कंप्लीशन जेनरेट करने के लिए कहता है, तो अनुमानित आउटपुट टोकन काउंट को इनपुट काउंट में जोड़ दिया जाता है।
  3. **तेजी से लगातार कॉल** – यदि एक मिनट में बहुत सारे अनुरोध किए जाते हैं, तो वर्तमान मिनट में संचयी टोकन TPM कोटा से अधिक हो सकते हैं, भले ही प्रत्येक व्यक्तिगत अनुरोध सीमा से नीचे हो।

## इसे कैसे ठीक करें

| विकल्प | क्या करें | प्रभाव |
|--------|------------|--------|
| **प्रॉम्प्ट को छोटा करें** | अनावश्यक टेक्स्ट हटाएं, संक्षिप्त निर्देशों का उपयोग करें, या डेटा को कंप्रेस करें (जैसे, भेजने से पहले बड़े ब्लॉक्स को सारांशित करें)। | इनपुट टोकन काउंट कम होता है। |
| **`max_tokens` कम करें** | एक छोटा कंप्लीशन रिक्वेस्ट करें (उदाहरण के लिए, `max_tokens` को 2000 के बजाय 500 पर सेट करें)। | अनुमानित आउटपुट टोकन काउंट कम होता है। |
| **अनुरोध को विभाजित करें** | एक बड़े डॉक्यूमेंट को कई छोटे हिस्सों में तोड़ें और मॉडल को क्रमिक रूप से कॉल करें, परिणामों को बाद में जोड़ दें। | प्रत्येक कॉल TPM सीमा के अंतर्गत रहता है। |
| **टियर अपग्रेड करें** | एक उच्च-क्षमता वाले टियर (जैसे, Dev Tier) पर जाएँ जहाँ TPM सीमा बड़ी या असीमित हो। | त्रुटि के बिना बड़े सिंगल-रिक्वेस्ट पेलोड की अनुमति देता है। |
| **कॉल्स को थ्रॉटल करें** | अनुरोधों के बीच एक छोटी देरी जोड़ें या कुल टोकन प्रति मिनट ≤ 8,000 रखने के लिए रेट-लिमिटिंग लागू करें। | संचयी TMP ओवरफ्लो को रोकता है। |

## अनुरोध भेजने से पहले त्वरित चेकलिस्ट

1.  **टोकन गिनें** – कुल टोकन (प्रॉम्प्ट + मैक्स टोकन) का अनुमान लगाने के लिए OpenAI के टोकनाइज़र टूल (या `tiktoken`) का उपयोग करें।
2.  **ऑन-डिमांड टियर के लिए ≤ 8,000 TPM पर रहें।**
3.  **यदि सीमा के करीब हैं**, तो ऊपर बताए गए समाधानों में से एक पर विचार करें।

अनुरोध को 8,000-टोकन-प्रति-मिनट कोटा के भीतर रखकर, 413 "Request Too Large" त्रुटि से बचा जा सकता है। [1]

उद्धरण:
[1] https://www.reddit.com/r/OpenAI/comments/1nbtl2p/wow_weve_been_burning_money_for_6_months/