---
audio: false
generated: false
lang: hi
layout: post
title: एमएल, डीएल और जीपीटी
translated: true
type: note
---

1. मशीन लर्निंग (ML) कंप्यूटर विज्ञान की एक शाखा है जो सिस्टम को डेटा से सीखने और स्पष्ट प्रोग्रामिंग के बिना अपने प्रदर्शन में सुधार करने में सक्षम बनाती है।

2. डीप लर्निंग (DL) ML की एक उप-शाखा है जो डेटा में जटिल पैटर्न को मॉडल करने के लिए बहु-परत न्यूरल नेटवर्क का उपयोग करती है।

3. न्यूरल नेटवर्क मानव मस्तिष्क से प्रेरित कम्प्यूटेशनल मॉडल हैं, जो परस्पर जुड़े नोड्स (न्यूरॉन्स) से बने होते हैं जो सूचना को परतों में प्रोसेस करते हैं।

4. ट्रेनिंग डेटा वह लेबल या अनलेबल डेटासेट है जिसका उपयोग मशीन लर्निंग मॉडल को एक कार्य करना सिखाने के लिए किया जाता है।

5. सुपरवाइज्ड लर्निंग में मॉडल को लेबल किए गए डेटा पर प्रशिक्षित किया जाता है, जहां प्रत्येक उदाहरण में एक इनपुट और एक संबद्ध सही आउटपुट होता है।

6. अनसुपरवाइज्ड लर्निंग अनलेबल डेटा का उपयोग करती है, जो मॉडल को स्पष्ट निर्देश के बिना छिपे हुए पैटर्न या समूहों की खोज करने की अनुमति देती है।

7. रीइन्फोर्समेंट लर्निंग (RL) एजेंटों को वांछित व्यवहारों को पुरस्कृत करके और अवांछनीय व्यवहारों को दंडित करके निर्णय लेने के लिए प्रशिक्षित करती है।

8. जनरेटिव मॉडल अपने प्रशिक्षण उदाहरणों (जैसे, टेक्स्ट, इमेज) के समान नया डेटा उत्पन्न करना सीखते हैं।

9. डिस्क्रिमिनेटिव मॉडल इनपुट को श्रेणियों में वर्गीकृत करने या विशिष्ट परिणामों की भविष्यवाणी करने पर केंद्रित होते हैं।

10. ट्रांसफर लर्निंग एक कार्य पर प्रशिक्षित मॉडल को संबंधित कार्य पर पुन: उपयोग या फाइन-ट्यून करने की अनुमति देती है।

11. GPT (जनरेटिव प्री-ट्रेन्ड ट्रांसफॉर्मर) OpenAI द्वारा विकसित बड़े लैंग्वेज मॉडल्स का एक परिवार है जो मानव-जैसा टेक्स्ट जनरेट कर सकता है।

12. ChatGPT GPT का एक इंटरैक्टिव वेरिएंट है, जिसे वार्तालाप और निर्देश-अनुसरण कार्यों के लिए फाइन-ट्यून किया गया है।

13. ट्रांसफॉर्मर आर्किटेक्चर को "Attention Is All You Need" पेपर में पेश किया गया था, जिसने अटेंशन मैकेनिज्म पर निर्भर करके नेचुरल लैंग्वेज प्रोसेसिंग में क्रांति ला दी।

14. सेल्फ-अटेंशन मैकेनिज्म मॉडल को आउटपुट रिप्रेजेंटेशन के निर्माण के दौरान इनपुट सीक्वेंस के विभिन्न भागों को वेट करने देता है।

15. ट्रांसफॉर्मर में पोजिशनल एन्कोडिंग मॉडल को एक सीक्वेंस में टोकन्स के क्रम की पहचान करने में मदद करती है।

16. प्री-ट्रेनिंग प्रारंभिक चरण है जहां एक मॉडल विशिष्ट कार्यों पर फाइन-ट्यून किए जाने से पहले बड़े पैमाने के डेटा से सामान्य विशेषताएं सीखता है।

17. फाइन-ट्यूनिंग एक प्री-ट्रेन्ड मॉडल को लेने और इसे एक छोटे, टास्क-स्पेसिफिक डेटासेट का उपयोग करके एक संकीर्ण कार्य के लिए अनुकूलित करने की प्रक्रिया है।

18. लैंग्वेज मॉडलिंग एक सीक्वेंस में अगले टोकन (शब्द या उप-शब्द) की भविष्यवाणी करने का कार्य है, जो GPT-जैसे मॉडल्स के लिए आधारभूत है।

19. जीरो-शॉट लर्निंग एक मॉडल को स्पष्ट प्रशिक्षण उदाहरणों के बिना कार्यों को संभालने की अनुमति देती है, जो सीखे गए सामान्य ज्ञान पर निर्भर करती है।

20. फ्यू-शॉट लर्निग मॉडल की भविष्यवाणियों या व्यवहारों को मार्गदर्शन देने के लिए सीमित संख्या में टास्क-स्पेसिफिक उदाहरणों का लाभ उठाती है।

21. RLHF (रीइन्फोर्समेंट लर्निंग फ्रॉम ह्यूमन फीडबैक) का उपयोग मॉडल आउटपुट को मानवीय प्राथमिकताओं और मूल्यों के साथ संरेखित करने के लिए किया जाता है।

22. ह्यूमन फीडबैक में रैंकिंग या लेबल शामिल हो सकते हैं जो मॉडल की जनरेशन को अधिक वांछित प्रतिक्रियाओं की ओर मार्गदर्शन करते हैं।

23. प्रॉम्प्ट इंजीनियरिंग बड़े लैंग्वेज मॉडल्स को प्रभावी ढंग से मार्गदर्शन करने के लिए इनपुट क्वेरी या निर्देश तैयार करने की कला है।

24. कॉन्टेक्स्ट विंडो उस टेक्स्ट की अधिकतम मात्रा को संदर्भित करता है जिसे मॉडल एक साथ प्रोसेस कर सकता है; GPT मॉडल्स की एक सीमित कॉन्टेक्स्ट लंबाई होती है।

25. इनफेरेंस वह स्टेज है जहां एक प्रशिक्षित मॉडल नए इनपुट दिए जाने पर भविष्यवाणियां करता है या आउटपुट जनरेट करता है।

26. पैरामीटर काउंट मॉडल क्षमता में एक प्रमुख कारक है; बड़े मॉडल अधिक जटिल पैटर्न कैप्चर कर सकते हैं लेकिन अधिक कम्प्यूटेशन की आवश्यकता होती है।

27. मॉडल कम्प्रेशन तकनीकें (जैसे, प्रूनिंग, क्वांटिज़ेशन) न्यूनतम सटीकता हानि के साथ मॉडल के आकार को कम करती हैं और इनफेरेंस की गति बढ़ाती हैं।

28. ट्रांसफॉर्मर में अटेंशन हेड्स इनपुट के विभिन्न पहलुओं को समानांतर रूप से प्रोसेस करते हैं, जिससे रिप्रेजेंटेशनल पावर में सुधार होता है।

29. मास्क्ड लैंग्वेज मॉडलिंग (जैसे, BERT में) एक वाक्य में लुप्त टोकन की भविष्यवाणी करना शामिल है, जो मॉडल को संदर्भ सीखने में मदद करता है।

30. कॉजल लैंग्वेज मॉडलिंग (जैसे, GPT में) सभी पिछले टोकन के आधार पर अगले टोकन की भविष्यवाणी करना शामिल है।

31. एनकोडर-डिकोडर आर्किटेक्चर (जैसे, T5) इनपुट को एनकोड करने के लिए एक नेटवर्क और इसे टार्गेट सीक्वेंस में डिकोड करने के लिए दूसरे नेटवर्क का उपयोग करता है।

32. कन्वोल्यूशनल न्यूरल नेटवर्क (CNN) कन्वोल्यूशनल लेयर्स के माध्यम से ग्रिड-जैसे डेटा (जैसे, इमेज) को प्रोसेस करने में माहिर हैं।

33. रिकरंट न्यूरल नेटवर्क (RNN) टाइम स्टेप्स के साथ हिडन स्टेट्स को पास करके सीक्वेंशियल डेटा को प्रोसेस करते हैं, हालांकि उन्हें लॉन्ग-टर्म डिपेंडेंसी के साथ संघर्ष करना पड़ सकता है।

34. लॉन्ग शॉर्ट-टर्म मेमोरी (LSTM) और GRU, RNN के वेरिएंट हैं जिन्हें लॉन्ग-रेंज डिपेंडेंसी को बेहतर ढंग से कैप्चर करने के लिए डिज़ाइन किया गया है।

35. बैच नॉर्मलाइजेशन इंटरमीडिएट लेयर आउटपुट को नॉर्मलाइज़ करके ट्रेनिंग को स्थिर करने में मदद करता है।

36. ड्रॉपआउट एक रेगुलराइजेशन तकनीक है जो ओवरफिटिंग को रोकने के लिए ट्रेनिंग के दौरान न्यूरॉन्स को यादृच्छिक रूप से "ड्रॉप" करती है।

37. ऑप्टिमाइज़र अल्गोरिदम जैसे स्टोकैस्टिक ग्रेडिएंट डिसेंट (SGD), Adam, और RMSProp ग्रेडिएंट के आधार पर मॉडल पैरामीटर्स को अपडेट करते हैं।

38. लर्निंग रेट एक हाइपरपैरामीटर है जो निर्धारित करता है कि ट्रेनिंग के दौरान वेट्स को कितनी कठोरता से अपडेट किया जाता है।

39. हाइपरपैरामीटर्स (जैसे, बैच साइज, लेयर्स की संख्या) कॉन्फ़िगरेशन सेटिंग्स हैं जो ट्रेनिंग से पहले चुनी जाती हैं ताकि यह नियंत्रित किया जा सके कि सीखना कैसे unfolds होता है।

40. मॉडल ओवरफिटिंग तब होती है जब एक मॉडल ट्रेनिंग डेटा को बहुत अच्छी तरह से सीख जाता है, और नए डेटा के लिए जनरलाइज़ करने में विफल रहता है।

41. रेगुलराइजेशन तकनीकें (जैसे, L2 वेट डिके, ड्रॉपआउट) ओवरफिटिंग को कम करने और जनरलाइजेशन में सुधार करने में मदद करती हैं।

42. वैलिडेशन सेट का उपयोग हाइपरपैरामीटर्स को ट्यून करने के लिए किया जाता है, जबकि टेस्ट सेट मॉडल के अंतिम प्रदर्शन का मूल्यांकन करता है।

43. क्रॉस-वैलिडेशन डेटा को कई सबसेट में विभाजित करता है, और अधिक मजबूत प्रदर्शन अनुमान प्राप्त करने के लिए व्यवस्थित रूप से ट्रेनिंग और वैलिडेशन करता है।

44. ग्रेडिएंट एक्सप्लोडिंग और वैनिशिंग की समस्याएं डीप नेटवर्क में होती हैं, जिससे ट्रेनिंग अस्थिर या अप्रभावी हो जाती है।

45. रेजिडुअल कनेक्शन (स्किप कनेक्शन) ResNet जैसे नेटवर्क में डेटा पाथ को शॉर्टकट करके वैनिशिंग ग्रेडिएंट को कम करने में मदद करते हैं।

46. स्केलिंग लॉ सुझाव देते हैं कि मॉडल आकार और डेटा बढ़ाने से आम तौर पर बेहतर प्रदर्शन होता है।

47. कम्प्यूट एफिशिएंसी महत्वपूर्ण है; बड़े मॉडल को प्रशिक्षित करने के लिए ऑप्टिमाइज्ड हार्डवेयर (GPU, TPU) और अल्गोरिदम की आवश्यकता होती है।

48. एथिकल कंसिडरेशन में बायस, फेयरनेस और संभावित नुकसान शामिल हैं—ML मॉडल्स को सावधानीपूर्वक परीक्षण और निगरानी की आवश्यकता होती है।

49. डेटा ऑग्मेंटेशन कृत्रिम रूप से ट्रेनिंग डेटासेट का विस्तार करता है ताकि मॉडल की मजबूती में सुधार हो सके (विशेष रूप से इमेज और स्पीच टास्क में)।

50. डेटा प्रीप्रोसेसिंग (जैसे, टोकनाइजेशन, नॉर्मलाइजेशन) प्रभावी मॉडल ट्रेनिंग के लिए आवश्यक है।

51. टोकनाइजेशन टेक्स्ट को टोकन (शब्द या उप-शब्द) में विभाजित करता है, जो लैंग्वेज मॉडल द्वारा प्रोसेस की जाने वाली मौलिक इकाइयाँ हैं।

52. वेक्टर एम्बेडिंग टोकन या अवधारणाओं को संख्यात्मक वेक्टर के रूप में प्रस्तुत करती हैं, जो शब्दार्थ संबंधों को संरक्षित करती हैं।

53. पोजिशनल एम्बेडिंग प्रत्येक टोकन की स्थिति के बारे में जानकारी जोड़ती हैं ताकि ट्रांसफॉर्मर को सीक्वेंस ऑर्डर समझने में मदद मिल सके।

54. अटेंशन वेट्स बताते हैं कि एक मॉडल इनपुट के विभिन्न भागों में फोकस कैसे वितरित करता है।

55. बीम सर्च लैंग्वेज मॉडल में एक डिकोडिंग रणनीति है जो सर्वोत्तम समग्र अनुक्रम खोजने के लिए प्रत्येक चरण में कई उम्मीदवार आउटपुट रखती है।

56. ग्रीडी सर्च प्रत्येक चरण पर सबसे संभावित टोकन चुनती है, लेकिन इससे सबऑप्टिमल अंतिम आउटपुट हो सकते हैं।

57. सैंपलिंग में टेम्परेचर लैंग्वेज जनरेशन की रचनात्मकता को समायोजित करता है: उच्च तापमान = अधिक यादृच्छिकता।

58. टॉप-के और टॉप-पी (न्यूक्लियस) सैंपलिंग विधियां उम्मीदवार टोकन को k सबसे संभावित या संचयी संभावना p तक सीमित करती हैं, जिससे विविधता और सुसंगतता का संतुलन बनता है।

59. पर्प्लेक्सिटी मापती है कि एक प्रोबेबिलिटी मॉडल एक सैंपल की कितनी अच्छी तरह भविष्यवाणी करता है; कम पर्प्लेक्सिटी बेहतर भविष्यवाणी प्रदर्शन को इंगित करती है।

60. प्रिसिजन और रिकॉल क्लासिफिकेशन टास्क के लिए मेट्रिक्स हैं, जो क्रमशः शुद्धता और पूर्णता पर केंद्रित होते हैं।

61. F1 स्कोर प्रिसिजन और रिकॉल का हार्मोनिक माध्य है, जो दोनों मेट्रिक्स को एकल मूल्य में संतुलित करता है।

62. एक्यूरेसी सही भविष्यवाणियों का अंश है, लेकिन यह असंतुलित डेटासेट में भ्रामक हो सकती है।

63. ROC कर्व के अंतर्गत क्षेत्र (AUC) विभिन्न थ्रेशोल्ड पर एक क्लासिफायर के प्रदर्शन को मापता है।

64. कन्फ्यूजन मैट्रिक्स ट्रू पॉजिटिव, फॉल्स पॉजिटिव, फॉल्स नेगेटिव और ट्रू नेगेटिव की संख्या दिखाता है।

65. अनसर्टेन्टी एस्टिमेशन विधियाँ (जैसे, मोंटे कार्लो ड्रॉपआउट) मापती हैं कि एक मॉडल अपनी भविष्यवाणियों में कितना आश्वस्त है।

66. एक्टिव लर्निंग में नए डेटा उदाहरणों को क्वेरी करना शामिल है जिनके बारे में मॉडल सबसे कम आश्वस्त है, जिससे डेटा दक्षता में सुधार होता है।

67. ऑनलाइन लर्निंग नए डेटा आने पर मॉडल को वृद्धिशील रूप से अपडेट करती है, बजाय स्क्रैच से रीट्रेनिंग के।

68. इवोल्यूशनरी अल्गोरिदम और जेनेटिक अल्गोरिदम बायो-इंस्पायर्ड म्यूटेशन और चयन का उपयोग करके मॉडल या हाइपरपैरामीटर्स को ऑप्टिमाइज़ करते हैं।

69. बायेसियन विधियां पूर्व ज्ञान को शामिल करती हैं और आने वाले डेटा के साथ विश्वासों को अपडेट करती हैं, जो अनिश्चितता मात्रा निर्धारण के लिए उपयोगी हैं।

70. एन्सेम्बल विधियाँ (जैसे, रैंडम फॉरेस्ट, ग्रेडिएंट बूस्टिंग) प्रदर्शन और स्थिरता में सुधार के लिए कई मॉडलों को जोड़ती हैं।

71. बैगिंग (बूटस्ट्रैप एग्रीगेटिंग) डेटा के विभिन्न सबसेट पर कई मॉडल प्रशिक्षित करती है, फिर उनकी भविष्यवाणियों का औसत निकालती है।

72. बूस्टिंग पहले से प्रशिक्षित मॉडल द्वारा की गई त्रुटियों को सही करने के लिए नए मॉडलों को पुनरावृत्त रूप से प्रशिक्षित करती है।

73. ग्रेडिएंट बूस्टेड डिसीजन ट्री (GBDT) स्ट्रक्चर्ड डेटा के लिए शक्तिशाली हैं, और अक्सर सरल न्यूरल नेटवर्क से बेहतर प्रदर्शन करते हैं।

74. ऑटोरिग्रेसिव मॉडल एक सीक्वेंस में पिछले आउटपुट के आधार पर अगले मान (या टोकन) की भविष्यवाणी करते हैं।

75. ऑटोएनकोडर एक न्यूरल नेटवर्क है जिसे डेटा को लेटेंट रिप्रेजेंटेशन में एनकोड करने और फिर इसे वापस डिकोड करने के लिए डिज़ाइन किया गया है, जो कम्प्रेस्ड डेटा रिप्रेजेंटेशन सीखता है।

76. वेरिएशनल ऑटोएनकोडर (VAE) प्रशिक्षण सेट के समान नया डेटा जनरेट करने के लिए एक प्रोबेबिलिस्टिक ट्विस्ट पेश करता है।

77. जनरेटिव एडवरसैरियल नेटवर्क (GAN) एक जनरेटर को एक डिस्क्रिमिनेटर के खिलाफ खड़ा करता है, जिससे यथार्थवादी छवियां, टेक्स्ट या अन्य डेटा उत्पन्न होते हैं।

78. सेल्फ-सुपरवाइज्ड लर्निंग कृत्रिम प्रशिक्षण कार्य (जैसे, लुप्त भागों की भविष्यवाणी) बनाकर बड़ी मात्रा में अनलेबल डेटा का लाभ उठाती है।

79. फाउंडेशन मॉडल बड़े प्री-ट्रेन्ड मॉडल हैं जिन्हें विभिन्न प्रकार के डाउनस्ट्रीम टास्क के लिए अनुकूलित किया जा सकता है।

80. मल्टीमोडल लर्निंग समृद्ध रिप्रेजेंटेशन बनाने के लिए कई स्रोतों (जैसे, टेक्स्ट, इमेज, ऑडियो) से डेटा को एकीकृत करती है।

81. डेटा लेबलिंग अक्सर ML का सबसे अधिक समय लेने वाला हिस्सा होता है, जिसके लिए सटीकता के लिए सावधानीपूर्वक एनोटेशन की आवश्यकता होती है।

82. एज कम्प्यूटिंग ML इनफेरेंस को डेटा स्रोत के करीब लाती है, जिससे लेटेंसी और बैंडविड्थ उपयोग कम होता है।

83. फेडरेटेड लर्निंग स्थानीय डेटा नमूनों को रखने वाले विकेंद्रीकृत उपकरणों या सर्वरों पर मॉडल को प्रशिक्षित करती है, बिना उन्हें एक्सचेंज किए।

84. प्राइवेसी-प्रिजर्विंग ML में डिफरेंशियल प्राइवेसी और होमोमोर्फिक एन्क्रिप्शन जैसी तकनीकें शामिल हैं ताकि संवेदनशील डेटा की सुरक्षा की जा सके।

85. एक्सप्लेनएबल AI (XAI) का लक्ष्य जटिल मॉडलों के निर्णयों को मनुष्यों के लिए अधिक व्याख्यायोग्य बनाना है।

86. ML में बायस और फेयरनेस की सावधानीपूर्वक निगरानी की आवश्यकता होती है, क्योंकि मॉडल अनजाने में सामाजिक पूर्वाग्रहों को सीख और प्रवर्धित कर सकते हैं।

87. कॉन्सेप्ट ड्रिफ्ट तब होती है जब लक्ष्य चर के सांख्यिकीय गुण समय के साथ बदलते हैं, जिससे मॉडल प्रदर्शन प्रभावित होता है।

88. A/B टेस्टिंग वास्तविक दुनिया के वातावरण में यह देखने के लिए एक मॉडल के दो या अधिक संस्करणों की तुलना करती है कि कौन सा बेहतर प्रदर्शन करता है।

89. GPU एक्सेलेरेशन ML ट्रेनिंग को काफी तेज करने के लिए ग्राफिक्स कार्ड पर समानांतर कम्प्यूटिंग का लाभ उठाता है।

90. TPU (टेंसर प्रोसेसिंग यूनिट) Google द्वारा कुशल डीप लर्निंग वर्कलोड के लिए विशेष हार्डवेयर एक्सेलेरेटर हैं।

91. ओपन-सोर्स फ्रेमवर्क (जैसे, TensorFlow, PyTorch) ML मॉडल डेवलपमेंट के लिए बिल्डिंग ब्लॉक्स और टूल्स प्रदान करते हैं।

92. मॉडल सर्विंग प्रशिक्षित मॉडल को डिप्लॉय करने का अभ्यास है ताकि वे रीयल-टाइम या बैच भविष्यवाणियों को संभाल सकें।

93. स्केलेबिलिटी बड़े डेटासेट या भारी ट्रैफिक को संभालने के लिए महत्वपूर्ण है, जिसके लिए वितरित प्रशिक्षण और अनुमान रणनीतियों की आवश्यकता होती है।

94. MLOps ML डेवलपमेंट को ऑपरेशन प्रथाओं के साथ जोड़ता है, जो पुनरुत्पादनशीलता, परीक्षण और निरंतर एकीकरण पर केंद्रित है।

95. डेटा और मॉडल के लिए वर्जन कंट्रोल सुसंगत प्रयोग ट्रैकिंग और सहयोग सुनिश्चित करता है।

96. डिप्लॉयमेंट स्ट्रैटेजी (जैसे, कंटेनर, माइक्रोसर्विसेज) व्यवस्थित करती हैं कि मॉडल को कैसे पैकेज और सर्व किया जाता है।

97. मॉनिटरिंग डिप्लॉयमेंट के बाद मॉडल प्रदर्शन पर नज़र रखती है, और गिरावट या विसंगतियों को देखती है।

98. रीट्रेनिंग और मॉडल अपडेट नए डेटा और बदलती परिस्थितियों के आने पर मॉडल को अद्यतन रखते हैं।

99. टाइम कॉम्प्लेक्सिटी (O-नोटेशन) मापती है कि एक अल्गोरिदम का रनटाइम इनपुट आकार के साथ कैसे स्केल करता है; O(1) स्थिर समय को दर्शाता है।

100. ML का भविष्य तेजी से परिष्कृत और सामान्य मॉडल का वादा करता है, लेकिन इसे नैतिक, सामाजिक और पर्यावरणीय विचारों को संबोधित करना चाहिए।