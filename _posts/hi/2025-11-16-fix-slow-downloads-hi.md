---
audio: false
generated: true
image: false
lang: hi
layout: post
model: openai/gpt-5
title: हगिंग फेस डाउनलोड की गति बढ़ाना
translated: true
type: note
---

यह एक सामान्य समस्या है जब प्रॉक्सी के माध्यम से बड़ी HF डेटासेट डाउनलोड कर रहे होते हैं। निम्नलिखित के संयोजन से:

* कई सैकड़ों-मेगाबाइट की फाइलें
* Python `requests` / `huggingface_hub`
* एक स्थानीय HTTP प्रॉक्सी (विशेष रूप से Clash, V2Ray, या tun2socks)

अक्सर अत्यधिक धीमी थ्रूपुट या कनेक्शन रीसेट होने की स्थिति उत्पन्न होती है।

नीचे सबसे उपयोगी समाधान दिए गए हैं।

---

## 1. **सबसे अच्छा समाधान: `hf_transfer` का उपयोग करें**

Hugging Face के पास एक त्वरित डाउनलोडर है जो **10×–50× तेज** गति प्रदान करता है और अधिक स्थिर होता है।

इंस्टॉल करें:

```bash
pip install hf_transfer
export HF_HUB_ENABLE_HF_TRANSFER=1
```

अपना कमांड फिर से चलाएं।

यह अकेले आमतौर पर प्रॉक्सी के माध्यम से धीमे डाउनलोड को ठीक कर देता है।

---

## 2. Hugging Face CLI के साथ `aria2c` का उपयोग करें (बहुत बड़ी फाइलों के लिए सबसे तेज़)

यदि आप मैन्युअल रूप से डाउनलोड करते हैं:

```bash
pip install huggingface_hub[cli]
sudo apt install aria2
```

फिर डाउनलोड करें:

```bash
huggingface-cli download --repo-type dataset openwebtext --local-dir ./openwebtext --local-dir-use-symlinks False
```

HF CLI स्वचालित रूप से aria2 का उपयोग करता है, जो संभालता है:

* समानांतर कनेक्शन
* रिज्यूम
* अस्थिर प्रॉक्सी

`requests` की तुलना में बहुत बेहतर।

---

## 3. स्थानीय प्रॉक्सी की धीमी गति का समाधान: HTTP के बजाय सिस्टम-वाइड SOCKS का उपयोग करें

यदि आप कुछ इस तरह का उपयोग कर रहे हैं:

```
HTTP_PROXY=http://127.0.0.1:7890
HTTPS_PROXY=http://127.0.0.1:7890
```

यदि आपका प्रॉक्सी इसका समर्थन करता है तो SOCKS5 पर स्विच करें:

```bash
export ALL_PROXY=socks5://127.0.0.1:7891
```

SOCKS बड़ी फाइल स्ट्रीमिंग के लिए **बहुत अधिक स्थिर** होता है।

---

## 4. बड़ी फाइलों के लिए प्रॉक्सी अक्षम करें

यदि आपका रॉ नेटवर्क ठीक है लेकिन प्रॉक्सी गति धीमी कर रहा है:

```bash
unset HTTP_PROXY
unset HTTPS_PROXY
unset ALL_PROXY
```

फिर पुनः प्रयास करें। क्षेत्र के आधार पर कुछ HF सर्वर प्रॉक्सी के बिना भी तेज़ होते हैं।

---

## 5. HF मिरर का उपयोग करें (चीनी मुख्य भूमि / TW कभी-कभी धीमी)

आप CDN फोर्स कर सकते हैं:

```bash
export HF_ENDPOINT=https://hf-mirror.com
```

फिर फिर से चलाएं।
यह कुछ क्षेत्रों के लिए गति में नाटकीय रूप से सुधार करता है।

---

## 6. बाधित डाउनलोड को फिर से शुरू करें

HF डेटासेट यहाँ कैश किए जाते हैं:

```
~/.cache/huggingface/datasets/
```

यदि कोई फाइल आंशिक रूप से डाउनलोड की गई थी, तो HF स्वचालित रूप से रिज्यूम करता है — शून्य से फिर से शुरू करने की आवश्यकता नहीं है।

---

## 7. यदि फिर भी धीमा है: पूर्ण डेटासेट से बचें, एक छोटा स्लाइस उपयोग करें

OpenWebText >40GB है।
आप केवल एक छोटा हिस्सा लोड कर सकते हैं:

```python
from datasets import load_dataset
ds = load_dataset("openwebtext", split="train[:1%]")
```

---

## त्वरित सिफारिश

सबसे तेज़ + आसान:

```bash
pip install hf_transfer
export HF_HUB_ENABLE_HF_TRANSFER=1
python data/openwebtext_10k/prepare.py
```

आपको तुरंत डाउनलोड गति में वृद्धि दिखनी चाहिए।

---

यदि आप चाहें, तो मैं आपको दिखा सकता हूं कि कैसे अपने `prepare.py` को रिट्री/बैकऑफ और समानांतर फ़ेचिंग के साथ पूरी तरह से कस्टम डाउनलोडर का उपयोग करने के लिए संशोधित किया जाए, ताकि आपकी पाइपलाइन हमेशा तेजी से डाउनलोड हो और कभी अटके नहीं।