---
audio: false
generated: true
image: false
lang: hi
layout: post
title: मिस्ट्रल नीमो पुनरावृत्ति लूपों को ठीक करना
translated: true
type: note
---

जब **Mistral-Nemo** जैसा मॉडल खुद को दोहराता रहता है, तो यह आमतौर पर एक **जनरेशन लूप** का लक्षण होता है - मॉडल के आउटपुट में एक फीडबैक चक्र।
यह कई तकनीकी कारणों से हो सकता है:

---

**1. कॉन्टेक्स्ट में कमजोर "रुकने" के संकेत**
अगर प्रॉम्प्ट या वार्तालाप मॉडल को स्टॉप करने या टॉपिक बदलने के बारे में कोई स्पष्ट संकेत नहीं देता, तो यह समान टोकन पैदा करता रह सकता है क्योंकि यह सांख्यिकीय रूप से सबसे अधिक संभावित निरंतरता "देखता" है।

---

**2. टोकन-लेवल फीडबैक लूप**
लैंग्वेज मॉडल एक समय में एक टोकन की भविष्यवाणी करते हैं, प्रत्येक भविष्यवाणी अब तक के टोकन्स के आधार पर होती है।
यदि हाल के अनुक्रम में दोहराने की उच्च संभावना है (जैसे `"educational educational"`), तो मॉडल उच्च-आत्मविश्वास पुनरावृत्ति लूप में फंस सकता है क्योंकि प्रत्येक पुनरावृत्ति इसे फिर से करने की संभावना को बढ़ाती है।

---

**3. डिकोडिंग सेटिंग्स में कम विविधता**
यदि **टेम्परेचर** कम है (जैसे 0–0.2) और **top-k/top-p** सैंपलिंग बहुत प्रतिबंधात्मक है, तो मॉडल हर बार सबसे अधिक संभावित टोकन चुनेगा, जिससे लूप और मजबूत होते हैं बजाय टूटने के।
दूसरी ओर, बहुत अधिक टेम्परेचर यादृच्छिक लेकिन फिर भी दोहराव वाला शोर पैदा कर सकता है।

---

**4. प्रॉम्प्ट आर्टिफैक्ट्स**
यदि इनपुट टेक्स्ट में पहले से ही आंशिक पुनरावृत्ति है, तो मॉडल उस पर "अटक सकता है", यह सोचकर कि यह एक शैलीगत विकल्प या महत्वपूर्ण जोर है - इसलिए यह उसे दर्पण करता है और बढ़ाता है।

---

**5. मॉडल सीमाएँ या फाइन-ट्यूनिंग बायस**
कुछ ओपन मॉडल, खासकर अगर चैट-स्टाइल या सिंथेटिक डेटा पर फाइन-ट्यून किए गए हैं, ने ऐसे पैटर्न सीखे हो सकते हैं जहां पुनरावृत्ति को अधिक प्रतिनिधित्व मिला हो (जोर या सुदृढीकरण के लिए), जिससे वे एज केस में इसके प्रति अधिक संवेदनशील हो जाते हैं।

---

**6. कोई रिपीटिशन पेनल्टी लागू नहीं**
कुछ फ्रेमवर्क (जैसे Hugging Face `transformers`) एक `repetition_penalty` या `frequency_penalty` की अनुमति देते हैं ताकि एक ही टोकन का पुन: उपयोग करने से हतोत्साहित किया जा सके।
यदि इन्हें `1.0` (कोई पेनल्टी नहीं) पर सेट किया गया है, तो मॉडल को दोहराने की कोई "लागत" नहीं है।

---

**Mistral-Nemo में इस व्यवहार को कैसे कम करें**

* **रिपीटिशन पेनल्टी** जोड़ें (1.1–1.3)
* **top-k** बढ़ाएँ (जैसे 50–100) या **top-p** एडजस्ट करें (0.9–0.95)
* **टेम्परेचर** थोड़ा बढ़ाएँ अगर बहुत कम है (0.7–0.9)
* प्रॉम्प्ट में इसे दोहराए गए वाक्यांश देना तब तक अवॉइड करें जब तक जरूरी न हो
* **स्पष्ट निर्देश** दें या एक एक्सप्लिसिट स्टॉप सीक्वेंस प्रदान करें

---

अगर आप चाहें, तो मैं आपको Mistral-Nemo के लिए एक **स्टेप-बाय-स्टेप कॉन्फ़िग उदाहरण** दे सकता हूं जो इन लूप्स को कम करता है।
इस तरह, आप सीधे टेस्ट कर सकते हैं और अंतर देख सकते हैं।