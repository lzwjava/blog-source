---
audio: false
generated: true
lang: hi
layout: post
title: कोसाइन समानता
translated: true
type: note
---

कोसाइन समानता (Cosine Similarity) मशीन लर्निंग में व्यापक रूप से इस्तेमाल होने वाला एक मीट्रिक है जो उच्च-आयामी स्पेस में दो वेक्टरों के बीच समानता को मापता है। यह प्राकृतिक भाषा प्रसंस्करण (NLP), सूचना पुनर्प्राप्ति, और सिफारिश प्रणालियों जैसे क्षेत्रों में विशेष रूप से लोकप्रिय है, क्योंकि यह वेक्टरों के परिमाण के बजाय उनके बीच के ओरिएंटेशन (या कोण) को पकड़ने की क्षमता रखता है। यह इसे टेक्स्ट दस्तावेज़ों, उपयोगकर्ता प्राथमिकताओं, या एम्बेडिंग्स जैसी वस्तुओं की तुलना के लिए मजबूत बनाता है, जहां वेक्टर की दिशा उसकी लंबाई से अधिक मायने रखती है।

### कोसाइन समानता क्या है?

कोसाइन समानता मापती है कि दो वेक्टर कितने समान हैं, उनके बीच के कोण की कोसाइन की गणना करके। गणितीय रूप से, इसे इस प्रकार परिभाषित किया जाता है:

\\[
\text{कोसाइन समानता} = \cos(\theta) = \frac{A \cdot B}{\|A\| \|B\|}
\\]

जहाँ:
- \\( A \\) और \\( B \\) दो वेक्टर हैं (उदाहरण के लिए, दस्तावेज़ों, एम्बेडिंग्स, या फीचर सेट्स का प्रतिनिधित्व करते हुए)।
- \\( A \cdot B \\) वेक्टरों का डॉट प्रोडक्ट है, जिसकी गणना \\( \sum_{i=1}^n A_i B_i \\) के रूप में की जाती है।
- \\( \|A\| \\) और \\( \|B\| \\) वेक्टर \\( A \\) और \\( B \\) के यूक्लिडियन नॉर्म (परिमाण) हैं, जिनकी गणना क्रमशः \\( \sqrt{\sum_{i=1}^n A_i^2} \\) और \\( \sqrt{\sum_{i=1}^n B_i^2} \\) के रूप में की जाती है।
- \\( \theta \\) वेक्टरों के बीच का कोण है।

परिणाम की सीमा होती है:
- **1**: वेक्टर दिशा में समान हैं (कोण = 0°)।
- **0**: वेक्टर ऑर्थोगोनल हैं (कोण = 90°), जो कोई समानता नहीं दर्शाता।
- **-1**: वेक्टर विपरीत दिशा में हैं (कोण = 180°), जो अधिकतम असमानता दर्शाता है।

### मुख्य गुण

1.  **सीमा**: कोसाइन समानता के मान -1 और 1 के बीच होते हैं, जिससे इसे समझना आसान हो जाता है।
2.  **परिमाण स्वतंत्रता**: चूंकि वेक्टरों को उनके परिमाण से सामान्यीकृत किया जाता है, कोसाइन समानता लंबाई पर नहीं बल्कि दिशा पर केंद्रित होती है। यह तब उपयोगी होती है जब अलग-अलग लंबाई के दस्तावेजों या अलग-अलग स्केल वाली एम्बेडिंग्स की तुलना की जाती है।
3.  **गैर-नकारात्मक फीचर्स**: कई अनुप्रयोगों में (जैसे टर्म फ्रीक्वेंसी वाले टेक्स्ट डेटा), वेक्टरों के घटक गैर-नकारात्मक होते हैं, इसलिए समानता आमतौर पर 0 से 1 के बीच होती है।
4.  **कम्प्यूटेशनल दक्षता**: डॉट प्रोडक्ट और नॉर्म की गणना सीधी-साधी होती है, जो उच्च-आयामी डेटा के लिए कोसाइन समानता को कम्प्यूटेशनल रूप से कुशल बनाती है।

### मशीन लर्निंग में इसका उपयोग कैसे किया जाता है

कोसाइन समानता का उपयोग इसकी बहुमुखी प्रतिभा के कारण विभिन्न मशीन लर्निंग कार्यों में किया जाता है:

1.  **टेक्स्ट विश्लेषण और NLP**:
    - **दस्तावेज़ समानता**: क्लस्टरिंग या सर्च इंजन जैसे कार्यों में, दस्तावेजों को वेक्टर (जैसे TF-IDF या Word2Vec, GloVe, या BERT जैसे वर्ड एम्बेडिंग) के रूप में दर्शाया जाता है। कोसाइन समानता मापती है कि उनकी सामग्री के आधार पर दो दस्तावेज़ कितने समान हैं।
    - **सेंटीमेंट विश्लेषण**: टेक्स्ट स्निपेट्स के सेंटीमेंट वेक्टरों की तुलना करना।
    - **साहित्यिक चोरी का पता लगाना**: टेक्स्ट के वेक्टर रिप्रेजेंटेशन की तुलना करके टेक्स्ट के बीच समानताएं पहचानना।

2.  **सिफारिश प्रणालियाँ**:
    - कोसाइन समानता का उपयोग उपयोगकर्ता या आइटम प्रोफाइल्स (जैसे कि सहयोगात्मक फ़िल्टरिंग में) की तुलना करने के लिए किया जाता है। उदाहरण के लिए, यह माप सकता है कि दो उपयोगकर्ताओं की प्राथमिकताएं उनकी रेटिंग या व्यवहार के आधार पर कितनी समान हैं।
    - यह कंटेंट-आधारित फ़िल्टरिंग में प्रभावी है, जहां आइटम (जैसे मूवी, उत्पाद) को फीचर वेक्टर के रूप में दर्शाया जाता है।

3.  **इमेज और ऑडियो प्रोसेसिंग**:
    - कंप्यूटर विजन में, कोसाइन समानता विजुअल समानता मापने के लिए इमेज से निकाले गए फीचर वेक्टरों (जैसे CNN से) की तुलना करती है।
    - ऑडियो प्रोसेसिंग में, इसका उपयोग साउंड क्लिप के स्पेक्ट्रोग्राम या एम्बेडिंग्स की तुलना करने के लिए किया जाता है।

4.  **क्लस्टरिंग और वर्गीकरण**:
    - क्लस्टरिंग एल्गोरिदम (जैसे टेक्स्ट डेटा के साथ K-means) में, कोसाइन समानता समान आइटमों को समूहित करने के लिए दूरी मीट्रिक के रूप में कार्य करती है।
    - वर्गीकरण कार्यों में, इसका उपयोग इनपुट वेक्टरों की क्लास प्रोटोटाइप से तुलना करने के लिए किया जाता है।

5.  **अनियमितता का पता लगाना**:
    - कोसाइन समानता डेटा पॉइंट्स की सेंट्रॉइड या अपेक्षित पैटर्न से तुलना करके आउटलायर्स की पहचान कर सकती है। कम समानता संभावित अनियमितताओं का संकेत देती है।

### उदाहरण: टेक्स्ट विश्लेषण में कोसाइन समानता

मान लीजिए हमारे पास दो दस्तावेज़ हैं जिन्हें TF-IDF वेक्टर के रूप में दर्शाया गया है:
- दस्तावेज़ 1: \\( A = [2, 1, 0, 3] \\) (उदाहरण के लिए, चार शब्दों के लिए शब्द आवृत्तियाँ)।
- दस्तावेज़ 2: \\( B = [1, 1, 1, 0] \\)।

**चरण 1: डॉट प्रोडक्ट की गणना करें**:
\\[
A \cdot B = (2 \cdot 1) + (1 \cdot 1) + (0 \cdot 1) + (3 \cdot 0) = 2 + 1 + 0 + 0 = 3
\\]

**चरण 2: नॉर्म की गणना करें**:
\\[
\|A\| = \sqrt{2^2 + 1^2 + 0^2 + 3^2} = \sqrt{4 + 1 + 0 + 9} = \sqrt{14} \approx 3.742
\\]
\\[
\|B\| = \sqrt{1^2 + 1^2 + 1^2 + 0^2} = \sqrt{1 + 1 + 1 + 0} = \sqrt{3} \approx 1.732
\\]

**चरण 3: कोसाइन समानता की गणना करें**:
\\[
\cos(\theta) = \frac{A \cdot B}{\|A\| \|B\|} = \frac{3}{3.742 \cdot 1.732} \approx \frac{3}{6.483} \approx 0.462
\\]

कोसाइन समानता लगभग 0.462 है, जो दस्तावेजों के बीच मध्यम समानता दर्शाती है।

### कोसाइन समानता के फायदे

- **स्केल इनवेरिएंस**: यह वेक्टरों के परिमाण से अप्रभावित रहती है, जिससे यह टेक्स्ट डेटा के लिए आदर्श बन जाती है जहां दस्तावेज़ की लंबाई अलग-अलग होती है।
- **उच्च-आयामी डेटा को संभालती है**: स्पार्स, उच्च-आयामी स्पेस (जैसे हजारों फीचर्स वाला टेक्स्ट डेटा) में प्रभावी।
- **सहज व्याख्या**: कोसाइन मान सीधे कोण से संबंधित होता है, जो समानता का स्पष्ट माप प्रदान करता है।

### सीमाएँ

- **परिमाण को नजरअंदाज करती है**: कुछ मामलों में, परिमाण के अंतर महत्वपूर्ण होते हैं (जैसे पूर्ण मात्राओं की तुलना करते समय)।
- **रैखिक संबंध मानती है**: कोसाइन समानता यह मानती है कि समानता को कोणीय दूरी द्वारा सबसे अच्छा तरीके से पकड़ा जाता है, जो हमेशा सही नहीं हो सकता।
- **स्पार्स डेटा संवेदनशीलता**: बहुत अधिक स्पार्स वेक्टरों में, कोसाइन समानता कम भेदभावपूर्ण हो सकती है, क्योंकि कई आयाम डॉट प्रोडक्ट में बहुत कम योगदान देते हैं।

### कोसाइन समानता बनाम अन्य मीट्रिक्स

- **यूक्लिडियन दूरी**: सीधी-रेखा की दूरी को मापती है और परिमाण के प्रति संवेदनशील है, कोसाइन समानता के विपरीत। कोसाइन तब पसंद की जाती है जब दिशा निरपेक्ष अंतर से अधिक मायने रखती है।
- **जैकार्ड समानता**: सेटों (जैसे बाइनरी डेटा) के लिए उपयोग की जाती है, जो वेक्टर ओरिएंटेशन के बजाय साझा तत्वों पर केंद्रित होती है।
- **पियर्सन सहसंबंध**: रैखिक सहसंबंध को मापता है, माध्य-केंद्रित डेटा को ध्यान में रखते हुए, जबकि कोसाइन समानता कच्चे वेक्टरों पर काम करती है।

### व्यावहारिक कार्यान्वयन

कोसाइन समानता कई मशीन लर्निंग लाइब्रेरीज में लागू की गई है:
- **Python**: `scikit-learn` `sklearn.metrics.pairwise` में `cosine_similarity` प्रदान करता है।
  ```python
  from sklearn.metrics.pairwise import cosine_similarity
  import numpy as np

  A = np.array([[2, 1, 0, 3]])
  B = np.array([[1, 1, 1, 0]])
  similarity = cosine_similarity(A, B)
  print(similarity)  # Output: [[0.46225063]]
  ```
- **TensorFlow/PyTorch**: डीप लर्निंग मॉडल्स में एम्बेडिंग्स की तुलना करने के लिए उपयोग किया जाता है।
- **Spark**: बड़े पैमाने पर वितरित समानता गणनाओं के लिए।

### उन्नत अनुप्रयोग

1.  **वर्ड एम्बेडिंग्स**: कोसाइन समानता शब्दार्थ समानता को मापने के लिए वर्ड या सेंटेंस एम्बेडिंग्स (जैसे BERT, Sentence-BERT) की तुलना करने के लिए मानक है।
2.  **ग्राफ-आधारित मॉडल**: ग्राफ न्यूरल नेटवर्क के लिए नोड समानता में उपयोग किया जाता है।
3.  **व्यक्तिगत खोज**: Elasticsearch जैसे सर्च इंजन क्वेरी की प्रासंगिकता के अनुसार दस्तावेजों को रैंक करने के लिए कोसाइन समानता का उपयोग करते हैं।

### निष्कर्ष

कोसाइन समानता मशीन लर्निंग में समानता मापने के लिए एक शक्तिशाली, सहज और कम्प्यूटेशनल रूप से कुशल मीट्रिक है। वेक्टर ओरिएंटेशन पर इसका फोकस इसे टेक्स्ट, एम्बेडिंग्स और सिफारिश प्रणालियों के लिए आदर्श बनाता है, हालांकि यह उन कार्यों के लिए कम उपयुक्त है जहां परिमाण मायने रखता है। इसकी ताकत और सीमाओं को समझकर, व्यवसायी इसे NLP से कंप्यूटर विजन तक विविध अनुप्रयोगों में प्रभावी ढंग से लागू कर सकते हैं। यदि आप किसी विशिष्ट उपयोग के मामले या कार्यान्वयन में गहराई से जाना चाहते हैं, तो मुझे बताएं!