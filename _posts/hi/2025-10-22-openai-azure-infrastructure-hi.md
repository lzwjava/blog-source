---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: ओपनएआई इंफ्रास्ट्रक्चर और एज़्योर निर्भरता
translated: true
type: note
---

### OpenAI की टेक स्टैक अवलोकन

OpenAI का इन्फ्रास्ट्रक्चर बड़े पैमाने पर AI रिसर्च, ट्रेनिंग और डिप्लॉयमेंट के लिए भारी ऑप्टिमाइज़ किया गया है, जिसमें स्केलेबिलिटी, सुरक्षा और तेज़ प्रयोगों पर जोर दिया गया है। वे AWS से 2017 की शुरुआत में माइग्रेट होने के बाद से अपना अधिकांश इन्फ्रास्ट्रक्चर Microsoft Azure के इर्द-गिर्द बना चुके हैं, जो उनके सुपरकंप्यूटरों और वर्कलोड के लिए मूल क्लाउड प्लेटफॉर्म प्रदान करता है। इस बदलाव ने विशेष हार्डवेयर और लागत दक्षता के साथ बेहतर एकीकरण को सक्षम किया। प्रमुख तत्वों में विकास के लिए एकीकृत Python मोनोरेपो, ऑर्केस्ट्रेशन के लिए Kubernetes, और Apache Kafka जैसे स्ट्रीमिंग टूल शामिल हैं। नीचे, मैं इसे श्रेणी के अनुसार विभाजित करूंगा, जिसमें Azure पर निर्भरता और Kubernetes की विशिष्टताओं को संबोधित किया जाएगा।

#### क्लाउड इन्फ्रास्ट्रक्चर: Azure पर भारी निर्भरता
OpenAI अपने रिसर्च और प्रोडक्शन वातावरण के लिए Azure का व्यापक रूप से उपयोग करता है, जिसमें GPT श्रृंखला जैसे फ्रंटियर मॉडल की ट्रेनिंग भी शामिल है। इसमें शामिल है:
- **मुख्य प्लेटफॉर्म के रूप में Azure**: सभी प्रमुख वर्कलोड Azure पर चलते हैं, जिसमें संवेदनशील डेटा (जैसे, मॉडल वेट) के लिए प्राइवेट-लिंक्ड स्टोरेज का उपयोग इंटरनेट एक्सपोजर को कम करने के लिए किया जाता है। प्रमाणीकरण, पहचान प्रबंधन के लिए Azure Entra ID से जुड़ा होता है, जो जोखिम-आधारित एक्सेस नियंत्रण और विसंगति पहचान को सक्षम बनाता है।
- **इतना अधिक Azure क्यों?**: एक लीक हुआ आंतरिक दस्तावेज़ (संभवतः उनकी 2024 सुरक्षा आर्किटेक्चर पोस्ट का जिक्र) ट्रेनिंग के दौरान बौद्धिक संपदा की सुरक्षा में Azure की भूमिका को उजागर करता है। यह रोबोटिक्स, गेमिंग आदि में AI प्रयोगों के लिए विशाल GPU क्लस्टर का समर्थन करता है। Microsoft के साथ OpenAI की साझेदारी Azure OpenAI Service के माध्यम से मॉडल्स तक कम-विलंबता वाली पहुंच सुनिश्चित करती है, लेकिन आंतरिक रूप से, यह कस्टम सुपरकंप्यूटिंग के लिए रीढ़ की हड्डी है। वे GPU-हेवी कार्यों के लिए ऑन-प्रिमाइसेस डेटा सेंटर के साथ संकरण भी करते हैं, विश्वसनीयता और बैकअप के लिए नियंत्रण तल (जैसे, etcd) का प्रबंधन Azure में करते हैं।

यह गहरा एकीकरण का मतलब है कि OpenAI का स्टैक आसानी से पोर्टेबल नहीं है—यह प्रदर्शन और अनुपालन के लिए Azure के इकोसिस्टम के अनुरूप बनाया गया है।

#### ऑर्केस्ट्रेशन और स्केलिंग: Azure ऑप्टिमाइज़ेशन के साथ Kubernetes (AKS)
वर्कलोड प्रबंधन के लिए Kubernetes केंद्रीय भूमिका निभाता है, जो बैच शेड्यूलिंग, कंटेनर ऑर्केस्ट्रेशन और क्लस्टर में पोर्टेबिलिटी को संभालता है। OpenAI Azure Kubernetes Service (AKS) पर प्रयोग चलाता है, जो हाल के वर्षों में 2,500 (2017 में) से बढ़कर 7,500 से अधिक नोड्स तक स्केल कर चुका है।
- **Azure के इकोसिस्टम में AKS की विश्वसनीयता**: जैसा कि आपने बताया, Azure की Kubernetes सेवा तब और बेहतर काम करती है जब वह Azure उत्पादों में पूरी तरह से एम्बेडेड हो। OpenAI ने नेटवर्किंग के लिए Azure CNI (Container Network Interface) पर स्विच किया, जो Azure के क्लाउड के लिए विशेष रूप से निर्मित है—यह उच्च-प्रदर्शन, बड़े पैमाने के वातावरण को संभालता है जिन्हें Flannel जैसे जेनेरिक CNI इस आकार पर विश्वसनीय रूप से मैच नहीं कर सकते। यह बॉटलनेक के बिना डायनामिक स्केलिंग, स्वचालित पॉड हेल्थ चेक और आउटेज के दौरान फेलओवर की अनुमति देता है। Azure के नेटिव इंटीग्रेशन (जैसे, ब्लॉब स्टोरेज और वर्कलोड आइडेंटिटी के लिए) के बिना, विलंबता, प्रमाणीकरण समस्याओं, या क्षमता की बाधाओं के कारण विश्वसनीयता कम हो जाती है। उनका कस्टम ऑटोस्केलर नोड्स को गतिशील रूप से जोड़ता/हटाता है, जिससे निष्क्रिय संसाधनों पर लागत कम होती है और साथ ही दिनों में प्रयोगों को 10x स्केल करना संभव होता है।
- **सुरक्षा परत**: Kubernetes कम से कम विशेषाधिकार पहुंच के लिए RBAC लागू करता है, कंटेनर नीतियों के लिए एडमिशन कंट्रोलर, और डिफ़ॉल्ट रूप से नेटवर्क इग्रेस को अस्वीकार करता है (जिसमें अनुमोदित पथों के लिए व्हाइटलिस्ट होती है)। उच्च-जोखिम वाली नौकरियों के लिए, वे अतिरिक्त अलगाव के लिए gVisor की परत चढ़ाते हैं। मल्टी-क्लस्टर फेलओवर क्षेत्रीय समस्याओं के दौरान नौकरियों को चालू रखता है।

#### विकास और कोड प्रबंधन: मोनोरेपो दृष्टिकोण
OpenAI अधिकांश शोध और इंजीनियरिंग कार्य के लिए एक एकल Python मोनोरेपो बनाए रखता है। यह कोड, लाइब्रेरी और निर्भरताओं को केंद्रीकृत करता है, जिससे टीमें AI-विशिष्ट पाइपलाइनों के साथ-साथ परिचित Python टूल (जैसे, NumPy, PyTorch) का उपयोग कर सकती हैं। यह उनकी स्ट्रीम प्रोसेसिंग के साथ सहजता से एकीकृत होता है, जिससे प्रयोगों के लिए घर्षण कम होता है। CI/CD पाइपलाइनें बहु-पक्षीय अनुमोदन और सुसंगत डिप्लॉयमेंट के लिए IaC (इन्फ्रास्ट्रक्चर एज कोड) के साथ लॉक डाउन हैं।

#### डेटा प्रोसेसिंग और स्ट्रीमिंग
- **Apache Kafka**: लॉग, ट्रेनिंग डेटा और परिणामों के लिए इवेंट बैकबोन। यह उच्च उपलब्धता के लिए मल्टी-प्राइमरी है, जिसमें कस्टम कनेक्टर (जैसे, पढ़ने के लिए यूनियन स्ट्रीम, लिखने के लिए Prism Sink) और वॉचडॉग्स हैं जो फेलओवर जैसे टोपोलॉजी परिवर्तनों के अनुकूल होते हैं।
- **Kubernetes पर PyFlink**: GenAI स्ट्रीम प्रोसेसिंग के लिए, जो ऑटोमेशन के लिए Flink Kubernetes Operator का उपयोग करता है। यह Python में DataStream/Table APIs का समर्थन करता है, जिसमें स्टेट के लिए RocksDB और चेकपॉइंट के लिए Azure ब्लॉब स्टोरेज का उपयोग होता है—जो वर्कलोड आइडेंटिटी के माध्यम से सुरक्षित है (कोई लॉन्ग-लिव्ड कीज़ नहीं)।

#### मॉनिटरिंग और कम्युनिकेशन
- **Prometheus**: डीबगिंग और मेट्रिक्स के लिए।
- **gRPC**: इंटर-सर्विस कम्युनिकेशन के लिए।

#### 2025 में विकास
हालिया अपडेट (जैसे, OpenAI DevDay 2025 से) मॉडल API और AgentKit जैसे एजेंट टूल्स पर अधिक केंद्रित हैं, लेकिन इन्फ्रा स्टैक Azure-Kubernetes केंद्रित बना हुआ है। उन्होंने अपनी सीख साझा करने के लिए अपने ऑटोस्केलर जैसे टूल्स ओपन-सोर्स किए हैं।

यह स्टैक तेज पुनरावृत्ति के लिए "डेटा फ्लाईव्हील" को प्राथमिकता देता है लेकिन हाइपरस्केल पर Azure की विश्वसनीयता के लिए पोर्टेबिलिटी का व्यापार करता है। यदि आप कुछ इसी तरह का निर्माण कर रहे हैं, तो AKS + Kafka से शुरुआत करके इसकी नकल की जा सकती है, लेकिन Azure के बाहर समायोजन की अपेक्षा करें।

[How OpenAI Uses Kubernetes And Apache Kafka for GenAI](https://blog.bytebytego.com/p/how-openai-uses-kubernetes-and-apache)  
[Securing Research Infrastructure for Advanced AI](https://openai.com/index/securing-research-infrastructure-for-advanced-ai/)  
[OpenAI Kubernetes Case Study](https://kubernetes.io/case-studies/openai/)  
[How OpenAI Scaled Kubernetes with Azure CNI](https://medium.com/@PlanB./how-openai-scaled-kubernetes-with-azure-cni-to-handle-7-500-nodes-591162d0efa5)