---
audio: true
lang: hi
layout: post
title: आई सोचना
translated: true
---

- सत्य नाडेला ने जेवन्स पराडॉक्स का उल्लेख किया है। इसको सीखना मजेदार है।

- यिन वांग: प्रौद्योगिक इंटेलिजेंस में 'समझदारी' का कोई भाग नहीं है, नेवरल नेटवर्क में 'नेवरल' का कोई भाग नहीं है, मशीन लर्निंग में 'लर्निंग' का कोई भाग नहीं है और डीप लर्निंग में 'गहराई' का कोई भाग नहीं है। डीप लर्निंग में 'गहराई' का कोई भाग नहीं है। इस क्षेत्र में ये काम करने वाली बात कहलाती है 'कैलकुलस'। इसलिए मैं इस क्षेत्र को 'अनुक्रमणिक संकलन' कहना पसंद करता हूँ और मोडेल बनाने का प्रक्रिया को 'अनुक्रमणिक प्रोग्रामिंग' कहता हूँ।

- यिन वांग: मशीन लर्निंग हल्का सा वर्णन लेने से कितना उपयोगी और कितना सौंदर्यपूर्ण थेорी है, क्योंकि यह सिर्फ कैलकुलस का एक नया अवतर है! यह न्यूटन, लाइब्निज़ के पुराने और महान थेरी का एक सरल, सौंदर्यपूर्ण और शक्तिशाली रूप है। मशीन लर्निंग सिर्फ कैलकुलस का उपयोग करके कुछ फ़ंक्शन निकालने और अनुसार करने का प्रयोग है, और डीप लर्निंग इसका बहुत ज़्यादा ज़्यादा फ़ंक्शन अनुसार करने का प्रयोग है।

- वर्तमान में, व्यापक भाषा मोडल्स यामल या पाइथन जैसे फ़ाइल भाषा के अनुसार फ़िल्टर कर नहीं सकते हैं। लेकिन वास्तव में संसार की एक व्यापक हिस्से से जानकारी इस तरीके से ऑर्गनाइज़ की गयी है। यह मतलब है कि हम व्यापक भाषा मोडल्स को फ़ाइलों का उपयोग करके ट्रेन कर सकते हैं।

- व्यापक भाषा मोडल्स ट्रेन करने के लिए, हम एक सिस्टम विकसित कर सकते हैं जो समान मिलावट को खोजता है। शायद हम कैथ-मॉरिस-प्राट (KMP) खोज अल्गोरिडम को ट्रान्सफ़ॉर्मर अर्किटेक्चर के साथ मिलाकर खोज क्षमता बढ़ा सकते हैं।