---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: इमेजनेट वर्गीकरण में 2025 की प्रगति
translated: true
type: note
---

2012 के बाद हुए नाटकीय सुधारों के बाद से इमेजनेट (विशेष रूप से इमेज वर्गीकरण के लिए इमेजनेट-1K वैलिडेशन सेट) पर स्टेट-ऑफ-द-आर्ट (SOTA) में लगातार प्रगति जारी है। नवंबर 2025 तक, अग्रणी मॉडल लगभग 91% की शीर्ष-1 सटीकता हासिल करते हैं, जो लगभग 9% की शीर्ष-1 त्रुटि दर के अनुरूप है। शीर्ष-5 सटीकता और भी अधिक है, जो आमतौर पर 99% से अधिक होती है, जिसके लिए शीर्ष-5 त्रुटि दर 1% से कम होती है।

### प्रमुख SOTA मॉडल (पेपर्स विथ कोड लीडरबोर्ड से शीर्ष-5)
शीर्ष-1 सटीकता के आधार पर वर्तमान शीर्ष प्रदर्शन करने वालों (इमेजनेट-1K पर फाइन-ट्यून किए गए) का एक स्नैपशॉट यहां दिया गया है। इन बहुत ही उच्च-प्रदर्शन वाले मॉडल के लिए शीर्ष-5 सटीकता हमेशा स्पष्ट रूप से दोबारा रिपोर्ट नहीं की जाती है (क्योंकि वे लगभग-सही स्तरों पर संतृप्त हो जाते हैं), लेकिन समान हालिया आर्किटेक्चर के साथ क्रॉस-रेफरेंसिंग से पता चलता है कि सभी के लिए शीर्ष-5 त्रुटि 1% से कम है:

| रैंक | मॉडल | शीर्ष-1 सटीकता | अनुमानित शीर्ष-5 सटीकता | पैरामीटर्स | नोट्स |
|------|--------|----------------|---------------------|------------|-------|
| 1 | CoCa (फाइन-ट्यून्ड) | 91.0% (9.0% त्रुटि) | ~99.5% (<0.5% त्रुटि) | 2.1B | मल्टीमॉडल इमेज-टेक्स्ट मॉडल; जीरो-शॉट (86.3% शीर्ष-1) और फ्रोजन-एनकोडर सेटिंग्स (90.6% शीर्ष-1) में उत्कृष्ट। |
| 2 | Model Soups (BASIC-L) | 90.98% (9.02% त्रुटि) | ~99.4% (<0.6% त्रुटि) | ~1B | बेहतर रोबस्टनेस के लिए फाइन-ट्यून्ड मॉडल्स का एन्सेम्बल एवरेजिंग। |
| 3 | Model Soups (ViT-G/14) | 90.94% (9.06% त्रुटि) | ~99.4% (<0.6% त्रुटि) | 1.8B | ViT-आधारित; आउट-ऑफ-डिस्ट्रीब्यूशन डेटा के लिए मजबूत सामान्यीकरण। |
| 4 | DaViT-Giant | 90.4% (9.6% त्रुटि) | ~99.3% (<0.7% त्रुटि) | 1.4B | ड्यूल-अटेंशन ViT; 1.5B इमेज-टेक्स्ट जोड़े पर प्रशिक्षित। |
| 5 | ConvNeXt V2-Huge | 88.9% (11.1% त्रुटि) | ~99.0% (~1.0% त्रुटि) | 660M | मास्क्ड ऑटोएनकोडर प्रीट्रेनिंग के साथ CNN पुनरुद्धार; एज डिवाइस के लिए कुशल। |

### "आज <3%" पर स्पष्टीकरण
- यह **शीर्ष-5 त्रुटि दर** को संदर्भित करता है, शीर्ष-1 को नहीं। 2012 से पहले के बेसलाइन (जैसे, SVM) लगभग 25% शीर्ष-5 त्रुटि के आसपास थे। 2017 (SENet) तक, यह घटकर ~2.3% हो गई। आधुनिक SOTA मॉडल्स ने इसे 1% से नीचे धकेल दिया है, जिससे शीर्ष-5 भविष्यवाणियां अधिकांश वास्तविक दुनिया के उपयोग के मामलों के लिए अनिवार्य रूप से विश्वसनीय हो गई हैं।
- शीर्ष-1 त्रुटि अभी भी अधिक (~9%) बनी हुई है क्योंकि इसके लिए *सटीक* शीर्ष भविष्यवाणी का मेल होना आवश्यक है, जो अधिक सख्त है और अस्पष्ट छवियों जैसे एज केस के प्रति अधिक संवेदनशील है।

डेटासेट संतृप्ति के कारण हाल के वर्षों में प्रगति धीमी हो गई है—लाभ अब बड़े पैमाने पर प्रीट्रेनिंग (जैसे, इमेजनेट-21K या वेब-स्केल डेटा पर) और मॉडल एन्सेम्बलिंग या डिस्टिलेशन जैसी तकनीकों से आते हैं। मानव विशेषज्ञ प्रदर्शन लगभग ~5% शीर्ष-1 त्रुटि (या अध्ययन के अनुसार 2-12% शीर्ष-5) पर अनुमानित है, इसलिए AI ने इस बेंचमार्क पर मनुष्यों को पछाड़ दिया है।

[इमेजनेट बेंचमार्क (पेपर्स विथ कोड)](https://paperswithcode.com/sota/image-classification-on-imagenet)  
[इमेज क्लासिफिकेशन: 2025 में स्टेट-ऑफ-द-आर्ट मॉडल (हायरिंगनेट)](https://hiringnet.com/image-classification-state-of-the-art-models-in-2025)  
[CoCa: कंट्रास्टिव कैप्शनर्स आर इमेज-टेक्स्ट फाउंडेशन मॉडल्स (arXiv)](https://arxiv.org/abs/2205.01917)