---
audio: false
generated: true
image: false
lang: hi
layout: post
title: एआई की गति मिलती है वास्तविक दुनिया की उपयोगिता से
translated: true
type: note
---

यहां पेपर के **मुख्य बिंदु** दिए गए हैं:

---

### मूल अवधारणा

* **पारंपरिक AI बेंचमार्क** मुख्य रूप से सटीकता/गुणवत्ता पर केंद्रित होते हैं, लेकिन **प्रसंस्करण गति** को नजरअंदाज करते हैं, जो वास्तविक दुनिया की समय-संवेदनशील एप्लिकेशन्स (जैसे, स्वायत्त ड्राइविंग, ग्राहक सेवा) के लिए महत्वपूर्ण है।
* मौजूदा गति मेट्रिक्स (TTFT, TPS) **टोकन-केंद्रित** हैं और एक बहु-मोडल AI भविष्य के लिए अपर्याप्त हैं।
* **प्रस्तावित नया मेट्रिक**: **इंटेलिजेंस बैंडविड्थ** — प्रति इकाई समय में एक AI द्वारा उत्पादित उपयोगी जानकारी की मात्रा।

---

### इंटेलिजेंस बैंडविड्थ के अनुमान

1. **बेंचमार्क स्कोर प्रति समय**

   * लिए गए समय से विभाजित सामान्यीकृत बेंचमार्क प्रदर्शन का उपयोग करें।
   * व्यावहारिक कार्यों के लिए टोकन/सेकंड से अधिक जानकारीपूर्ण।

2. **सूचना सिद्धांत दृष्टिकोण**

   * संभाव्यता वितरण के माध्यम से आउटपुट सूचना सामग्री मापें।
   * सीमित है क्योंकि सूचना ≠ उपयोगिता और इसके लिए संभाव्यता वैक्टर तक पहुंच की आवश्यकता होती है।

3. **कच्चे आउटपुट बिट्स प्रति सेकंड**

   * सबसे सरल, मोडैलिटी-अग्नोस्टिक।
   * AI आउटपुट (टेक्स्ट, इमेज, वीडियो) के बिट्स/सेकंड को मापता है।
   * सीधे तौर पर उपयोगिता को नहीं मापता, लेकिन काम करता है यदि केवल शीर्ष-प्रदर्शन करने वाले मॉडल्स पर लागू किया जाए।

---

### ऐतिहासिक संदर्भ

* गति को पहले नजरअंदाज किया गया था क्योंकि:

  1. AI इसे जरूरत के लिए पर्याप्त रूप से उन्नत नहीं था।
  2. एप्लिकेशन संकीर्ण और कार्य-विशिष्ट थे।
* **LLMs** और **बहु-मोडल AI** के साथ, एक **एकीकृत गति मेट्रिक** आवश्यक हो गया है।

---

### मानव-AI इंटरैक्शन के निहितार्थ

* **मूर का नियम** और **नील्सन का नियम** के समान, यह मेट्रिक विकास के रुझानों को प्रकट कर सकता है।
* **सीमा अवधारणा**: एक बार AI आउटपुट गति मानव अवधारणात्मक गति (जैसे, पढ़ना या सुनना) से आगे निकल जाती है, तो रियल-टाइम इंटरैक्शन संभव हो जाता है।
* AI पहले से ही मानव पढ़ने और सुनने की गति से आगे निकल चुका है; अगला फ्रंटियर **रियल-टाइम इमेज और वीडियो एकीकरण** है।
* भविष्य: AI **रियल-टाइम विज़ुअल रीजनिंग, व्हाइटबोर्ड-स्टाइल डिज़ाइन, और इमर्सिव वर्चुअल वातावरण** का समर्थन कर सकता है।

---

### प्रयोग और डेटा

* **कच्चे आउटपुट बिट्स/सेकंड** का उपयोग करके ऐतिहासिक LLMs, इमेज और वीडियो जनरेटर में माप।
* **अवलोकन**:

  * LLMs: 0–3 KB/s.
  * इमेज जनरेटर: घातीय वृद्धि।
  * वीडियो जनरेटर: वर्तमान में पिछड़े हुए हैं लेकिन तेज होने की उम्मीद है।
  * **Gemini 2.5 Flash** एक अपवाद है (कम विलंबता के लिए अनुकूलित)।

---

### जिन का नियम

* **सूत्रीकरण**: *सर्वश्रेष्ठ सार्वजनिक रूप से उपलब्ध होस्टेड AI मॉडल की इंटेलिजेंस बैंडविड्थ हर साल दोगुनी हो जाती है।*
* वर्तमान में **इमेज जनरेटर** द्वारा अगुआई; वीडियो के सर्विंग में सुधार के साथ अग्रणी होने की उम्मीद है।
* **भविष्यवाणियां**:

  1. **AI चैट में इमेज इंटीग्रेशन** 1 वर्ष के भीतर मानक बन जाएगा।
  2. **रियल-टाइम वीडियो इंटरैक्शन** लगभग ~3 वर्षों के भीतर संभव (लगभग ~8× गति वृद्धि की आवश्यकता है)।

---

### सीमाएं

* **"उपयोगी जानकारी"** को परिभाषित करना अनसुलझा रहता है।
* वर्तमान डेटा विरल है, इसलिए 1-वर्ष की दोगुनी होने का अनुमान अनिश्चित है।
* वृद्धि प्रौद्योगिकी प्रगति से ही नहीं, बल्कि ऊर्जा/अर्थव्यवस्था द्वारा सीमित हो सकती है।

---

### निष्कर्ष

* AI मूल्यांकन को **सहीता और गति दोनों** को ध्यान में रखना चाहिए, जो मानव बुद्धिमत्ता मूल्यांकन को दर्शाता है।
* **इंटेलिजेंस बैंडविड्थ** AI के भविष्य, विशेष रूप से **रियल-टाइम, बहु-मोडल इंटरैक्शन** के लिए एक भविष्यसूचक ढांचा प्रदान करता है।

---

क्या आप चाहते हैं कि मैं जिन के नियम की भविष्यवाणियों (टेक्स्ट → इमेज → वीडियो → इमर्सिव वातावरण) की एक **विज़ुअल-स्टाइल टाइमलाइन** भी बनाऊं ताकि इसे एक नजर में समझना आसान हो?