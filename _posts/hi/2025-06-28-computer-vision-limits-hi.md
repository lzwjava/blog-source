---
audio: false
generated: true
lang: hi
layout: post
title: कंप्यूटर विज़न मनुष्यों से कमतर है
translated: true
type: note
---

यिन वांग की ब्लॉग पोस्ट में तर्क दिया गया है कि कंप्यूटर विज़न सिस्टम, यहां तक कि 2019 में मौजूद उन्नत सिस्टम भी, मानव-स्तरीय प्रदर्शन प्राप्त करने से बहुत दूर थे। यह दावा करती है कि ये सिस्टम बुनियादी ऑब्जेक्ट रिकग्निशन (जैसे, कार की पहचान) में संघर्ष करते हैं और एडवरसैरियल उदाहरणों या छोटे-मोटे इमेज परिवर्तनों से आसानी से भ्रमित हो जाते हैं, जबकि मनुष्य बिना किसी प्रयास के ऑब्जेक्ट्स को पहचान लेते हैं। वांग का सुझाव है कि यह क्षेत्र अपनी प्रगति को अतिरंजित करता है और वास्तविक मानव-स्तरीय कंप्यूटर विज़न, इन सिस्टम्स के इमेज प्रोसेसिंग और समझने के तरीके में मौजूद मौलिक सीमाओं के कारण, अब भी एक दूर का लक्ष्य बना हुआ है।

### क्या यह सच है?
पोस्ट के अक्टूबर 2019 में प्रकाशित होने के समय तक, उस समय कंप्यूटर विज़न की स्थिति के आधार पर वांग का तर्क वाजिब था:

- **सीमित सामान्यीकरण**: कंप्यूटर विज़न मॉडल, जैसे कन्व्होल्यूशनल न्यूरल नेटवर्क (CNN), प्रशिक्षण डेटा के भीतर पैटर्न मिलान पर बहुत अधिक निर्भर थे। वे अक्सर नए संदर्भों में सामान्यीकरण करने में विफल रहते थे या एज केस को अच्छी तरह से हैंडल नहीं कर पाते थे, जैसा कि वांग बताते हैं। उदाहरण के लिए, प्रकाश व्यवस्था, कोण या पृष्ठभूमि में महत्वपूर्ण परिवर्तन होने पर मॉडल ऑब्जेक्ट्स को गलत वर्गीकृत कर सकते थे।

- **एडवरसैरियल भेद्यता**: एडवरसैरियल उदाहरणों के बारे में वांग का बिंदु—ऐसी छवियां जिनमें मॉडल को गुमराह करने के लिए सूक्ष्म परिवर्तन किए गए हों—सही था। गुडफेलो एट अल (2014) जैसे शोध ने दिखाया कि छोटे, अगोचर विक्षोभ मॉडल को उच्च आत्मविश्वास के साथ छवियों को गलत वर्गीकृत करने के लिए प्रेरित कर सकते हैं, जो मानव और मशीनी दृष्टि के बीच की खाई को उजागर करता है।

- **अतिरंजित दावे**: यह पोस्ट कंप्यूटर विज़न के आसपास के हाइप की आलोचना करती है। 2019 में, जबकि ResNet, YOLO और शुरुआती ट्रांसफॉर्मर जैसे मॉडल बेंचमार्क (जैसे ImageNet) पर प्रभावशाली परिणाम दिखा रहे थे, ये नियंत्रित डेटासेट थे। वास्तविक दुनिया के अनुप्रयोगों ने अक्सर कमजोरियों को उजागर किया, जैसे स्वायत्त ड्राइविंग या फेशियल रिकग्निशन सिस्टम में गलत पहचान।

हालाँकि, पोस्ट का स्वर निरपेक्ष है, जिसमें दावा किया गया है कि "कोई मानव-स्तरीय कंप्यूटर विज़न नहीं है।" यह विशिष्ट कार्यों में प्रगति को नज़रअंदाज़ करता है। उदाहरण के लिए:
- **कार्य-विशिष्ट सफलता**: 2019 तक, कंप्यूटर विज़न सिस्टम संकीर्ण कार्यों में मनुष्यों से बेहतर प्रदर्शन कर रहे थे, जैसे कुछ चिकित्सा छवियों का वर्गीकरण (जैसे, डायबिटिक रेटिनोपैथी का पता लगाना) या नियंत्रित सेटिंग्स में विशिष्ट वस्तुओं को पहचानना।
- **2019 के बाद की प्रगति**: 2025 तक, विज़न ट्रांसफॉर्मर (जैसे ViT, CLIP) और बड़े पैमाने वाले मल्टीमॉडल मॉडल (जैसे GPT-4o, DALL·E 3) जैसी उन्नति ने इस अंतर को कम किया है। ये मॉडल अधिक विविध इनपुट को हैंडल करते हैं, विभिन्न संदर्भों में बेहतर सामान्यीकरण करते हैं, और बेहतर तर्क के लिए भाषा और दृष्टि को एकीकृत करते हैं। फिर भी, वे मानव दृष्टि की मजबूती, संदर्भ जागरूकता या सहज समझ की पूर्ण नकल नहीं करते।

### गंभीर आकलन
वांग का मुख्य दावा—कि 2019 में कंप्यूटर विज़न मानव-स्तरीय नहीं था—बड़े पैमाने पर सच है। मॉडलों में मानवीय दृष्टि के सामान्यीकरण, मजबूती और सहज समझ का अभाव था। हालाँकि, प्रगति को खारिज करना उनका अत्यधिक निराशावादी रवैया हो सकता है, क्योंकि तब से महत्वपूर्ण प्रगति हुई है। यहां तक कि 2025 में भी, जबकि कंप्यूटर विज़न विशिष्ट डोमेन में उत्कृष्ट प्रदर्शन करता है, यह अभी भी ओपन-वर्ल्ड परिदृश्यों में मानव-स्तरीय धारणा से छूट जाता है, जैसे मुद्दों के कारण:
- **सांदर्भिक तर्क**: मनुष्य संवेदी डेटा को दुनिया के ज्ञान के साथ सहजता से एकीकृत करते हैं; मशीनें इसके साथ संघर्ष करती हैं।
- **एज केस**: मॉडल दुर्लभ या नवीन स्थितियों में विफल हो सकते हैं जहां मनुष्य जल्दी से अनुकूलन कर लेते हैं।
- **ऊर्जा दक्षता**: मानव दृष्टि कम्प्यूटेशनल मॉडल की तुलना में कहीं अधिक ऊर्जा कुशल है।

यह पोस्ट AI क्षमताओं के अतिरंजन की आलोचना के रूप में प्रासंगिक बनी हुई है, लेकिन इस क्षेत्र में तेजी से हो रही प्रगति को ध्यान में नहीं रखती। कोई भी एकल स्रोत यह पुष्टि नहीं करता कि 2025 तक "मानव-स्तरीय" दृष्टि हासिल कर ली गई है, लेकिन यह अंतर काफी कम हो गया है।[](https://yinwang0.wordpress.com/2019/10/20/human-level-computer-vision/)