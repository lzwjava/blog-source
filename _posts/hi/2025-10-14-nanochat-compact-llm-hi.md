---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: नैनोचैट कॉम्पैक्ट फुल स्टैक एलएलएम
translated: true
type: note
---

### नैनोचैट क्या है?

नैनोचैट एक बड़े भाषा मॉडल (LLM) सिस्टम, जैसे कि ChatGPT, का एक सघन, फुल-स्टैक कार्यान्वयन है, जो एक ही न्यूनतम कोडबेस में बनाया गया है जिसे हैक करना आसान है और इसके लिए कम निर्भरताओं की आवश्यकता होती है। इसे आंद्रेज कार्पाथी (AI में उनके काम के लिए प्रसिद्ध, जैसे nanoGPT) द्वारा बनाया गया है, और यह पूरी LLM पाइपलाइन—टोकनाइजेशन और प्रीट्रेनिंग से लेकर फाइन-ट्यूनिंग, मूल्यांकन, अनुमान, और यहां तक कि आपके मॉडल से चैट करने के लिए एक साधारण वेब UI तक—को किफायती हार्डवेयर जैसे कि एक सिंगल 8xH100 GPU नोड पर चलाने के लिए डिज़ाइन किया गया है।

इसे "$100 में मिलने वाला सबसे अच्छा ChatGPT" के रूप में प्रस्तुत किया गया है, जो बजट-अनुकूल LLM विकास (कुल $1,000 से कम) के लिए एक बेसलाइन के रूप में कार्य करता है। यह इसे यूरेका लैब्स द्वारा आगामी LLM101n पाठ्यक्रम के लिए एक कैपस्टोन प्रोजेक्ट बनाता है, जो जटिल कॉन्फ़िग्स पर सादगी को प्राथमिकता देता है।

### मुख्य विशेषताएं
- **एंड-टू-एंड पाइपलाइन**: लगभग 2,000 लाइनों के कोड में सब कुछ संभालता है (निर्भरताओं के लिए एक छोटी सी `uv.lock` फ़ाइल के साथ)। 8xH100 सेटअप पर लगभग $24/घंटा की लागत में लगभग 4 घंटे में 4e19 FLOPs के साथ एक सक्षम मॉडल को प्रशिक्षित करता है।
- **ChatGPT-जैसा UI**: प्रशिक्षण के बाद, वास्तविक ChatGPT की तरह ही अपने मॉडल के साथ बातचीत करने के लिए एक वेब सर्वर शुरू करें।
- **मूल्यांकन रिपोर्ट**: ARC-Challenge, GSM8K, HumanEval, MMLU, और अन्य जैसे कार्यों पर बेंचमार्क स्कोर के साथ एक `report.md` स्वचालित रूप से उत्पन्न करता है। उदाहरण के लिए, एक नमूना $100 रन चरणों (BASE, MID, SFT, RL) में प्रगतिशील सुधार दिखाता है:

| मीट्रिक        | BASE   | MID    | SFT    | RL     |
|---------------|--------|--------|--------|--------|
| CORE          | 0.2219 | -      | -      | -      |
| ARC-Challenge | -      | 0.2875 | 0.2807 | -      |
| ARC-Easy      | -      | 0.3561 | 0.3876 | -      |
| GSM8K         | -      | 0.0250 | 0.0455 | 0.0758 |
| HumanEval     | -      | 0.0671 | 0.0854 | -      |
| MMLU          | -      | 0.3111 | 0.3151 | -      |
| ChatCORE      | -      | 0.0730 | 0.0884 | -      |

(कुल समय: पूरे रन के लिए ~3h51m।)
- **हार्डवेयर लचीलापन**: Ampere 8xA100 (धीमा), सिंगल GPU (ऑटो ग्रेडिएंट एक्यूमुलेशन के साथ), या बैच साइज को ट्वीक करके कम-VRAM सेटअप पर काम करता है। वैनिला PyTorch का उपयोग करता है; ट्वीक्स के साथ अन्य डिवाइसों के लिए अनुकूलनीय।
- **डेटा स्रोत**: Hugging Face डेटासेट जैसे FineWeb और SmolTalk से डेटा लेता है।
- **अतिरिक्त**: टेस्ट शामिल हैं (उदा., Rust-आधारित टोकनाइज़र के लिए), और पूरे रेपो (~330KB) को अन्य LLM के साथ क्वेरी करने के लिए पैकेज करना आसान है।

यह कार्पाथी के पहले के nanoGPT प्रोजेक्ट और modded-nanoGPT से प्रेरित है, लेकिन एक पूर्ण चैट अनुभव के लिए स्केल किया गया है।

### कैसे शुरुआत करें
सबसे तेज़ तरीका `speedrun.sh` स्क्रिप्ट है, जो 8xH100 (उदा., Lambda Labs के माध्यम से) पर $100-टियर मॉडल को एंड-टू-एंड हैंडल करती है:

1. एक 8xH100 इंस्टेंस बूट करें और रेपो को क्लोन करें।
2. रन करें:
   ```
   bash speedrun.sh
   ```
   (या लॉगिंग के लिए स्क्रीन सेशन में: `screen -L -Logfile speedrun.log -S speedrun bash speedrun.sh`. डिटैच करने के लिए Ctrl+A+D दबाएं और लॉग को टेल करें।)

3. एक बार पूरा होने (~4 घंटे) के बाद, env को एक्टिवेट करें (`source .venv/bin/activate`) और UI सर्व करें:
   ```
   python -m scripts.chat_web
   ```
   अपने मॉडल से चैट करने के लिए लोकल URL (जैसे, http://your-ip:8000) खोलें। परिणामों के लिए `report.md` जांचें।

बड़े मॉडल (उदा., $300 टियर लगभग 12 घंटे में, कुछ स्कोर पर GPT-2 को मात देते हुए) के लिए, अधिक डेटा शार्ड डाउनलोड करने और डेप्थ/बैच साइज़ को एडजस्ट करने के लिए `speedrun.sh` को एडिट करें। टेस्ट रन करें जैसे `python -m pytest tests/test_rustbpe.py -v -s`.

यह MIT-लाइसेंस्ड है और माइक्रो-मॉडल्स को आगे बढ़ाने के लिए योगदान के लिए खुला है। विस्तृत वॉकथ्रू के लिए, रेपो के Discussions देखें।

[nanoChat GitHub Repo](https://github.com/karpathy/nanochat)