---
audio: false
generated: true
lang: hi
layout: post
title: рд╕реАрдПрдирдПрди рдФрд░ рд╡рд┐рдЬрд╝рди рдЯреНрд░рд╛рдВрд╕рдлреЙрд░реНрдорд░ (рд╡реАрдЖрдИрдЯреА) рдХреЗ рд╕рд╛рде рдЫрд╡рд┐ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг
translated: true
type: note
---

рдиреАрдЪреЗ **Convolutional Neural Networks (CNNs)** рдФрд░ **Vision Transformers (ViT)** рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ Python рдореЗрдВ **PyTorch** рдХреЗ рд╕рд╛рде рдЫрд╡рд┐ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдХреЗ рдХреЛрдб рдЙрджрд╛рд╣рд░рдг рджрд┐рдП рдЧрдП рд╣реИрдВред

---

## **1. рд╕реАрдПрдирдПрди (рдХрдиреНрд╡реЙрд▓реНрдпреВрд╢рдирд▓ рдиреНрдпреВрд░рд▓ рдиреЗрдЯрд╡рд░реНрдХ) рдХреЗ рд╕рд╛рде рдЫрд╡рд┐ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг**
рд╕реАрдПрдирдПрди рдХрд╛ рд╡реНрдпрд╛рдкрдХ рд░реВрдк рд╕реЗ рдЫрд╡рд┐ рд╡рд░реНрдЧреАрдХрд░рдг, рд╡рд╕реНрддреБ рдкрд╣рдЪрд╛рди рдФрд░ рдлреАрдЪрд░ рдирд┐рд╖реНрдХрд░реНрд╖рдг рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИред

### **рдЙрджрд╛рд╣рд░рдг: рдПрдХ рдкреНрд░реА-рдЯреНрд░реЗрдВрдб рд╕реАрдПрдирдПрди (ResNet) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдирд╛**
```python
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image

# рдПрдХ рдкреНрд░реА-рдЯреНрд░реЗрдВрдб ResNet рдореЙрдбрд▓ рд▓реЛрдб рдХрд░реЗрдВ
model = models.resnet18(pretrained=True)
model.eval()  # рдореВрд▓реНрдпрд╛рдВрдХрди рдореЛрдб рдореЗрдВ рд╕реЗрдЯ рдХрд░реЗрдВ

# рдЫрд╡рд┐ рдкреНрд░реАрдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░реЗрдВ
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# рдПрдХ рдЫрд╡рд┐ рд▓реЛрдб рдХрд░реЗрдВ рдФрд░ рдЙрд╕рдХреА рдкреНрд░реАрдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдХрд░реЗрдВ
image = Image.open("example.jpg")  # рдЕрдкрдиреА рдЫрд╡рд┐ рдкрде рдХреЗ рд╕рд╛рде рдмрджрд▓реЗрдВ
input_tensor = preprocess(image)
input_batch = input_tensor.unsqueeze(0)  # рдмреИрдЪ рдбрд╛рдпрдореЗрдВрд╢рди рдЬреЛрдбрд╝реЗрдВ

# рдпрджрд┐ рдЙрдкрд▓рдмреНрдз рд╣реЛ рддреЛ GPU рдкрд░ рд▓реЗ рдЬрд╛рдПрдВ
if torch.cuda.is_available():
    input_batch = input_batch.to('cuda')
    model.to('cuda')

# рдлреАрдЪрд░реНрд╕ рдирд┐рдХрд╛рд▓реЗрдВ (рдЕрдВрддрд┐рдо рд╡рд░реНрдЧреАрдХрд░рдг рд▓реЗрдпрд░ рд╕реЗ рдкрд╣рд▓реЗ)
with torch.no_grad():
    features = model(input_batch)

print("рдлреАрдЪрд░ рд╡реЗрдХреНрдЯрд░ рдЖрдХрд╛рд░:", features.shape)  # рдЙрджрд╛., torch.Size([1, 1000])
```
**рд╕реНрдкрд╖реНрдЯреАрдХрд░рдг**:
1. **ResNet18** рдПрдХ рд╕реАрдПрдирдПрди рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рд╣реИ рдЬреЛ ImageNet рдкрд░ рдкреНрд░реА-рдЯреНрд░реЗрдВрдб рд╣реИред
2. рдЫрд╡рд┐ рдХреА рдкреНрд░реАрдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдХреА рдЬрд╛рддреА рд╣реИ (рдЖрдХрд╛рд░ рдмрджрд▓рд╛ рд╣реБрдЖ, рд╕рд╛рдорд╛рдиреНрдпреАрдХреГрдд)ред
3. рдореЙрдбрд▓ рдЫрд╡рд┐ рдХреЛ рдПрдХ **рдлреАрдЪрд░ рд╡реЗрдХреНрдЯрд░** рдореЗрдВ рдмрджрд▓ рджреЗрддрд╛ рд╣реИ (рдЙрджрд╛., ResNet18 рдХреЗ рд▓рд┐рдП 1000-рдбрд╛рдпрдореЗрдВрд╢рдирд▓)ред

---

## **2. рд╡рд┐рдЬрди рдЯреНрд░рд╛рдВрд╕рдлреЙрд░реНрдорд░ (ViT) рдХреЗ рд╕рд╛рде рдЫрд╡рд┐ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг**
ViT рдЫрд╡рд┐рдпреЛрдВ рдХреЛ рдкреИрдЪ рдХреЗ рдЕрдиреБрдХреНрд░рдо рдХреЗ рд░реВрдк рдореЗрдВ рдорд╛рдирддреЗ рд╣реИрдВ рдФрд░ рд╕реЗрд▓реНрдл-рдЕрдЯреЗрдВрд╢рди рдореИрдХреЗрдирд┐рдЬреНрдо (рдЬреИрд╕реЗ NLP рдореЗрдВ) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред

### **рдЙрджрд╛рд╣рд░рдг: рдПрдХ рдкреНрд░реА-рдЯреНрд░реЗрдВрдб ViT (Hugging Face) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдирд╛**
```python
from transformers import ViTFeatureExtractor, ViTModel
from PIL import Image
import torch

# рдПрдХ рдкреНрд░реА-рдЯреНрд░реЗрдВрдб рд╡рд┐рдЬрди рдЯреНрд░рд╛рдВрд╕рдлреЙрд░реНрдорд░ (ViT) рд▓реЛрдб рдХрд░реЗрдВ
model_name = "google/vit-base-patch16-224-in21k"
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)
model = ViTModel.from_pretrained(model_name)

# рдПрдХ рдЫрд╡рд┐ рд▓реЛрдб рдХрд░реЗрдВ
image = Image.open("example.jpg")  # рдЕрдкрдиреА рдЫрд╡рд┐ рдкрде рдХреЗ рд╕рд╛рде рдмрджрд▓реЗрдВ

# рдЫрд╡рд┐ рдХреА рдкреНрд░реАрдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдХрд░реЗрдВ (рдкреИрдЪ рдореЗрдВ рдмрджрд▓реЗрдВ)
inputs = feature_extractor(images=image, return_tensors="pt")

# рдлреАрдЪрд░реНрд╕ рдирд┐рдХрд╛рд▓реЗрдВ (CLS рдЯреЛрдХрди рдпрд╛ рдкреИрдЪ рдПрдореНрдмреЗрдбрд┐рдВрдЧ)
with torch.no_grad():
    outputs = model(**inputs)

# рдлреАрдЪрд░ рд╡реЗрдХреНрдЯрд░ рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВ (CLS рдЯреЛрдХрди)
features = outputs.last_hidden_state[:, 0, :]  # рдЖрдХрд╛рд░: [1, 768]

print("рдлреАрдЪрд░ рд╡реЗрдХреНрдЯрд░ рдЖрдХрд╛рд░:", features.shape)  # рдЙрджрд╛., torch.Size([1, 768])
```
**рд╕реНрдкрд╖реНрдЯреАрдХрд░рдг**:
1. **ViT** рдЫрд╡рд┐ рдХреЛ **16x16 рдкреИрдЪ** рдореЗрдВ рд╡рд┐рднрд╛рдЬрд┐рдд рдХрд░рддрд╛ рд╣реИ рдФрд░ рдЙрдиреНрд╣реЗрдВ NLP рдореЗрдВ рдЯреЛрдХрди рдХреА рддрд░рд╣ рдкреНрд░реЛрд╕реЗрд╕ рдХрд░рддрд╛ рд╣реИред
2. `CLS рдЯреЛрдХрди` (рдкрд╣рд▓рд╛ рдЯреЛрдХрди) рдкреВрд░реА рдЫрд╡рд┐ рдХреЗ рдлреАрдЪрд░ рд╡реЗрдХреНрдЯрд░ рдХреЛ рдкреНрд░рд╕реНрддреБрдд рдХрд░рддрд╛ рд╣реИред
3. рдЖрдЙрдЯрдкреБрдЯ рдПрдХ **768-рдбрд╛рдпрдореЗрдВрд╢рдирд▓ рд╡реЗрдХреНрдЯрд░** рд╣реЛрддрд╛ рд╣реИ (`vit-base` рдХреЗ рд▓рд┐рдП)ред

---

## **3. рд╕реАрдПрдирдПрди рдмрдирд╛рдо ViT рдлреАрдЪрд░ рдирд┐рд╖реНрдХрд░реНрд╖рдг рдХреА рддреБрд▓рдирд╛**

| рдореЙрдбрд▓ | рдЕрдкреНрд░реЛрдЪ | рдлреАрдЪрд░ рд╡реЗрдХреНрдЯрд░ рд╕рд╛рдЗрдЬ | рд▓рд╛рдЗрдмреНрд░реЗрд░реАрдЬ |
|-------|----------|---------------------|-----------|
| **рд╕реАрдПрдирдПрди (ResNet18)** | рдХрдиреНрд╡реЙрд▓реНрдпреВрд╢рдирд▓ рд▓реЗрдпрд░реНрд╕ + рдкреВрд▓рд┐рдВрдЧ | 1000 (ImageNet рдХреНрд▓рд╛рд╕реЗрд╕) | `torchvision` |
| **ViT (Google ViT-Base)** | рдкреИрдЪ рдПрдореНрдмреЗрдбрд┐рдВрдЧ + рдЯреНрд░рд╛рдВрд╕рдлреЙрд░реНрдорд░ | 768 (рд╣рд┐рдбрди рдбрд╛рдпрдореЗрдВрд╢рди) | `transformers` |

---

## **4. рдЫрд╡рд┐ рдлреАрдЪрд░ рд╡реЗрдХреНрдЯрд░реНрд╕ рдХреЗ рдЕрдиреБрдкреНрд░рдпреЛрдЧ**
- **рдЫрд╡рд┐ рдЦреЛрдЬ**: рдлреАрдЪрд░ рд╡реЗрдХреНрдЯрд░реНрд╕ рдХреА рддреБрд▓рдирд╛ рдХрд░реЗрдВ (рдЙрджрд╛., рдХреЛрд╕рд╛рдЗрди рд╕рдорд╛рдирддрд╛)ред
- **рдЯреНрд░рд╛рдВрд╕рдлрд░ рд▓рд░реНрдирд┐рдВрдЧ**: рдХрд╕реНрдЯрдо рдЯрд╛рд╕реНрдХ рдХреЗ рд▓рд┐рдП рдкреНрд░реА-рдЯреНрд░реЗрдВрдб рдлреАрдЪрд░реНрд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред
- **рд╡рд╕реНрддреБ рдкрд╣рдЪрд╛рди**: рдлреАрдЪрд░реНрд╕ рд╕реЗ рд░реБрдЪрд┐ рдХреЗ рдХреНрд╖реЗрддреНрд░ (ROI) рдирд┐рдХрд╛рд▓реЗрдВред

```python
# рдЙрджрд╛рд╣рд░рдг: рджреЛ рдЫрд╡рд┐рдпреЛрдВ рдХреЗ рдмреАрдЪ рд╕рдорд╛рдирддрд╛ рдХреА рдЧрдгрдирд╛ рдХрд░реЗрдВ
from sklearn.metrics.pairwise import cosine_similarity

# рдорд╛рди рд▓реЗрдВ рдХрд┐ features1 рдФрд░ features2 рдирд┐рдХрд╛рд▓реЗ рдЧрдП рд╡реЗрдХреНрдЯрд░ рд╣реИрдВ
similarity = cosine_similarity(features1, features2)
print("рд╕рдорд╛рдирддрд╛ рд╕реНрдХреЛрд░:", similarity[0][0])
```

---

## **рдореБрдЦреНрдп рдмрд╛рддреЗрдВ**
1. **рд╕реАрдПрдирдПрди** (рдЙрджрд╛., ResNet) рд╣рд╛рдпрд░рд╛рд░реНрдХрд┐рдХрд▓ рдлреАрдЪрд░реНрд╕ рдирд┐рдХрд╛рд▓рдиреЗ рдХреЗ рд▓рд┐рдП **рдХрдиреНрд╡реЙрд▓реНрдпреВрд╢рдирд▓ рд▓реЗрдпрд░реНрд╕** рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред
2. **ViT** (рдЙрджрд╛., Google рдХрд╛ ViT) рдЫрд╡рд┐рдпреЛрдВ рдХреЛ **рдкреИрдЪ рдЕрдиреБрдХреНрд░рдо** рдХреЗ рд░реВрдк рдореЗрдВ рдорд╛рдирддреЗ рд╣реИрдВ рдФрд░ **рд╕реЗрд▓реНрдл-рдЕрдЯреЗрдВрд╢рди** рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред
3. рджреЛрдиреЛрдВ рдбрд╛рдЙрдирд╕реНрдЯреНрд░реАрдо рдЯрд╛рд╕реНрдХ рдХреЗ рд▓рд┐рдП рдЫрд╡рд┐рдпреЛрдВ рдХреЛ **рдлреАрдЪрд░ рд╡реЗрдХреНрдЯрд░реНрд╕** рдореЗрдВ рдмрджрд▓ рджреЗрддреЗ рд╣реИрдВред

рдХреНрдпрд╛ рдЖрдк **рдПрдХ рдХрд╕реНрдЯрдо рд╕реАрдПрдирдПрди/рд╡реАрдЖрдИрдЯреА рдХреЛ рд╕реНрдХреНрд░реИрдЪ рд╕реЗ рдЯреНрд░реЗрди рдХрд░рдиреЗ** рдХрд╛ рдЙрджрд╛рд╣рд░рдг рдЪрд╛рд╣реЗрдВрдЧреЗ? рдореБрдЭреЗ рдмрддрд╛рдПрдВ! ЁЯЪА