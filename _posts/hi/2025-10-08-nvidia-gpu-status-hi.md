---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: एनवीडीआईए जीपीयू स्थिति सिंहावलोकन
translated: true
type: note
---

### अवलोकन
यह `nvidia-smi` कमांड का आउटपुट है, जो लिनक्स सिस्टम (यहाँ, पथों के आधार पर, उबंटू या इसी तरह के डिस्ट्रो जैसा लगता है) पर NVIDIA GPU की निगरानी और प्रबंधन के लिए एक टूल है। यह आपके GPU की स्थिति का एक स्नैपशॉट प्रदान करता है, जिसमें हार्डवेयर विवरण, उपयोगिता, बिजली खपत, मेमोरी उपयोग और सक्रिय प्रक्रियाएं शामिल हैं। यह कमांड 7 अक्टूबर, 2025 को स्थानीय समयानुसार रात 3:16:58 बजे, nanoGPT प्रोजेक्ट (एक लोकप्रिय PyTorch-आधारित GPT ट्रेनिंग रेपो) से संबंधित डायरेक्टरी में चलाई गई थी।

आउटपुट को तीन मुख्य भागों में बांटा गया है: सॉफ्टवेयर संस्करणों वाला एक हेडर, GPU की वर्तमान स्थिति का सारांश देने वाली एक तालिका, और GPU का उपयोग कर रही प्रक्रियाओं की एक तालिका। मैं इसे चरण दर चरण समझाऊंगा।

### हेडर
```
मंगल Oct  7 03:16:58 2025
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |
```
- **टाइमस्टैम्प**: जब कमांड निष्पादित की गई थी।
- **NVIDIA-SMI वर्जन**: 535.247.01 (टूल स्वयं)।
- **ड्राइवर वर्जन**: 535.247.01 (आपके सिस्टम पर इंस्टॉल किया गया NVIDIA कर्नल ड्राइवर)।
- **CUDA वर्जन**: 12.2 (CUDA टूलकिट वर्जन, जिसका उपयोग GPU-त्वरित कंप्यूटिंग जैसे PyTorch या TensorFlow में किया जाता है)।

यह सेटअप आधुनिक ML वर्कलोड, जैसे nanoGPT में मॉडल ट्रेनिंग, के लिए अनुकूल है।

### GPU स्थिति तालिका
यह तालिका आपके एकल पहचाने गए GPU (इंडेक्स 0) के विवरण दिखाती है। इसे हार्डवेयर ID, डिस्प्ले स्थिति, एरर करेक्शन, और रियल-टाइम मेट्रिक्स के कॉलम के साथ फॉर्मेट किया गया है।

```
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 4070        On  | 00000000:01:00.0  On |                  N/A |
| 32%   47C    P2              74W / 215W |   3144MiB / 12282MiB |      2%      Default |
|                                         |                      |                  N/A |
```
- **GPU 0**: पहला (और एकमात्र) GPU।
- **नाम**: NVIDIA GeForce RTX 4070 (12GB GDDR6X VRAM वाला एक कंज्यूमर-ग्रेड GPU, गेमिंग और ML ट्रेनिंग के लिए बेहतरीन)।
- **Persistence-M**: "On" का मतलब है कि GPU ड्राइवर तब भी लोडेड रहता है जब कोई ऐप्स इसका उपयोग नहीं कर रही होतीं (ऐप्स के लिए स्टार्टअप लेटेंसी कम करता है)।
- **Bus-Id**: 00000000:01:00.0 (PCIe स्लॉट एड्रेस; मल्टी-GPU सेटअप के ट्रबलशूटिंग के लिए उपयोगी)।
- **Disp.A**: "On" का मतलब है कि GPU एक डिस्प्ले को चला रहा है (जैसे, आपका मॉनिटर)।
- **Volatile Uncorr. ECC**: N/A (मेमोरी के लिए एरर-करेक्टिंग कोड; कंज्यूमर GPU जैसे 4070 पर सपोर्टेड/एनेबल्ड नहीं)।
- **फैन**: 32% स्पीड (कूलिंग फैन मध्यम रूप से चल रहा है)।
- **तापमान**: 47°C (वर्तमान तापमान; सुरक्षित, क्योंकि RTX 4070 ~90°C तक संभाल सकता है)।
- **Perf**: P2 (परफॉर्मेंस स्टेट; P0 मैक्स बूस्ट है, P8 आइडल है—P2 एक संतुलित मध्य स्थिति है)।
- **Pwr:Usage/Cap**: 215W अधिकतम में से 74W करंट ड्रॉ (कम बिजली उपयोग, हल्के लोड का संकेत)।
- **Memory-Usage**: 12282MiB कुल में से 3144MiB उपयोग में (~3GB/12GB; लगभग 26% भरा—बड़े मॉडलों के लिए जगह)।
- **GPU-Util**: 2% (कोर उपयोगिता; बहुत कम, इसलिए GPU ज्यादातर निष्क्रिय है)।
- **Compute M.**: Default (कंप्यूट मोड; कई प्रक्रियाओं को GPU साझा करने की अनुमति देता है)।
- **MIG M.**: N/A (मल्टी-इंस्टेंस GPU पार्टीशनिंग; इस कंज्यूमर कार्ड पर उपलब्ध नहीं)।

कुल मिलाकर, आपका GPU स्वस्थ है और हल्के लोड पर है—शायद सिर्फ डेस्कटॉप ग्राफिक्स और कुछ बैकग्राउंड टास्क्स को संभाल रहा है।

### प्रक्रियाएं तालिका
यह सभी प्रक्रियाओं को सूचीबद्ध करती है जो वर्तमान में GPU मेमोरी या कंप्यूट संसाधनों का उपयोग कर रही हैं। कॉलम में GPU इंडेक्स, प्रोसेस ID (यहाँ GI/CI N/A हैं, क्योंकि वे एडवांस्ड मल्टी-इंस्टेंस ट्रैकिंग के लिए हैं), PID (प्रोसेस ID), टाइप (G=ग्राफिक्स जैसे रेंडरिंग, C=कंप्यूट जैसे ML ट्रेनिंग), प्रोसेस नाम, और मेमोरी उपयोग शामिल हैं।

```
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      2927      G   /usr/lib/xorg/Xorg                          814MiB |
|    0   N/A  N/A      3072      G   /usr/bin/gnome-shell                        158MiB |
|    0   N/A  N/A     24177      G   firefox                                     235MiB |
|    0   N/A  N/A    213795      G   /proc/self/exe                              112MiB |
|    0   N/A  N/A    213796      G   ...erProcess --variations-seed-version       96MiB |
|    0   N/A  N/A    232689      C   python3.10                                 1708MiB |
```
- **2927 G /usr/lib/xorg/Xorg**: 814MiB—X11 डिस्प्ले सर्वर (आपके ग्राफिकल डेस्कटॉप को संभालता है; रेंडरिंग के कारण बड़ा उपयोगकर्ता)।
- **3072 G /usr/bin/gnome-shell**: 158MiB—GNOME डेस्कटॉप एनवायरनमेंट (UI इफेक्ट्स और विंडो प्रबंधन)।
- **24177 G firefox**: 235MiB—Firefox ब्राउज़र (वेब रेंडरिंग/वीडियो के लिए GPU एक्सेलेरेशन)।
- **213795 G /proc/self/exe**: 112MiB—संभवतः एक ब्राउज़र रेंडरर प्रक्रिया (सैंडबॉक्स्ड ऐप्स जैसे Chrome में सेल्फ-रेफरेंशियल पथ आम है)।
- **213796 G ...erProcess --variations-seed-version**: 96MiB—शायद एक Chrome रेंडरर सबप्रोसेस (एलिप्सिस पूरा पथ छुपाता है; फ्लैग्स फीचर एक्सपेरिमेंट्स से संबंधित हैं)।
- **232689 C python3.10**: 1708MiB—कंप्यूट मोड में Python 3.10 प्रक्रिया (यह बड़ी वाली है—संभवतः आपकी nanoGPT ट्रेनिंग स्क्रिप्ट या Jupyter सेशन जो PyTorch/CUDA का उपयोग कर रही है; यह ~1.7GB VRAM पर कब्जा कर रही है)।

कुल GPU मेमोरी लगभग ~3.1GB तक जुड़ती है, जो पहले के उपयोग आंकड़े से मेल खाती है। Python प्रक्रिया यहां मुख्य कंप्यूट वर्कलोड है।

### त्वरित सुझाव
- यदि आप nanoGPT में मॉडल ट्रेन कर रहे हैं, तो उच्च GPU-Util (>80%) और मेमोरी के 12GB के नजदीक पहुंचने पर नजर रखें—यदि यह OOM (आउट ऑफ मेमोरी) हो जाए तो बैच साइज ट्वीक करने पर विचार करें।
- लाइव अपडेट्स के लिए `nvidia-smi -l 1` चलाएं (हर सेकंड)।
- किसी प्रक्रिया को रोकने के लिए: `kill <PID>` (उदाहरण के लिए, यदि Python हैंग कर जाए)।

यह स्नैपशॉट एक स्थिर, कम-लोड वाला सिस्टम दिखाता है जो GPU टास्क्स के लिए तैयार है!