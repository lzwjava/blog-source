---
audio: false
generated: false
image: true
lang: hi
layout: post
title: वेबसाइट की सामग्री को स्क्रैप करना
translated: true
---

ऐसे बहुत से उपकरण उपलब्ध हैं जो वेबसाइटों की सामग्री को स्क्रैप कर सकते हैं। हालांकि, अगर हम उनका उपयोग करते हैं, तो हम पीछे के प्रक्रिया को बेहतर ढंग से समझ नहीं पाएंगे। अगर काम में जटिल या विशेष वेबसाइटों का सामना होता है, तो उनका उपयोग करने से हमें वांछित परिणाम नहीं मिल सकते हैं। हमें पहियों को फिर से बनाने की आवश्यकता है, ताकि हम उन्हें बेहतर ढंग से सीख सकें और उनका बेहतर उपयोग कर सकें।

आइए पहले से मौजूद कुछ टूल्स पर भी एक नज़र डालें।

## डेटा माइनर

![खनिक](assets/images/scrape/miner.png)

`Data Miner` Chrome पर एक बहुत ही सुविधाजनक एक्सटेंशन है। इसका उपयोग लिंक और सामग्री को आसानी से स्क्रैप करने के लिए किया जा सकता है।

## getbook

`getbook` एक बहुत ही सुविधाजनक ई-बुक निर्माण उपकरण है।

```powershell
pip install getbook
```

`book.json`:

```json
{
  "uid": "book",
  "title": "Hello World",
  "author": "Armin",
  "chapters": [
    "http://lucumr.pocoo.org/2018/7/13/python/",
    "http://lucumr.pocoo.org/2017/6/5/diversity-in-technology",
  ]
}
```

```shell
getbook -f ./book.json --mobi
```

इस तरह से कुछ लिंक्स को आसानी से ई-बुक में बदल दिया गया। `Data Miner` और `getbook` का उपयोग करके, एक लिंक्स को क्रॉल करता है और दूसरा उन्हें ई-बुक में बदल देता है, जिससे ई-बुक बनाना बहुत आसान हो जाता है।

## फ़ेमन भौतिकी व्याख्यान

![fl](assets/images/scrape/fl.png)

「项目实战：将费曼物理讲义网页做成电子书」章节中，我们学会了如何将一个使用`mathjax`渲染的`html`网页制作成电子书。这里我们继续这个项目，来看看如何获取所有的网页。费曼物理讲义共有三卷。上图是第一卷的目录。

> http.client — HTTP प्रोटोकॉल क्लाइंट
>
> स्रोत कोड: Lib/http/client.py
>
> यह मॉड्यूल क्लासेस को परिभाषित करता है जो HTTP और HTTPS प्रोटोकॉल के क्लाइंट साइड को लागू करते हैं। यह आमतौर पर सीधे उपयोग नहीं किया जाता है — urllib.request मॉड्यूल HTTP और HTTPS का उपयोग करने वाले URLs को हैंडल करने के लिए इसका उपयोग करता है।
>
> यह भी देखें: उच्च-स्तरीय HTTP क्लाइंट इंटरफेस के लिए Requests पैकेज की सिफारिश की जाती है।

देखा जाए तो `requests` एक उच्च-स्तरीय इंटरफ़ेस है।

```python
import requests
```

```python
def main():
    r = requests.get('https://api.github.com/user', auth=('user', 'pass'))
    print(r.status_code)
```

मुख्य()
```

```shell
401
```

```python
import requests
```

```python
def main():
    r = requests.get('https://github.com')
    print(r.status_code)
    print(r.text)
```

मुख्य()
```

```html
200
<html>
  ...
</html>
```

मैंने कोशिश की, और यह साबित हो गया कि `requests` का इंटरफ़ेस काम कर रहा है।

```html
     <div class="toc-chapter" id="C03">
        <span class="triangle">
         â¶
        </span>
        <a class="chapterlink" href="javascript:Goto(1,3)">
         <span class="tag">
          Chapter 3.
         </span>
         भौतिकी का अन्य विज्ञानों से संबंध
        </a>
        <div class="sections">
         <a href="javascript:Goto(1,3,1)">
          <span class="tag">
           3-1
          </span>
          परिचय
         </a>
         <a href="javascript:Goto(1,3,2)">
          <span class="tag">
           3-2
          </span>
          रसायन विज्ञान
         </a>
         <a href="javascript:Goto(1,3,3)">
          <span class="tag">
           3-3
          </span>
          जीव विज्ञान
         </a>
         <a href="javascript:Goto(1,3,4)">
          <span class="tag">
           3-4
          </span>
          खगोल विज्ञान
         </a>
         <a href="javascript:Goto(1,3,5)">
          <span class="tag">
           3-5
          </span>
          भूविज्ञान
         </a>
         <a href="javascript:Goto(1,3,6)">
          <span class="tag">
           3-6
          </span>
          मनोविज्ञान
         </a>
         <a href="javascript:Goto(1,3,7)">
          <span class="tag">
           3-7
          </span>
          यह इस तरह कैसे हो गया?
         </a>
        </div>
       </div>
```

यह डायरेक्टरी पेज में तीसरे अध्याय का `html` कोड है। यहां से हर अध्याय का लिंक निकालना चाहते हैं। `<a href="javascript:Goto(1,3,7)">` से देखा जा सकता है कि यह एक `javascript` का हाइपरलिंक है।

```
https://www.feynmanlectures.caltech.edu/I_03.html
```

फिर यह पता चला कि प्रत्येक अध्याय का पथ बहुत ही नियमित है। `I_03.html` पहले खंड के तीसरे अध्याय को दर्शाता है।

```python
import requests
from bs4 import BeautifulSoup
from multiprocessing import Process
```

```python
def scrape(chapter):
    if chapter < 1 or chapter > 52:
        raise Exception(f'chapter {chapter}')
    chapter_str = '{:02d}'.format(chapter)
    url = f'https://www.feynmanlectures.caltech.edu/I_{chapter_str}.html'
    print(f'scraping {url}')
    r = requests.get(url)
    if r.status_code != 200:
        raise Exception(r.status_code)
    soup = BeautifulSoup(r.text, features='lxml')
    f = open(f'./chapters/I_{chapter_str}.html', 'w')
    f.write(soup.prettify())
    f.close()
```

```python
def main():
    for i in range(52):
        p = Process(target=scrape, args=(i+1))
        p.start()
        p.join()
        
main()
```

आगे बढ़ते हुए, हम कोड को स्क्रैप करने के बारे में लिखेंगे। यहाँ `Process` का उपयोग किया गया है।

```shell
    raise RuntimeError('''
RuntimeError: 
        वर्तमान प्रक्रिया के बूटस्ट्रैपिंग चरण को पूरा करने से पहले
        एक नई प्रक्रिया शुरू करने का प्रयास किया गया है।
```

        इसका मतलब यह हो सकता है कि आप अपने चाइल्ड प्रक्रियाओं को शुरू करने के लिए fork का उपयोग नहीं कर रहे हैं और आपने मुख्य मॉड्यूल में सही idiom का उपयोग करना भूल गए हैं:

```python
if __name__ == '__main__':
    freeze_support()
    ...
```

        "freeze_support()" लाइन को छोड़ा जा सकता है यदि प्रोग्राम
        को एक एक्जीक्यूटेबल बनाने के लिए फ्रीज नहीं किया जा रहा है।
```

```python
def main():
    for i in range(52):        
        p = Process(target=scrape, args=(i+1,))
        p.start()
    p.join()
```

(यह कोड Python में एक मल्टीप्रोसेसिंग उदाहरण है जहां 52 प्रक्रियाएं शुरू की जाती हैं, जिनमें से प्रत्येक `scrape` फ़ंक्शन को एक अलग आर्ग्युमेंट के साथ कॉल करती है। अंत में, सभी प्रक्रियाओं के समाप्त होने की प्रतीक्षा की जाती है।)

```python
if __name__ == "__main__":
    main()
```

```python
def main():
    start = timeit.default_timer()
    ps = [Process(target=scrape, args=(i+1,)) for i in range(52)]
    for p in ps:
        p.start()
    for p in ps:
        p.join()
    stop = timeit.default_timer()
    print('समय: ', stop - start)
```

यदि __name__ == "__main__":    
    main()
```

```shell
scraping https://www.feynmanlectures.caltech.edu/I_01.html
scraping https://www.feynmanlectures.caltech.edu/I_04.html
...
scraping https://www.feynmanlectures.caltech.edu/I_51.html
scraping https://www.feynmanlectures.caltech.edu/I_52.html
समय:  9.144841699
```

![fig](assets/images/scrape/fig.png)

```html
<div class="figure" id="Ch1-F1">
        <img src="img/FLP_I/f01-01/f01-01_tc_big.svgz">
        <div class="caption empty">
         <span class="tag">
          चित्र 1â1
         </span>
        </div>
</div>
```

```python
import requests
from bs4 import BeautifulSoup
from multiprocessing import Process
import timeit
```

```python
def scrape(chapter):
    if chapter < 1 or chapter > 52:
        raise Exception(f'chapter {chapter}')
    chapter_str = '{:02d}'.format(chapter)
    url = f'https://www.feynmanlectures.caltech.edu/I_{chapter_str}.html'
    print(f'scraping {url}')
    r = requests.get(url)
    if r.status_code != 200:
        raise Exception(r.status_code)
    soup = BeautifulSoup(r.text, features='lxml')
    f = open(f'./chapters/I_{chapter_str}.html', 'w')
    f.write(soup.prettify())
    f.close()
```

```python
def main():
    start = timeit.default_timer()
    ps = [Process(target=scrape, args=(i+1,)) for i in range(52)]
    for p in ps:
        p.start()
    for p in ps:
        p.join()
    stop = timeit.default_timer()
    print('समय: ', stop - start)
```

यदि __name__ == "__main__":    
    main()
```

लिंक देखें।

```python
    imgs = soup.find_all('img')
    for img in imgs:
        print(img)
```

यह कोड Python में लिखा गया है और यह एक वेब पेज से सभी `img` टैग्स को ढूंढता है और उन्हें प्रिंट करता है। `soup.find_all('img')` का उपयोग करके सभी `img` टैग्स को एक लिस्ट में एकत्रित किया जाता है, और फिर `for` लूप के माध्यम से प्रत्येक `img` टैग को प्रिंट किया जाता है।

```html
स्क्रैपिंग https://www.feynmanlectures.caltech.edu/I_01.html
<img id="TwitLink" src=""/>
<img id="FBLink" src=""/>
<img id="MailLink" src=""/>
<img id="MobileLink" src=""/>
<img id="DarkModeLink" src=""/>
<img id="DesktopLink" src=""/>
<img src="img/camera.svg"/>
<img src="img/FLP_I/f01-00/f01-00.jpg"/>
<img data-src="img/FLP_I/f01-01/f01-01_tc_big.svgz"/>
<img data-src="img/FLP_I/f01-02/f01-02_tc_big.svgz"/>
<img data-src="img/FLP_I/f01-03/f01-03_tc_big.svgz"/>
<img data-src="img/FLP_I/f01-04/f01-04_tc_big.svgz"/>
<img data-src="img/FLP_I/f01-05/f01-05_tc_big.svgz"/>
<img data-src="img/FLP_I/f01-06/f01-06_tc_big.svgz"/>
<img class="first" data-src="img/FLP_I/f01-07/f01-07_tc_iPad_big_a.svgz"/>
<img class="last" data-src="img/FLP_I/f01-07/f01-07_tc_iPad_big_b.svgz"/>
<img data-src="img/FLP_I/f01-08/f01-08_tc_big.svgz"/>
<img data-src="img/FLP_I/f01-09/f01-09_tc_big.svgz"/>
<img data-src="img/FLP_I/f01-10/f01-10_tc_big.svgz"/>
```

https://www.feynmanlectures.caltech.edu/img/FLP_I/f01-01/f01-01_tc_big.svgz

```shell
निषिद्ध
```

आपके पास इस संसाधन तक पहुंचने की अनुमति नहीं है।

Apache/2.4.38 (Debian) सर्वर www.feynmanlectures.caltech.edu पर पोर्ट 443 पर चल रहा है
```

```shell
% pip install selenium
Collecting selenium
  Using cached selenium-3.141.0-py2.py3-none-any.whl (904 kB)
Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/site-packages (from selenium) (1.24.2)
Installing collected packages: selenium
Successfully installed selenium-3.141.0
```

```shell
export CHROME_DRIVER_HOME=$HOME/dev-env/chromedriver
export PATH="${PATH}:${CHROME_DRIVER_HOME}"
```

(यह कोड ब्लॉक है, इसे अनुवादित नहीं किया जाना चाहिए।)

```shell
% chromedriver -h
उपयोग: chromedriver [विकल्प]
```

विकल्प
  --port=PORT                     सुनने के लिए पोर्ट
  --adb-port=PORT                 adb सर्वर पोर्ट
  --log-path=FILE                 सर्वर लॉग को stderr के बजाय फ़ाइल में लिखें, लॉग स्तर को INFO तक बढ़ाएं
  --log-level=LEVEL               लॉग स्तर सेट करें: ALL, DEBUG, INFO, WARNING, SEVERE, OFF
  --verbose                       विस्तृत लॉग (--log-level=ALL के समान)
  --silent                        कुछ भी लॉग न करें (--log-level=OFF के समान)
  --append-log                    लॉग फ़ाइल को फिर से लिखने के बजाय जोड़ें
  --replayable                    (प्रायोगिक) विस्तृत लॉग और लंबी स्ट्रिंग्स को छोटा न करें ताकि लॉग को दोबारा चलाया जा सके।
  --version                       संस्करण संख्या प्रिंट करें और बाहर निकलें
  --url-base                      कमांड के लिए आधार URL पथ उपसर्ग, उदाहरण के लिए wd/url
  --readable-timestamp            लॉग में पठनीय टाइमस्टैम्प जोड़ें
  --enable-chrome-logs            ब्राउज़र से लॉग दिखाएं (अन्य लॉगिंग विकल्पों को ओवरराइड करता है)
  --allowed-ips                   दूरस्थ IP पतों की अनुमति सूची जो ChromeDriver से कनेक्ट करने की अनुमति देते हैं, अल्पविराम से अलग किए गए
```

```python
```

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support.expected_conditions import presence_of_element_located
```

यह कोड Selenium वेब ड्राइवर का उपयोग करके वेब ऑटोमेशन के लिए आवश्यक मॉड्यूल्स को इम्पोर्ट करता है। इसमें `webdriver` वेब ब्राउज़र को नियंत्रित करने के लिए, `By` वेब एलिमेंट्स को ढूंढने के लिए, `Keys` कीबोर्ड इनपुट सिम्युलेट करने के लिए, `WebDriverWait` विशिष्ट शर्तों की प्रतीक्षा करने के लिए, और `presence_of_element_located` यह सुनिश्चित करने के लिए कि एक एलिमेंट पेज पर मौजूद है, शामिल हैं।

```python
with webdriver.Chrome() as driver:
    wait = WebDriverWait(driver, 10)
    driver.get("https://google.com/ncr")
    driver.find_element(By.NAME, "q").send_keys("cheese" + Keys.RETURN)
    first_result = wait.until(presence_of_element_located((By.CSS_SELECTOR, "h3>div")))
    print(first_result.get_attribute("textContent"))
```

```python
```

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support.expected_conditions import presence_of_element_located
import urllib
```

यह कोड Selenium और urllib लाइब्रेरी का उपयोग करता है। Selenium एक वेब ब्राउज़र ऑटोमेशन टूल है, जिसका उपयोग वेब एप्लिकेशन को टेस्ट करने और वेब स्क्रैपिंग के लिए किया जाता है। urllib लाइब्रेरी का उपयोग URL को खोलने और डेटा को पढ़ने के लिए किया जाता है।

```python
def main():
    driver = webdriver.Chrome()
    wait = WebDriverWait(driver, 10)
    driver.get("https://www.feynmanlectures.caltech.edu/I_01.html")
    elements = driver.find_elements(By.TAG_NAME, "img")
    # print(dir(elements[0]))
    print(driver.page_source)
    i = 0
    for element in elements:
        # src = element.get_attribute('src')
        element.screenshot(f'images/{i}.png')        
        i +=1                
    driver.close()
main()
```

```python
from bs4 import BeautifulSoup
from multiprocessing import Process
import timeit
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.common.by import By
```

```python
def img_path(chapter):
    return f'./chapters/{chapter}/img'
```

```python
def img_name(url):
    splits = url.split('/')
    last = splits[len(splits) - 1]
    parts = last.split('.')
    name = parts[0]
    return name
```

यह फ़ंक्शन `img_name` एक URL लेता है और उस URL से छवि का नाम निकालता है। यह URL को '/' से विभाजित करता है, अंतिम भाग को लेता है, और फिर उसे '.' से विभाजित करके छवि का नाम प्राप्त करता है। अंत में, यह छवि का नाम वापस करता है।

```python
def download_images(driver: webdriver.Chrome, chapter):        
    path = img_path(chapter)
    Path(path).mkdir(parents=True, exist_ok=True)    
        
    elements = driver.find_elements(By.TAG_NAME, "img")    
    for element in elements:
        src = element.get_attribute('src')
        name = img_name(src)
        element.screenshot(f'{path}/{name}.png')
```

USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15'

```python
def scrape(chapter):
    if chapter < 1 or chapter > 52:
        raise Exception(f'chapter {chapter}')
    chapter_str = '{:02d}'.format(chapter)
    url = f'https://www.feynmanlectures.caltech.edu/I_{chapter_str}.html'
    driver = webdriver.Chrome()
    driver.get(url)
    page_source = driver.page_source        
    Path(f'./chapters/{chapter_str}').mkdir(parents=True, exist_ok=True)    
    print(f'scraping {url}')
        
    download_images(driver, chapter_str)
        
    soup = BeautifulSoup(page_source, features='lxml')        
    imgs = soup.find_all('img')
    for img in imgs:
        if 'src' in img.attrs or 'data-src' in img.attrs:
            src = ''
            if 'src' in img.attrs:
                src = img.attrs['src']
            elif 'data-src' in img.attrs:
                src = img.attrs['data-src']
                del img.attrs['data-src']
            name = img_name(src)
            img.attrs['src'] = f'img/{name}.png'                
    
    f = open(f'./chapters/{chapter_str}/I_{chapter_str}.html', 'w')
    f.write(soup.prettify())
    f.close()
    
    driver.close()
```

```python
def main():
    start = timeit.default_timer()
    ps = [Process(target=scrape, args=(i+1,)) for i in range(2)]
    for p in ps:
        p.start()
    for p in ps:
        p.join()
    stop = timeit.default_timer()
    print('समय: ', stop - start)
```

यदि __name__ == "__main__":    
    main()
```

```shell
स्क्रैपिंग https://www.feynmanlectures.caltech.edu/I_01.html
स्क्रैपिंग https://www.feynmanlectures.caltech.edu/I_02.html
समय:  21.478510914999998
```

```shell
 errpipe_read, errpipe_write = os.pipe()
OSError: [Errno 24] बहुत सारे फ़ाइलें खुली हुई हैं
```

```shell
 % ulimit a
ulimit: अमान्य संख्या: a
lzw@lzwjava feynman-lectures-mobi % ulimit -a
-t: CPU समय (सेकंड)              असीमित
-f: फ़ाइल आकार (ब्लॉक)              असीमित
-d: डेटा सेगमेंट आकार (किलोबाइट)          असीमित
-s: स्टैक आकार (किलोबाइट)             8192
-c: कोर फ़ाइल आकार (ब्लॉक)         0
-v: एड्रेस स्पेस (किलोबाइट)          असीमित
-l: मेमोरी में लॉक्ड आकार (किलोबाइट)  असीमित
-u: प्रक्रियाएं                       2784
-n: फ़ाइल डिस्क्रिप्टर्स                256
```

```shell
12
download_images
12
mathjax2svg
latexs 128
make_svg 0
insert_svg 0
make_svg 1
insert_svg 1
make_svg 2
insert_svg 2
make_svg 3
insert_svg 3
convert
```

(यह कोड ब्लॉक को हिंदी में अनुवाद करने की आवश्यकता नहीं है क्योंकि यह एक प्रोग्रामिंग कोड है और इसे अपरिवर्तित रहना चाहिए।)

```shell
12
download_images
12
mathjax2svg
latexs 0
latexs 0
convert
समय:  11.369145162
```

```shell
% grep --include=\*.html -r '\$' *
43/I_43.html:एक लंबे समय $T$ के दौरान, टक्करों की एक निश्चित संख्या, $N$, होती है। यदि हम
43/I_43.html:टक्करों की संख्या समय $T$ के समानुपाती होती है। हम चाहेंगे कि
43/I_43.html:हमने आनुपातिकता स्थिरांक को $1/\tau$ के रूप में लिखा है, जहां
43/I_43.html:$\tau$ का आयाम समय का होगा। स्थिरांक $\tau$ है
43/I_43.html:यदि $60$ टक्करें होती हैं; तो $\tau$ एक मिनट होगा। हम कहेंगे
43/I_43.html:कि $\tau$ (एक मिनट) है
```

```shell
त्रुटि	E21018: फ़ाइल में सामग्री को पार्स करते समय, बेहतर Mobi डोमेन बनाने में विफल। सामग्री: <In earlier chapters > फ़ाइल: /private/var/folders/_3/n3b7dq8x6652drmx6_d3t3bh0000gr/T/069e0b8a-f12e-4102-aed3-977c0c3c1178/cTemp/mTemp/mobi-GxL1ye/OEBPS/c-49.xhtml पंक्ति: 969
सूचना	W28001: Kindle रीडर सामग्री में निर्दिष्ट CSS स्टाइल का समर्थन नहीं करता है। CSS गुण हटाया जा रहा है: 'max-width' फ़ाइल: /private/var/folders/_3/n3b7dq8x6652drmx6_d3t3bh0000gr/T/069e0b8a-f12e-4102-aed3-977c0c3c1178/cTemp/mTemp/mobi-GxL1ye/OEBPS/stylesheet.css
सूचना	W29004: खुले टैग को जबरन बंद किया गया: <span amzn-src-id="985"> फ़ाइल: /private/var/folders/_3/n3b7dq8x6652drmx6_d3t3bh0000gr/T/069e0b8a-f12e-4102-aed3-977c0c3c1178/cTemp/mTemp/mobi-GxL1ye/OEBPS/c-4.xhtml पंक्ति: 0000102
सूचना	W29004: खुले टैग को जबरन बंद किया गया: <p amzn-src-id="975"> फ़ाइल: /private/var/folders/_3/n3b7dq8x6652drmx6_d3t3bh0000gr/T/069e0b8a-f12e-4102-aed3-977c0c3c1178/cTemp/mTemp/mobi-GxL1ye/OEBPS/c-4.xhtml पंक्ति: 0000102
```

```shell
चेतावनी	W14001: हाइपरलिंक में समस्या है, अभी तक हल नहीं हुई:  /private/var/folders/_3/n3b7dq8x6652drmx6_d3t3bh0000gr/T/97c9cb4d-35f7-4920-81eb-4705325c482f/cTemp/mTemp/mobi-pvawPN/OEBPS/c-1.xhtml#Ch1-F1			
चेतावनी	W14001: हाइपरलिंक में समस्या है, अभी तक हल नहीं हुई:  /private/var/folders/_3/n3b7dq8x6652drmx6_d3t3bh0000gr/T/97c9cb4d-35f7-4920-81eb-4705325c482f/cTemp/mTemp/mobi-pvawPN/OEBPS/c-1.xhtml#Ch1-F2			
चेतावनी	W14001: हाइपरलिंक में समस्या है, अभी तक हल नहीं हुई:  /private/var/folders/_3/n3b7dq8x6652drmx6_d3t3bh0000gr/T/97c9cb4d-35f7-4920-81eb-4705325c482f/cTemp/mTemp/mobi-pvawPN/OEBPS/c-1.xhtml#Ch1-F3			
```

```html
<span class="disabled" href="#Ch1-F1">
          1–1
</span>
```

```shell
'OEBPS/84b8b4179175f097be1180a10089107be75d7d85.svg' को 1264x1011 में रेस्टराइज़ कर रहा है
'OEBPS/23a4df37f269c8ed43f54753eb838b29cff538a1.svg' को 1264x259 में रेस्टराइज़ कर रहा है
Traceback (most recent call last):
  File "runpy.py", line 194, in _run_module_as_main
  File "runpy.py", line 87, in _run_code
  File "site.py", line 39, in <module>
  File "site.py", line 35, in main
  File "calibre/utils/ipc/worker.py", line 216, in main
  File "calibre/gui2/convert/gui_conversion.py", line 41, in gui_convert_override
  File "calibre/gui2/convert/gui_conversion.py", line 28, in gui_convert
  File "calibre/ebooks/conversion/plumber.py", line 1274, in run
  File "calibre/ebooks/conversion/plugins/mobi_output.py", line 214, in convert
  File "calibre/ebooks/conversion/plugins/mobi_output.py", line 237, in write_mobi
  File "calibre/ebooks/oeb/transforms/rasterize.py", line 55, in __call__
  File "calibre/ebooks/oeb/transforms/rasterize.py", line 142, in rasterize_spine
  File "calibre/ebooks/oeb/transforms/rasterize.py", line 152, in rasterize_item
  File "calibre/ebooks/oeb/transforms/rasterize.py", line 185, in rasterize_external
  File "calibre/ebooks/oeb/base.py", line 1092, in bytes_representation
  File "calibre/ebooks/oeb/base.py", line 432, in serialize
TypeError: 'NoneType' ऑब्जेक्ट को बाइट्स में कन्वर्ट नहीं किया जा सकता
```

```shell
% kindlepreviewer feynman-lectures-on-physics-volumn-1.epub -convert
निर्दिष्ट तर्कों की जाँच की जा रही है।
प्री-प्रोसेसिंग प्रगति पर है।
1/1 पुस्तक(एँ) को प्रोसेस किया जा रहा है।
पुस्तक को चेतावनियों के साथ परिवर्तित किया गया! : /Users/lzw/projects/feynman-lectures-mobi/feynman-lectures-on-physics-volumn-1.epub
पोस्ट-प्रोसेसिंग प्रगति पर है।
आउटपुट/लॉग फ़ाइलें /Users/lzw/projects/feynman-lectures-mobi/output में लिखी जा रही हैं।
```

```shell
मैनिफेस्ट को साफ कर रहा है...
मैनिफेस्ट से अनुपयोगी फाइलों को हटा रहा है...
AZW3 आउटपुट बना रहा है...
संसाधनों को सीरियलाइज़ कर रहा है...
पेज ब्रेक और फ्लो लिमिट पर मार्कअप को विभाजित कर रहा है, यदि कोई हो...
KF8 आउटपुट बना रहा है
	KF8 मार्कअप जनरेट कर रहा है...
टैग टेबल में कोई aid नहीं है और चंक साइज़ बहुत बड़ा है। फिर भी जोड़ रहा है।
टैग टेबल में कोई aid नहीं है और चंक साइज़ बहुत बड़ा है। फिर भी जोड़ रहा है।
टैग टेबल में कोई aid नहीं है और चंक साइज़ बहुत बड़ा है। फिर भी जोड़ रहा है।
	मार्कअप को संपीड़ित कर रहा है...
	इंडेक्स बना रहा है...
```