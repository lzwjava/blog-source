---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: वरिष्ठ एआई इंजीनियर साक्षात्कार प्रश्न २०२४-२०२५
translated: true
type: note
---

यहाँ 2024-2025 के लिए **सीनियर AI/एजेंट/LLM इंजीनियर** की भूमिका में सामने आने वाले सबसे सामान्य और विशिष्ट इंटरव्यू प्रश्न दिए गए हैं, खासकर शीर्ष कंपनियों (FAANG-टियर, Anthropic/OpenAI/xAI जैसी AI लैब्स, Adept, Imbue, आदि जैसी स्केल-अप कंपनियों) में।

ये श्रेणी और कठिनाई के आधार पर समूहीकृत हैं (अधिकतर सीनियर-लेवल के हैं, जिनमें गहरी समझ और प्रोडक्शन अनुभव की अपेक्षा की जाती है)।

### सिस्टम डिज़ाइन और आर्किटेक्चर
1. एक स्केलेबल LLM इन्फ़रेंस सर्विंग सिस्टम डिज़ाइन करें जो 10k+ QPS को <200ms p99 लेटेंसी के साथ हैंडल कर सके।
2. आप एक रियल-टाइम AI एजेंट कैसे डिज़ाइन करेंगे जो वेब ब्राउज़ कर सके, टूल्स का उपयोग कर सके और लॉन्ग-टर्म मेमोरी बनाए रख सके?
3. स्क्रैच से एक रिट्रीवल-ऑगमेंटेड जेनरेशन (RAG) पाइपलाइन डिज़ाइन करें (वेक्टर DB चॉइस, चंकिंग, रिरैंकिंग, हाइब्रिड सर्च, मूल्यांकन)।
4. आप क्वालिटी डिग्रेडेशन को <2% रखते हुए 70B मॉडल की इन्फ़रेंस लागत को 5–10x तक कैसे कम करेंगे?
5. ओपन-एंडेड एजेंट टास्क (जैसे, वेब शॉपिंग, रिसर्च) के लिए एक मूल्यांकन फ्रेमवर्क डिज़ाइन करें।
6. आप एक मल्टी-एजेंट सिस्टम कैसे बनाएंगे जहाँ एजेंट्स सहयोग करते हों (बहस, पदानुक्रम, आदि)?

### LLM फंडामेंटल और एडवांस्ड यूसेज
- स्क्रैच से समझाएं कि अटेंशन कैसे काम करता है (रोटरी पोजिशनल एम्बेडिंग्स, ग्रुप्ड-क्वेरी अटेंशन, स्लाइडिंग विंडो अटेंशन सहित)।
- Llama 3/4 ALiBi के बजाय RoPE का उपयोग क्यों करता है? फायदे/नुकसान।
- स्केलिंग लॉज़ को डेरिव करें (Kaplan, Hoffmann "Chinchilla", DeepMind "Emergent Abilities")।
- लॉन्ग-कॉन्टेक्स्ट मॉडल्स में "लॉस्ट इन द मिडिल" क्या कारण है? आप इसे कैसे ठीक करते हैं?
- मिक्सचर-ऑफ-एक्सपर्ट्स (MoE) आर्किटेक्चर (Mixtral, DeepSeek, Grok-1, Qwen-2.5-MoE) की तुलना करें। प्रैक्टिस में एक्टिवेशन स्पार्सिटी मुश्किल क्यों है?
- क्वांटिज़ेशन (GPTQ, AWQ, SmoothQuant, bitsandbytes) वास्तव में कैसे काम करता है? 4-बिट, 3-बिट, 2-बिट के बीच ट्रेड-ऑफ़।
- RLHF, DPO, KTO, PPO, GRPO में क्या अंतर है, और आप प्रत्येक का उपयोग कब करेंगे?

### एजेंट्स और टूल यूज़
- आप JSON मोड बनाम ReAct बनाम OpenAI टूल्स के साथ विश्वसनीय टूल कॉलिंग / फंक्शन कॉलिंग कैसे इम्प्लीमेंट करते हैं?
- ReAct, Reflexion, ReWOO, Toolformer, DEPS, Chain-of-Verification समझाएं।
- आप एजेंट एक्ज़िक्यूशन में इनफ़िनिट लूप्स को कैसे रोकते हैं?
- आप GAIA, WebArena, AgentBench जैसे बेंचमार्क पर एजेंट परफॉर्मेंस का मूल्यांकन कैसे करते हैं?
- आप एक एजेंट में लॉन्ग-टर्म मेमोरी कैसे जोड़ेंगे (वेक्टर स्टोर बनाम की-वैल्यू स्टोर बनाम एपिसोडिक मेमोरी)?

### ट्रेनिंग, फाइन-ट्यूनिंग और अलाइनमेंट
- पूरी फाइन-ट्यूनिंग स्टैक के माध्यम से चलें: LoRA, QLoRA, DoRA, LoftQ, LLaMA-Adapter, IA³।
- QLoRA हुड के नीचे कैसे काम करता है (NF4, डबल क्वांटिज़ेशन, पेज्ड ऑप्टिमाइज़र्स)?
- आपके पास 10k हाई-क्वालिटी इंस्ट्रक्शन उदाहरण हैं और आप 8×H100s पर एक 70B मॉडल को फाइन-ट्यून करना चाहते हैं। सटीक रेसिपी दें।
- कॉन्स्टीट्यूशनल AI, RLAIF, सेल्फ-क्रिटिक, प्रोसेस बनाम आउटकम सुपरविज़न समझाएं।
- आप RLHF में रिवार्ड हैकिंग का पता कैसे लगाते हैं और कम करते हैं?

### कोडिंग और इम्प्लीमेंटेशन (लाइव कोडिंग या टेक-होम)
- स्क्रैच से एक साधारण ReAct एजेंट इम्प्लीमेंट करें (Python)।
- फ्लैश-अटेंशन स्टाइल कैशिंग के साथ एफिशिएंट स्लाइडिंग-विंडो अटेंशन इम्प्लीमेंट करें।
- LangChain / LlamaIndex के साथ एक बेसिक RAG सिस्टम बनाएं (वे आर्किटेक्चर पर निर्णय लेंगे)।
- 128k कॉन्टेक्स्ट के लिए एक ट्रांसफॉर्मर फॉरवर्ड पास को मेमोरी एफिशिएंट ऑप्टिमाइज़ करें।
- एक नए क्वांटिज़ेशन कर्नेल के लिए एक कस्टम PyTorch autograd फंक्शन लिखें।

### ML फंडामेंटल (वे सीनियर्स से अभी भी पूछते हैं)
- AdamW, Adam से बेहतर क्यों काम करता है? वेट-डिके फॉर्मूलेशन डेरिव करें।
- लेबल स्मूदिंग, टीचर फोर्सिंग, सीक्वेंस-लेवल बनाम टोकन-लेवल ट्रेनिंग ऑब्जेक्टिव्स समझाएं।
- BLEU, ROUGE, BERTScore, LLM-as-a-judge, G-Eval में क्या अंतर है?
- ट्रांसफॉर्मर लॉस फंक्शन को डेरिव करें और समझाएं कि हम पैडिंग टोकन्स को क्यों इग्नोर करते हैं।

### प्रोडक्शन और MLOps
- आप प्रोडक्शन में LLM आउटपुट्स की मॉनिटरिंग कैसे करते हैं (ड्रिफ्ट, टॉक्सिसिटी, PII लीकेज, प्रॉम्प्ट इंजेक्शन)?
- आप देखते हैं कि आपके 5% यूज़र्स मॉडल को जेलब्रेक कर रहे हैं। आप पता कैसे लगाते हैं और बचाव कैसे करते हैं?
- इन्फ़रेंस स्पीड के लिए vLLM, TGI, TensorRT-LLM, lmdeploy, Outlines, Guidance की तुलना करें।
- आप कंटीन्यूअस फाइन-ट्यूनिंग / ऑनलाइन लर्निंग सुरक्षित रूप से कैसे करते हैं?

### बिहेवियरल / अनुभव
- मुझे LLMs के साथ आपके द्वारा ठीक की गई सबसे कठिन प्रोडक्शन समस्या के बारे में बताएं।
- आपने एक एजेंट प्रोडक्ट कैसे शिप किया जिसे वास्तविक यूज़र्स ने पसंद किया?
- ऐसे समय का वर्णन करें जब आपने इन्फ़रेंस लागत को >50% तक कम किया हो।
- आपने जो सबसे खराब हालुसिनेशन डिज़ास्टर देखा है और आपने उसे कैसे ठीक किया?

### करेंट हॉट टॉपिक्स (2025)
- टेस्ट-टाइम स्केलिंग मेथड्स कैसे काम करती हैं (DeepSeek R1, o1-स्टाइल रीजनिंग, प्रोसेस रिवार्ड मॉडल)?
- चेन-ऑफ-थॉट, ट्री-ऑफ-थॉट, ग्राफ-ऑफ-थॉट, प्रोसेस बनाम आउटकम रिवार्ड की तुलना करें।
- वर्तमान में सर्वश्रेष्ठ ओपन-सोर्स रीजनिंग मॉडल कौन से हैं (Llama-3.1-405B, Qwen-2.5-72B-Instruct, DeepSeek-V3, Gemma-2-27B)?
- सिंथेटिक डेटा जनरेशन लूप्स (Self-Refine, STaR, Quiet-STaR, MCTS-आधारित डेटा सिंथ) पर विचार।

कंपनियाँ जो अभी सबसे कठिन प्रश्न पूछती हैं: OpenAI, Anthropic, xAI, Adept, Scale AI, Helion, Imbue, Character.AI, Cohere, Mistral।

व्हाइटबोर्ड सिस्टम डिज़ाइन और लैपटॉप पर कोड करने के लिए तैयार रहें (कोई इंटरनेट नहीं)। अधिकांश सीनियर लूप 5-7 राउंड के होते हैं जिनमें भारी सिस्टम डिज़ाइन और डीप-डाइव कोडिंग शामिल होती है।

गुड लक!