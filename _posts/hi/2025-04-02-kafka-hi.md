---
audio: false
generated: true
lang: hi
layout: post
title: अपाचे काफ्का
translated: true
type: note
---

ऐसा लगता है कि आपके अनुरोध में कुछ गलतफहमी हो सकती है। आपके Redis के बारे में पिछले प्रश्न और इस प्रश्न के संदर्भ के आधार पर, मैं मान रहा हूं कि आप लेखक फ्रांज काफ्का के बजाय **Apache Kafka**, वितरित इवेंट स्ट्रीमिंग प्लेटफॉर्म, के बारे में एक व्यापक गाइड मांग रहे हैं। अगर मैंने गलत समझा है और आपका कुछ और मतलब है, तो कृपया स्पष्ट करें! फिलहाल, Apache Kafka पर एक विस्तृत गाइड यहां दी गई है।

---

### Apache Kafka क्या है?
Apache Kafka एक ओपन-सोर्स, वितरित इवेंट स्ट्रीमिंग प्लेटफॉर्म है जिसे हाई-थ्रूपुट, फॉल्ट-टॉलरेंट और स्केलेबल रीयल-टाइम डेटा प्रोसेसिंग के लिए डिज़ाइन किया गया है। मूल रूप से 2010 में LinkedIn द्वारा विकसित और बाद में 2011 में Apache Software Foundation को दान किया गया, Kafka Java और Scala में लिखा गया है। इसका व्यापक रूप से रीयल-टाइम डेटा पाइपलाइन, स्ट्रीमिंग एप्लिकेशन और इवेंट-ड्रिवन आर्किटेक्चर बनाने के लिए उपयोग किया जाता है।

मुख्य विशेषताएं:
- **वितरित**: कई सर्वरों पर एक क्लस्टर के रूप में चलता है।
- **इवेंट-ड्रिवन**: रीयल टाइम में इवेंट्स की स्ट्रीम को प्रोसेस करता है।
- **स्थायी**: कॉन्फ़िगर करने योग्य रिटेंशन के साथ डेटा को डिस्क पर स्थायी रूप से संग्रहीत करता है।
- **स्केलेबल**: प्रतिदिन खरबों इवेंट्स को संभालता है।

---

### Kafka का उपयोग क्यों करें?
Kafka उन परिदृश्यों में उत्कृष्ट प्रदर्शन करता है जिनमें रीयल-टाइम डेटा प्रोसेसिंग और उच्च स्केलेबिलिटी की आवश्यकता होती है। सामान्य उपयोग के मामलों में शामिल हैं:
1. **मैसेजिंग**: पारंपरिक मैसेज ब्रोकर्स (जैसे, RabbitMQ) को बेहतर थ्रूपुट और फॉल्ट टॉलरेंस के साथ प्रतिस्थापित करता है।
2. **एक्टिविटी ट्रैकिंग**: उपयोगकर्ता की कार्रवाइयों (जैसे, क्लिक, लॉगिन) को रीयल टाइम में ट्रैक करता है।
3. **लॉग एग्रीगेशन**: केंद्रीकृत प्रोसेसिंग के लिए कई स्रोतों से लॉग एकत्र करता है।
4. **स्ट्रीम प्रोसेसिंग**: रीयल-टाइम एनालिटिक्स या ट्रांसफॉर्मेशन को पावर देता है।
5. **इवेंट सोर्सिंग**: एप्लिकेशन के लिए स्टेट परिवर्तनों को लॉग करता है।
6. **मेट्रिक्स संग्रह**: सिस्टम या IoT डिवाइसों की निगरानी करता है।

---

### मुख्य विशेषताएं
1. **मुख्य घटक**:
   - **टॉपिक्स**: वे श्रेणियां जहां संदेश (इवेंट) प्रकाशित किए जाते हैं।
   - **पार्टीशन**: समानांतरता और स्केलेबिलिटी के लिए टॉपिक्स के उप-विभाजन।
   - **प्रोड्यूसर**: वे एप्लिकेशन जो टॉपिक्स को संदेश भेजते हैं।
   - **कंज्यूमर**: वे एप्लिकेशन जो टॉपिक्स से संदेश पढ़ते हैं।
   - **ब्रोकर**: Kafka क्लस्टर में सर्वर जो डेटा को संग्रहीत और प्रबंधित करते हैं।

2. **रेप्लिकेशन**: ब्रोकरों के बीच डेटा को डुप्लिकेट करके फॉल्ट टॉलरेंस सुनिश्चित करता है।
3. **रिटेंशन**: कॉन्फ़िगर करने योग्य डेटा रिटेंशन (समय-आधारित या आकार-आधारित)।
4. **Kafka Connect**: बाहरी सिस्टम (जैसे, डेटाबेस, फ़ाइलें) के साथ एकीकृत करता है।
5. **Kafka Streams**: रीयल-टाइम स्ट्रीम प्रोसेसिंग के लिए एक लाइब्रेरी।
6. **उच्च थ्रूपुट**: कम विलंबता (जैसे, 2ms) के साथ प्रति सेकंड लाखों संदेश प्रोसेस करता है।

---

### आर्किटेक्चर
Kafka का आर्किटेक्चर एक वितरित कमिट लॉग के आसपास बनाया गया है:
- **क्लस्टर**: एक साथ काम करने वाले ब्रोकरों का समूह।
- **टॉपिक्स और पार्टीशन**: संदेश टॉपिक्स में लिखे जाते हैं, जिन्हें लोड बैलेंसिंग और स्केलेबिलिटी के लिए पार्टीशन में विभाजित किया जाता है। प्रत्येक पार्टीशन एक क्रमबद्ध, अपरिवर्तनीय लॉग होता है।
- **रेप्लिकेशन**: प्रत्येक पार्टीशन का एक लीडर और रेप्लिका होता है; यदि लीडर विफल हो जाता है, तो एक रेप्लिका उसकी जगह ले लेता है।
- **ऑफसेट**: एक पार्टीशन के भीतर संदेशों के लिए अद्वितीय पहचानकर्ता, जो कंज्यूमर को उनकी स्थिति ट्रैक करने की अनुमति देते हैं।
- **ZooKeeper (या KRaft)**: पारंपरिक रूप से, ZooKeeper क्लस्टर मेटाडेटा और समन्वय का प्रबंधन करता है। Kafka 3.3 के बाद से, KRaft (Kafka Raft) मोड स्व-प्रबंधित मेटाडेटा की अनुमति देता है, जिससे ZooKeeper निर्भरता समाप्त हो जाती है।

---

### इंस्टालेशन
Linux सिस्टम पर Kafka इंस्टॉल करने का तरीका यहां बताया गया है (मानता है कि Java 8+ इंस्टॉल है):

1. **Kafka डाउनलोड करें**:
   ```bash
   wget https://downloads.apache.org/kafka/3.7.0/kafka_2.13-3.7.0.tgz
   tar -xzf kafka_2.13-3.7.0.tgz
   cd kafka_2.13-3.7.0
   ```

2. **ZooKeeper शुरू करें** (यदि KRaft का उपयोग नहीं कर रहे हैं):
   ```bash
   bin/zookeeper-server-start.sh config/zookeeper.properties
   ```

3. **Kafka सर्वर शुरू करें**:
   ```bash
   bin/kafka-server-start.sh config/server.properties
   ```

4. **एक टॉपिक बनाएं**:
   ```bash
   bin/kafka-topics.sh --create --topic mytopic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
   ```

5. **सत्यापित करें**:
   ```bash
   bin/kafka-topics.sh --list --bootstrap-server localhost:9092
   ```

KRaft मोड (ZooKeeper-मुक्त) के लिए, एक क्लस्टर ID जनरेट करें और `config/kraft/server.properties` को एडजस्ट करें:
```bash
bin/kafka-storage.sh random-uuid
bin/kafka-storage.sh format -t <UUID> -c config/kraft/server.properties
bin/kafka-server-start.sh config/kraft/server.properties
```

---

### बेसिक ऑपरेशन
Kafka कमांड-लाइन इंटरफेस या क्लाइंट लाइब्रेरीज़ का उपयोग करता है। `kafka-console-*` टूल्स के माध्यम से उदाहरण:

#### संदेश उत्पादन (Producing Messages)
```bash
bin/kafka-console-producer.sh --topic mytopic --bootstrap-server localhost:9092
> Hello, Kafka!
> Another message
```

#### संदेश उपभोग (Consuming Messages)
```bash
bin/kafka-console-consumer.sh --topic mytopic --from-beginning --bootstrap-server localhost:9092
```
आउटपुट: `Hello, Kafka!` `Another message`

#### मुख्य कमांड
- टॉपिक्स सूचीबद्ध करें: `bin/kafka-topics.sh --list --bootstrap-server localhost:9092`
- टॉपिक का वर्णन करें: `bin/kafka-topics.sh --describe --topic mytopic --bootstrap-server localhost:9092`

---

### Kafka के साथ प्रोग्रामिंग
Kafka क्लाइंट लाइब्रेरीज़ के माध्यम से कई भाषाओं का समर्थन करता है। यहां `kafka-python` का उपयोग करते हुए एक Python उदाहरण दिया गया है:

1. **लाइब्रेरी इंस्टॉल करें**:
   ```bash
   pip install kafka-python
   ```

2. **प्रोड्यूसर उदाहरण**:
   ```python
   from kafka import KafkaProducer

   producer = KafkaProducer(bootstrap_servers='localhost:9092')
   producer.send('mytopic', b'Hello, Kafka!')
   producer.flush()
   ```

3. **कंज्यूमर उदाहरण**:
   ```python
   from kafka import KafkaConsumer

   consumer = KafkaConsumer('mytopic', bootstrap_servers='localhost:9092', auto_offset_reset='earliest')
   for message in consumer:
       print(message.value.decode('utf-8'))
   ```

---

### एडवांस्ड कॉन्सेप्ट्स
1. **कंज्यूमर ग्रुप्स**:
   - एक ग्रुप में कई कंज्यूमर पार्टीशन साझा करते हैं; प्रत्येक संदेश प्रति ग्रुप में एक बार प्रोसेस होता है।
   - उदाहरण: कंज्यूमर कॉन्फ़िग में `group.id=mygroup`।

2. **रेप्लिकेशन और फॉल्ट टॉलरेंस**:
   - डेटा के ब्रोकर फेलियर से बचे रहने के लिए `replication-factor` > 1 सेट करें।
   - उदाहरण: `--replication-factor 3`।

3. **Kafka Streams**:
   - रीयल टाइम में डेटा प्रोसेस करें (जैसे, एग्रीगेशन, जॉइन)।
   - Java में उदाहरण:
     ```java
     StreamsBuilder builder = new StreamsBuilder();
     KStream<String, String> stream = builder.stream("mytopic");
     stream.foreach((key, value) -> System.out.println(value));
     ```

4. **Kafka Connect**:
   - डेटा आयात/निर्यात करें (जैसे, MySQL से Kafka में)।
   - उदाहरण: एक JDBC सोर्स कनेक्टर का उपयोग करें।

5. **रिटेंशन और कॉम्पैक्शन**:
   - `log.retention.hours=168` (7 दिन डिफॉल्ट)।
   - लॉग कॉम्पैक्शन प्रति कुंजी नवीनतम मान रखता है।

---

### परफॉर्मेंस टिप्स
1. **पार्टीशनिंग**: समानांतरता के लिए पार्टीशन बढ़ाएं लेकिन अति-पार्टीशनिंग से बचें (जैसे, प्रति टॉपिक 10-100)।
2. **बैचिंग**: उच्च थ्रूपुट के लिए `batch.size` और `linger.ms` को ट्यून करें।
3. **कम्प्रेशन**: `compression.type=gzip` के साथ सक्षम करें।
4. **मॉनिटरिंग**: Kafka Manager या Prometheus + Grafana जैसे टूल्स का उपयोग करें।

---

### सुरक्षा
- **प्रमाणीकरण**: SASL सक्षम करें (जैसे, `sasl.mechanism=PLAIN`)।
- **अधिकार प्रबंधन**: `kafka-acls.sh` के माध्यम से ACLs का उपयोग करें।
- **एन्क्रिप्शन**: SSL कॉन्फ़िगर करें (`security.protocol=SSL`)।
- **एक्सेस प्रतिबंधित करें**: `server.properties` में विशिष्ट IPs को बाइंड करें।

---

### Kafka बनाम अन्य
- **Kafka बनाम RabbitMQ**: Kafka उच्च थ्रूपुट और स्थायित्व प्रदान करता है; RabbitMQ पारंपरिक मैसेजिंग के लिए सरल है।
- **Kafka बनाम Redis**: Kafka इवेंट स्ट्रीमिंग के लिए है; Redis इन-मेमोरी कैशिंग/की-वैल्यू स्टोरेज के लिए है।
- **Kafka बनाम AWS Kinesis**: Kafka सेल्फ-मैनेज्ड और अधिक अनुकूलन योग्य है; Kinesis पूरी तरह से मैनेज्ड है।

---

### सीमाएं
- **जटिलता**: क्लस्टरिंग और ट्यूनिंग के लिए सीखने की अवस्था कठिन है।
- **संसाधन गहन**: पर्याप्त मेमोरी और डिस्क स्पेस की आवश्यकता होती है।
- **कोई नेटिव क्वेरीिंग नहीं**: प्रोसेसिंग के लिए बाहरी टूल्स (जैसे, Kafka Streams) पर निर्भर करता है।

---

### संसाधन
- **आधिकारिक साइट**: [kafka.apache.org](https://kafka.apache.org)
- **डॉक्यूमेंटेशन**: [kafka.apache.org/documentation](https://kafka.apache.org/documentation)
- **Confluent**: [confluent.io](https://www.confluent.io) (ट्यूटोरियल्स, मैनेज्ड Kafka)

---

यह गाइड Kafka की आवश्यकताओं और उससे आगे को कवर करती है। यदि आप किसी विशिष्ट क्षेत्र (जैसे, क्लस्टरिंग, Streams, या कोई उपयोग मामला) को और गहराई से एक्सप्लोर करना चाहते हैं, तो मुझे बताएं!