---
audio: false
generated: true
image: false
lang: hi
layout: post
title: कड़वा सबक ट्रांसफॉर्मर विकास को चलाता है
translated: true
type: note
---

स्टैनफोर्ड सीएस25 इवेंट में अपने टॉक में, ह्युंग वॉन चुंग ने **ट्रांसफॉर्मर आर्किटेक्चर** का एक विस्तृत ऐतिहासिक और भविष्यकथन विश्लेषण प्रस्तुत किया, और तर्क दिया कि उनके विकास के पीछे की प्रेरक शक्तियों को समझना एआई के भविष्य की आशंका करने की कुंजी है। उनके तर्क का मूल "एआई विकास के कड़वे सबक" पर केंद्रित है, जिसे उन्होंने ट्रांसफॉर्मर मॉडल के विकास के माध्यम से चित्रित किया।

***

### एआई प्रगति की प्रेरक शक्ति

चुंग का मानना है कि एआई शोध को आगे बढ़ाने वाला सबसे महत्वपूर्ण कारक **कंप्यूट की तेजी से घटती लागत** है, जिसने मॉडल और डेटा के पैमाने में संबंधित वृद्धि को सक्षम किया है। उनका तर्क है कि इस क्षेत्र में परिवर्तन की तीव्र गति को समझने के लिए, व्यक्तिगत वास्तुशिल्प नवाचारों के विवरण में खो जाने के बजाय इस प्रमुख प्रेरक शक्ति पर ध्यान केंद्रित करना चाहिए।

वे **"द बिटर लेसन"** की अवधारणा पेश करते हैं, जो बताती है कि दीर्घकालिक एआई प्रगति कम अंतर्निहित धारणाओं (इंडक्टिव बायस) वाली सरल, अधिक सामान्य विधियों का पक्ष लेती है। हालांकि अत्यधिक संरचित, डोमेन-विशिष्ट मॉडल अल्पकालिक लाभ प्रदान कर सकते हैं, लेकिन कंप्यूट और डेटा के पैमाने के साथ वे अंततः बाधा बन जाते हैं। वे शोधकर्ताओं को अपने मॉडलों की अंतर्निहित संरचनाओं को लगातार प्रश्न करने और सरल बनाने के लिए प्रोत्साहित करते हैं।

***

### ट्रांसफॉर्मर आर्किटेक्चर का विकास

चुंग ने अपने बिंदुओं को उदाहरणित करने के लिए तीन प्रमुख ट्रांसफॉर्मर आर्किटेक्चर का उपयोग किया:

1.  **एनकोडर-डिकोडर (मूल ट्रांसफॉर्मर):** यह आर्किटेक्चर, जिसे मूल रूप से मशीन अनुवाद जैसे कार्यों के लिए उपयोग किया जाता था, में अधिक अंतर्निहित संरचना है। यह एनकोडर और डिकोडर के लिए अलग-अलग पैरामीटर और विशिष्ट क्रॉस-अटेंशन पैटर्न का उपयोग करता है। हालांकि विशिष्ट इनपुट/आउटपुट कार्यों के लिए प्रभावी, यह संरचना बड़े, सामान्य-उद्देश्य वाले मॉडलों के युग में कम प्रासंगिक होती जा रही है।

2.  **एनकोडर-ओनली (उदाहरण: BERT):** एक सरल आर्किटेक्चर जो जनरेशन को छोड़ देता है, और वर्गीकरण जैसे कार्यों पर केंद्रित होता है। हालांकि विशिष्ट बेंचमार्क के लिए शक्तिशाली, इसका संकीर्ण फोकस इसे आधुनिक अनुप्रयोगों की एक विस्तृत श्रृंखला के लिए कम सामान्यीकरण योग्य बनाता है।

3.  **डिकोडर-ओनली (उदाहरण: GPT-3):** यह तीनों में से सबसे सामान्य और कम से कम संरचित है। यह परतों के एक स्टैक और साझा पैरामीटर का उपयोग करता है, जिससे यह आधुनिक बड़े भाषा मॉडलों के लिए अत्यधिक उपयुक्त हो जाता है जो विविध कार्यों को संभालते हैं, सामान्य ज्ञान सीखते हैं और लंबी-फॉर्म जनरेशन करते हैं।

***

### मुख्य बातें और भविष्यवाणियाँ

चुंग के अनुसार, रुझान स्पष्ट है: एआई **कम लगाई गई संरचना वाले सरल, अधिक सामान्य आर्किटेक्चर** की ओर बढ़ रहा है। यह मॉडलों को निश्चित धारणाओं से विवश हुए बिना विशाल मात्रा में डेटा से जटिल पैटर्न और संबंध सीखने की स्वतंत्रता देता है।

उनका सुझाव है कि एआई में अगली बाधा स्वयं आर्किटेक्चर नहीं बल्कि **सीखने का उद्देश्य (लर्निंग ऑब्जेक्टिव)** हो सकता है। वे रीइन्फोर्समेंट लर्निंग फ्रॉम ह्यूमन फीडबैक (RLHF) जैसी विधियों को कम संरचित, सीखे गए उद्देश्य फलनों की ओर एक कदम मानते हैं जो खुले-समाप्त और जटिल जनरेशन कार्यों के लिए अधिक उपयुक्त हैं। वे दर्शकों से एआई के भविष्य को आकार देने में मदद करने के लिए इन सिद्धांतों पर गंभीरता से सोचने के लिए प्रोत्साहित करते हैं।

आप पूरा टॉक यहाँ देख सकते हैं: [https://www.youtube.com/watch?v=3gb-ZkVRemQ&pp=0gcJCfwAo7VqN5tD](https://www.youtube.com/watch?v=3gb-ZkVRemQ&pp=0gcJCfwAo7VqN5tD)