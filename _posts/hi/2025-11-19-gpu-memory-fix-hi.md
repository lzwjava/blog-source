---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: जीपीयू मेमोरी त्रुटियों को ठीक करना
translated: true
type: note
---

हाँ, आपको मेमोरी कम होने (OOM) की त्रुटि इसलिए आ रही है क्योंकि आपकी वर्तमान सेटिंग्स के साथ "125M" nanoGPT-स्टाइल मॉडल भी 12 GB GPU (जैसे 3090/4090/3090 Ti/A6000) की सीमा को पार कर रहा है। आइए समझते हैं कि VRAM का उपयोग कहाँ हो रहा है और आपको पहले क्या बदलना चाहिए।

### VRAM उपयोग का वर्तमान अनुमान (आपकी सेटिंग्स पर)
- मॉडल आकार: लगभग 124M पैरामीटर्स → ~500–550 MB (FP16/BF16 में)
- ऑप्टिमाइज़र स्टेट्स (AdamW): ~1–1.2 GB
- ग्रेडिएंट्स: ~500 MB
- एक्टिवेशन्स (मुख्य कारण):
  - batch_size = 16
  - block_size = 1024
  - gradient_accumulation_steps = 32
  → माइक्रो-बैच: 16 सीक्वेंस × 1024 टोकन = 16,384 टोकन प्रति फॉरवर्ड/बैकवर्ड पास
  - 12 लेयर्स, 768 डाइमेंशन, 12 हेड्स के साथ → एक्टिवेशन अकेले एक माइक्रो-बैच के लिए आसानी से 9–11 GB उपयोग कर लेते हैं

कुल मिलाकर → आप 12 GB के बहुत करीब या उससे ऊपर पहुँच रहे हैं, खासकर जब PyTorch का ओवरहेड, कंपाइल कैश, CUDA ग्राफ़्स, आदि शामिल हो जाते हैं।

### `batch_size` वास्तव में क्या करता है?
nanoGPT में `batch_size` माइक्रो-बैच का आकार होता है (ग्रेडिएंट लागू होने से पहले एक ही फॉरवर्ड/बैकवर्ड पास में प्रोसेस होने वाली सीक्वेंस की संख्या)।

आपका प्रभावी (कुल) बैच आकार है:

effective_batch_size = batch_size × gradient_accumulation_steps
= 16 × 32 = 512 सीक्वेंस

यह 512 ही ग्रेडिएंट की गुणवत्ता/शोर के लिए मायने रखता है। माइक्रो-बैच (16) मुख्यतः VRAM और गति को प्रभावित करता है।

### सबसे अच्छे समाधान (आपके 12 GB कार्ड के लिए प्रभावशीलता के अनुसार क्रमबद्ध)

| विकल्प | नए मान | प्रभावी बैच | VRAM बचत | ट्रेनिंग पर प्रभाव | सिफारिश |
|------|------------|------------------|------------|---------------------|----------------|
| 1. केवल माइक्रो-बैच घटाएँ | batch_size = 8<br>gradient_accumulation_steps = 64 | अभी भी 512 | ~40–50% कम एक्टिवेशन → आराम से फिट होगा | अंतिम मॉडल पर लगभग शून्य प्रभाव | सबसे अच्छा विकल्प |
| 2. माइक्रो-बैच थोड़ा और घटाएँ | batch_size = 4<br>gradient_accumulation_steps = 128 | अभी भी 512 | और सुरक्षित, थोड़ी धीमी गति | अभी भी नगण्य अंतर | यदि फिर भी OOM आए |
| 3. दोनों घटाएँ (आसान लेकिन थोड़ा बदतर) | batch_size = 8<br>gradient_accumulation_steps = 32 | अब 256 | VRAM में बड़ी बचत | ग्रेडिएंट्स में थोड़ा अधिक शोर, कन्वर्ज होने के लिए 10–20% अधिक स्टेप्स की आवश्यकता हो सकती है | स्वीकार्य |
| 4. मॉडल आकार घटाएँ | n_layer=9 or n_embd=512 | छोटा मॉडल | VRAM में भारी बचत | क्षमता कम हो जाती है | केवल अगर बहुत तेजी से एक्सपेरिमेंट करना चाहते हैं |

### अनुशंसित कॉन्फ़िगरेशन जो निश्चित रूप से 12 GB पर फिट होगी
```python
batch_size = 8                    # ← मुख्य बदलाव (पहले 16 था)
gradient_accumulation_steps = 64  # ← प्रभावी बैच 512 रखने के लिए बढ़ाएँ
block_size = 1024                 # यूँ ही रखें
# बाकी सब कुछ यूँ ही रखें
```

इससे एक्टिवेशन मेमोरी लगभग आधी हो जाएगी और आपको ग्रेडिएंट की वही गुणवत्ता मिलेगी। ट्रेनिंग वास्तविक समय में ~10–15% धीमी होगी (अधिक एक्यूमुलेशन स्टेप्स = अधिक Python ओवरहेड), लेकिन यह क्रैश करने के बजाय चलेगी।

### अतिरिक्त सुरक्षित मोड (यदि उपरोक्त के बाद भी OOM आए)
```python
batch_size = 4
gradient_accumulation_steps = 128   # प्रभावी बैच अभी भी 512
# या batch_size=2 + 256 भी, अगर आपका कार्ड सख्ती से 12 GB का है
```

### अन्य छोटे बदलाव जो कुछ सौ MB मदद करते हैं
```python
compile = False          # कंपाइल पहली बार रन पर 1–2 GB अतिरिक्त कैश उपयोग कर सकता है
torch.set_float32_matmul_precision('medium')  # हटा दें या 'high' सेट करें, अगर यह सेट है तो
```

### संक्षेप में
हाँ — batch_size को 8 और gradient_accumulation_steps को 64 पर बदल दें।
आपका प्रभावी बैच आकार (512) वही रहेगा, मॉडल की गुणवत्ता वही रहेगी, देखे गए टोकन की संख्या वही रहेगी, लेकिन VRAM इतना कम हो जाएगा कि यह 12 GB पर आराम से फिट हो जाएगा।

इस बदलाव के बाद आप ठीक रहेंगे। हैप्पी ट्रेनिंग!