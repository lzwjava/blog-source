---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: सामान्य मॉडल डोमेन विशिष्ट एआई से बेहतर प्रदर्शन करते हैं
translated: true
type: note
---

आप एक बहुत अच्छा और समय पर सवाल उठा रहे हैं। AI उद्योग में पेंडुलम वास्तव में **जनरल-पर्पस फाउंडेशन मॉडल्स** की ओर वापस झुक गया है, जो अब अधिकांश उपयोग के मामलों में संकीर्ण डोमेन-विशिष्ट मॉडल्स की तुलना में अधिक उचित (और आर्थिक रूप से प्रभावशाली) साबित हो रहे हैं। यहाँ कारण है कि 2024-2025 में "ब्लूमबर्गजीपीटी / मेड-पाल्म / फाइनेंसजीपीटी / लॉजीपीटी" शैली का दृष्टिकोण कम आकर्षक हो गया है:

### 1. डेटा दूषितीकरण और ओवरलैप बहुत बड़ा है
आधुनिक प्री-ट्रेनिंग कॉर्पोरा (रिफाइंडवेब, फाइनवेब, डोलमा, रेडपजामा v2, आदि) में पहले से ही वित्त, कानून, चिकित्सा और कोड टेक्स्ट की भारी मात्रा शामिल है। उदाहरण के लिए:
- कॉमन क्रॉल में अकेले अरबों एसईसी फाइलिंग, कोर्ट दस्तावेज, गिटहब रेपो, arXiv पेपर्स, वित्तीय समाचार, आदि हैं।
- 10-30T टोकन पर प्रशिक्षित एक सामान्य मॉडल, 1T टोकन के हाथ से चुने गए डोमेन डेटा पर प्रशिक्षित "डोमेन-विशिष्ट" मॉडल की तुलना में लगभग उतना ही उच्च-गुणवत्ता वाला वित्त/कानून/कोड डेटा देखता है।

परिणाम: 100B-400B के सामान्य मॉडल और 100B के "फाइनेंसजीपीटी" के बीच प्रदर्शन का अंतर नाटकीय रूप से सिकुड़ गया है। ब्लूमबर्गजीपीटी (2023) ने वित्त कार्यों पर सामान्य मॉडल्स को ~10-20% से हराया, लेकिन आज का लामा 3.1 405B या क्यूवेन2.5 72B अक्सर ब्लूमबर्गजीपीटी के आंकड़ों को बिना किसी डोमेन-विशिष्ट प्रशिक्षण के मैच कर देता है या उससे आगे निकल जाता है।

### 2. डोमेन की सीमाएं धुंधली और चलायमान हैं
आपने इसे पहले ही बिल्कुल सही बताया: फाइनेंस + AI, क्रिप्टो + लॉ, बायोटेक + फाइनेंस, प्रोग्रामिंग + मैथ + फिजिक्स, आदि। ज्ञान अब भारी मात्र में आपस में गुथा हुआ है।
- एक शुद्ध "फाइनेंस" मॉडल DeFi/स्मार्ट-कॉन्ट्रैक्ट सवालों पर विफल हो जाएगा क्योंकि इसने पर्याप्त कोड नहीं देखा होगा।
- एक शुद्ध "लॉ" मॉडल AI-रेगुलेशन केसों से जूझेगा जिनके लिए ट्रांसफॉर्मर्स और ट्रेनिंग डेटा की समझ की आवश्यकता होती है।
- एक शुद्ध "प्रोग्रामिंग" मॉडल ट्रेडिंग अल्गोरिदम लिखने में खराब होगा जिन्हें मार्केट माइक्रोस्ट्रक्चर नॉलेज की जरूरत होती है।

सामान्य मॉडल इन कम्पाउंड डोमेन को स्वाभाविक रूप से हैंडल करते हैं क्योंकि उन्होंने सब कुछ एक साथ मिला-जुला देखा है—ठीक वास्तविक दुनिया की तरह।

### 3. MoE स्पेशलाइजेशन को लगभग मुफ्त बना देता है
मिश्चर-ऑफ-एक्सपर्ट्स (मिक्सट्रल, डीपसीक-V3, क्यूवेन2.5-MoE, ग्रोक-1.5, आदि) पहले से ही आंतरिक रूप से हल्का-फुल्का डोमेन रूटिंग करता है। कुछ एक्सपर्ट्स कोड पर, कुछ फाइनेंस पर, कुछ बायोमेडिकल टेक्स्ट पर, आदि पर अधिक सक्रिय होना सीखते हैं, बिना किसी को स्पष्ट रूप से डेटा को अलग करने की आवश्यकता के। आपको डोमेन-विशिष्ट रूटिंग का अधिकांश लाभ बिना किसी अतिरिक्त इंजीनियरिंग या सेल्स प्रयास के मिल जाता है।

### 4. अर्थशास्त्र और वितरण बदल गए हैं
2023 की सोच: "प्रोप्राइटरी डेटा पर 50B का फाइनेंसजीपीटी प्रशिक्षित करें → बैंकों को $50-200 प्रति मिलियन टोकन पर API एक्सेस बेचें।"
2025 की वास्तविकता:
- बैंक केवल क्लॉड 3.5 / GPT-4o / लामा 405B + अपने आंतरिक दस्तावेजों पर RAG का उपयोग कर सकते हैं और 1/50 लागत पर 95-98% प्रदर्शन प्राप्त कर सकते हैं।
- ओपन-सोर्स फ्रंटियर मॉडल (लामा 3.1 405B, क्यूवेन2.5 72B, डीपसीक-V3) अब पर्याप्त अच्छे हैं कि अधिकांश कंपनियां एक बंद डोमेन मॉडल के लिए भारी प्रीमियम देने के बजाय फाइन-ट्यूनिंग या कॉन्टेक्स्ट इंजेक्शन पसंद करती हैं।
- एक समर्पित 70B-400B डोमेन मॉडल की होस्टिंग और इनफेरेंस लागत बहुत अधिक है यदि आपका ग्राहक आधार छोटा है।

### 5. पोस्ट-ट्रेनिंग (SFT + RL) लगभग पूरे शेष अंतर को बंद कर देती है
यहां तक कि अगर प्री-ट्रेनिंग के बाद कोई सामान्य मॉडल शुद्ध डोमेन ज्ञान पर थोड़ा पीछे है, तो भी सुपरवाइज्ड फाइन-ट्यूनिंग + DPO/RLHF में 500-5000 उच्च-गुणवत्ता वाले सिंथेटिक या मानव-लिखित उदाहरण उस डोमेन के अनुरूप उसे वैसे भी स्टेट-ऑफ-द-आर्ट तक पहुंचा देंगे। यह डोमेन प्री-ट्रेनिंग डेटा के टेराबाइट्स एकत्र करने और साफ करने से 100 गुना सस्ता और तेज है।

### जब डोमेन-विशिष्ट मॉडल अभी भी समझ में आते हैं (शेष कुछ मामले)
- अत्यधिक विनियमित या सुरक्षा-संवेदनशील वातावरण जहां आप सचमुच डेटा ओपनएआई/एन्थ्रोपिक/मेटा को नहीं भेज सकते (कुछ रक्षा, कुछ केंद्रीय बैंक, कुछ स्वास्थ्य सेवा प्रणालियाँ)।
- जब आपके पास बड़े पैमाने पर प्रोप्राइटरी डेटा है जो वास्तव में सार्वजनिक इंटरनेट पर नहीं है (जैसे, निजी व्यापार रिकॉर्ड के खरबों, आंतरिक कानूनी मेमो के दशक) और आप साबित कर सकते हैं कि सामान्य मॉडल सिग्नल को मिस कर रहे हैं।
- छोटे मॉडल जो ऑन-डिवाइस या एयर-गैप्ड सिस्टम में चलते हैं (जैसे, लीगल को-पायलट जो पूरी तरह से एक लॉ फर्म के फ़ायरवॉल के अंदर <7B पैरामीटर्स के साथ चलता है)।

हालाँकि, 2025 में 95%+ वाणिज्यिक उपयोग के मामलों के लिए, जवाब है:
सामान्य फ्रंटियर मॉडल (ओपन या क्लोज्ड) + डोमेन-विशिष्ट पोस्ट-ट्रेनिंग / RAG / टूल यूज >> समर्पित डोमेन प्री-ट्रेन्ड मॉडल।

तो हाँ — आप बिल्कुल सही हैं: ट्रांसफॉर्मर का सार डोमेन की परवाह किए बिना टेक्स्ट की भविष्यवाणी करना है, और डेटा मिक्सिंग समस्या + स्केलिंग लॉज़ + MoE + सस्ती पोस्ट-ट्रेनिंग ने शुद्ध रूप से डोमेन-विशिष्ट मॉडल्स को ज्यादातर एक 2022-2023 की घटना बना दिया है।