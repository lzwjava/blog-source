---
audio: false
generated: true
lang: hi
layout: post
title: ओपनएआई का सोरा
translated: true
type: note
---

हालांकि OpenAI ने Sora की आर्किटेक्चर पर कोई विस्तृत तकनीकी पेपर जारी नहीं किया है, फिर भी उनकी घोषणाओं और जनरेटिव AI, विशेष रूप से टेक्स्ट-टू-इमेज और वीडियो जनरेशन में सामान्य प्रगति के आधार पर हम अनुमान लगा सकते हैं कि यह कैसे काम करता होगा। यहां प्रमुख अवधारणाओं का विवरण दिया गया है:

**1. डिफ्यूज़न ट्रांसफॉर्मर मॉडल:**

* OpenAI द्वारा Sora को एक **डिफ्यूज़न ट्रांसफॉर्मर** के रूप में वर्णित किया गया है। इसका मतलब है कि यह दो शक्तिशाली AI आर्किटेक्चर के गुणों को जोड़ता है:
    * **डिफ्यूज़न मॉडल:** ये मॉडल एक नॉइज़ प्रक्रिया को उलट कर डेटा जनरेट करना सीखते हैं। ये यादृच्छिक नॉइज़ से शुरू होते हैं और धीरे-धीरे कई चरणों में इसे परिष्कृत करते हैं, दिए गए प्रॉम्प्ट से मेल खाती एक यथार्थवादी छवि या वीडियो फ्रेम उत्पन्न करने के लिए। इसे स्टैटिक से शुरू करके धीरे-धीरे एक तस्वीर उभरते हुए देखने की तरह समझें।
    * **ट्रांसफॉर्मर नेटवर्क:** मूल रूप से प्राकृतिक भाषा प्रसंस्करण के लिए डिजाइन किए गए, ट्रांसफॉर्मर डेटा के अनुक्रमों के भीतर संदर्भ और संबंधों को समझने में उत्कृष्ट होते हैं। Sora के मामले में, "अनुक्रम" शब्द नहीं हैं, बल्कि स्थान और समय में विजुअल पैच या टोकन की एक श्रृंखला है।

**2. पैच और टोकन:**

* जिस तरह बड़े भाषा मॉडल टेक्स्ट को टोकन में तोड़ते हैं, उसी तरह Sora संभवतः वीडियो को छोटी इकाइयों में तोड़ता है जिन्हें **पैच** कहा जाता है। वीडियो के लिए, ये पैच संभवतः 3D हैं, जिसमें स्थानिक जानकारी (एक फ्रेम के भीतर) और लौकिक जानकारी (फ्रेम्स के पार) दोनों शामिल हैं।
* इन पैचों को फिर टोकन के अनुक्रम के रूप में माना जाता है, जिसे ट्रांसफॉर्मर नेटवर्क प्रोसेस कर सकता है। यह मॉडल को यह समझने की अनुमति देता है कि वीडियो के विभिन्न हिस्से समय के साथ एक-दूसरे से कैसे संबंधित हैं, जो सुसंगत गति और लंबी दूरी की निर्भरताएं उत्पन्न करने के लिए महत्वपूर्ण है।

**3. टेक्स्ट-टू-वीडियो जनरेशन प्रक्रिया:**

* **टेक्स्ट प्रॉम्प्ट:** प्रक्रिया की शुरुआत उपयोगकर्ता द्वारा वांछित वीडियो का एक पाठ विवरण प्रदान करने के साथ होती है।
* **प्रॉम्प्ट को समझना:** Sora प्रॉम्प्ट की बारीकियों और विवरणों की व्याख्या करने के लिए भाषा की अपनी प्रशिक्षित समझ का उपयोग करता है। इसमें DALL-E 3 में उपयोग की जाने वाली तकनीकों के समान तकनीकें शामिल हो सकती हैं, जहां प्रॉम्प्ट को अधिक विशिष्ट विवरण शामिल करने के लिए पुन: वाक्यांशित या संवर्धित किया जाता है।
* **लेटेंट स्पेस रिप्रेजेंटेशन जनरेट करना:** मॉडल संभवतः टेक्स्ट प्रॉम्प्ट को एक निम्न-आयामी "लेटेंट स्पेस" में एक प्रतिनिधित्व में अनुवादित करता है। यह स्थान वीडियो का सार पकड़ता है।
* **लेटेंट स्पेस में डिनॉइज़िंग:** डिफ्यूज़न प्रक्रिया इस लेटेंट स्पेस में शुरू होती है। Sora नॉइज़ी पैच के साथ शुरू करता है और टेक्स्ट प्रॉम्प्ट और अपने प्रशिक्षण डेटा से सीखे गए पैटर्न के मार्गदर्शन में उन्हें पुनरावृत्त रूप से डिनॉइज़ करता है। ट्रांसफॉर्मर आर्किटेक्चर यह सुनिश्चित करने में मदद करता है कि डिनॉइज़िंग प्रक्रिया स्थान और समय में स्थिरता बनाए रखे।
* **वीडियो डीकंप्रेशन:** एक बार लेटेंट स्पेस में डिनॉइज़िंग प्रक्रिया पूरी हो जाने के बाद, परिणामी प्रतिनिधित्व को वीडियो फ्रेम के अनुक्रम में वापस "डिकोड" किया जाता है।

**4. प्रमुख क्षमताएं और तकनीकें:**

* **लौकिक स्थिरता:** वीडियो जनरेशन में एक महत्वपूर्ण चुनौती कई फ्रेम्स में वस्तुओं और दृश्यों की स्थिरता बनाए रखना है। वीडियो को स्पेशियो-टेम्पोरल पैच के अनुक्रम के रूप में ट्रांसफॉर्मर के साथ प्रोसेस करके, Sora इस स्थिरता को बेहतर ढंग से समझ और बनाए रख सकता है।
* **गति और कैमरा मूवमेंट को संभालना:** Sora ने जटिल कैमरा मूवमेंट और यथार्थवादी वस्तु गति वाले वीडियो उत्पन्न करने की प्रभावशाली क्षमता दिखाई है। इससे पता चलता है कि इसकी आर्किटेक्चर विजुअल दुनिया की गतिशीलता को प्रभावी ढंग से मॉडल कर सकती है।
* **3D की समझ:** OpenAI ने उल्लेख किया है कि Sora ने प्रतीत होता है कि प्रॉम्प्ट में स्पष्ट 3D जानकारी के बिना भी अपने प्रशिक्षण डेटा से 3D कंटेंट जनरेट करना सीख लिया है। इसका तात्पर्य स्थानिक संबंधों की मजबूत समझ से है।
* **रीकैप्शनिंग:** DALL-E 3 के समान, Sora संभवतः उत्पन्न वीडियो की निष्ठा में सुधार के लिए रीकैप्शनिंग नामक तकनीक का उपयोग करता है। इसमें प्रशिक्षण वीडियो के लिए विस्तृत कैप्शन बनाने के लिए वीडियो-टू-टेक्स्ट मॉडल का उपयोग शामिल है, जो टेक्स्ट-टू-वीडियो मॉडल को अधिक प्रभावी ढंग से सीखने में मदद करता है।

**5. प्रशिक्षण डेटा:**

* Sora को वीडियो और संभावित रूप से साथ में टेक्स्ट विवरण वाली छवियों के एक विशाल डेटासेट पर प्रशिक्षित किया गया है। इस डेटा का पैमाना और विविधता यथार्थवादी और विविध वीडियो सामग्री उत्पन्न करने की मॉडल की क्षमता के लिए महत्वपूर्ण है। OpenAI ने प्रशिक्षण के लिए सार्वजनिक रूप से उपलब्ध वीडियो के साथ-साथ लाइसेंस प्राप्त कॉपीराइट वीडियो का उपयोग करने का उल्लेख किया है।

**सार रूप में, Sora उच्च-गुणवत्ता वाली विजुअल सामग्री उत्पन्न करने के लिए डिफ्यूज़न मॉडल की शक्ति और वीडियो की लौकिक गतिशीलता को समझने और मॉडल करने के लिए ट्रांसफॉर्मर आर्किटेक्चर का लाभ उठाता है। वीडियो को प्रबंधनीय पैच में तोड़कर और उन्हें एक अनुक्रम के रूप में प्रोसेस करके, Sora टेक्स्ट प्रॉम्प्ट से सुसंगत, यथार्थवादी और कल्पनाशील वीडियो क्लिप उत्पन्न कर सकता है।**

यह ध्यान रखना महत्वपूर्ण है कि यह वर्तमान में उपलब्ध जानकारी के आधार पर एक उच्च-स्तरीय स्पष्टीकरण है। भविष्य में OpenAI अधिक तकनीकी विवरण प्रकट कर सकती है।