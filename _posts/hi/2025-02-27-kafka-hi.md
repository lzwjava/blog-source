---
audio: false
generated: true
lang: hi
layout: post
title: जावा में अपाचे काफ्का का उपयोग
translated: true
type: note
---

Java में Apache Kafka का उपयोग करने के लिए आपको अपने Java एप्लिकेशन में एक Kafka क्लाइंट सेट अप करना होता है ताकि आप मैसेज भेज (produce) और प्राप्त (consume) कर सकें। Kafka एक डिस्ट्रिब्यूटेड स्ट्रीमिंग प्लेटफॉर्म है, और इसकी Java क्लाइंट लाइब्रेरी इंटीग्रेशन को सीधा-साधा बनाती है। नीचे, मैं आपको शुरुआत करने के लिए बुनियादी कदमों से गुजरूँगा।

सबसे पहले, आपको अपना एनवायरनमेंट सेट अप करना होगा। सुनिश्चित करें कि आपके सिस्टम या सर्वर पर Kafka इंस्टॉल और चल रहा है। आप इसे ऑफिशियल Apache Kafka वेबसाइट से डाउनलोड कर सकते हैं और दिए गए स्क्रिप्ट्स का उपयोग करके ZooKeeper और Kafka सर्वर शुरू कर सकते हैं। सरलता के लिए, मैं मानकर चलूँगा कि आप डिफॉल्ट सेटिंग्स (जैसे `localhost:9092` बूटस्ट्रैप सर्वर के रूप में) के साथ Kafka को लोकल रन कर रहे हैं।

अगला कदम, अपने Java प्रोजेक्ट में Kafka क्लाइंट डिपेंडेंसी जोड़ना है। यदि आप Maven का उपयोग कर रहे हैं, तो अपनी `pom.xml` फ़ाइल में इसे शामिल करें:

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>3.6.0</version> <!-- नवीनतम वर्जन का उपयोग करें -->
</dependency>
```

अब, कुछ कोड लिखते हैं। मैं आपको दिखाऊंगा कि कैसे एक साधारण प्रोड्यूसर और कंज्यूमर बनाया जाता है।

### Kafka Producer उदाहरण
प्रोड्यूसर, एक Kafka टॉपिक को मैसेज भेजता है। यहाँ एक बुनियादी उदाहरण है:

```java
import org.apache.kafka.clients.producer.*;
import java.util.Properties;

public class SimpleProducer {
    public static void main(String[] args) {
        // प्रोड्यूसर प्रॉपर्टीज कॉन्फ़िगर करें
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092"); // Kafka सर्वर एड्रेस
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // एक प्रोड्यूसर इंस्टेंस बनाएँ
        try (Producer<String, String> producer = new KafkaProducer<>(props)) {
            // "test-topic" नामक टॉपिक को एक मैसेज भेजें
            String topic = "test-topic";
            for (int i = 0; i < 10; i++) {
                String key = "key" + i;
                String value = "Hello, Kafka " + i;
                ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);

                producer.send(record, (metadata, exception) -> {
                    if (exception == null) {
                        System.out.println("Sent message: " + value + " to partition " + metadata.partition());
                    } else {
                        exception.printStackTrace();
                    }
                });
            }
        }
    }
}
```

इस कोड में:
- `bootstrap.servers` निर्दिष्ट करता है कि Kafka कहाँ चल रहा है।
- सीरियलाइज़र परिभाषित करते हैं कि की और वैल्यू (दोनों यहाँ स्ट्रिंग) को बाइट्स में कैसे बदला जाता है।
- `ProducerRecord` मैसेज को रिप्रेजेंट करता है, और `send()` इसे एक कॉलबैक के साथ एसिंक्रोनस तरीके से भेजता है ताकि सफलता या विफलता को हैंडल किया जा सके।

### Kafka Consumer उदाहरण
कंज्यूमर एक टॉपिक को सब्सक्राइब करता है और मैसेज पढ़ता है। यहाँ एक उदाहरण है:

```java
import org.apache.kafka.clients.consumer.*;
import java.util.Collections;
import java.util.Properties;

public class SimpleConsumer {
    public static void main(String[] args) {
        // कंज्यूमर प्रॉपर्टीज कॉन्फ़िगर करें
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "test-group"); // कंज्यूमर ग्रुप ID
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("auto.offset.reset", "earliest"); // टॉपिक की शुरुआत से शुरू करें

        // एक कंज्यूमर इंस्टेंस बनाएँ
        try (KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {
            // टॉपिक को सब्सक्राइब करें
            consumer.subscribe(Collections.singletonList("test-topic"));

            // मैसेज के लिए पोल करें
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(1000); // टाइमआउट ms में
                for (ConsumerRecord<String, String> record : records) {
                    System.out.printf("Received: key=%s, value=%s, partition=%d, offset=%d%n",
                            record.key(), record.value(), record.partition(), record.offset());
                }
            }
        }
    }
}
```

यहाँ:
- `group.id` कोऑर्डिनेशन के लिए कंज्यूमर ग्रुप की पहचान करता है।
- डीसीरियलाइज़र बाइट डेटा को वापस स्ट्रिंग में बदलते हैं।
- `poll()` लूप में मैसेज फ़ेच करता है, और `auto.offset.reset` सुनिश्चित करता है कि यदि कोई ऑफसेट कमिट नहीं है तो आप सबसे पहले मैसेज से शुरू करें।

### कोड चलाना
1.  **Kafka शुरू करें**: सुनिश्चित करें कि ZooKeeper और Kafka चल रहे हैं (उदा. यूनिक्स-जैसे सिस्टम पर `bin/zookeeper-server-start.sh config/zookeeper.properties` और `bin/kafka-server-start.sh config/server.properties`)।
2.  **एक टॉपिक बनाएँ**: यदि `test-topic` मौजूद नहीं है, तो इसे बनाने के लिए Kafka कमांड-लाइन टूल का उपयोग करें: `bin/kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1`।
3.  **प्रोड्यूसर चलाएँ**: मैसेज भेजने के लिए `SimpleProducer` क्लास को एक्जीक्यूट करें।
4.  **कंज्यूमर चलाएँ**: मैसेज को कंज्यूम होते देखने के लिए `SimpleConsumer` क्लास को रन करें।

### टिप्स
-   **एरर हैंडलिंग**: प्रोडक्शन कोड के लिए ट्राई-कैच ब्लॉक या लॉगिंग जोड़ें।
-   **कॉन्फ़िगरेशन**: अपनी ज़रूरतों के आधार पर `acks` (प्रोड्यूसर रिलायबिलिटी के लिए) या `max.poll.records` (कंज्यूमर बैच साइज के लिए) जैसी प्रॉपर्टीज को एडजस्ट करें।
-   **लाइब्रेरीज़**: अधिक कॉम्प्लेक्स एप्लिकेशन के लिए, Spring Kafka का उपयोग करने पर विचार करें, जो कॉन्फ़िगरेशन और उपयोग को सरल बनाता है।

यह आपको शुरुआत करने के लिए एक बुनियादी सेटअप है। यदि आप विशेष फीचर्स जैसे पार्टीशनिंग, एरर हैंडलिंग, या बड़े एप्लिकेशन के साथ इंटीग्रेशन में गहराई से जाना चाहते हैं, तो मुझे बताएं!