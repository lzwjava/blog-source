---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-code-fast-1
title: म्यूऑन ऑप्टिमाइज़र का परिचय और अवलोकन
translated: true
type: note
---

### म्यूऑन ऑप्टिमाइज़र की व्यापक परिचय

म्यूऑन ऑप्टिमाइज़र एक विशेष, सेकंड-ऑर्डर से प्रेरित ऑप्टिमाइज़ेशन एल्गोरिदम है जिसे मुख्य रूप से न्यूरल नेटवर्क में लीनियर लेयर्स (जैसे, fully connected या embedding layers) को प्रशिक्षित करने के लिए डिज़ाइन किया गया है, हालांकि इसे अन्य के लिए भी बढ़ाया जा सकता है। इसकी मूल रूप से 2024 के अंत में केलर जॉर्डन और जेरेमी बर्नस्टीन सहित शोधकर्ताओं द्वारा पेश की गई थी, जिसकी जड़ें ज्यामितीय ऑप्टिमाइज़ेशन तकनीकों जैसे कि polar initialization और modular duality framework[1][2] में हैं। झिलिंग यांग, मूनशॉट एआई और किमी एआई के संस्थापक, ने अपने किमी K2 मॉडल—एक 1-ट्रिलियन-पैरामीटर लार्ज लैंग्वेज मॉडल (LLM)—को प्रशिक्षित करने के बारे में चर्चाओं में म्यूऑन पर प्रकाश डाला, जहां यह कुशल, उच्च-रैंक अपडेट की रीढ़ के रूप में कार्य करता था जो लॉस लैंडस्केप की ज्यामिति के अनुकूल होता है[3][4]। हालाँकि, इसके बेसलाइन संस्करण को अस्थिरता (जैसे, लंबे प्रशिक्षण के दौरान लॉस स्पाइक्स) का सामना करना पड़ा, जिसने मूनशॉट एआई को म्यूऑनक्लिप विकसित करने के लिए प्रेरित किया, एक उन्नत वेरिएंट जिसमें अटेंशन लेयर्स के लिए QK-clipping जैसी स्थिरता तंत्र शामिल हैं[3][2]।

म्यूऑन अपनी टोकन दक्षता के लिए उभरता है: इसके तुलनीय प्रदर्शन को प्राप्त करने के लिए AdamW जैसे फर्स्ट-ऑर्डर ऑप्टिमाइज़र की तुलना में इसे कम प्रशिक्षण टोकन की आवश्यकता होती है, जो इसे LLM प्री-ट्रेनिंग जैसे संसाधन-गहन कार्यों के लिए मूल्यवान बनाता है। इसका लक्ष्य सेकंड-ऑर्डर विधियों (जैसे, न्यूटन की विधि) का पूर्ण कम्प्यूटेशनल लागत के बिना अनुमान लगाना है, जो eigenvalue adaptation पर उच्च-रैंक मैट्रिक्स अपडेट के माध्यम से केंद्रित है। यह बड़े पैमाने के मॉडल में विशेष रूप से उपयोगी है जहां ग्रेडिएंट शोरयुक्त होते हैं, क्योंकि म्यूऑन प्रीकंडीशनिंग का natural gradients और मैट्रिक्स वर्गमूल से प्रेरित होकर लाभ उठाता है।

#### मुख्य सिद्धांत और व्युत्पत्ति
- **मूल अवधारणा**: म्यूऑन की जड़ें ज्यामितीय ऑप्टिमाइज़ेशन में हैं, जो लॉस फ़ंक्शन के "ऊर्जा परिदृश्य" के लिए अपडेट को अनुकूलित करता है। यह ग्रेडिएंट को स्केल करने के लिए फिशर सूचना मैट्रिक्स (या सन्निकटन) पर आधारित एक प्रीकंडीशनर का उपयोग करता है, जो AdaGrad या Shampoo के समान है लेकिन घने लीनियर लेयर्स के लिए अनुकूलित है[1][2]।
- **एल्गोरिदम चरण**:
  1. **ग्रेडिएंट गणना**: लीनियर लेयर्स में वज़न \(W\) के लिए मानक ग्रेडिएंट \(\nabla W\) की गणना करें।
  2. **प्रीकंडीशनिंग**: एक प्रीकंडीशनर (जैसे, लेयर सांख्यिकी से व्युत्पन्न) के मैट्रिक्स वर्गमूल का अनुमान लगाने के लिए न्यूटन-शुल्ज़ पुनरावृत्तियों का उपयोग करें। यह पूर्ण eigendecomposition के बिना रैंक अनुकूलन सक्षम करता है।
  3. **अपडेट नियम**: एक अपडेट लागू करें जो उच्च-रैंक घटकों को अधिक प्रभावी ढंग से स्केल करता है, जो अक्सर स्थिरता के लिए मोमेंटम या क्लिपिंग के साथ संयुक्त होता है।
- **गणितीय अंतर्दृष्टि**: यदि \(G\) ग्रेडिएंट मैट्रिक्स है, तो म्यूऑन \(W \leftarrow W - \eta \cdot \sqrt{P}^{-1} G\) जैसे अपडेट का अनुमान लगाता है, जहाँ \(\sqrt{P}\) पुनरावृत्त मैट्रिक्स वर्गमूल[2][5] का उपयोग करता है। यह AdamW के विकर्ण या मोमेंट-आधारित स्केलिंग के विपरीत है, जो म्यूऑन को पैरामीटर-अंतर सहसंबंधों को बेहतर ढंग से पकड़ने की अनुमति देता है।
- **दक्षता बढ़ावा**: म्यूऑन कुछ बेंचमार्क में प्रशिक्षण चरणों की संख्या को 20-50% तक कम कर सकता है, जैसा कि NanoGPT रिकॉर्ड्स के साथ इसके उपयोग में देखा गया है[1]।

#### लाभ और कमियां
- **लाभ**:
  - **लीनियर लेयर्स पर बेहतर अभिसरण**: LLM में आम तौर पर पाए जाने वाले घने, उच्च-आयामी स्थानों में उत्कृष्ट प्रदर्शन करता है, जिससे कम टोकन के साथ कम लॉस होता है[4][6]।
  - **संसाधन-कुशल**: कम ग्रेडिएंट गणना की आवश्यकता के कारण प्रति-युग तेज प्रशिक्षण।
  - **ओपन-सोर्स और विस्तार योग्य**: कई कार्यान्वयन मौजूद हैं, जिनमें GPU त्वरण के लिए Flash-Muon जैसे विशिष्ट शामिल हैं[4][7]।
- **कमियां**:
  - **अस्थिरता**: गहरे नेटवर्क या sparse layers में विचलन की संभावना; म्यूऑनक्लिप प्रशिक्षण के दौरान अटेंशन स्कोर (जैसे, query-key products) को क्लिप करके इसे संबोधित करता है[3][2]।
  - **लेयर विशिष्टता**: convolutional या recurrent layers के लिए आदर्श नहीं; यह लीनियर/MoE आर्किटेक्चर की ओर पक्षपाती है। Keras नोट करता है कि इसका उपयोग गैर-रैखिक layers[8] के लिए नहीं किया जाना चाहिए।
  - **हाइपरपैरामीटर संवेदनशीलता**: लर्निंग रेट (\(\eta\)) और ऑर्थोगोनैलिटी-प्रेरित चालों के लिए ट्यूनिंग की आवश्यकता होती है; समायोजन के बिना मॉडल आकारों में स्थानांतरित नहीं हो सकता है[2]।
- **म्यूऑनक्लिप वेरिएंट (किमी-विशिष्ट)**: यह म्यूऑन का विकास है, जो 15.5 ट्रिलियन-टोकन प्री-ट्रेनिंग में अस्थिरता को रोकने के लिए QK-clipping के साथ एकीकृत है। इसने किमी K2 के 32 बिलियन सक्रिय पैरामीटर को स्थिर किया, जिससे शून्य-लॉस-स्पाइक प्रशिक्षण और श्रेष्ठ बेंचमार्क (जैसे, Tau2-Bench पर 66.1)[3][8] सक्षम हुए। अभी तक सार्वजनिक कोड के बिना, यह मालिकाना है लेकिन खुले म्यूऑन पर निर्मित है।

म्यूऑन ने AI ऑप्टिमाइज़ेशन लैंडस्केप को प्रभावित किया है, जो Scion जैसे बेंचमार्क और Reddit/X पर चर्चाओं में दिखाई देता है, जिसकी अक्सर इसकी "ज्यामितीय अंतर्ज्ञान" के लिए प्रशंसा की जाती है। पूर्ण व्युत्पत्तियों के लिए, जेरेमी बर्नस्टीन के ब्लॉग[2] देखें। अब, एक व्यावहारिक कार्यान्वयन पर नजर डालते हैं।

### कोड उदाहरण: PyTorch में म्यूऑन ऑप्टिमाइज़र को लागू करना
नीचे आधिकारिक रिपॉजिटरी (https://github.com/KellerJordan/Muon) से अनुकूलित म्यूऑन ऑप्टिमाइज़र का एक PyTorch कार्यान्वयन है। यह घने लीनियर लेयर्स के लिए एक सरलीकृत संस्करण है; इसमें प्रीकंडीशनर के लिए न्यूटन-शुल्ज़ पुनरावृत्तियाँ शामिल हैं।

```python
import torch
import torch.nn as nn

class Muon(torch.optim.Optimizer):
    """
    लीनियर लेयर्स के लिए म्यूऑन ऑप्टिमाइज़र।
    From: https://github.com/KellerJordan/Muon
    """
    def __init__(self, params, lr=1e-3, lr_b=2e-3, b2=0.95, wd=0.0):
        defaults = dict(lr=lr, lr_b=lr_b, b2=b2, wd=wd)
        super().__init__(params, defaults)

    def step(self):
        for group in self.param_groups:
            lr = group['lr']
            lr_b = group['lr_b']
            b2 = group['b2']
            wd = group['wd']

            for p in group['params']:
                if p.grad is None:
                    continue

                grad = p.grad.data.float()
                state = self.state[p]
                if 'momentum' not in state:
                    state['momentum'] = torch.zeros_like(grad)

                # मोमेंटम अपडेट
                state['momentum'].mul_(b2).add_(grad)

                # वेट डिके
                if wd != 0:
                    p.data.mul_(1 - lr * wd)

                # म्यूऑन का ऑर्थोनॉर्मलाइजेशन (रैंक अनुकूलन)
                grad_vec = state['momentum'].view(-1, grad.shape[-1])
                p_vec = p.data.view(-1, p.shape[-1])

                # मैट्रिक्स वर्गमूल सन्निकटन के लिए न्यूटन-शुल्ज़ (सरलीकृत)
                G = grad_vec @ grad_vec.t() / grad_vec.shape[0]
                # पूर्ण कार्यान्वयन में, यह पुनरावृत्त है; यहाँ, पावर श्रृंखला के साथ अनुमानित
                sqrt_G = torch.sqrt(G + 1e-6 * torch.eye(G.shape[0], device=G.device))

                # अपडेट
                update = grad_vec.t() @ sqrt_G @ grad_vec / sqrt_G.shape[0]
                p.data.sub_(lr_b * update.view(p.shape))

# उदाहरण उपयोग
model = nn.Linear(768, 768)  # घनी परत
optimizer = Muon(model.parameters(), lr=0.01)
loss_fn = nn.MSELoss()
data = torch.randn(32, 768)
target = torch.randn(32, 768)

for epoch in range(10):
    optimizer.zero_grad()
    output = model(data)
    loss = loss_fn(output, target)
    loss.backward()
    optimizer.step()
    print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")
```

**कोड पर नोट्स**:
- यह एक सरलीकृत संस्करण है; पूर्ण GitHub रेपो में दक्षता के लिए CUDA kernels शामिल हैं (जैसे, तेज़ matmuls के लिए Flash-Muon)[3][4]।
- Keras/TensorFlow के लिए: `from keras.optimizers import Muon; opt = Muon(learning_rate=0.01)`[8] का उपयोग करें।
- ट्यून किए गए हाइपरपैरामीटर (जैसे, `lr_b=2e-3`) महत्वपूर्ण हैं; अपने मॉडल के साथ प्रयोग करें। किमी K2 के म्यूऑनक्लिप के लिए, कोई सार्वजनिक कोड मौजूद नहीं है, लेकिन यह अटेंशन फॉरवर्ड पास में क्लिपिंग लॉजिक जोड़ता है[2][5]।

यदि आपको एक्सटेंशन या बेंचमार्क की आवश्यकता है, तो मुझे बताएं!

उद्धरण:
[1] https://kellerjordan.github.io/posts/muon/
[2] https://jeremybernste.in/writing/deriving-muon
[3] https://github.com/KellerJordan/Muon
[4] https://github.com/nil0x9/flash-muon
[5] https://www.lakernewhouse.com/writing/muon-2
[6] https://medium.com/@kyeg/building-the-muon-optimizer-in-pytorch-a-geometric-approach-to-neural-network-optimization-17f4601be548
[7] https://discuss.huggingface.co/t/tutorial-understanding-and-implementing-the-muon-optimizer/167717
[8] https://keras.io/api/optimizers/muon/