---
audio: true
lang: hi
layout: post
title: AI सोचना
translated: true
---

- सत्या नाडेल्ला ने जेवन्स पैराडॉक्स का उल्लेख किया है। इसे सीखना महत्वपूर्ण है।

- यिन वांग: वास्तव में अर्टिफिशल इंटेलिजेंस में "इंटेलिजेंस" नहीं है, नेयरल नेटवर्क में "नेयरल" नहीं है, मशीन लर्निंग में "लर्निंग" नहीं है, और डीप लर्निंग में "डीप" नहीं है। इस क्षेत्र में काम करने वाला वस्तु के नाम काल्कुलस है। इसलिए, मुझे इस क्षेत्र को "अवकलज गणित" कहना पसंद है, और मोडेल बनाने का प्रक्रम को "अवकलज प्रोग्रामिंग" कहना पसंद है।

- यिन वांग: मशीन लर्निंग वास्तव में भी काफी उपयोगी, हालाँकि कभी कहीं कौन कहें कि यह काफी सुन्दर सिद्धांत भी है, क्योंकि यह सीखा हुआ नया व्यापार है! यह व्यक्त होने के पूर्व न्यूटन, लाइब्निज़ का पुराना और महान सिद्धांत है, एक सरल, सुंदर और शक्तिशाली रूप में। मशीन लर्निंग किसी तरह के कैल्कुलस का उपयोग करके कुछ फ़ंक्शनों को निकालने और फ़िट करने का उपयोग है, और डीप लर्निंग कुछ ज्यादा जटिल फ़ंक्शनों को फ़िट करना है।

- वर्तमान में, विशाल भाषा मॉडल यमल या पाइथन जैसे फ़ाइल की भाषा के आधार पर फ़िल्टर नहीं कर सकते हैं। किंतु समय-शील विश्व में काफी से जानकारी इस तरह संगत की गयी है। यह मतलब है कि हम विशाल भाषा मॉडल को फ़ाइलों का उपयोग करके प्रशिक्षित कर सकते हैं।

- विशाल भाषा मॉडल को प्रशिक्षित करने के लिए, हम एक सिस्टम विकसित कर सकते हैं जो समान मैच पाए। शायद हम कन्ठ-मोर्रिस-प्राट् सर्च एल्गोरिडम को ट्रांसफर्मर अर्किटेक्चर के साथ मिलाकर खोज क्षमता को बढ़ा सकते हैं।

- कोई टेक्नॉलॉजी का राज़ नहीं है। ओपन सोर्स सारे रहस्य बता देगा जो बहुत सावधानी से संरक्षित किए जाते हैं।