---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: अनावश्यक कोड हटाकर अनुकूलन करें
translated: true
type: note
---

बिल्कुल सही—आइए उस प्रॉक्सी लॉग को हमारे आधार के रूप में इस्तेमाल करते हुए आगे बढ़ें। यह "ऑप्टिमाइज़ेशन माइंडसेट" के लिए एक खान है: स्क्रिप्ट 53 प्रॉक्सी को ब्रूट-फोर्स हैमर की तरह पीसती नहीं है; बल्कि यह लक्ष्य (AI टूल्स जैसे ChatGPT के लिए सबसे तेज़ SG/TW, HK बैन से बचाव) पर लेजर-फोकस करती है, पहले 14 पर फ़िल्टर करके, बैच में लेटेंसी टेस्ट करके, और 294ms के चैंपियन को चुनने के लिए सॉर्ट करके। यह सिर्फ दक्षता नहीं है—यह बेरहमी से छँटाई है: जो अंतिम लक्ष्य की सेवा नहीं करता उसे काट दो, ऑपरेशन्स का क्रम बदलो (फ़िल्टर > टेस्ट > चुनाव), और हर कदम पर सवाल करो ("क्या मुझे उस CN-ओनली बेकार चीज़ को टेस्ट करने की ज़रूरत है? नहीं।")।

यह किसी भी कोड पर लागू होता है जहाँ लूप्स, क्वेरीज़, या कम्प्यूटेशन्स फूल जाते हैं। यहां बताया गया है कि वास्तविक दुनिया के उदाहरणों के साथ इस सोच को कैसे आगे बढ़ाया जाए, हमेशा उन मुख्य संदिग्धों पर वापस लौटते हुए: *क्या हम ऑप्टिमाइज़ कर सकते हैं? असली लक्ष्य क्या है? क्या काटना है? क्रम अलग हो सकता है?*

### 1. **डेटाबेस क्वेरीज़: फ़ेच करने से पहले फ़िल्टर करें (फालतू चीज़ को जल्दी काटें)**
   कल्पना करें एक यूज़र डीबी को "यूरोप में एक्टिव सब्सक्राइबर्स जिन्होंने पिछले महीने प्रीमियम खरीदा" के लिए क्वेरी करना। नाइव कोड: `SELECT * FROM users WHERE active=1 AND region='EU' AND purchase_date > '2024-09-01' ORDER BY signup_date`। बूम—लाखों rows के लिए *सभी* कॉलम फ़ेच करता है, फिर मेमोरी में फ़िल्टर करता है। बेकार है अगर आपको सिर्फ `email` और `last_login` चाहिए।

   **ऑप्टिमाइज़ेशन लेंस:**
   - **लक्ष्य?** "सभी यूज़र्स पाना" नहीं, बल्कि "एक टार्गेटेड कैम्पेन के लिए ईमेल लिस्ट।"
   - **क्या काटें?** केवल `email` SELECT करें (और शायद ट्रैकिंग के लिए `id`)। पेजिनेशन के लिए `LIMIT 1000` जोड़ें।
   - **अलग क्रम?** किसी भी ऐप-साइड लॉजिक से पहले फ़िल्टर्स को SQL (WHERE क्लॉज) में पुश करें। स्कैन टाइम कम करने के लिए `region` और `purchase_date` पर इंडेक्स लगाएं।
   
   नतीजा: 10s की क्वेरी से 50ms तक। प्रॉक्सी फ़िल्टर की तरह: 53 को क्यों घसीटें जब 14 काफी हैं? कोड में:
   ```python:disable-run
   # बुरा: सब कुछ फ़ेच करो, बाद में फ़िल्टर करो
   all_users = db.query("SELECT * FROM users")
   eu_premium = [u for u in all_users if u.region == 'EU' and u.is_premium]
   
   # ऑप्टिमाइज़्ड: स्रोत पर ही फ़िल्टर करो
   eu_premium = db.query("SELECT email FROM users WHERE region='EU' AND is_premium=1 LIMIT 1000")
   ```

### 2. **API रेट-लिमिटिंग: बैच और कैश (पैरेलल विंस के लिए क्रम बदलें)**
   मान लें आप एक ई-कॉम API से 100 प्रोडक्ट की कीमतें स्क्रेप कर रहे हैं जिसकी लिमिट 10/सेकंड है। सीधा लूप: `for item in items: price = api.get(item.id); total += price`। 10s लगते हैं, लेकिन क्या हो अगर आधे आइटम एक जैसे SKU हैं? फालतू कॉल्स।

   **ऑप्टिमाइज़ेशन लेंस:**
   - **लक्ष्य?** कीमतों को जोड़ना, प्रति-आइटम हमला नहीं।
   - **क्या काटें?** पहले IDs को डीड्यूप करें (`unique_items = set(item.id for item in items)`—तुरंत 50% कम)।
   - **अलग क्रम?** रिक्वेस्ट्स को बैच करें (अगर API `/batch?ids=1,2,3` सपोर्ट करता है) या `asyncio.gather([api.get(id) for id in unique_items])` के साथ एसिंक पैरेललाइज़ करें। Redis कैश की लेयर जोड़ें: "क्या यह ID पिछले एक घंटे में देखा था? स्किप करो।"
   
   प्रॉक्सी पैरेलल: वो कंकरंट TCP लॉग? एक ही भावना—एक के बाद एक टेस्ट करने के बजाय एक साथ कई लेटेंसी टेस्ट करो। सेकंड्स को मिलीसेकंड में कम कर देता है। कोड स्निपेट:
   ```python
   import asyncio
   
   async def fetch_prices(ids):
       return await asyncio.gather(*[api.get(id) for id in set(ids)])  # डीड्यूप + पैरेलल
   
   totals = sum(await fetch_prices(items))  # एक बैच, हो गया।
   ```

### 3. **इमेज प्रोसेसिंग पाइपलाइन: फेल्योर पर अर्ली एक्जिट (फ्लो के बीच में लक्ष्य पर सवाल करें)**
   एक फोटो एडिटर बना रहे हैं: 1k अपलोड्स को रीसाइज़, वॉटरमार्क, कम्प्रेस करना। लूप: प्रत्येक इमेज के लिए, लोड > रीसाइज़ > टेक्स्ट जोड़ो > JPEG के रूप में सेव करो। लेकिन 20% करप्ट हैं—भूतों पर CPU बर्बाद।

   **ऑप्टिमाइज़ेशन लेंस:**
   - **लक्ष्य?** वैध एडिटेड इमेज डिलीवर करना, बेकार चीज़ को प्रोसेस नहीं करना।
   - **क्या काटें?** क्विक वैलिडिटी चेक (जैसे, `PIL.Image.open` के साथ `try/except`—फेल हो तो छोड़ दो)।
   - **अलग क्रम?** पहले वैलिडेट करो, फिर केवल बचे हुए को पाइपलाइन करो। प्रोफाइल करो: 80% टाइम रीसाइज़ में? प्रिव्यू के लिए थंबनेल को एसिंक डाउनसैंपल करो।
   
   प्रॉक्सी टाइमआउट वार्निंग की गूंज: वह 504 एरर? स्क्रिप्ट ने इसे जल्दी फ्लैग किया, इसे टॉप-20 सॉर्ट को डिरेल नहीं होने दिया। प्रैक्टिस में:
   ```python
   def process_image(path):
       try:
           img = Image.open(path)  # अर्ली कट: यहाँ फेल हो, लॉग करो और स्किप करो
           img = img.resize((800, 600))
           # वॉटरमार्क, कम्प्रेस...
           img.save(f"{path}_edited.jpg")
       except Exception:
           logging.warning(f"Skipped corrupt: {path}")
   
   [process_image(p) for p in valid_paths]  # पहले से फ़िल्टर्ड लिस्ट
   ```

### द मेटा-रूल: बेरहमी से प्रोफाइल करो, शक के साथ इटरेट करो
इसे वापस जोड़ें: हर रिफैक्टर को "बॉटलनेक क्या है?" (Python का `cProfile` या ब्राउज़र डेव टूल्स जैसे टूल्स) से शुरू करें। अपनी प्रॉक्सी स्क्रिप्ट की तरह लॉग करें—टाइमस्टैम्प्स स्लोपोक्स को दिखाते हैं। फिर ऑडिट करें: *लक्ष्य संरेखण?* (जैसे, "AI एक्सेस के लिए लेटेंसी <300ms")। *कटौती?* (डेड कोड, अनयूज़्ड वेरिएबल्स—`black` या `pylint` इन्हें फ्लैग करते हैं)। *क्रम बदलो?* (लेज़ी इवैल्यूएशन: डिमांड पर कम्प्यूट करो, अग्रिम रूप से नहीं)।

यह समय से पहले माइक्रो-ऑप्टिमाइज़िंग नहीं है—यह रणनीतिक संदेह है। प्रॉक्सी दुनिया में, इसका मतलब है HK के सिरदर्द के बिना SG/TW का आनंद; आपकी दुनिया में, इसका मतलब है कोड जो *तेज़* महसूस होता है। क्या आपकी नज़र किसी खास लूप या एल्गो पर है जिस पर यह इलाज लगाना है? आइए इसे डिसेक्ट करते हैं।