---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: विकिपीडिया डंप फ़ाइल संरचना अंतर
translated: true
type: note
---

मुख्य अंतर यह है कि पूरा विकिपीडिया लेख टेक्स्ट कैसे कई फाइलों में विभाजित है — विशेष रूप से यह कि क्या एक `.xml.bz2` फाइल में केवल रिविज़नों की एक ही स्ट्रीम होती है (नॉन-मल्टीस्ट्रीम) या कई संपीड़ित स्ट्रीम्स एक साथ बंडल की गई होती हैं (मल्टीस्ट्रीम)।

### 1. नॉन-मल्टीस्ट्रीम डंप (पुरानी शैली, या डिफ़ॉल्ट "pages-articles" फाइलें)
उदाहरण फाइलनाम:
`enwiki-20251101-pages-articles1.xml-p1p41242.bz2`

- प्रत्येक `.xml.bz2` फाइल में पेजों का एक हिस्सा (जैसे, पेज 1–41242) पेज-आईडी क्रम में होता है।
- फाइल के अंदर बिल्कुल एक सतत `<page>` … `<page>` … अनुक्रम होता है।
- एक ही पेज के सभी रिविज़न उस एक पेज टैग के अंदर एक साथ होते हैं (नवीनतम रिविज़न + पुराने वाले, यदि आपने "करंट + हिस्ट्री" मांगी है)।
- किसी एक लेख को निकालने के लिए, आप बस किसी भी XML/BZ2 टूल से बड़े XML को डीकंप्रेस और पार्स करते हैं।
- `wget -c` सरल तरीके से पूरी तरह काम करता है: यह बिल्कुल वहीं से रिज्यूम करता है जहां यह रुका था क्योंकि फाइल एक ही bzip2 स्ट्रीम है।

### 2. मल्टीस्ट्रीम डंप (जिन फाइलों के नाम में "multistream" होता है)
उदाहरण फाइलनाम (जिसे आपने लिंक किया है):
`enwiki-20251101-pages-articles-multistream1.xml-p1p41242.bz2`

- वही पेज रेंज (p1p41242) कवर की गई है, लेकिन हर रिविज़न का पूरा टेक्स्ट अब मुख्य XML फाइल के अंदर संग्रहीत नहीं है।
- इसके बजाय:
  - मुख्य XML फाइल में केवल मेटाडेटा (शीर्षक, आईडी, प्रतिबंध, नवीनतम रिविज़न टाइमस्टैम्प, आदि) और एक पॉइंटर (बाइट ऑफसेट + लंबाई) होता है जो बताता है कि वास्तविक रिविज़न टेक्स्ट कहां स्थित है।
  - वास्तविक रिविज़न टेक्स्ट अलग से उसी `.bz2` फाइल के अंदर कई छोटी संपीड़ित स्ट्रीम्स में संग्रहीत होते हैं (इसलिए "मल्टीस्ट्रीम")।
- आमतौर पर एक साथी `...-multistream-index1.txt.bz2` फाइल होती है जिसमें प्रत्येक पेज/रिविज़न के लिए सटीक बाइट ऑफसेट होते हैं ताकि टूल सीधे सही संपीड़ित स्ट्रीम पर जा सकें और पूरी 10–30 GB फाइल को डीकंप्रेस किए बिना केवल उसी टेक्स्ट को निकाल सकें।

### यह `wget -c` के लिए क्यों मायने रखता है?

व्यवहार में, दोनों कमांड:

```bash
wget -c https://.../enwiki-20251101-pages-articles1.xml-p1p41242.bz2
wget -c https://.../enwiki-20251101-pages-articles-multistream1.xml-p1p41242.bz2
```

wget के दृष्टिकोण से बिल्कुल समान व्यवहार करती हैं: दोनों सामान्य सिंगल bzip2 फाइलें हैं, इसलिए `-c` के साथ रिज्यूमेबल डाउनलोड दोनों ही मामलों में पूरी तरह से काम करता है।

अंतर तभी दिखाई देता है जब आप डाउनलोड की गई फाइल को प्रोसेस करना शुरू करते हैं।

### सारांश तालिका

| विशेषता                              | नॉन-मल्टीस्ट्रीम (नियमित)                      | मल्टीस्ट्रीम                                      |
|--------------------------------------|-------------------------------------------------|--------------------------------------------------|
| फाइलनाम में होता है                  | `-pages-articlesN.xml-...bz2`                  | `-pages-articles-multistreamN.xml-...bz2`        |
| लेख टेक्स्ट स्थान                | XML `<page><revision><text>...</text></revision></page>` के अंदर | XML के बाहर, अलग संपीड़ित स्ट्रीम्स में |
| फाइल आकार (समान पेज रेंज के लिए)  | बहुत बड़ा (अक्सर 2–3×)                        | बहुत छोटा                                    |
| रैंडम एक्सेस / सिंगल-पेज एक्सट्रैक्ट  | बहुत धीमा (पूरी फाइल को डीकंप्रेस करना होगा)          | बहुत तेज़ (इंडेक्स फाइल के साथ)                  |
| सीधे समझने वाले टूल    | कोई भी XML पार्सर (SAX, xmltodict, आदि)           | wikimedia के dump-generator टूल्स, pywiki, mwxml, आदि. |
| साथी इंडेक्स फाइल की आवश्यकता?          | नहीं                                              | हाँ (`-multistream-index....txt.bz2`)            |
| `wget -c` रिज्यूमेबिलिटी               | परफेक्ट                                         | परफेक्ट (अभी भी एक bzip2 फाइल)                   |

### तो आपको कौन सी डाउनलोड करनी चाहिए?

- यदि आप सिर्फ एक बार फुल सीक्वेंशियल पास करना चाहते हैं (जैसे एक लैंग्वेज मॉडल ट्रेन करना), तो नॉन-मल्टीस्ट्रीम फाइलें सरल हैं।
- यदि आप कभी भी अलग-अलग पेजों को जल्दी से देखना चाहते हैं, या आप डिस्क स्पेस और एक्सट्रैक्शन स्पीड की परवाह करते हैं, तो हमेशा मल्टीस्ट्रीम + इंडेक्स जोड़ी को प्राथमिकता दें। लगभग सभी गंभीर विकिमीडिया प्रोसेसिंग टूल्स (WikiExtractor, gensim का WikiCorpus, jawiki स्क्रिप्ट्स, आदि) आजकल मल्टीस्ट्रीम वर्जन की अपेक्षा करते हैं या सख्ती से सलाह देते हैं।

दोनों फाइलें आप `wget -c` के साथ बिना किसी समस्या के रिज्यूम कर सकते हैं; "मल्टीस्ट्रीम" भाग केवल फाइल के अंदर क्या है उसे बदलता है, न कि HTTP/wget इसे कैसे देखता है।