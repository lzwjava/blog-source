---
audio: false
generated: true
image: false
lang: hi
layout: post
title: एआई प्रॉम्प्ट से छवि रूपांतरित करें
translated: true
type: note
---

अगस्त 2025 तक, OpenAI के DALL-E मॉडल, विशेष रूप से नए "GPT Image" मॉडल (जैसे `gpt-image-1`), अधिक परिष्कृत इमेज मैनिपुलेशन को सपोर्ट करने के लिए विकसित हुए हैं, जिसमें "इमेज-टू-इमेज" ट्रांसफॉर्मेशन शामिल हैं। जहां DALL-E 2 के पास इसके लिए एक विशिष्ट "वेरिएशंस" एंडपॉइंट था, वहीं नए मॉडल इमेज इनपुट और विस्तृत टेक्स्ट प्रॉम्प्ट के संयोजन के माध्यम से इस फंक्शनैलिटी को एकीकृत करते हैं।

यहां बताया गया है कि आप OpenAI API का उपयोग करके Ghibli स्टाइल लागू करने जैसे "इमेज-टू-इमेज" टास्क को कैसे अंजाम देंगे:

### मूल अवधारणा: टेक्स्ट प्रॉम्प्ट के साथ इमेज एडिट्स

एक साधारण टेक्स्ट-टू-इमेज प्रॉम्प्ट के विपरीत, OpenAI के API के साथ इमेज-टू-इमेज में एक इमेज प्रदान करना और एक टेक्स्ट प्रॉम्प्ट शामिल होता है जो वांछित परिवर्तनों का वर्णन करता है। मुख्य बात यह है कि मॉडल को निर्देश देना कि इमेज को एक नई शैली में कैसे "पुनर्व्याख्या" करें।

### चरण-दर-चरण API उपयोग

इस प्रक्रिया में आमतौर पर कुछ प्रमुख चरण शामिल होते हैं:

1.  **अपनी इमेज तैयार करें:** जिस इमेज को आप ट्रांसफॉर्म करना चाहते हैं, उसे एक सपोर्टेड फॉर्मेट (जैसे, PNG, JPEG) में होना चाहिए और आकार संबंधी आवश्यकताओं को पूरा करना चाहिए (अक्सर स्क्वायर एस्पेक्ट रेशियो सबसे अच्छा होता है)। आपको इस इमेज को API कॉल को प्रदान करना होगा।

2.  **एक शक्तिशाली प्रॉम्प्ट तैयार करें:** यह सबसे महत्वपूर्ण हिस्सा है। आप केवल "इसे Ghibli स्टाइल बनाओ" नहीं कह रहे हैं। आपको Ghibli स्टाइल के उन *तत्वों* का वर्णन करने की आवश्यकता है जिन्हें आप चाहते हैं कि मॉडल लागू करे। एक अच्छा प्रॉम्प्ट AI के लिए एक गाइड का काम करेगा, जो उसे यह निर्देशित करेगा कि इमेज को कैसे पुनः रेंडर करना है।

      * **खराब प्रॉम्प्ट:** "Ghibli स्टाइल"
      * **बेहतर प्रॉम्प्ट:** "स्टूडियो Ghibli की शैली में एक जादुई जंगल का दृश्य। नरम वॉटरकलर टेक्स्चर, गोल्डन आवर लाइटिंग के साथ एक जीवंत लेकिन कोमल कलर पैलेट का उपयोग करें, और एक विंपिसिकल, स्वप्निल वातावरण जोड़ें।"
      * **और भी बेहतर प्रॉम्प्ट:** "इस पोर्ट्रेट को एक स्टूडियो Ghibli कैरेक्टर में बदलें, उनके आवश्यक फीचर्स को बनाए रखते हुए लेकिन विशिष्ट Ghibli एस्थेटिक्स के साथ स्टाइल करें: थोड़ा सरलीकृत चेहरे के विवरण, अभिव्यंजक आंखें, और एक कोमल कलर पैलेट। हैंड-पेंटेड टेक्स्चर और एक नॉस्टैल्जिक फील का उपयोग करें।"

3.  **API कॉल करें:** आप इमेज एडिट्स के लिए OpenAI API का उपयोग करेंगे। इसके लिए एंडपॉइंट आमतौर पर इमेज जनरेशन API का हिस्सा होता है, लेकिन इमेज इनपुट के लिए विशिष्ट पैरामीटर्स के साथ। आप अपनी इमेज (अक्सर Base64 एन्कोडेड स्ट्रिंग के रूप में या फ़ाइल ID के रूप में यदि आपने इसे OpenAI के सर्वर पर अपलोड किया है) और अपना विस्तृत प्रॉम्प्ट पास करेंगे।

      * **एंडपॉइंट:** उपयोग करने के लिए विशिष्ट एंडपॉइंट DALL-E 2 के लिए `/v1/images/edits` हो सकता है, लेकिन GPT Image जैसे नए मॉडल्स के लिए, यह एक एकल, अधिक शक्तिशाली `/v1/chat/completions` एंडपॉइंट में एकीकृत हो सकता है जो मल्टीमॉडल इनपुट (टेक्स्ट और इमेज दोनों) को हैंडल करता है। डॉक्युमेंटेशन सही एंडपॉइंट और आपके रिक्वेस्ट को स्ट्रक्चर करने का तरीका निर्दिष्ट करेगा।

      * **पैरामीटर्स:**

          * `model`: आपके द्वारा उपयोग किए जाने वाले मॉडल को निर्दिष्ट करें, जैसे `dall-e-2` या एक नया मॉडल जैसे `gpt-image-1`।
          * `image`: आपके द्वारा तैयार किया गया इमेज डेटा।
          * `prompt`: Ghibli स्टाइल का टेक्स्ट विवरण जिसे आप लागू करना चाहते हैं।
          * `n`: जनरेट करने के लिए इमेज की संख्या (अक्सर नए मॉडल्स के लिए 1 तक सीमित)।
          * `size`: वांछित आउटपुट आकार (जैसे, "1024x1024")।

4.  **रिस्पॉन्स को हैंडल करें:** API एक JSON ऑब्जेक्ट लौटाएगा जिसमें नव निर्मित इमेज का URL होता है। आप फिर इस इमेज को डाउनलोड और सेव कर सकते हैं।

### उदाहरण कोड (कॉन्सेप्चुअल Python)

हालांकि सटीक कोड API अपडेट के साथ बदल सकता है, यहां `openai` Python लाइब्रेरी का उपयोग करके एक कॉन्सेप्चुअल उदाहरण दिया गया है:

```python
import openai
import base64
from io import BytesIO
from PIL import Image

# अपनी OpenAI API key सेट करें
# आपको इसे अपने एनवायरनमेंट वेरिएबल्स से प्राप्त करना चाहिए, हार्डकोड नहीं करना चाहिए
openai.api_key = os.getenv("OPENAI_API_KEY")

# इमेज को base64 में एनकोड करने के लिए फंक्शन
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

# उस इमेज का पाथ जिसे आप ट्रांसफॉर्म करना चाहते हैं
image_path = "your_photo.png"
base64_image = encode_image(image_path)

# आपका विस्तृत Ghibli-स्टाइल प्रॉम्प्ट
prompt_text = "इस इमेज को स्टूडियो Ghibli एनिमेशन स्टाइल में बदलें। नरम वॉटरकलर टेक्स्चर, गोल्डन आवर लाइटिंग के साथ एक जीवंत लेकिन कोमल कलर पैलेट, और एक विंपिसिकल, स्वप्निल वातावरण लागू करें। इमेज की मूल कंपोजिशन को बनाए रखें।"

try:
    response = openai.images.generate(
        model="gpt-image-1", # या "dall-e-2" वेरिएशंस एंडपॉइंट के लिए
        prompt=prompt_text,
        image_base64=base64_image, # यह पैरामीटर API वर्जन के आधार पर अलग हो सकता है
        size="1024x1024",
        n=1,
    )

    image_url = response.data[0].url
    print(f"जनरेट की गई Ghibli-स्टाइल इमेज: {image_url}")

except Exception as e:
    print(f"एक एरर आई: {e}")

```

**महत्वपूर्ण नोट्स:**

  * **API अपडेट्स:** OpenAI API लगातार विकसित हो रही है। सबसे अप-टू-डेट एंडपॉइंट, पैरामीटर्स और कोड उदाहरणों के लिए हमेशा आधिकारिक OpenAI API डॉक्युमेंटेशन देखें।
  * **मॉडल चयन:** नया `gpt-image-1` मॉडल आम तौर पर जटिल, सूक्ष्म निर्देशों का पालन करने में बेहतर है और इमेज एनालिसिस और जनरेशन दोनों के लिए इस्तेमाल किया जा सकता है, जो इमेज-टू-इमेज टास्क्स के लिए एक शक्तिशाली टूल है।
  * **प्रॉम्प्ट इंजीनियरिंग:** आपके आउटपुट की गुणवत्ता काफी हद तक आपके प्रॉम्प्ट पर निर्भर करती है। सटीक Ghibli-esque फील पाने के लिए विभिन्न वर्णनात्मक शब्दों और शैलीगत तत्वों के साथ प्रयोग करें।