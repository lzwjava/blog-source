---
audio: false
generated: true
lang: hi
layout: post
title: डीपसीक आर१ - वार्तालाप
translated: true
type: note
---

ए: अरे, मैं DeepSeek-R1 मॉडल्स और उनकी रीजनिंग क्षमताओं के बारे में बहुत कुछ सुन रहा हूं। क्या तुम मेरे लिए इसे समझा सकते हो?

बी: ज़रूर! चलिए बुनियादी बातों से शुरू करते हैं। DeepSeek-R1, DeepSeek-AI द्वारा विकसित मॉडल्स की एक श्रृंखला है जो रीइन्फोर्समेंट लर्निंग (RL) के माध्यम से रीजनिंग क्षमताओं को बढ़ाने पर केंद्रित है। इसकी दो मुख्य वर्जन हैं: DeepSeek-R1-Zero और DeepSeek-R1।

ए: DeepSeek-R1-Zero और DeepSeek-R1 में क्या अंतर है?

बी: DeepSeek-R1-Zero को बिना किसी सुपरवाइज्ड फाइन-ट्यूनिंग (SFT) के, पूरी तरह से RL के माध्यम से प्रशिक्षित किया गया है। यह मजबूत रीजनिंग क्षमताएं दिखाता है लेकिन इसमें खराब पठनीयता और भाषा मिश्रण जैसी समस्याएं हैं। वहीं DeepSeek-R1, इन मुद्दों को हल करने और प्रदर्शन को और बढ़ाने के लिए RL से पहले मल्टी-स्टेज ट्रेनिंग और कोल्ड-स्टार्ट डेटा को शामिल करता है।

ए: यह दिलचस्प है। इन मॉडल्स में रीइन्फोर्समेंट लर्निंग प्रक्रिया कैसे काम करती है?

बी: RL प्रक्रिया में मॉडल के सीखने को मार्गदर्शन देने के लिए एक रिवार्ड सिस्टम का उपयोग शामिल है। DeepSeek-R1-Zero के लिए, वे एक रूल-बेस्ड रिवार्ड सिस्टम का उपयोग करते हैं जो सटीकता और फॉर्मेट पर केंद्रित होता है। मॉडल एक रीजनिंग प्रक्रिया उत्पन्न करना सीखता है जिसके बाद अंतिम उत्तर आता है, और समय के साथ सुधार करता है।

ए: और DeepSeek-R1 में कोल्ड-स्टार्ट डेटा के बारे में क्या? यह कैसे मदद करता है?

बी: कोल्ड-स्टार्ट डेटा, RL से पहले बेस मॉडल को फाइन-ट्यून करने के लिए उच्च-गुणवत्ता वाले, लंबे चेन-ऑफ-थॉट (CoT) उदाहरणों की एक छोटी मात्रा प्रदान करता है। यह पठनीयता में सुधार करने और मॉडल को मानवीय प्राथमिकताओं के साथ संरेखित करने में मदद करता है, जिससे रीजनिंग प्रक्रियाएं अधिक सुसंगत और उपयोगकर्ता-अनुकूल बनती हैं।

ए: वे कैसे सुनिश्चित करते हैं कि मॉडल की प्रतिक्रियाएं सटीक और अच्छी तरह से फॉर्मेटेड हों?

बी: वे सटीकता रिवार्ड्स और फॉर्मेट रिवार्ड्स के संयोजन का उपयोग करते हैं। सटीकता रिवार्ड्स यह सुनिश्चित करते हैं कि प्रतिक्रियाएं सही हैं, जबकि फॉर्मेट रिवार्ड्स मॉडल को विशिष्ट टैग्स के बीच अपनी सोच प्रक्रिया को संरचित करने के लिए प्रेरित करते हैं। यह स्थिरता और पठनीयता बनाए रखने में मदद करता है।

ए: उन्होंने इन मॉडल्स का मूल्यांकन करने के लिए किस तरह के बेंचमार्क्स का उपयोग किया है?

बी: उन्होंने मॉडल्स का मूल्यांकन विभिन्न बेंचमार्क्स पर किया है, जिनमें AIME 2024, MATH-500, GPQA Diamond, Codeforces, और भी बहुत कुछ शामिल हैं। ये बेंचमार्क गणित, कोडिंग और सामान्य रीजनिंग कार्यों को कवर करते हैं, जो मॉडल्स की क्षमताओं का व्यापक मूल्यांकन प्रदान करते हैं।

ए: DeepSeek-R1, OpenAI के o1 सीरीज जैसे अन्य मॉडल्स की तुलना में कैसा प्रदर्शन करता है?

बी: DeepSeek-R1, रीजनिंग कार्यों पर OpenAI-o1-1217 के बराबर प्रदर्शन प्राप्त करता है। उदाहरण के लिए, यह AIME 2024 पर 79.8% Pass@1 और MATH-500 पर 97.3% स्कोर करता है, जो कुछ मामलों में OpenAI के मॉडल्स से मेल खाता है या उनसे आगे निकल जाता है।

ए: यह प्रभावशाली है। डिस्टिलेशन प्रक्रिया के बारे में क्या? यह कैसे काम करती है?

बी: डिस्टिलेशन में DeepSeek-R1 जैसे बड़े मॉडल्स की रीजनिंग क्षमताओं को छोटे, अधिक कुशल मॉडल्स में स्थानांतरित करना शामिल है। वे DeepSeek-R1 द्वारा उत्पन्न डेटा का उपयोग करके Qwen और Llama जैसे ओपन-सोर्स मॉडल्स को फाइन-ट्यून करते हैं, जिसके परिणामस्वरूप छोटे मॉडल बनते हैं जो असाधारण रूप से अच्छा प्रदर्शन करते हैं।

ए: छोटे मॉडल्स पर सीधे RL की तुलना में डिस्टिलेशन के क्या लाभ हैं?

बी: डिस्टिलेशन अधिक आर्थिक और प्रभावी है। बड़े पैमाने पर RL के माध्यम से सीधे प्रशिक्षित छोटे मॉडल, बड़े मॉडल्स से डिस्टिल किए गए मॉडल्स जैसा प्रदर्शन हासिल नहीं कर सकते हैं। डिस्टिलेशन बड़े मॉडल्स द्वारा खोजे गए उन्नत रीजनिंग पैटर्न का लाभ उठाता है, जिससे छोटे मॉडल्स में बेहतर प्रदर्शन होता है।

ए: क्या डिस्टिलेशन दृष्टिकोण के साथ कोई समझौता या सीमाएं हैं?

बी: एक सीमा यह है कि डिस्टिल किए गए मॉडल्स को अपनी पूरी क्षमता तक पहुंचने के लिए अभी भी आगे RL की आवश्यकता हो सकती है। हालांकि डिस्टिलेशन प्रदर्शन में काफी सुधार करता है, लेकिन इन मॉडल्स पर RL लागू करने से और भी बेहतर परिणाम मिल सकते हैं। हालाँकि, इसके लिए अतिरिक्त कम्प्यूटेशनल संसाधनों की आवश्यकता होती है।

ए: DeepSeek-R1-Zero में सेल्फ-इवोल्यूशन प्रक्रिया के बारे में क्या? यह कैसे काम करती है?

बी: DeepSeek-R1-Zero में सेल्फ-इवोल्यूशन प्रक्रिया आकर्षक है। मॉडल विस्तारित टेस्ट-टाइम कम्प्यूटेशन का लाभ उठाकर तेजी से जटिल रीजनिंग कार्यों को हल करना स्वाभाविक रूप से सीखता है। इससे रिफ्लेक्शन और वैकल्पिक समस्या-समाधान दृष्टिकोण जैसे परिष्कृत व्यवहारों का उदय होता है।

ए: क्या तुम समय के साथ मॉडल की रीजनिंग क्षमताओं के विकास का एक उदाहरण दे सकते हो?

बी: ज़रूर! उदाहरण के लिए, मॉडल की औसत प्रतिक्रिया लंबाई समय के साथ बढ़ती है, जो इंगित करता है कि यह अधिक समय सोचने और अपने समाधानों को परिष्कृत करने में बिताना सीखता है। इससे AIME 2024 जैसे बेंचमार्क पर बेहतर प्रदर्शन होता है, जहां पास@1 स्कोर 15.6% से बढ़कर 71.0% हो जाता है।

ए: और पेपर में उल्लेखित 'अहा मोमेंट' के बारे में क्या? वह क्या है?

बी: 'अहा मोमेंट' प्रशिक्षण के दौरान एक ऐसे बिंदु को संदर्भित करता है जहां मॉडल किसी समस्या के अपने प्रारंभिक दृष्टिकोण का पुनर्मूल्यांकन करना सीखता है, जिससे इसकी रीजनिंग क्षमताओं में महत्वपूर्ण सुधार होता है। यह मॉडल की उन्नत समस्या-समाधान रणनीतियों को स्वायत्त रूप से विकसित करने की क्षमता का प्रमाण है।

ए: वे मॉडल्स में भाषा मिश्रण के मुद्दे को कैसे संभालते हैं?

बी: भाषा मिश्रण को संबोधित करने के लिए, वे RL प्रशिक्षण के दौरान एक भाषा स्थिरता रिवार्ड पेश करते हैं। यह रिवार्ड मॉडल को मानवीय प्राथमिकताओं के साथ संरेखित करता है, जिससे प्रतिक्रियाएं अधिक पठनीय और सुसंगत बनती हैं। हालांकि यह प्रदर्शन को थोड़ा कम कर देता है, लेकिन यह समग्र उपयोगकर्ता अनुभव में सुधार करता है।

ए: पेपर में उन्होंने कुछ असफल प्रयासों का उल्लेख किया है? वे क्या हैं?

बी: उन्होंने प्रोसेस रिवार्ड मॉडल (PRM) और मोंटे कार्लो ट्री सर्च (MCTS) के साथ प्रयोग किए, लेकिन दोनों दृष्टिकोणों को चुनौतियों का सामना करना पड़ा। PRM रिवार्ड हैकिंग और स्केलेबिलिटी के मुद्दों से ग्रस्त था, जबकि MCTS टोकन जनरेशन में तेजी से बढ़ते सर्च स्पेस से जूझ रहा था।

ए: DeepSeek-R1 के लिए भविष्य की दिशाएं क्या हैं?

बी: उनकी योजना सामान्य क्षमताओं में सुधार करने, भाषा मिश्रण को संबोधित करने, प्रॉम्प्टिंग इंजीनियरिंग को बढ़ाने और सॉफ्टवेयर इंजीनियरिंग कार्यों पर प्रदर्शन में सुधार करने की है। वे डिस्टिलेशन की क्षमता को और खोजने और विभिन्न कार्यों के लिए लंबे CoT के उपयोग की जांच करने का भी लक्ष्य रखते हैं।

ए: वे सामान्य क्षमताओं में सुधार कैसे करने की योजना बना रहे हैं?

बी: वे फंक्शन कॉलिंग, मल्टी-टर्न कन्वर्सेशन, कॉम्प्लेक्स रोल-प्लेइंग और json आउटपुट जैसे कार्यों को बढ़ाने के लिए लंबे CoT का लाभ उठाने का लक्ष्य रखते हैं। यह मॉडल को अधिक बहुमुखी और कार्यों की एक विस्तृत श्रृंखला को संभालने में सक्षम बनाने में मदद करेगा।

ए: और भाषा मिश्रण के मुद्दे के बारे में क्या? वे इसे कैसे संबोधित करने की योजना बना रहे हैं?

बी: वे मॉडल को कई भाषाओं के लिए ऑप्टिमाइज़ करने की योजना बना रहे हैं, यह सुनिश्चित करते हुए कि जब यह अन्य भाषाओं में क्वेरीज़ को संभालता है तो यह रीजनिंग और प्रतिक्रियाओं के लिए डिफॉल्ट रूप से अंग्रेजी का उपयोग न करे। यह मॉडल को वैश्विक दर्शकों के लिए अधिक सुलभ और उपयोगी बना देगा।

ए: वे प्रॉम्प्टिंग इंजीनियरिंग को कैसे बढ़ाने की योजना बना रहे हैं?

बी: वे उपयोगकर्ताओं को सीधे समस्या का वर्णन करने और आउटपुट फॉर्मेट को जीरो-शॉट सेटिंग का उपयोग करके निर्दिष्ट करने की सलाह देते हैं। यह दृष्टिकोण फ्यू-शॉट प्रॉम्प्टिंग की तुलना में अधिक प्रभावी साबित हुआ है, जो मॉडल के प्रदर्शन को खराब कर सकता है।

ए: सॉफ्टवेयर इंजीनियरिंग कार्यों में उन्हें किन चुनौतियों का सामना करना पड़ता है?

बी: लंबे मूल्यांकन समय RL प्रक्रिया की दक्षता को प्रभावित करते हैं, जिससे सॉफ्टवेयर इंजीनियरिंग कार्यों में बड़े पैमाने पर RL को व्यापक रूप से लागू करना चुनौतीपूर्ण हो जाता है। वे दक्षता में सुधार के लिए सॉफ्टवेयर इंजीनियरिंग डेटा पर रिजेक्ट सैंपलिंग लागू करने या एसिंक्रोनस मूल्यांकनों को शामिल करने की योजना बना रहे हैं।

ए: वे कैसे सुनिश्चित करते हैं कि मॉडल की प्रतिक्रियाएं सहायक और हानिरहित हैं?

बी: वे मॉडल की सहायकता और हानिरहितता में सुधार के उद्देश्य से एक द्वितीयक रीइन्फोर्समेंट लर्निंग स्टेज लागू करते हैं। इसमें मॉडल को मानवीय प्राथमिकताओं के साथ संरेखित करने और संभावित जोखिमों को कम करने के लिए रिवार्ड सिग्नल्स और विविध प्रॉम्प्ट डिस्ट्रीब्यूशन के संयोजन का उपयोग शामिल है।

ए: LLM के लिए रीइन्फोर्समेंट लर्निंग में कुछ उभरते रुझान क्या हैं?

बी: कुछ उभरते रुझानों में अधिक उन्नत रिवार्ड मॉडल्स का उपयोग, नए RL एल्गोरिदम की खोज और डिस्टिलेशन जैसी अन्य प्रशिक्षण तकनीकों के साथ RL को एकीकृत करना शामिल है। बड़े मॉडल्स के लिए RL को अधिक कुशल और स्केलेबल बनाने में भी बढ़ती रुचि है।

ए: वे डिस्टिल किए गए मॉडल्स के प्रदर्शन की तुलना अन्य तुलनीय मॉडल्स से कैसे करते हैं?

बी: वे डिस्टिल किए गए मॉडल्स की तुलना GPT-4o-0513, Claude-3.5-Sonnet-1022, और QwQ-32B-Preview जैसे अन्य मॉडल्स से विभिन्न बेंचमार्क्स पर करते हैं। डिस्टिल किए गए मॉडल, जैसे DeepSeek-R1-Distill-Qwen-7B, इन मॉडल्स को सभी मापदंडों पर पछाड़ देते हैं, जो डिस्टिलेशन दृष्टिकोण की प्रभावशीलता को प्रदर्शित करता है।

ए: DeepSeek-R1 पेपर से कुछ प्रमुख टेकअवे क्या हैं?

बी: प्रमुख टेकअवे में LLM में रीजनिंग क्षमताओं को बढ़ाने के लिए RL की क्षमता, इन क्षमताओं को छोटे मॉडल्स में स्थानांतरित करने में डिस्टिलेशन की प्रभावशीलता और भाषा मिश्रण और प्रॉम्प्ट संवेदनशीलता जैसे मुद्दों को संबोधित करने का महत्व शामिल है। पेपर RL को अधिक कुशल और स्केलेबल बनाने में आगे के शोध की आवश्यकता पर भी प्रकाश डालता है।