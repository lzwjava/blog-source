---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: बृहत भाषा मॉडल तर्क तकनीकें
translated: true
type: note
---

### अवलोकन
डेनी झोउ (संभावित रूप से अभीष्ट "डैनी झोउ") ने स्टैनफोर्ड के CS25: ट्रांसफॉर्मर्स यूनाइटेड कोर्स (वर्जन 5) के हिस्से के रूप में "लार्ज लैंग्वेज मॉडल रीजनिंग" शीर्षक से एक व्याख्यान दिया। इसमें, वह बड़े भाषा मॉडल (LLM) में रीजनिंग का एक व्यापक अवलोकन प्रदान करते हैं, जिसमें व्यावहारिक तकनीकों, सैद्धांतिक आधारों और चल रही चुनौतियों पर जोर दिया गया है। नीचे उनके मुख्य बिंदुओं का एक संरचित सारांश दिया गया है, जो सीधे तौर पर उनकी स्लाइड्स और साथ के नोट्स से लिया गया है।

### एलएलएम में रीजनिंग की परिभाषा
- एलएलएम में रीजनिंग मूल रूप से अंतिम आउटपुट पर सीधे पहुंचने के बजाय, इनपुट प्रॉम्प्ट और अंतिम आउटपुट के बीच **मध्यवर्ती टोकन** (या चरण) उत्पन्न करने के बारे में है। यह प्रक्रिया मॉडल को जटिल समस्याओं को तोड़ने में सक्षम बनाती है।
- इसके लिए मानवीय रीजनिंग की हूबहू नकल करने की आवश्यकता नहीं है—लक्ष्य प्रभावी समस्या-समाधान है। उदाहरण के लिए, "'artificial intelligence' के अंतिम दो अक्षर क्या हैं?" को शब्दों के अंत को चरणबद्ध तरीके से जोड़कर हल करने पर "le" मिलता है, जो दर्शाता है कि मध्यवर्ती चरण गणना में कैसे सहायता करते हैं।
- सैद्धांतिक आधार: *T* आकार के बूलियन सर्किट द्वारा हल की जा सकने वाली समस्याओं के लिए, निरंतर आकार के ट्रांसफॉर्मर उन्हें *O(T)* मध्यवर्ती टोकन उत्पन्न करके संभाल सकते हैं, जिससे बड़े पैमाने पर मॉडल स्केलिंग की आवश्यकता नहीं रह जाती।

### प्रेरणाएं
- प्री-ट्रेंड एलएलएम विशेष प्रॉम्प्टिंग या फाइन-ट्यूनिंग के बिना ही स्वाभाविक रूप से रीजनिंग करने में सक्षम होते हैं; यह मिथक कि वे ऐसा नहीं कर सकते, खारिज हो चुका है—समस्या डीकोडिंग तरीकों से उत्पन्न होती है जो तर्कसंगत आउटपुट सामने नहीं ला पाते।
- यह दृष्टिकोण "द बिटर लेसन" के साथ संरेखित है: मानव-जैसे शॉर्टकट पर निर्भर रहने के बजाय कम्प्यूटेशन (टोकन जनरेशन के माध्यम से) का लाभ उठाएं, जो नेक्स्ट-टोकन प्रेडिक्शन के माध्यम से उभरते हुए मानव-जैसे व्यवहारों को सक्षम बनाता है।
- एंड-गोल मेट्रिक्स जैसे सही उत्तर के लिए ऑप्टिमाइज़ करने पर ध्यान केंद्रित करें, महंगे मानव-एनोटेशन के बजाय मॉडल-जनरेटेड डेटा का उपयोग करें।

### मुख्य विचार
- **चेन-ऑफ-थॉट (CoT) डीकोडिंग**: कई उम्मीदवार प्रतिक्रियाएं उत्पन्न करें और अंतिम उत्तर पर सबसे अधिक आत्मविश्वास वाली प्रतिक्रिया का चयन करें। तर्कपूर्ण पथों पर अक्सर सीधे अनुमानों की तुलना में अधिक आत्मविश्वास होता है (उदाहरण के लिए, किसी परिदृश्य में सेबों की गिनती करना)।
- **गहराई के बजाय लंबाई के माध्यम से स्केलिंग**: सीरियल समस्याओं के लिए मॉडल को लंबे अनुक्रम (*O(T)* टोकन) उत्पन्न करने के लिए प्रशिक्षित करें, जिससे वे मॉडल आकार बढ़ाए बिना ही मनमाने ढंग से शक्तिशाली बन जाएं।
- **सिंगल शॉट्स पर एग्रीगेशन**: कई प्रतिक्रियाओं को उत्पन्न करना और संयोजित करना (जैसे, बहुमत वोट के माध्यम से) एकल आउटपुट से बेहतर प्रदर्शन करता है; समान समस्याओं को रिट्रीव करना + रीजनिंग केवल रीजनिंग से बेहतर होता है।
- उदाहरण: जेमिनी 2.0 का "थिंकिंग मोड" ऑपरेशन्स को प्राथमिकता देकर (जैसे, 45 × 45 = 2025) पहेलियों को हल करता है जैसे 1-10 की संख्याओं से 2025 बनाना।

### प्रमुख तकनीकें
- **प्रॉम्प्टिंग**: मध्यवर्ती चरणों को उजागर करने के लिए फ्यू-शॉट उदाहरणों या "Let's think step by step" जैसे वाक्यांशों का उपयोग करें (जैसे, गणित की शब्द समस्याओं के लिए)। ज़ीरो-शॉट काम करता है लेकिन कम विश्वसनीय है।
- **सुपरवाइज्ड फाइन-ट्यूनिंग (SFT)**: तर्कसंगत पथों की संभावना को बढ़ाने के लिए मानव-एनोटेटेड चरण-दर-चरण समाधानों पर प्रशिक्षित करें।
- **स्व-सुधार**: मॉडल आउटपुट से सही तर्कसंगत समाधानों को फ़िल्टर करके अपना स्वयं का प्रशिक्षण डेटा उत्पन्न करें।
- **आरएल फाइन-ट्यूनिंग (ReFT)**: एक वेरिफायर का उपयोग करके सही पूर्ण प्रतिक्रियाओं (रीजनिंग + उत्तर) को पुनरावृत्त रूप से पुरस्कृत करें और गलत प्रतिक्रियाओं को दंडित करें। यह सत्यापन योग्य कार्यों के लिए सबसे अच्छा सामान्यीकरण करता है; जोनाथन लाई जैसे टीम सदस्यों का श्रेय।
- **स्व-संगति**: कई पथ सैंपल करें, फिर एग्रीगेट करें (जैसे, सबसे अधिक बार आने वाला उत्तर)। ओपन-एंडेड कार्यों के लिए यूनिवर्सल वेरिएंट मॉडल को स्व-चयन करने देता है।
- **रिट्रीवल + रीजनिंग**: बूटस्ट्रैप करने के लिए संबंधित उदाहरणों को शामिल करें (जैसे, क्षेत्रफल प्रश्नों के लिए दूरी के सूत्र याद करना)।
- **अन्य एन्हांसर**: अमूर्तता के लिए "Take a Step Back"; प्रोबेबिलिस्टिक डीकोडिंग पूर्वाग्रहों को ठीक करने के लिए मार्जिनलाइजेशन।

### सीमाएँ
- **प्रॉम्प्टिंग**: सरल लेकिन नाजुक—इसे कार्य-विशिष्ट उदाहरणों की आवश्यकता होती है; सामान्य प्रॉम्प्ट कम प्रदर्शन करते हैं।
- **SFT**: आउट-ऑफ-डिस्ट्रीब्यूशन समस्याओं पर अच्छा सामान्यीकरण नहीं करता है (जैसे, प्रशिक्षण के बावजूद नए "strawberry" अक्षर-गिनती कार्य में विफल)।
- **RL**: विश्वसनीय वेरिफायर पर निर्भर करता है, जो सभी कार्यों के लिए उपलब्ध नहीं हैं (जैसे, रचनात्मक लेखन)।
- **सामान्य चुनौतियाँ**: एलएलएम प्रोबेबिलिस्टिक प्रेडिक्टर हैं, इसलिए ग्रीडी डीकोडिंग सहज-लेकिन-गलत उत्तरों को प्राथमिकता देती है। एग्रीगेशन मदद करता है लेकिन गैर-सत्यापन योग्य डोमेन को हल नहीं करता।
- डीकोडिंग मिसअलाइनमेंट: बिना हस्तक्षेप के, यहां तक कि मजबूत मॉडल भी तर्कसंगत आउटपुट को सर्वोच्च रैंक पर नहीं रख सकते हैं।

### भविष्य की दिशाएं
- बेंचमार्क्स से आगे बढ़कर वास्तविक दुनिया के ऐप्स, विशेष रूप से गैर-सत्यापन योग्य कार्यों (जैसे, बिना परफेक्ट मेट्रिक्स के ट्रांसलेशन ऑप्टिमाइजेशन) पर ध्यान केंद्रित करें।
- बड़े लाभ के लिए एग्रीगेशन और रिट्रीवल को स्केल करें।
- प्रोबेबिलिस्टिक आउटपुट को सही उत्तर के साथ बेहतर संरेखित करने के लिए डीकोडिंग (जैसे, मार्जिनलाइजेशन के माध्यम से) में सुधार करें।
- ऐसी प्रणालियों का निर्माण करें जो सत्रों में सफल रीजनिंग पथों को "याद" रख सकें।

यह व्याख्यान RL फाइन-ट्यूनिंग को वर्तमान की शक्तिशाली तकनीक के रूप में उजागर करता है, जिसमें रीजनिंग को एक स्केलेबल जनरेशन समस्या के रूप में देखने की ओर रुझान है।

### संदर्भ
- [LLM Reasoning Slides (PDF)](https://dennyzhou.github.io/LLM-Reasoning-Stanford-CS-25.pdf)
- [Denny Zhou's X Post on Key Points](https://x.com/denny_zhou/status/1948499173986201915)
- [Lecture Video on YouTube](https://www.youtube.com/watch?v=ebnX5Ur1hBk)
- [CS25 Course Page](https://web.stanford.edu/class/cs25/)