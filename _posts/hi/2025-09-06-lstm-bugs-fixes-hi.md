---
audio: false
date: 2025-09-06
generated: true
image: false
lang: hi
layout: post
title: एलएसटीएम कार्यान्वयन में त्रुटियाँ और उनके समाधान
translated: true
type: note
---

ठीक है—यहाँ एक स्पष्ट, एंड-टू-एंड वॉकथ्रू है कि यह LSTM-फ्रॉम-स्क्रैच स्क्रिप्ट क्या कर रही है, साथ ही वे सूक्ष्म बग्स जो ट्रेनिंग को तोड़ देंगे और उन्हें कैसे ठीक करें। मैं इसे रैखिक और स्कैन करने में आसान रखूंगा (कोई चौड़ी टेबल नहीं)।

# कोड क्या करने की कोशिश कर रहा है

आप NumPy में एक मिनिमल कैरेक्टर/वर्ड-लेवल LSTM लैंग्वेज मॉडल इम्प्लीमेंट कर रहे हैं:

1. **सेटअप और साइज**

* `hidden_size`, `vocab_size`, डेटासेट (`training_set`, `validation_set`, `test_set`), टोकन↔इंडेक्स मैप, और `sigmoid`, `tanh`, `softmax`, `one_hot_encode_sequence` जैसे फंक्शन `data.py` / `utils.py` से आने की उम्मीद है।
* प्रत्येक टाइम स्टेप का इनपुट एक वन-हॉट वेक्टर `x ∈ R^{vocab_size×1}` है।
* आप पिछले hidden state और करंट इनपुट को कॉन्केटेनेट करते हैं:
  `z = [h_{t-1}; x_t] ∈ R^{(hidden_size+vocab_size)×1}`।
  इसीलिए `W_f, W_i, W_g, W_o ∈ R^{hidden_size×(hidden_size+vocab_size)}`।

2. **पैरामीटर इनिशियलाइज़ेशन**

* `init_lstm(...)` चार गेट्स (फॉरगेट f, इनपुट i, कैंडिडेट g, आउटपुट o) के लिए वेट्स आवंटित करता है, साथ ही आउटपुट प्रोजेक्शन `W_v` वोकैबुलरी के लिए।
* `init_orthogonal` प्रत्येक वेट मैट्रिक्स को ऑर्थोनॉर्मल बनाता है (QR के माध्यम से)। यह RNNs/LSTMs के लिए एक अच्छा विकल्प है।

3. **फॉरवर्ड पास (प्रति सीक्वेंस)**
   प्रत्येक टाइम स्टेप के लिए:

* `z = [h_prev; x]` बनाएं।
* गेट्स की गणना करें:

  * `f_t = σ(W_f z + b_f)`
  * `i_t = σ(W_i z + b_i)`
  * `g_t = tanh(W_g z + b_g)`
  * `C_t = f_t ⊙ C_{t-1} + i_t ⊙ g_t`
  * `o_t = σ(W_o z + b_o)`
  * `h_t = o_t ⊙ tanh(C_t)`
* वोकैब में प्रोजेक्ट करें और softmax लगाएं:

  * `v_t = W_v h_t + b_v`
  * `ŷ_t = softmax(v_t)`
* कोड बैकप्रॉप के लिए बहुत सारे इंटरमीडिएट्स (`z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, output_s`) स्टोर करता है।

4. **लॉस**

* वन-हॉट टार्गेट के साथ प्रत्येक स्टेप पर क्रॉस-एन्ट्रॉपी:
  `L_t = − log ŷ_t[target]`
  (कोड एलिमेंटवाइज `-mean(log(ŷ)*one_hot)` का उपयोग करता है, जो एक कॉन्स्टेंट स्केलिंग तक `-log(ŷ[target])` के बराबर है।)

5. **बैकवर्ड पास (LSTM के माध्यम से BPTT)**

* क्लासिक LSTM ग्रेडिएंट्स, `t = T−1 → 0` से एकत्रित।
* ग्लोबल ग्रेडिएंट नॉर्म को क्लिप करें, फिर SGD अपडेट।

6. **ट्रेनिंग लूप**

* प्रत्येक एपोक के लिए: वैलिडेशन सेट पर मूल्यांकन करें (सिर्फ लॉस), फिर ट्रेनिंग सेट पर ट्रेन करें (लॉस + ग्रेड्स + अपडेट)। अंत में, ट्रेनिंग/वैलिडेशन लॉस को प्लॉट करें।

---

# गंभीर मुद्दे (ये सीखने को चुपचाप तोड़ देंगे)

## 1) बैकप्रॉप में `h` और `C` के लिए ऑफ-बाय-वन इंडेक्सिंग

`forward` में, आप *इनिशियल* स्टेट्स को पहले पुश करते हैं:

* `h_s[0] = h_init`, फिर स्टेप 0 के बाद आप `h_0` जोड़ते हैं → इसलिए `h_s` की लंबाई `T+1` है जिसमें `h_s[t+1] = h_t` है।
* `C_s` के लिए भी यही: `C_s[0] = C_init`, फिर `C_s[t+1] = C_t`।

लेकिन `backward(...)` में आप `h[t]` और `C[t]` का उपयोग ऐसे करते हैं जैसे वे `h_t` और `C_t` हों। वे नहीं हैं; वे एक से शिफ्ट हैं।

**फिक्स (सरल नियम):**

* जहाँ आप `h_t` चाहते हैं वहाँ `h[t+1]` का उपयोग करें।
* जहाँ आप `C_t` चाहते हैं वहाँ `C[t+1]` का उयोग करें।
* "पिछली सेल स्टेट" के लिए आप `C_prev = C[t]` चाहते हैं (`C[t-1]` नहीं)।

तो `for t in reversed(range(T)):` लूप के अंदर:

* करंट स्टेट: `h_t = h[t+1]`, `C_t = C[t+1]`
* पिछली स्टेट: `C_{t-1} = C[t]`

आपकी मौजूदा लाइन:

```python
C_prev = C[t - 1]
```

`t==0` के लिए गलत है (अंतिम एलिमेंट पर रैप हो जाता है) और सामान्य रूप से ऑफ-बाय-वन है। यह होनी चाहिए:

```python
C_prev = C[t]       # पिछली सेल स्टेट
# और "करंट" के रूप में C_t = C[t+1] का उपयोग करें
```

और जहाँ भी आप करंट hidden state का इरादा करते हुए `h[t]` का उपयोग करते हैं, उसे `h[t+1]` में बदलें।

## 2) कई गेट्स के लिए गलत डेरिवेटिव्स

आप कभी-कभी इसके डेरिवेटिव के बजाय नॉनलीनियरिटी को फिर से लगा देते हैं, या डेरिवेटिव फ्लैग भूल जाते हैं।

* **सेल स्टेट पाथ:**
  सही:
  `dC_t += dh_t ⊙ o_t ⊙ (1 - tanh(C_t)^2)`
  आपका कोड:

  ```python
  dC += dh * o[t] * tanh(tanh(C[t]), derivative=True)
  ```

  यह `tanh` दो बार लगा है। इसे इससे बदलें:

  ```python
  dC += dh * o_t * (1 - np.tanh(C_t)**2)
  ```

* **फॉरगेट गेट:**
  सही: `df = dC_t ⊙ C_{t-1} ⊙ f_t ⊙ (1 - f_t)`
  आपका कोड:

  ```python
  df = dC * C_prev
  df = sigmoid(f[t]) * df
  ```

  डेरिवेटिव टर्म गायब है। होना चाहिए:

  ```python
  df = dC * C_prev
  df *= f[t] * (1 - f[t])      # अगर f[t] σ प्री-एक्टिवेशन आउटपुट स्टोर करता है
  ```

* **इनपुट गेट:**
  आपने किया:

  ```python
  di = dC * g[t]
  di = sigmoid(i[t], True) * di
  ```

  यह ठीक है **अगर** `sigmoid(x, True)` σ’(x) लौटाता है *न कि* σ(x)। अधिक मजबूत (यह मेल खाता है कि आपने `i[t]` को गेट आउटपुट के रूप में स्टोर किया है):

  ```python
  di = dC * g[t]
  di *= i[t] * (1 - i[t])
  ```

* **कैंडिडेट गेट:**
  आपने किया:

  ```python
  dg = dC * i[t]
  dg = tanh(g[t], derivative=True) * dg
  ```

  अगर `g[t]` `tanh(preact)` स्टोर करता है, तो `tanh’(preact) = 1 - g[t]^2`। तो:

  ```python
  dg = dC * i[t]
  dg *= (1 - g[t]**2)
  ```

* **आउटपुट गेट:**
  आपने किया:

  ```python
  do = dh * tanh(C[t])
  do = sigmoid(o[t], derivative=True) * do
  ```

  इंडेक्सिंग फिक्स (`C_t = C[t+1]`, `o_t = o[t]`) और ऊपर के अनुसार डेरिवेटिव के साथ:

  ```python
  do = dh * np.tanh(C_t)
  do *= o[t] * (1 - o[t])
  ```

* **अगली सेल ग्रेडिएंट:**
  सही:

  ```python
  dC_next = dC * f[t]
  ```

## 3) `dh_next` और `dC_next` का साइज करने के लिए `h[0]` / `C[0]` का उपयोग करना

आप **करंट** h/C (सीक्वेंस के अंत) के शेप चाहते हैं, इनिशियल जीरोस के नहीं। उपयोग करें:

```python
dh_next = np.zeros_like(h[-1])
dC_next = np.zeros_like(C[-1])
```

## 4) क्रॉस-एन्ट्रॉपी अंकगणितीय स्थिरता

`loss += -np.mean(np.log(outputs[t]) * targets[t])` ठीक रहेगा अगर `softmax` आंतरिक रूप से क्लैंप/एप्सिलन करता है। यदि नहीं, तो एक छोटा एप्सिलन जोड़ें:

```python
eps = 1e-12
loss += -np.sum(targets[t] * np.log(outputs[t] + eps))
```

## 5) ट्रेनिंग स्थिरता ट्वीक्स

* **फॉरगेट-गेट बायस:** `b_f` को एक सकारात्मक मान (जैसे, `1.0`) पर इनिशियलाइज़ करें ताकि ट्रेनिंग की शुरुआत में LSTM मेमोरी रखने की प्रवृत्ति रखे:

  ```python
  b_f = np.ones((hidden_size, 1)) * 1.0
  ```
* **लर्निंग रेट:** `lr=1e-1` रॉ SGD के साथ आक्रामक है। `1e-2` से शुरू करें या Adam का उपयोग करें।
* **ग्रेडिएंट क्लिपिंग:** अच्छा है। जरूरत पड़ने पर प्रति-मैट्रिक्स नॉर्म्स पर विचार करें।

---

# बैकप्रॉप लूप के लिए एक सही किया गया कोर

यह स्केच इंडेक्सिंग और डेरिवेटिव फिक्स दिखाता है। यह मानता है कि `f[t], i[t], g[t], o[t]` उनकी नॉनलीनियरिटीज के *आउटपुट* हैं (जैसा कि आपके फॉरवर्ड में है):

```python
T = len(outputs)
dh_next = np.zeros_like(h[-1])
dC_next = np.zeros_like(C[-1])

for t in reversed(range(T)):
    # सही इंडेक्सिंग के साथ छोटे नाम
    y_hat = outputs[t]                 # softmax आउटपुट
    y_true = targets[t]
    h_t   = h[t+1]
    C_t   = C[t+1]
    C_tm1 = C[t]

    # आउटपुट लेयर
    dv = y_hat.copy()
    dv[np.argmax(y_true)] -= 1
    W_v_d += dv @ h_t.T
    b_v_d += dv

    # h में बैकप्रॉप
    dh = W_v.T @ dv
    dh += dh_next

    # आउटपुट गेट
    do = dh * np.tanh(C_t)
    do *= o[t] * (1 - o[t])
    W_o_d += do @ z[t].T
    b_o_d += do

    # सेल स्टेट
    dC = dC_next + dh * o[t] * (1 - np.tanh(C_t)**2)

    # कैंडिडेट (g), इनपुट (i), फॉरगेट (f)
    dg = dC * i[t]
    dg *= (1 - g[t]**2)               # चूंकि g[t] = tanh(preact)

    di = dC * g[t]
    di *= i[t] * (1 - i[t])

    df = dC * C_tm1
    df *= f[t] * (1 - f[t])

    # गेट वेट/बायस ग्रेड्स जमा करें
    W_g_d += dg @ z[t].T;  b_g_d += dg
    W_i_d += di @ z[t].T;  b_i_d += di
    W_f_d += df @ z[t].T;  b_f_d += df

    # z तक प्रचारित करें और h_{t-1} भाग में विभाजित करें
    dz = (W_f.T @ df) + (W_i.T @ di) + (W_g.T @ dg) + (W_o.T @ do)
    dh_next = dz[:hidden_size, :]
    dC_next = dC * f[t]
```

---

# छोटे लेकिन महत्वपूर्ण विवरण और सिफारिशें

* **ऑर्थोगोनल इनिट:** रिकरंट वेट्स के लिए अच्छा है। इनपुट भागों के लिए, आप `1/√fan_in` से भी स्केल कर सकते हैं। यहाँ महत्वपूर्ण नहीं है।
* **बैचिंग:** कोड 1 सीक्वेंस पर एक बार में ट्रेन करता है (कोई बैचिंग नहीं)। स्पष्टता के लिए ठीक है, लेकिन धीमा/शोर वाला। मिनी-बैचिंग के लिए सावधानीपूर्वक शेप परिवर्तनों की आवश्यकता होगी।
* **टीचर फोर्सिंग:** आप टार्गेट के रूप में ग्राउंड-ट्रुथ नेक्स्ट टोकन का उपयोग कर रहे हैं; सब ठीक है। यदि आप कभी भी फ्री-रनिंग जनरेशन करते हैं, तो `softmax` आउटपुट से सैंपल लें और मॉडल में वापस फीड करें।
* **लॉस रिपोर्टिंग:** आप सीक्वेंस के पार प्रति-टाइम-स्टेप लॉस को जोड़ते हैं और फिर डेटासेट लंबाई से औसत करते हैं; यह स्केल मिलाता है अगर सीक्वेंस लंबाई में भिन्न होते हैं। कुल टोकन द्वारा सामान्यीकरण पर विचार करें।
* **प्लॉटिंग:** स्थानीय रूप से काम करता है। हेडलेस वातावरण में, बैकएंड्स स्विच करना या savefig याद रखें।

---

# TL;DR ठीक अब आपको जो फिक्स करने चाहिए

1. **इंडेक्सिंग**: बैकप्रॉप में हर `h[t]` को `h[t+1]` से, हर `C[t]` को `C[t+1]` से बदलें, और `C_prev = C[t]` सेट करें।
2. **डेरिवेटिव्स**:

   * सेल स्टेट पाथ के लिए `(1 - tanh(C_t)**2)` का उपयोग करें।
   * σ-गेट्स के लिए `gate * (1 - gate)` का उपयोग करें क्योंकि आपने गेट आउटपुट स्टोर किए हैं।
   * कैंडिडेट गेट के लिए `(1 - g[t]**2)` का उपयोग करें क्योंकि `g[t]=tanh(preact)`।
3. **इनिट**: `b_f` को \~`1.0` पर सेट करें।
4. **LR**: `1e-2` तक कम करें (या Adam पर स्विच करें)।
5. **स्थिरता**: `log` में `eps` जोड़ें।

वे परिवर्तन करें और आपका लॉस एक बहुत अधिक समझदार तरीके से घटना शुरू कर देना चाहिए। यदि आप चाहें, तो अपना अपडेटेड `backward(...)` पेस्ट करें और मैं उसकी सैनिटी-चेक करूंगा।