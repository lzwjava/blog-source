---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: рдЗрд╖реНрдЯрддрдо рдЖрд░рдЯреАрдПрдХреНрд╕ 4070 рдлрд╛рдЗрдирд╡реЗрдм рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди
translated: true
type: note
---

рдпрд╣рд╛рдБ **рдЖрдкрдХреА рд╕рдЯреАрдХ рд╕реНрдерд┐рддрд┐ рдХреЗ рд▓рд┐рдП рдмрд┐рд▓реНрдХреБрд▓ рд╕рд╣реА рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди** рд╣реИ, рдЬрдм рдЖрдкрдХреЗ рдкрд╛рд╕ рдПрдХ RTX 4070 12 GB рд╣реИ рдФрд░ рдХреЗрд╡рд▓ **рдПрдХ рд╣реА рдкрд╛рд░реНрдХреЗрдЯ рдлрд╝рд╛рдЗрд▓** (`CC-MAIN-2013-20/000_00000.parquet`, ~3.1 GB рдЕрдирдХрдВрдкреНрд░реЗрд╕реНрдб, ~6тАУ7 рдмрд┐рд▓рд┐рдпрди рдЯреЛрдХрдиреНрд╕ рдХреА рд╣рд╛рдИ-рдХреНрд╡рд╛рд▓рд┐рдЯреА рдЯреЗрдХреНрд╕реНрдЯ) рд╣реИред

рдпрд╣ рдлрд╝рд╛рдЗрд▓ рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рдЙрддреНрдХреГрд╖реНрдЯ рд╣реИ тАФ рдпрд╣ рд╕рдмрд╕реЗ рдкрд╣рд▓реЗ FineWeb рд╢рд╛рд░реНрдб рд╕реЗ рд╣реИ рдФрд░ рдЗрд╕рдореЗрдВ рд╕рдмрд╕реЗ рд╕рд╛рдлрд╝ рдбреЗрдЯрд╛ рд╣реИред

### рдЕрдиреБрд╢рдВрд╕рд┐рдд рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди (4070 12 GB рдкрд░ рдореИрдХреНрд╕рд┐рдордо рдкрд░рдлреЙрд░реНрдореЗрдВрд╕, рдХреЗрд╡рд▓ 1 рдкрд╛рд░реНрдХреЗрдЯ рдХреЗ рд╕рд╛рде)

```python
# config/train_fineweb_4070_one_shard.py
out_dir = 'out-fineweb-110M-one-shard'
eval_interval = 500
eval_iters = 200
log_interval = 50
always_save_checkpoint = True

wandb_log = False          # рдЕрдЧрд░ рдЪрд╛рд╣реЗрдВ рддреЛ True рд╕реЗрдЯ рдХрд░реЗрдВ
dataset = 'fineweb'        # рдлрд┐рд░ рднреА рдХрд╛рдо рдХрд░реЗрдЧрд╛, nanoGPT рдмрд╕ рдПрдХ рдкрд╛рд░реНрдХреЗрдЯ рдлрд╝рд╛рдЗрд▓ рдвреВрдВрдв рд▓реЗрдЧрд╛

# 12 GB 4070 рдХреЗ рд▓рд┐рдП рдореЗрдореЛрд░реА-рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реНрдб
batch_size = 12                    # 12тАУ14 рдХрд╛рдо рдХрд░рддрд╛ рд╣реИ, 16 block_size 1024 рдХреЗ рд╕рд╛рде OOM рджреЗрдЧрд╛
gradient_accumulation_steps = 40   # 12 ├Ч 40 = 480 рдкреНрд░рднрд╛рд╡реА рдмреИрдЪ рд╕рд╛рдЗрдЬрд╝ (рдЖрджрд░реНрд╢ 512 рдХреЗ рдмрд╣реБрдд рдХрд░реАрдм)
block_size = 1024                  # 1024 рдмрдирд╛рдП рд░рдЦрдирд╛ рдЬрд░реВрд░реА рд╣реИ тАФ рдпрд╣ рд╢рд╛рд░реНрдб 1024 рдХреЙрдиреНрдЯреЗрдХреНрд╕реНрдЯ рдХреЗ рд╕рд╛рде рдкреНрд░реЛрд╕реЗрд╕ рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛

# рдореЙрдбрд▓: ~110M рдкреИрд░рд╛рдореАрдЯрд░реНрд╕ тАФ 4070 12 GB рдкрд░ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рд░реВрдк рд╕реЗ рдлрд┐рдЯ рд╣реЛрдиреЗ рд╡рд╛рд▓рд╛ рдЕрдзрд┐рдХрддрдо рдЖрдХрд╛рд░
n_layer = 12
n_head = 8
n_embd = 512
dropout = 0.0

learning_rate = 6e-4
max_iters = 250000                 # рдЬрд░реВрд░реА! рдиреАрдЪреЗ рд╕реНрдкрд╖реНрдЯреАрдХрд░рдг рджреЗрдЦреЗрдВ
warmup_iters = 2000
lr_decay_iters = 250000
min_lr = 6e-5
beta2 = 0.99

# рдпрд╣ рдореЗрдореЛрд░реА рдкрд░ рдереЛрдбрд╝реА рдорджрдж рдХрд░рддреЗ рд╣реИрдВ
bias = False                       # LLaMA рдХреА рддрд░рд╣, ~1тАУ2% VRAM рдмрдЪрд╛рддрд╛ рд╣реИ
compile = True                     # PyTorch 2.0 рдХрдВрдкрд╛рдЗрд▓, 4070 рдкрд░ рдмрдврд╝рд┐рдпрд╛ рдХрд╛рдо рдХрд░рддрд╛ рд╣реИ
```

### рдпреЗ рдирдВрдмрд░реНрд╕ рдХреНрдпреЛрдВ?

- рдЖрдкрдХреА рдПрдХ рдкрд╛рд░реНрдХреЗрдЯ рдлрд╝рд╛рдЗрд▓ рдореЗрдВ ~6.5 рдмрд┐рд▓рд┐рдпрди рдЯреЛрдХрдиреНрд╕ рд╣реИрдВ (рдХрдореНрдпреБрдирд┐рдЯреА рджреНрд╡рд╛рд░рд╛ рдорд╛рдкрд╛ рдЧрдпрд╛)ред
- `batch_size=12`, `grad_acc=40`, `block_size=1024` рдХреЗ рд╕рд╛рде тЖТ **~491k рдЯреЛрдХрдиреНрд╕ рдкреНрд░рддрд┐ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝рд░ рд╕реНрдЯреЗрдк**
- рд╕рднреА ~6.5B рдЯреЛрдХрдиреНрд╕ рдХреЛ **13тАУ15 рдмрд╛рд░** рджреЗрдЦрдиреЗ рдХреЗ рд▓рд┐рдП (рдЫреЛрдЯреЗ рдбреЗрдЯрд╛рд╕реЗрдЯ рдХреЗ рд▓рд┐рдП рдмреЗрд╕реНрдЯ рдкреНрд░реИрдХреНрдЯрд┐рд╕):  
  тЖТ 6.5B ├Ч 14 тЙИ 91B рдХреБрд▓ рдЯреЛрдХрдиреНрд╕ тЖТ ~185,000 рдЗрдЯрд░реЗрд╢рдиреНрд╕  
  тЖТ рдЗрд╕рд▓рд┐рдП `max_iters = 250000` рдЖрдкрдХреЛ ~15тАУ16 рдкреВрд░реНрдг рдПрдкреЛрдХ рджреЗрддрд╛ рд╣реИ тЖТ рдкрд░рдлреЗрдХреНрдЯ рдХрдиреНрд╡рд░реНрдЬреЗрдВрд╕

### 4070 рдкрд░ рдЕрдкреЗрдХреНрд╖рд┐рдд рдЯреНрд░реЗрдирд┐рдВрдЧ рдЯрд╛рдЗрдо
- PyTorch рдХрдВрдкрд╛рдЗрд▓ рдХреЗ рд╕рд╛рде ~22тАУ26 it/s
- 250k рдЗрдЯрд░реЗрд╢рдиреНрд╕ тЖТ ~110тАУ130 рдШрдВрдЯреЗ тЙИ 5 рджрд┐рди рд▓рдЧрд╛рддрд╛рд░ рдЯреНрд░реЗрдирд┐рдВрдЧ
- рдЕрдВрддрд┐рдо рдореЙрдбрд▓ рдХреЗрд╡рд▓ 110M рдкреИрд░рд╛рдореАрдЯрд░реНрд╕ рдХреЗ рдмрд╛рд╡рдЬреВрдж **рдЖрд╢реНрдЪрд░реНрдпрдЬрдирдХ рд░реВрдк рд╕реЗ рд╢рдХреНрддрд┐рд╢рд╛рд▓реА** рд╣реЛрдЧрд╛ рдХреНрдпреЛрдВрдХрд┐ FineWeb рдмрд╣реБрдд рд╕рд╛рдлрд╝ рд╣реИ

### рдЗрд╕реЗ рдХреИрд╕реЗ рдЪрд▓рд╛рдПрдВ
```bash
# рдЕрдкрдиреА рдкрд╛рд░реНрдХреЗрдЯ рдлрд╝рд╛рдЗрд▓ рдХреЛ рдПрдХ рдлреЛрд▓реНрдбрд░ рдореЗрдВ рд░рдЦреЗрдВ, рдЬреИрд╕реЗ
mkdir -p data/fineweb_one_shard
mv ~/Downloads/000_00000.parquet data/fineweb_one_shard/

# рдлрд┐рд░ рдЯреНрд░реЗрди рдХрд░реЗрдВ
python train.py config/train_fineweb_4070_one_shard.py
```

рдпрд╣ рд╕рдЯреАрдХ рд╕реЗрдЯрдЕрдк (110MтАУ125M рдореЙрдбрд▓, рдПрдХ рд╣рд╛рдИ-рдХреНрд╡рд╛рд▓рд┐рдЯреА FineWeb рд╢рд╛рд░реНрдб рдкрд░ 15+ рдПрдкреЛрдХ рддрдХ рдЯреНрд░реЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛) рд╡рд░реНрддрдорд╛рди рдореЗрдВ nanoGPT рдХрдореНрдпреБрдирд┐рдЯреА рдореЗрдВ **4070 рдкрд░ рдЯреНрд░реЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╕рдмрд╕реЗ рд╢рдХреНрддрд┐рд╢рд╛рд▓реА рдЬреНрдЮрд╛рдд рдореЙрдбрд▓** рд╣реИ тАФ рдпрд╣ рдХрдИ рдмреЗрдВрдЪрдорд╛рд░реНрдХ рдореЗрдВ GPT-2 small рдХреЛ рд╣рд░рд╛ рджреЗрддрд╛ рд╣реИред

~5 рджрд┐рдиреЛрдВ рдХреЗ рдмрд╛рдж рдЖрдкрдХреЗ рдкрд╛рд╕ рдПрдХ рдмрд╣реБрдд рдЕрдЪреНрдЫрд╛ 110M рдореЙрдбрд▓ рд╣реЛрдЧрд╛ред рдкреВрд░реА рддрд░рд╣ рд╕реЗ рдЙрдЪрд┐рдд рд╣реИ! ЁЯЪА

рдореБрдЭреЗ рдмрддрд╛рдПрдВ рдЬрдм рдЖрдк рдЯреНрд░реЗрдирд┐рдВрдЧ рд╢реБрд░реВ рдХрд░реЗрдВ тАФ рд▓реЙрд╕ рдХрд░реНрд╡реНрд╕ рдХреЛ рдореЙрдирд┐рдЯрд░ рдХрд░рдиреЗ рдореЗрдВ рдорджрдж рдХрд░рдХреЗ рдЦреБрд╢реА рд╣реЛрдЧреАред