---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: 'एलेक्सनेट: 2012 का एक मील का पत्थर'
translated: true
type: note
---

### एलेक्सनेट का परिचय: 2012 की लैंडमार्क पेपर

एलेक्सनेट एक ग्राउंडब्रेकिंग डीप कन्वॉल्यूशनल न्यूरल नेटवर्क (सीएनएन) आर्किटेक्चर और उसे प्रस्तुत करने वाले सेमिनल 2012 रिसर्च पेपर दोनों को संदर्भित करता है। **ImageNet Classification with Deep Convolutional Neural Networks** शीर्षक वाला यह पेपर एलेक्स क्रिज़ेव्स्की, इल्या सुत्स्केवर, और जेफ्री ई. हिंटन—सभी यूनिवर्सिटी ऑफ टोरंटो से—द्वारा लिखा गया था और 25वीं इंटरनेशनल कॉन्फ्रेंस ऑन न्यूरल इनफॉर्मेशन प्रोसेसिंग सिस्टम्स (NeurIPS/NIPS 2012) में प्रस्तुत किया गया था। यह कंप्यूटर विजन और मशीन लर्निंग में एक महत्वपूर्ण मोड़ था, जिसने दर्शाया कि डीप न्यूरल नेटवर्क बड़े पैमाने की इमेज क्लासिफिकेशन टास्क्स पर पारंपरिक तरीकों से बेहतर प्रदर्शन कर सकते हैं। इस कार्य की प्रेरणा ImageNet जैसे बड़े डेटासेट और GPU जैसे शक्तिशाली हार्डवेयर की उपलब्धता थी, जिसने अंततः डीप सीएनएन को प्रशिक्षित करना संभव बना दिया।

पेपर का सारांश संक्षेप में इसका सार पकड़ता है: लेखकों ने ImageNet लार्ज स्केल विजुअल रिकग्निशन चैलेंज (ILSVRC-2010) डेटासेट की 1.2 मिलियन हाई-रिज़ॉल्यूशन इमेजेज पर एक बड़े, डीप सीएनएन को प्रशिक्षित किया, उन्हें 1,000 वर्गों में वर्गीकृत किया। इसने टेस्ट सेट पर टॉप-1 और टॉप-5 एरर रेट्स क्रमशः 37.5% और 17.0% हासिल किए—जो पहले के स्टेट-ऑफ-द-आर्ट रिजल्ट्स से कहीं बेहतर थे। ILSVRC-2012 प्रतियोगिता में भेजे गए एक वेरिएंट ने 15.3% की टॉप-5 एरर (बनाम दूसरे स्थान के 26.2%) के साथ जीत हासिल की। नेटवर्क में 60 मिलियन पैरामीटर्स और 650,000 न्यूरॉन्स हैं, जिसमें पांच कन्वॉल्यूशनल लेयर्स (कुछ के बाद मैक्स-पूलिंग), तीन फुली-कनेक्टेड लेयर्स और एक अंतिम 1000-वे सॉफ्टमैक्स आउटपुट शामिल है। मुख्य सक्षमकर्ताओं में तेज प्रशिक्षण के लिए नॉन-सैचुरेटिंग एक्टिवेशन्स, एक कुशल GPU-आधारित कन्वॉल्यूशन इम्प्लीमेंटेशन, और ओवरफिटिंग से निपटने के लिए ड्रॉपआउट रेगुलराइजेशन शामिल थे।

यह परिचय पेपर की पृष्ठभूमि, आर्किटेक्चर, नवाचारों, प्रशिक्षण दृष्टिकोण, परिणामों और स्थायी प्रभाव का सीधे तौर पर इसकी सामग्री से उपयोग करते हुए पता लगाता है।

### पृष्ठभूमि और प्रेरणा

2012 से पहले, कंप्यूटर विजन में ऑब्जेक्ट रिकग्निशन मुख्य रूप से हैंड-क्राफ्टेड फीचर्स (जैसे, SIFT या HOG) और SVM जैसे शैलो क्लासिफायरों पर निर्भर था। ये तरीके वास्तव-विश्व की छवियों में परिवर्तनशीलता—जैसे प्रकाश, मुद्रा, और ओक्लूजन में परिवर्तन—से जूझते थे, और अच्छे सामान्यीकरण के लिए बड़े लेबल किए गए डेटा की आवश्यकता होती थी। MNIST या CIFAR-10 (दसियों हज़ार छवियाँ) जैसे डेटासेट सरल कार्यों के लिए पर्याप्त थे, लेकिन लाखों विविध उदाहरणों के पैमाने पर सीमाएँ उजागर हुईं।

ImageNet के आगमन ने इसे बदल दिया। 2009 में लॉन्च किया गया, ImageNet ने 22,000 श्रेणियों में 15 मिलियन से अधिक लेबल की गई हाई-रिज़ॉल्यूशन छवियाँ प्रदान कीं, जिसमें ILSVRC सबसेट 1,000 वर्गों में 1.2 मिलियन प्रशिक्षण छवियों (प्लस 50,000 वैलिडेशन और 100,000 टेस्ट छवियों) पर केंद्रित था। हालाँकि, इस पैमाने से सीखने के लिए उच्च क्षमता और छवियों के अनुरूप इंडक्टिव बायस (जैसे ट्रांसलेशन इनवेरिएंस और लोकल कनेक्टिविटी) वाले मॉडल की मांग थी।

सीएनएन, जिसे पहली बार 1990 के दशक में LeCun के LeNet ने लोकप्रिय बनाया था, इस आवश्यकता को पूरा करते थे: वे पैरामीटर्स को कम करने और छवि संरचना का लाभ उठाने के लिए कन्वॉल्यूशनल कर्नेल में शेयर्ड वेट्स का उपयोग करते हैं। फिर भी, हाई-रिज़ॉल्यूशन डेटा पर डीप सीएनएन को प्रशिक्षित करना वैनिशिंग ग्रेडिएंट्स (tanh जैसे सैचुरेटिंग एक्टिवेशन्स के कारण) और हार्डवेयर बाधाओं के कारण कम्प्यूटेशनल रूप से निषेधात्मक था। लेखकों ने तर्क दिया कि बड़े डेटासेट, गहरे मॉडल और एंटी-ओवरफिटिंग तकनीकें सीएनएन की क्षमता को अनलॉक कर सकती हैं। उनके योगदानों में अब तक का सबसे बड़ा सीएनएन, एक सार्वजनिक GPU-अनुकूलित कोडबेस, और प्रदर्शन व दक्षता बढ़ाने के लिए नवीन फीचर्स शामिल थे।

### नेटवर्क आर्किटेक्चर

एलेक्सनेट का डिजाइन आठ लर्नेबल लेयर्स का एक स्टैक है: पांच कन्वॉल्यूशनल (Conv) के बाद तीन फुली-कनेक्टेड (FC), जिसके शीर्ष पर सॉफ्टमैक्स है। यह 224×224×3 RGB इनपुट छवियों (256×256 मूल से क्रॉप और रीसाइज़ की गई) को प्रोसेस करता है। आर्किटेक्चर हाइरार्किकल फीचर लर्निंग के लिए गहराई पर जोर देता है—प्रारंभिक लेयर्स एज और टेक्सचर का पता लगाती हैं, बाद वाली जटिल वस्तुओं को पकड़ती हैं—जबकि कन्वॉल्यूशन के माध्यम से पैरामीटर्स को प्रबंधनीय बनाए रखता है।

GPU मेमोरी सीमा (GTX 580 प्रति 3GB) को संभालने के लिए, नेटवर्क को दो GPU में विभाजित किया गया है: Conv2, Conv4, और Conv5 में कर्नेल केवल पिछली लेयर से समान-GPU फीचर मैप्स से जुड़ते हैं, जबकि क्रॉस-GPU कम्युनिकेशन केवल Conv3 में होता है। रिस्पॉन्स-नॉर्मलाइजेशन और मैक्स-पूलिंग लेयर्स चुनिंदा Conv लेयर्स के बाद क्रमशः एक्टिवेशन्स को सामान्य करने और डाउनसैंपल करने के लिए आती हैं।

स्पष्टता के लिए सारणीबद्ध रूप में एक लेयर-दर-लेयर ब्रेकडाउन यहाँ दिया गया है:

| लेयर | प्रकार | इनपुट साइज | कर्नेल साइज/स्ट्राइड | आउटपुट साइज | न्यूरॉन्स | पैरामीटर्स | नोट्स |
|-------|------|------------|---------------------|-------------|---------|------------|-------|
| 1 | Conv + ReLU + LRN + MaxPool | 224×224×3 | 11×11×3 / स्ट्राइड 4 | 55×55×96 | 55×55×96 | ~35M | 96 फिल्टर्स; LRN (लोकल रिस्पॉन्स नॉर्मलाइजेशन); 3×3 पूल / स्ट्राइड 2 |
| 2 | Conv + ReLU + LRN + MaxPool | 27×27×96 | 5×5×48 / स्ट्राइड 1 (समान GPU स्प्लिट) | 27×27×256 | 27×27×256 | ~307K | 256 फिल्टर्स; LRN; 3×3 पूल / स्ट्राइड 2 |
| 3 | Conv + ReLU | 13×13×256 | 3×3×256 / स्ट्राइड 1 (फुल क्रॉस-GPU) | 13×13×384 | 13×13×384 | ~1.2M | 384 फिल्टर्स |
| 4 | Conv + ReLU | 13×13×384 | 3×3×192 / स्ट्राइड 1 (समान GPU) | 13×13×384 | 13×13×384 | ~768K | 384 फिल्टर्स (आधे प्रति GPU) |
| 5 | Conv + ReLU + MaxPool | 13×13×384 | 3×3×192 / स्ट्राइड 1 (समान GPU) | 13×13×256 | 13×13×256 | ~512K | 256 फिल्टर्स; 3×3 पूल / स्ट्राइड 2 |
| 6 | FC + ReLU + Dropout | 6×6×256 (फ्लैटन: 9216) | - | 4096 | 4096 | ~38M | ड्रॉपआउट (p=0.5) |
| 7 | FC + ReLU + Dropout | 4096 | - | 4096 | 4096 | ~16.8M | ड्रॉपआउट (p=0.5) |
| 8 | FC + Softmax | 4096 | - | 1000 | 1000 | ~4.1M | अंतिम वर्गीकरण |

कुल: ~60M पैरामीटर्स, ~650K न्यूरॉन्स। इनपुट डायमेंशनैलिटी 150,528 है, जो 1,000 आउटपुट्स तक घटती है। गहराई महत्वपूर्ण साबित हुई—किसी भी Conv लेयर को हटाने से प्रदर्शन खराब हो गया, भले ही उनमें <1% पैरामीटर्स थे।

### मुख्य नवाचार

पेपर की नवीनता केवल पैमाने में नहीं, बल्कि व्यावहारिक ट्वीक्स में थी जिन्होंने प्रशिक्षण गति, ओवरफिटिंग और सामान्यीकरण को संबोधित किया:

- **ReLU एक्टिवेशन**: सैचुरेटिंग फंक्शन (tanh/sigmoid) को f(x) = max(0, x) से बदल दिया, जिसने CIFAR-10 पर अभिसरण 6x तेज किया (पेपर में चित्र 1 देखें)। यह "नॉन-सैचुरेटिंग" यूनिट ग्रेडिएंट वैनिशिंग से बचाती है, जिससे गहरे नेट्स संभव हो पाए।

- **ड्रॉपआउट रेगुलराइजेशन**: दो सबसे बड़ी FC लेयर्स पर लागू किया गया (प्रशिक्षण के दौरान p=0.5; टेस्ट पर आउटपुट को 0.5 से स्केल करें)। यह यादृच्छिक रूप से हिडन यूनिट्स को शून्य करके न्यूरॉन को-अडाप्टेशन को रोकता है, जो एन्सेम्बल एवरेजिंग की नकल करता है, जिसकी लागत प्रशिक्षण में ~2x होती है। इसके बिना, 1.2M उदाहरणों के बावजूद गंभीर ओवरफिटिंग होती थी।

- **ओवरलैपिंग मैक्स-पूलिंग**: नॉन-ओवरलैपिंग (s=z=2) के बजाय स्ट्राइड 2 के साथ 3×3 पूल (s=2, z=3) का उपयोग किया गया। इस सघन सैंपलिंग ने टॉप-1/5 एरर्स को 0.4%/0.3% कम किया और ओवरफिटिंग पर अंकुश लगाया।

- **डेटा ऑग्मेंटेशन**: प्रभावी डेटासेट को 2048x तक विस्तारित किया गया:
  - 256×256 छवियों से यादृच्छिक 224×224 क्रॉप्स + क्षैतिज फ्लिप्स (टेस्ट के लिए औसत निकालने के लिए 10 क्रॉप्स)।
  - PCA-आधारित कलर जिटरिंग: प्रिंसिपल कंपोनेंट्स के साथ RGB चैनल्स में गाऊसीयन नॉइज़ जोड़ें (σ=0.1 eigenvalues), जो प्रकाश व्यवस्था परिवर्तनों का अनुकरण करता है। इसने अकेले टॉप-1 एरर >1% काट दिया।

- **GPU-अनुकूलित इम्प्लीमेंटेशन**: 2D कन्वॉल्यूशन के लिए कस्टम CUDA कोड ने फॉरवर्ड/बैकवर्ड पासेज को CPU की तुलना में ~10x तेज किया। दो GPU पर समानांतरीकरण ने इंटर-GPU ट्रैफिक को न्यूनतम किया।

इन सबने एलेक्सनेट को दो GTX 580 पर 5–6 दिनों में प्रशिक्षित करने योग्य बना दिया, बनाम अन्यथा सप्ताह/महीने।

### प्रशिक्षण और प्रायोगिक सेटअप

उद्देश्य मल्टीनोमियल लॉजिस्टिक रिग्रेशन (क्रॉस-एन्ट्रॉपी लॉस) था, जिसे स्टोकेस्टिक ग्रेडिएंट डिसेंट (SGD) के माध्यम से ऑप्टिमाइज़ किया गया:
- मिनी-बैच साइज: 128
- मोमेंटम: 0.9
- वेट डिके: 0.0005 (L2 रेगुलराइजेशन वेट्स पर, बायसेस/सॉफ्टमैक्स को छोड़कर)
- प्रारंभिक लर्निंग रेट: 0.01 (हर 8 युग या वैलिडेशन पठार पर आधा किया गया)
- कुल युग: ~90 (अभिसरण तक)

बायसेस 0 पर इनिशियलाइज़ किए गए; वेट्स 0.01 (Xavier जैसा) पर। प्रशिक्षण में पूर्ण 1.2M ImageNet-2010 ट्रेनिंग सेट का उपयोग किया गया, हाइपरपैरामीटर ट्यूनिंग के लिए वैलिडेशन के साथ। कोई प्री-ट्रेनिंग नहीं; रैंडम इनिट से एंड-टू-एंड।

### परिणाम

ILSVRC-2010 टेस्ट सेट पर (होल्ड-आउट, कोई वैल ओवरलैप नहीं):
- टॉप-1 एरर: 37.5% (बनाम ~50% पूर्व SOTA)
- टॉप-5 एरर: 17.0% (बनाम ~28% पूर्व)

एब्लेशन ने नवाचारों के मूल्य की पुष्टि की:
- ReLU: ~25% तेज प्रशिक्षण।
- ड्रॉपआउट: 10–15% ओवरफिटिंग को रोका।
- ऑग्मेंटेशन: 5–7% एरर ड्रॉप।
- ओवरलैपिंग पूलिंग: 0.3–0.4% लाभ।

ILSVRC-2012 के लिए, वेरिएंट ने टेस्ट पर 15.3% टॉप-5 एरर स्कोर किया—दूसरे स्थान से 11% पूर्ण बेहतर। कन्फ्यूजन मैट्रिक्स ने दिखाया कि फाइन-ग्रेन्ड श्रेणियों में ताकत है लेकिन दृश्यत: समान वर्गों (जैसे, कुत्ते की नस्लों) के साथ चुनौतियाँ हैं।

### प्रभाव और विरासत

एलेक्सनेट की ILSVRC-2012 जीत (बड़े अंतर से) ने डीप लर्निंग पुनर्जागरण को प्रज्वलित किया, जिसने साबित किया कि सीएनएन वास्तव-विश्व विजन के लिए स्केलेबल हैं। इसने ML के लिए GPU को लोकप्रिय बनाया, ओपन-सोर्स टूल्स (जैसे, CUDA conv कोड ने Caffe/Torch को प्रभावित किया), और VGG, ResNet, और आधुनिक ट्रांसफॉर्मर जैसे आर्किटेक्चर को प्रेरित किया। ImageNet पर एरर रेट्स ~25% (2012 से पहले) से घटकर आज <3% हो गए हैं, जिससे स्वायत्त ड्राइविंग, मेडिकल इमेजिंग और इसके अलावा अनुप्रयोग संभव हुए हैं। महत्वपूर्ण रूप से, इसने पिक्सेल से लेबल तक "एंड-टू-एंड" लर्निंग को मान्य किया, जिससे फीचर इंजीनियरिंग से डेटा-ड्रिवन मॉडल्स की ओर प्रतिमान बदल गया। जैसा कि हिंटन ने बाद में कहा, इसने "सब कुछ बदल दिया।" सीमाएँ—जैसे बड़े डेटा/कम्प्यूट पर निर्भरता—ने दक्षता शोध (जैसे, MobileNets) को प्रेरित किया, लेकिन एलेक्सनेट एक मौलिक बेंचमार्क बना हुआ है।

पूर्ण पेपर के लिए: [ImageNet Classification with Deep Convolutional Neural Networks (PDF)](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)