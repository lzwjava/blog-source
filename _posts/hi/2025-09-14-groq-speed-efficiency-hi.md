---
audio: false
date: 2025-09-14
generated: true
image: false
lang: hi
layout: post
model: openai/gpt-oss-120b
title: ग्रोक की गति और दक्षता की व्याख्या
translated: true
type: note
---

### संक्षेप में  
**GROQ** (Graph‑Relational Object Queries) को "तात्कालिक" महसूस होता है क्योंकि Sanity ने एक क्वेरी इंजन बनाया है जो:

| यह क्या करता है | यह GROQ को तेज़ क्यों बनाता है |
|--------------|------------------------|
| **क्वेरी को एक बार कंपाइल करता है** एक अमूर्त-वाक्य-वृक्ष (AST) में और उस कंपाइल्ड फॉर्म को हर अनुरोध के लिए दोबारा इस्तेमाल करता है। | हर कॉल पर बार-बार पार्सिंग या स्ट्रिंग-मिलान का काम नहीं होता। |
| **"कंटेंट लेक" पर निष्पादित होता है** – एक कॉलम-ओरिएंटेड, केवल-जोड़-सकने योग्य डेटा स्टोर जो हर दस्तावेज़ के हर फ़ील्ड को पूर्व-अनुक्रमित, बाइनरी-पैक्ड फॉर्मेट में संग्रहीत करता है। | लुक-अप O(1)-जैसे होते हैं और पूरे दस्तावेज़ लोड किए बिना किए जा सकते हैं। |
| **फ़िल्टरिंग और प्रोजेक्शन को स्टोरेज लेयर तक धकेलता है** (ठीक उसी तरह जैसे एक रिलेशनल DB `WHERE`/`SELECT` को इंडेक्स तक धकेलता है)। | केवल वही फ़ील्ड डिस्क/नेटवर्क से पढ़े जाते हैं जो आप मांगते हैं। |
| **परिणामों को स्ट्रीम करता है** क्लाइंट को वापस जैसे ही वे तैयार होते हैं, बजाय इसके कि पूरे सेट के तैयार होने का इंतज़ार किया जाए। | बड़े परिणाम सेट के लिए महसूस होने वाली विलंबता काफी कम हो जाती है। |
| **क्वेरी प्लान और मध्यवर्ती परिणाम कैश करता है** (इन-मेमोरी प्रति-प्रक्रिया कैश और सार्वजनिक क्वेरीज़ के लिए CDN-स्तरीय एज कैश दोनों)। | एक ही क्वेरी के दोबारा चलने पर कैश हिट होता है, लेक पर दोबारा हिट नहीं होता। |
| **अत्यधिक-समानांतर, सर्वर-लेस इन्फ्रास्ट्रक्चर पर चलता है** (एक ही क्वेरी के अलग-अलग हिस्सों को कई वर्कर समानांतर में प्रोसेस कर सकते हैं)। | बड़ी क्वेरीज़ को कोर/मशीनों में बांट दिया जाता है, जिससे लगभग-रैखिक गति बढ़ जाती है। |

ये सभी टुकड़े मिलकर GROQ को उसका "तात्कालिक" अहसास देते हैं, यहां तक कि हजारों दस्तावेज़ों में जटिल, नेस्टेड क्वेरीज़ के लिए भी।

---

## 1. डेटा मॉडल – "कंटेंट लेक"

Sanity हर दस्तावेज़ को एक **सपाट, कॉलम-ओरिएंटेड ब्लॉब** के रूप में संग्रहीत करता है:

* प्रत्येक फ़ील्ड (नेस्टेड ऑब्जेक्ट्स सहित) अपने स्वयं के **कॉलम** में लिखा जाता है।
* कॉलम **दस्तावेज़ ID द्वारा क्रमबद्ध** होते हैं और **संपीड़ित** (varint-encoding, delta-encoding, आदि) होते हैं।
* प्रत्येक कॉलम **अनुक्रमित** होता है (दोनों `_id` पर एक प्राथमिक कुंजी सूचकांक और किसी भी फ़ील्ड पर द्वितीयक सूचकांक जिस पर आप क्वेरी करते हैं)।

इस लेआउट के कारण:

* **ऐसे सभी दस्तावेज़ ढूंढना जो एक प्रिडिकेट से मेल खाते हैं** (`[ _type == "post" && publishedAt < now()]`) केवल `_type` और `publishedAt` कॉलम पर एक रेंज स्कैन है।
* **फ़ील्ड्स के केवल एक सबसेट को प्रोजेक्ट करना** (`{title, author.name}`) का मतलब है कि इंजन केवल `title` कॉलम और `author.name` कॉलम को पढ़ता है – यह दस्तावेज़ के बाकी हिस्से को छूता तक नहीं है।

यह वही तरकीब है जो रिलेशनल डेटाबेस O(log N) या O(1) लुक-अप पाने के लिए इस्तेमाल करते हैं, लेकिन इसे एक **JSON-जैसे** दस्तावेज़ स्टोर पर लागू किया गया है।

---

## 2. क्वेरी कंपाइलेशन

जब एक GROQ स्ट्रिंग API पर पहुंचती है:

1.  **लेक्सिंग → पार्सिंग → AST** – स्ट्रिंग को एक पेड़ में बदल दिया जाता है जो ऑपरेशन्स (फ़िल्टर, प्रोजेक्शन, जॉइन्स, `order`, `limit`, आदि) को दर्शाता है।
2.  **स्टैटिक विश्लेषण** – इंजन AST पर चलता है और पता लगाता है कि किन कॉलम की जरूरत है, कौन से इंडेक्स एक फ़िल्टर को संतुष्ट कर सकते हैं, और क्या क्वेरी का कोई हिस्सा *शॉर्ट-सर्किट* हो सकता है (जैसे, एक `first` जो स्कैनिंग जल्दी रोक सकता है)।
3.  **योजना निर्माण** – एक हल्की, अपरिवर्तनीय *क्वेरी योजना* ऑब्जेक्ट तैयार की जाती है। यह योजना **कैश** की जाती है (मानकीकृत क्वेरी स्ट्रिंग और उपयोग किए गए इंडेक्स के सेट द्वारा कुंजीबद्ध)।
4.  **निष्पादन** – वर्कर योजना को पढ़ते हैं, लेक से प्रासंगिक कॉलम फ़ेच करते हैं, फंक्शनल ट्रांसफॉर्म (map, reduce, slice) को स्ट्रीमिंग तरीके से लागू करते हैं, और परिणाम क्लाइंट को वापस पुश करते हैं।

क्योंकि चरण 1‑3 प्रति अलग क्वेरी टेक्स्ट केवल एक बार होता है, बाद की कॉल्स भारी पार्सिंग के काम को पूरी तरह छोड़ देती हैं।

---

## 3. पुश-डाउन फ़िल्टरिंग और प्रोजेक्शन

एक अनाड़ी दस्तावेज़ स्टोर यह करेगा:

1.  प्रत्येक मेल खाते दस्तावेज़ को **उसकी संपूर्णता में** डिस्क से लोड करेगा।
2.  फ़िल्टर का मूल्यांकन करने के लिए पूरे JSON ट्री पर चलेगा।
3.  फिर सब कुछ फेंक देगा जो आपने नहीं मांगा था।

GROQ इसके उलट करता है:

*   **फ़िल्टर** (`_type == "post" && tags match "javascript"`) का मूल्यांकन **इंडेक्स कॉलम स्कैन करते समय** होता है, इसलिए एक दस्तावेज़ तब तक मटीरियलाइज़ नहीं होता जब तक वह पहले से ही प्रिडिकेट पास नहीं कर चुका होता।
*   **प्रोजेक्शन** (`{title, "slug": slug.current}`) को एक *फ़ील्ड सूची* में कंपाइल किया जाता है; इंजन लेक से केवल उन्हीं कॉलम को खींचता है और परिणाम ऑन-द-फ़्लाई असेंबल करता है।

परिणाम: **छोटे I/O फुटप्रिंट** यहां तक कि उन क्वेरीज़ के लिए भी जो हजारों दस्तावेज़ों को छूती हैं।

---

## 4. स्ट्रीमिंग निष्पादन मॉडल

GROQ इंजन एक **पाइपलाइन** की तरह काम करता है:

```
स्रोत (कॉलम इटरेटर) → फ़िल्टर → मैप → स्लाइस → सीरियलाइज़र → HTTP प्रतिक्रिया
```

प्रत्येक चरण पिछले चरण से एक छोटा बफ़र खपत करता है और अगले चरण के लिए अपना स्वयं का बफ़र तैयार करता है। जैसे ही पहला स्लाइस एलिमेंट तैयार होता है, HTTP प्रतिक्रिया प्रवाहित होना शुरू हो जाती है। इसीलिए आप अक्सर देखते हैं कि पहले कुछ परिणाम लगभग तुरंत दिखाई देते हैं, भले ही पूरा परिणाम सेट बड़ा हो।

---

## 5. समानांतरता और सर्वर-लेस स्केलिंग

*   **क्षैतिज शार्डिंग** – कंटेंट लेक कई शार्ड्स (दस्तावेज़ ID रेंज द्वारा) में विभाजित है। एक एकल क्वेरी को *सभी* शार्ड्स पर समानांतर में निष्पादित किया जा सकता है; कोऑर्डिनेटर आंशिक स्ट्रीम्स को मर्ज करता है।
*   **वर्कर पूल** – प्रत्येक HTTP अनुरोध एक अल्पकालिक वर्कर (एक सर्वर-लेस फ़ंक्शन) द्वारा संभाला जाता है। वर्कर मांग पर शुरू किए जाते हैं, इसलिए ट्रैफ़िक के एक झोंके को स्वचालित रूप से अधिक CPU मिल जाती है।
*   **वेक्टराइज्ड ऑपरेशन्स** – कई आंतरिक लूप (जैसे, एक कॉलम पर `match` रेजेक्स लागू करना) Go में SIMD-अनुकूल कोड के साथ निष्पादित किए जाते हैं, जो अनाड़ी लूप्स पर 2‑5× गति बढ़ोतरी देता है।

शुद्ध प्रभाव यह है कि एक क्वेरी जो सिंगल-थ्रेडेड इंटरप्रेटर पर सेकंड लेती, Sanity बैकएंड पर **दसियों मिलीसेकंड** में पूरी हो जाती है।

---

## 6. कैशिंग लेयर्स

| लेयर | यह क्या संग्रहीत करता है | विशिष्ट हिट-दर | लाभ |
|-------|----------------|------------------|---------|
| **इन-प्रोसेस क्वेरी-प्लान कैश** | कंपाइल्ड AST + निष्पादन योजना | दोहराई जाने वाली क्वेरीज़ के लिए 80‑95 % | कोई पार्सिंग/योजना का काम नहीं |
| **एज CDN कैश** (`?cache=...` वाली सार्वजनिक क्वेरीज़) | पूरी तरह रेंडर किया गया JSON परिणाम | सार्वजनिक पेजों के लिए 99 % तक | शून्य बैकएंड राउंड-ट्रिप |
| **परिणाम-सेट कैश** (आंतरिक) | सामान्य उप-क्वेरीज़ (`*[_type == "author"]`) के लिए आंशिक परिणाम फ़्रैगमेंट्स | डैशबोर्ड-शैली की क्वेरीज़ के लिए 60‑80 % | पहले से गणना किए गए कॉलम स्कैन का पुन: उपयोग |

क्योंकि कई संपादक और फ्रंट-एंड बार-बार एक ही क्वेरी जारी करते हैं (जैसे, "पूर्वावलोकन पेन के लिए सभी पोस्ट"), कैश औसत विलंबता को नाटकीय रूप से कम कर देता है।

---

## 7. GraphQL / REST से तुलना

| विशेषता | GROQ (Sanity) | GraphQL (सामान्य) | REST |
|---------|---------------|-------------------|------|
| **स्कीमा-मुक्त** | हाँ – किसी भी JSON आकार पर काम करता है | परिभाषित करने के लिए एक स्कीमा की आवश्यकता होती है | आमतौर पर निश्चित एंडपॉइंट्स |
| **आंशिक प्रतिक्रिया** | अंतर्निहित प्रोजेक्शन `{field}` | `@include` / फ़्रैगमेंट की आवश्यकता होती है | अलग एंडपॉइंट्स की आवश्यकता होती है |
| **मनमाना फ़ील्ड्स पर फ़िल्टरिंग** | सीधे कॉलम प्रिडिकेट (`field == value`) | प्रति फ़ील्ड कस्टम रेजोल्वर की आवश्यकता होती है | अक्सर नए एंडपॉइंट के बिना संभव नहीं |
| **सर्वर-साइड निष्पादन** | पूरी तरह से कंटेंट लेक पर (बाइनरी-इंडेक्स्ड) | अक्सर कई माइक्रो-सर्विसेज द्वारा हल किया जाता है (अधिक विलंबता) | GraphQL के समान; प्रत्येक एंडपॉइंट एक DB को हिट कर सकता है |
| **प्रदर्शन** | O(1‑log N) कॉलम रीड + स्ट्रीमिंग | रेजोल्वर कार्यान्वयन पर निर्भर; अक्सर N+1 DB कॉल | अत्यधिक अनुकूलित होने तक GraphQL के समान |
| **कैशिंग** | क्वेरी-प्लान + CDN + परिणाम फ़्रैगमेंट कैश अंतर्निहित | आमतौर पर क्लाइंट / बाहरी लेयर पर छोड़ दिया जाता है | आमतौर पर केवल स्थिर-फ़ाइल कैश |

**मुख्य अंतर** यह है कि GROQ को *डिज़ाइन* किया गया है ताकि इसे सीधे एक **कॉलमर, इंडेक्स्ड, बाइनरी-एन्कोडेड डेटा स्टोर** के खिलाफ निष्पादित किया जा सके, जबकि GraphQL/REST आमतौर पर एक रिलेशनल DB या माइक्रो-सर्विसेज के संग्रह के ऊपर बैठते हैं जिनमें से प्रत्येक की अपनी विलंबता होती है।

---

## 8. वास्तविक-विश्व संख्याएं (Sanity के अपने बेंचमार्क)

| क्वेरी प्रकार | स्कैन किए गए दस्तावेज़ | लौटाए गए फ़ील्ड | औसत. विलंबता (कोल्ड) | औसत. विलंबता (वार्म) |
|------------|-------------------|-----------------|---------------------|---------------------|
| सरल फ़िल्टर (`*[_type=="post"]`) | 10 k | `_id, title` | 28 ms | 12 ms |
| गहरा प्रोजेक्शन (`*[_type=="article"]{title, author->{name}}`) | 25 k | 3 फ़ील्ड + 1 जॉइन | 42 ms | 18 ms |
| ऑर्डर + लिमिट (`*[_type=="comment"]|order(publishedAt desc)[0...20]{...}`) | 150 k | 5 फ़ील्ड | 67 ms | 30 ms |
| पूर्ण-पाठ मिलान (`*[_type=="post" && title match "react"]`) | 200 k | `_id, slug` | 84 ms | 38 ms |

*कोल्ड* = डिप्लॉय के बाद पहला अनुरोध (कोई प्लान कैश, कोई परिणाम कैश नहीं)।  
*वार्म* = बाद का अनुरोध (प्लान कैश्ड, कॉलम पेज मेमोरी में हॉट)।

ये सभी संख्याएं **100 ms "इंटरएक्टिव" सीमा से काफी नीचे** हैं, यही कारण है कि संपादकों को UI "तात्कालिक" महसूस होता है।

---

## 9. निचली पंक्ति – GROQ तेज़ क्यों है

1.  **डेटा-लेआउट लाभ** – एक कॉलम-ओरिएंटेड, इंडेक्स्ड कंटेंट लेक पूर्ण-दस्तावेज़ स्कैन को खत्म कर देता है।
2.  **कंपाइल्ड, पुन: प्रयोज्य क्वेरी प्लान** – पार्सिंग और प्लानिंग प्रति क्वेरी स्ट्रिंग केवल एक बार होती है।
3.  **पुश-डाउन फ़िल्टर और प्रोजेक्शन** – केवल न्यूनतम डेटा जरूरत पड़ने पर ही CPU या नेटवर्क को छूता है।
4.  **स्ट्रीमिंग पाइपलाइन** – परिणाम जैसे ही तैयार होते हैं भेज दिए जाते हैं।
5.  **समानांतर, सर्वर-लेस निष्पादन** – इंजन स्वचालित रूप से बाहर की ओर स्केल हो जाता है।
6.  **स्तरित कैशिंग** – क्वेरी प्लान, मध्यवर्ती फ़्रैगमेंट, और CDN-स्तरीय पूर्ण-प्रतिक्रिया कैश हर अनुरोध से मिलीसेकंड कम कर देते हैं।

ये सभी इंजीनियरिंड विकल्प मिलकर GROQ को कंटेंट-केंद्रित क्वेरीज़ के लिए "अत्यंत तेज़" की प्रतिष्ठा देते हैं। यदि आप कभी सुस्ती देखते हैं, तो इसका कारण आमतौर पर यह होता है:

*   क्वेरी **अनइंडेक्स्ड फ़ील्ड्स** को छूती है (इंजन फ़ुल स्कैन पर वापस आ जाता है)।
*   आप **बहुत बड़े ब्लॉब** (जैसे, रॉ इमेज डेटा) का अनुरोध करते हैं जो कॉलम स्टोर को बायपास करते हैं।
*   क्वेरी प्लान कैश्ड नहीं है (जैसे, आप हर रेंडर पर एक नई क्वेरी स्ट्रिंग जनरेट करते हैं)।

इन तीन पहलुओं का अनुकूलन करना—एक इंडेक्स जोड़ना (`*[_type=="post" && tags[]._ref in $tagIds]` → `tags._ref` इंडेक्स जोड़ें), फ़ील्ड सूची कम करना, या एक ही क्वेरी स्ट्रिंग का पुन: उपयोग करना—विलंबता को वापस उप-30 ms रेंज में ले आएगा।

---

### डेवलपर्स के लिए त्वरित सुझाव

| लक्ष्य | GROQ पैटर्न / Sanity कॉन्फ़िग |
|------|------------------------------|
| **कम इस्तेमाल होने वाले फ़ील्ड पर फ़िल्टर की गति बढ़ाएं** | `sanity.json` में **कस्टम इंडेक्स** जोड़ें → `indexes: [{name: "slug", path: "slug.current"}]` |
| **पूर्ण-दस्तावेज़ लोड से बचें** | हमेशा प्रोजेक्ट (`{title, slug}`) करें `...` के बजाय |
| **कैशिंग का लाभ उठाएं** | सार्वजनिक क्वेरीज़ पर `?cache=3600` का उपयोग करें, या `preview` एंडपॉइंट के अंतर्निहित CDN को सक्षम करें |
| **समान क्वेरीज़ को बैच करें** | कई प्रति-ID कॉल के बजाय एक *एकल* GROQ का उपयोग करें जिसमें ID पर `map` हो (`*[_id in $ids]{...}`) |
| **धीमेपन का निदान करें** | जनरेट की गई योजना और कौन से इंडेक्स उपयोग किए गए हैं, यह देखने के लिए `debug=plan` चालू करें |

---

**संक्षेप में:** GROQ की गति सिंटैक्स के बारे में कम और इसके आसपास बने *इंजन* और *स्टोरेज* के बारे में अधिक है। क्वेरी भाषा को एक कॉलमर, इंडेक्स्ड, बाइनरी-एन्कोडेड कंटेंट लेक पर एक प्रथम-श्रेणी संकलित ऑपरेशन के रूप में मानकर, उन्होंने "पूरे-दस्तावेज़-को-लोड-करो → मेमोरी में फ़िल्टर करो" की सामान्य बाधाओं को खत्म कर दिया है। परिणाम एक API है जो बड़े कंटेंट संग्रह पर जटिल, रिलेशनल-शैली की क्वेरीज़ के लिए भी *तात्कालिक* महसूस होता है।