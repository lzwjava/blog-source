---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: 'ट्रांसफॉर्मर्स: उत्पत्ति, डिजाइन और भविष्य'
translated: true
type: note
---

### "हाउ आई लर्न्ड टू स्टॉप वरीइंग एंड लव द ट्रांसफॉर्मर" - आशीष वसवानी द्वारा - सारांश

यह 45 मिनट का वार्तालाप, जो 7 नवंबर, 2023 को स्टैनफोर्ड के CS25 ट्रांसफॉर्मर्स यूनाइटेड सीरीज़ के हिस्से के रूप में दिया गया, ट्रांसफॉर्मर आर्किटेक्चर की उत्पत्ति, डिजाइन, विकास और भविष्य पर एक चिंतनशील गहन विश्लेषण है। ग्राउंडब्रेकिंग 2017 के पेपर "अटेंशन इज़ ऑल यू नीड" के सह-लेखक होने के नाते, वसवानी गूगल ब्रेन में अपने समय के व्यक्तिगत किस्से साझा करते हैं, महत्वपूर्ण निर्णयों को स्पष्ट करते हैं, और AI के अगले चरण के लिए आशावादी लेकिन व्यावहारिक दृष्टिकोण प्रस्तुत करते हैं। यह ऐतिहासिक संदर्भ, मुख्य नवाचारों, पोस्ट-ट्रांसफॉर्मर प्रगति और आगे देखने वाले विचारों के इर्द-गिर्द संरचित है—यह समझने के लिए एकदम सही कि आखिर ट्रांसफॉर्मर आधुनिक AI की रीढ़ क्यों बन गए।

#### ऐतिहासिक पृष्ठभूमि और ट्रांसफॉर्मर्स के लिए चिंगारी
वसवानी की शुरुआत 1956 की डार्टमाउथ कॉन्फ्रेंस की याद से होती है, जहाँ AI अग्रदूतों ने विजन, भाषा, और अन्य क्षेत्रों में मानव बुद्धिमत्ता की नकल करने वाली एकीकृत मशीन का सपना देखा था—नियम-आधारित सिस्टम का उपयोग करके और जल्दी सफलता की धारणा के साथ। 70 साल आगे फास्ट-फॉरवर्ड: AI विंटर्स के बावजूद, हम ट्रांसफॉर्मर्स के साथ मल्टीमॉडल मॉडल्स को पावर देते हुए वापस चक्कर लगा रहे हैं। वे इसकी तुलना 2000 के दशक की NLP से करते हैं, जो मशीन अनुवाद जैसे कार्यों (जैसे, वर्ड अलाइनमेंट, फ्रेज एक्सट्रैक्शन, न्यूरल रिस्कोरिंग) के लिए पाइपलाइनों का एक अव्यवस्थित पैचवर्क थी। 2013 तक, यह फील्ड सेंटीमेंट एनालिसिस या डायलॉग जैसी साइलो में बंट गई थी, जहाँ प्रगति एकीकृत सिद्धांत के बजाय फंडिंग से प्रेरित थी।

मोड़ कब आया? डिस्ट्रिब्यूटेड रिप्रेजेंटेशन (जैसे, word2vec का "king - man + woman ≈ queen") और seq2seq मॉडल (2014–2015), जिन्होंने विविध टास्क को एनकोडर-डिकोडर फ्रेमवर्क में समेट दिया। लेकिन LSTM जैसे रिकरंट नेट्स एक समस्या थे: सीक्वेंशियल प्रोसेसिंग ने पैरेललिज़्म को मार दिया, हिडन स्टेट्स ने जानकारी को बॉटलनेक कर दिया, और लॉन्ग-रेंज डिपेंडेंसी कमजोर थीं। कन्वल्शन (जैसे, ByteNet, ConvS2S) ने स्पीड में मदद की लेकिन दूर के कनेक्शन्स में संघर्ष किया।

**इनसाइडर एनकडोट:** 2016 में गूगल न्यूरल मशीन ट्रांसलेशन (GNMT) पर काम करते हुए, वसवानी की टीम ने पाइपलाइन्स को छोड़कर शुद्ध LSTM का इस्तेमाल किया, और भारी मात्रा में डेटा के साथ स्टेट-ऑफ-द-आर्ट पर पहुँच गए। फिर भी, LSTM "निराशाजनक" लगे—GPU पर धीमे, स्केल करने में मुश्किल। "आहा" पल था फुल पैरेललिज़्म की चाहत: इनपुट को एनकोड और आउटपुट को डिकोड करना, बिना स्टेप-बाय-स्टेप की झंझट के। शुरुआती नॉन-ऑटोरेग्रेसिव सपने (एक साथ सब कुछ जनरेट करना, फिर रिफाइन करना) फ्लॉप हो गए क्योंकि मॉडल बाएं-से-दाएं मार्गदर्शन के बिना ऑर्डरिंग नहीं सीख पाए, जो स्वाभाविक रूप से असंभावित पथों को काट देता है।

#### मुख्य डिजाइन विकल्प: ओरिजिनल ट्रांसफॉर्मर का निर्माण
ट्रांसफॉर्मर्स ने रिकरेंस और कन्वल्शन को छोड़कर शुद्ध अटेंशन को अपनाया, जिससे कंटेंट सिमिलैरिटी के जरिए सीधे टोकन-टू-टोकन चैट संभव हो गई—जैसे विजन टास्क में समान इमेज पैच खींचना (जैसे, नॉन-लोकल मीन्स डीनोइजिंग)। सेल्फ-अटेंशन परम्यूटेशन-इनवेरिएंट लेकिन पैरेलल-फ्रेंडली है, जिसकी O(n² d) कॉम्प्लेक्सिटी GPU के लिए उपयुक्त है जब सीक्वेंस अंतहीन न हों।

मुख्य बिल्डिंग ब्लॉक्स:
- **स्केल्ड डॉट-प्रोडक्ट अटेंशन:** इनपुट से Q, K, V प्रोजेक्शन; स्कोर softmax(QK^T / √d_k) के रूप में V पर वेटेड। स्केलिंग वैनिशिंग ग्रेडिएंट्स से बचने के लिए (यूनिट वेरिएंस मानकर)। डिकोडर के लिए कॉजल मास्किंग आगे झांकने से रोकती है। मैट्रिक्स-मल स्पीड के लिए एडिटिव अटेंशन पर चुना गया।
- **मल्टी-हेड अटेंशन:** सिंगल-हेड बहुत ज्यादा एवरेज कर लेता है (जैसे, "बिल्ली ने हाथ चाटा" में भूमिकाओं को धुंधला देना)। हेड डायमेंशन को सबस्पेस में बांटते हैं—मल्टी-टेप ट्यूरिंग मशीन की तरह—फोकस्ड सबस्पेस के लिए (जैसे, एक हेड विशिष्ट चीजों पर प्रोबेबिलिटी 1 लॉक करता है)। एक्स्ट्रा कंप्यूट नहीं, कन्वल्शन जैसी सिलेक्टिविटी।
- **पोजिशनल एन्कोडिंग:** साइनसॉइड ऑर्डर इंजेक्ट करते हैं, जिसका लक्ष्य रिलेटिव पोजिशन होती है (दूरी से डीकम्पोजेबल)। शुरुआत में रिलेटिव को पूरी तरह नहीं सीखा, लेकिन काम कर गया।
- **स्टैक और स्टेबिलाइज:** एनकोडर-डिकोडर स्टैक रेजिडुअल और लेयर नॉर्म के साथ (बाद में डीपर नेट्स के लिए प्री-नॉर्म)। फीड-फॉरवर्ड रेसनेट्स की तरह एक्सपैंड/कॉन्ट्रैक्ट करते हैं। एनकोडर: सेल्फ-अटेंशन; डिकोडर: मास्क्ड सेल्फ + क्रॉस-अटेंशन।

इसने LSTM एन्सेम्बल्स की तुलना में 8x कम FLOPS के साथ WMT बेंचमार्क्स को क्रश कर दिया, पार्सिंग में जनरलाइज किया, और मल्टीमॉडल क्षमता का संकेत दिया। इंटरप्रेटेबिलिटी? हेड्स ने विशेषज्ञता दिखाई (कुछ लॉन्ग-रेंज, अन्य लोकल कन्व-जैसे), लेकिन वसवानी मजाक में कहते हैं कि यह "चाय की पत्ती पढ़ना" है—वादा तो करता है लेकिन धुंधला।

#### विकास: फिक्सेस और स्केलिंग जीत
ट्रांसफॉर्मर्स "अटक" गए क्योंकि वे सरल हैं, लेकिन ट्वीक्स ने उन्हें बढ़ा दिया:
- **पोजिशन 2.0:** साइनसॉइड रिलेटिव पर कमजोर रहे; रिलेटिव एम्बेडिंग (प्रति-जोड़ी बायस) ने ट्रांसलेशन/म्यूजिक को बूस्ट किया। ALiBi (सीखी गई दूरी बायस) लंबाई को एक्सट्रपोलेट करती है; RoPE (पूर्ण/सापेक्ष स्थिति को मिलाते घूर्णन) अब राजा है—मेमोरी बचाता है, रिलेटिव को पकड़ता है।
- **लॉन्ग कॉन्टेक्स्ट:** क्वाड्रेटिक श्राप? लोकल विंडो, स्पार्स पैटर्न (स्ट्राइडेड/ग्लोबल), हैशिंग (Reformer), रिट्रीवल (Memorizing Transformer), लो-रैंक हैक। Flash Attention स्पीड के लिए मेमोरी राइट्स को छोड़ देता है; Multi-Query इनफरेंस के लिए KV हेड्स को काटता है। बड़े मॉडल वैसे भी अटेंशन की लागत को कम कर देते हैं।
- **अन्य पॉलिश:** प्री-नॉर्म स्थिर करता है; स्पेक्युलेटिव डिकोडिंग (फास्ट ड्राफ्ट, स्लो वेरिफाई) प्रोडक्शन में नॉन-ऑटोरेग्रेसिव स्पीड की नकल करता है।

**इनसाइडर नगेट:** एफिशिएंट रिलेटिव अटेंशन को हैक करना "मैट्रिक्स कैलिसथेनिक्स" था, लेकिन हार्डवेयर फिजिक्स (जैसे, एक्सेलेरेटर के लिए डॉट-प्रोडक्ट) ने विकल्पों को मार्गदर्शन दिया।

#### भविष्य के दिशा-निर्देश: स्केलिंग से आगे
वसवानी आशावादी हैं: सेल्फ-सुपरवाइज्ड दिग्गज इन-कॉन्टेक्स्ट एजेंट को सक्षम करते हैं, जो डार्टमाउथ की एकीकृत मशीन की गूंज है। स्केलिंग लॉ राज करते हैं, लेकिन RNN पुनरुद्धार या बेहतर आर्किटेक्चर पर नजर रखें। प्राथमिकताएं:
- **मल्टीमॉडल एजेंट:** हजारों को प्रॉम्प्ट-प्रोग्राम करें; टूल्स पुल के रूप में (सरल को आंतरिक करें, जटिल पर सहयोग करें)।
- **डेटा और इन्फ्रा:** बेहतर डेटा से 2x लाभ; बैंडविड्थ के लिए FP8/INT8, InfiniBand-स्केल ट्रेनिंग।
- **अनुकूली स्मार्टनेस:** छोटे मॉडल + प्लानर/डेटा रिप्रेजेंटेशन बड़ों से मेल खाते हैं; इनफरेंस पर फ्यू-शॉट; अनसर्टेन्टी सिग्नलिंग; स्किल-बिल्डिंग (जैसे, Minecraft बॉट)।
- **फुल-स्टैक मैजिक:** वर्कफ्लो के लिए फीडबैक लूप (जैसे, डेटा विश्लेषण "डार्क नॉलेज" माइनिंग के रूप में)।
- **एमर्जेंट्स:** खिलौनों में ग्रोकिंग से लेकर GPT-4 रहस्यों तक—बड़े को समझने के लिए छोटे का अध्ययन करें।
- **सिस्टम्स:** मेमोरी बैंडविड्थ बॉटलनेक है; हर चीज के लिए रिट्रीवल।

वे सह-लेखक नोआम शेज़ीर के साथ अपनी स्टार्टअप की ओर इशारा करते हैं: डेटा क्रंचिंग से वर्कफ्लो को ऑटोमेट करना, फीडबैक मैजिक के लिए फुल-स्टैक। "ट्रांसफॉर्मर्स ऑल द वे डाउन" तक टूल्स, सॉफ्टवेयर स्मार्टनेस का लाभ उठाते हुए।

#### प्रश्नोत्तर हाइलाइट्स
पोस्ट-टॉक चैट में:
- नॉन-ऑटोरेग्रेसिव बाधाएं: स्वतंत्रता के लिए "ओरेकल ऑर्डरिंग" की आवश्यकता; लेटेंट स्पेस मदद करते हैं लेकिन मल्टी-मोडैलिटी समस्या देती है।
- टेक्स्ट से दुनिया: LLM + RLHF रोबोटिक्स प्लानर निकालते हैं; ट्रेनिंग डेटा को मिलाने से "नई" रचनात्मकता जगती है।
- मॉड्यूलैरिटी: MoE विशेषज्ञों को प्रेरित करता है; मल्टी-एजेंट कोऑर्डिनेशन (लक्ष्य, अपडेट, सत्यापन) महत्वपूर्ण है।
- सलाह: क्लोज्ड-लूप ह्यूमन-AI का पीछा करें; फील्ड आश्चर्य के लिए खुली है।

कालातीत सामग्री—ऐतिहासिक भावना, तकनीकी गहराई, प्रचार के बिना प्रेरणा। यदि आप AI में हैं, तो यह समझने के लिए कि ट्रांसफॉर्मर क्यों जीते, यह एक अनिवार्य देखने लायक है।

[हाउ आई लर्न्ड टू स्टॉप वरीइंग एंड लव द ट्रांसफॉर्मर (YouTube)](https://www.youtube.com/watch?v=1GbDTTK3aR4)