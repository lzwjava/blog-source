---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: गुडफेलो बेंजियो कूरविले की डीप लर्निंग बुक
translated: true
type: note
---

**इयान गुडफेलो**  
**योशुआ बेंजियो**  
**आरोन कौर्विल**

## विषय सूची

- वेबसाइट viii  
- आभार ix  
- संकेतन xiii  

### 1 परिचय 1

- 1.1 इस पुस्तक को कौन पढ़े? 8  
- 1.2 डीप लर्निंग में ऐतिहासिक रुझान 12  

## I अनुप्रयुक्त गणित और मशीन लर्निंग मूल बातें 27

### 2 रैखिक बीजगणित 29

- 2.1 अदिश, सदिश, आव्यूह और टेंसर 29  
- 2.2 आव्यूह और सदिशों का गुणन 32  
- 2.3 तत्समक और व्युत्क्रम आव्यूह 34  
- 2.4 रैखिक निर्भरता और स्पैन 35  
- 2.5 मानदंड 37  
- 2.6 आव्यूहों और सदिशों के विशेष प्रकार 38  
- 2.7 आइगेनवियो अपघटन 40  
- 2.8 एकवचन मान अपघटन 42  
- 2.9 मूर-पेनरोज़ स्यूडोइनवर्स 43  
- 2.10 ट्रेस ऑपरेटर 44  
- 2.11 सारणिक 45  
- 2.12 उदाहरण: प्रिंसिपल कंपोनेंट्स विश्लेषण 45  

### 3 प्रायिकता और सूचना सिद्धांत 51

- 3.1 प्रायिकता क्यों? 52  
- 3.2 यादृच्छिक चर 54  
- 3.3 प्रायिकता बंटन 54  
- 3.4 सीमांत प्रायिकता 56  
- 3.5 सप्रतिबंध प्रायिकता 57  
- 3.6 सप्रतिबंध प्रायिकताओं का श्रृंखला नियम 57  
- 3.7 स्वतंत्रता और सप्रतिबंध स्वतंत्रता 58  
- 3.8 प्रत्याशा, प्रसरण और सहप्रसरण 58  
- 3.9 सामान्य प्रायिकता बंटन 60  
- 3.10 सामान्य फलनों के उपयोगी गुण 65  
- 3.11 बेयस का नियम 68  
- 3.12 सतत चर के तकनीकी विवरण 69  
- 3.13 सूचना सिद्धांत 71  
- 3.14 संरचित प्रायिकता मॉडल 73  

### 4 संख्यात्मक संगणना 78

- 4.1 ओवरफ्लो और अंडरफ्लो 78  
- 4.2 खराब कंडीशनिंग 80  
- 4.3 ग्रेडिएंट-आधारित अनुकूलन 80  
- 4.4 प्रतिबंधित अनुकूलन 91  
- 4.5 उदाहरण: रैखिक न्यूनतम वर्ग 94  

### 5 मशीन लर्निंग मूल बातें 96

- 5.1 लर्निंग एल्गोरिदम 97  
- 5.2 क्षमता, ओवरफिटिंग और अंडरफिटिंग 108  
- 5.3 हाइपरपैरामीटर और वैलिडेशन सेट 118  
- 5.4 अनुमानक, पूर्वाग्रह और प्रसरण 120  
- 5.5 अधिकतम संभावना अनुमान 129  
- 5.6 बायेसियन सांख्यिकी 133  
- 5.7 पर्यवेक्षित लर्निंग एल्गोरिदम 137  
- 5.8 अपर्यवेक्षित लर्निंग एल्गोरिदम 142  
- 5.9 स्टोकैस्टिक ग्रेडिएंट डिसेंट 149  
- 5.10 एक मशीन लर्निंग एल्गोरिदम का निर्माण 151  
- 5.11 डीप लर्निंग के लिए प्रेरित करने वाली चुनौतियाँ 152  

## II डीप नेटवर्क: आधुनिक प्रथाएं 162

### 6 डीप फीडफॉरवर्ड नेटवर्क 164

- 6.1 उदाहरण: XOR सीखना 167  
- 6.2 ग्रेडिएंट-आधारित लर्निंग 172  
- 6.3 हिडन यूनिट्स 187  
- 6.4 आर्किटेक्चर डिजाइन 193  
- 6.5 बैक-प्रोपगेशन और अन्य विभेदन एल्गोरिदम 200  
- 6.6 ऐतिहासिक टिप्पणियाँ 220  

### 7 डीप लर्निंग के लिए नियमितीकरण 224

- 7.1 पैरामीटर नॉर्म दंड 226  
- 7.2 प्रतिबंधित अनुकूलन के रूप में नॉर्म दंड 233  
- 7.3 नियमितीकरण और अंडर-कंस्ट्रेंड समस्याएं 235  
- 7.4 डेटासेट ऑग्मेंटेशन 236  
- 7.5 शोर रोबस्टनेस 238  
- 7.6 अर्ध-पर्यवेक्षित लर्निंग 240  
- 7.7 मल्टीटास्क लर्निंग 241  
- 7.8 अर्ली स्टॉपिंग 241  
- 7.9 पैरामीटर टाइंग और पैरामीटर शेयरिंग 249  
- 7.10 स्पार्स रिप्रेजेंटेशन 251  
- 7.11 बैगिंग और अन्य एन्सेम्बल विधियाँ 253  
- 7.12 ड्रॉपआउट 255  
- 7.13 एडवरसैरियल ट्रेनिंग 265  
- 7.14 टेंजेंट डिस्टेंस, टेंजेंट प्रॉप और मैनिफोल्ड टेंजेंट क्लासिफायर 267  

### 8 डीप मॉडल प्रशिक्षण के लिए अनुकूलन 271

- 8.1 लर्निंग शुद्ध अनुकूलन से कैसे भिन्न है 272  
- 8.2 न्यूरल नेटवर्क अनुकूलन में चुनौतियाँ 279  
- 8.3 मूल एल्गोरिदम 290  
- 8.4 पैरामीटर आरंभीकरण रणनीतियाँ 296  
- 8.5 अनुकूली लर्निंग रेट वाले एल्गोरिदम 302  
- 8.6 अनुमानित द्वितीय-क्रम विधियाँ 307  
- 8.7 अनुकूलन रणनीतियाँ और मेटा-एल्गोरिदम 313  

### 9 कन्व्होल्यूशनल नेटवर्क 326

- 9.1 कन्व्होल्यूशन ऑपरेशन 327  
- 9.2 अभिप्रेरण 329  
- 9.3 पूलिंग 335  
- 9.4 अनंत रूप से मजबूत पूर्वधारणा के रूप में कन्व्होल्यूशन और पूलिंग 339  
- 9.5 मूल कन्व्होल्यूशन फलन के प्रकार 342  
- 9.6 संरचित आउटपुट 352  
- 9.7 डेटा प्रकार 354  
- 9.8 कुशल कन्व्होल्यूशन एल्गोरिदम 356  
- 9.9 यादृच्छिक या अपर्यवेक्षित फीचर्स 356  
- 9.10 कन्व्होल्यूशनल नेटवर्क का तंत्रिका वैज्ञानिक आधार 358  
- 9.11 कन्व्होल्यूशनल नेटवर्क और डीप लर्निंग का इतिहास 365  

### 10 अनुक्रम मॉडलिंग: आवर्ती और पुनरावर्ती नेट 367

- 10.1 अनफोल्डिंग कम्प्यूटेशनल ग्राफ 369  
- 10.2 आवर्ती न्यूरल नेटवर्क 372  
- 10.3 द्विदिश आवर्ती न्यूरल नेटवर्क 388  
- 10.4 एनकोडर-डिकोडर अनुक्रम-से-अनुक्रम आर्किटेक्चर 390  
- 10.5 डीप आवर्ती नेटवर्क 392  
- 10.6 पुनरावर्ती न्यूरल नेटवर्क 394  
- 10.7 दीर्घकालिक निर्भरताओं की चुनौती 396  
- 10.8 इको स्टेट नेटवर्क 399  
- 10.9 लीकी यूनिट्स और एकाधिक समय स्केल के लिए अन्य रणनीतियाँ 402  
- 10.10 लॉन्ग शॉर्ट-टर्म मेमोरी और अन्य गेटेड आवर्ती न्यूरल नेटवर्क 404  
- 10.11 दीर्घकालिक निर्भरताओं के लिए अनुकूलन 408  
- 10.12 स्पष्ट मेमोरी 412  

### 11 व्यावहारिक पद्धति 416

- 11.1 प्रदर्शन मेट्रिक्स  
- 11.2 डिफ़ॉल्ट बेसलाइन मॉडल  
- 11.3 अधिक डेटा एकत्र करने का निर्धारण  
- 11.4 हाइपरपैरामीटर का चयन  
- 11.5 डिबगिंग रणनीतियाँ  
- 11.6 उदाहरण: मल्टी-डिजिट नंबर पहचान  

## III डीप लर्निंग शोध 482

### 12 रैखिक फैक्टर मॉडल 485

- 12.1 प्रायिकता PCA और फैक्टर विश्लेषण  
- 12.2 स्वतंत्र कंपोनेंट विश्लेषण  
- 12.3 स्लो फीचर विश्लेषण  
- 12.4 स्पार्स कोडिंग  
- 12.5 PCA की मैनिफोल्ड व्याख्या  

### 13 ऑटोएनकोडर 500

- 13.1 अंडरकम्पलीट ऑटोएनकोडर  
- 13.2 नियमित ऑटोएनकोडर  
- 13.3 प्रस्तुतिकरण शक्ति, परत आकार और गहराई  
- 13.4 स्टोकैस्टिक एनकोडर और डिकोडर  
- 13.5 डीनॉइजिंग ऑटोएनकोडर  
- 13.6 ऑटोएनकोडर के साथ मैनिफोल्ड सीखना  
- 13.7 कॉन्ट्रैक्टिव ऑटोएनकोडर  
- 13.8 प्रिडिक्टिव स्पार्स डिकंपोजिशन  
- 13.9 ऑटोएनकोडर के अनुप्रयोग  

### 14 रिप्रेजेंटेशन लर्निंग 525

- 14.1 लालची लेयर-वाइज अपर्यवेक्षित प्रीट्रेनिंग  
- 14.2 ट्रांसफर लर्निंग और डोमेन एडाप्टेशन  
- 14.3 कारणात्मक कारकों का अर्ध-पर्यवेक्षित विघटन  
- 14.4 वितरित प्रस्तुतिकरण  
- 14.5 गहराई से घातीय लाभ  
- 14.6 अंतर्निहित कारणों की खोज के लिए संकेत प्रदान करना  

### 15 डीप लर्निंग के लिए संरचित प्रायिकता मॉडल 540

- 15.1 असंरचित मॉडलिंग की चुनौती  
- 15.2 मॉडल संरचना का वर्णन करने के लिए ग्राफ का उपयोग  
- 15.3 ग्राफिकल मॉडल से नमूना लेना  
- 15.4 संरचित मॉडलिंग के लाभ  
- 15.5 निर्भरताओं के बारे में सीखना  
- 15.6 अनुमान और अनुमानित अनुमान  
- 15.7 संरचित प्रायिकता मॉडल के लिए डीप लर्निंग दृष्टिकोण  

### 16 मोंटे कार्लो विधियाँ 557

- 16.1 सैंपलिंग और मोंटे कार्लो विधियाँ  
- 16.2 इम्पोर्टेंस सैंपलिंग  
- 16.3 मार्कोव चेन मोंटे कार्लो विधियाँ  
- 16.4 गिब्स सैंपलिंग  
- 16.5 पृथक्कृत मोड के बीच मिश्रण की चुनौती  

### 17 विभाजन फलन का सामना 567

- 17.1 लॉग-संभावना ग्रेडिएंट  
- 17.2 स्टोकैस्टिक अधिकतम संभावना और कंट्रास्टिव डाइवर्जेंस  
- 17.3 स्यूडोलिकलीहुड  
- 17.4 स्कोर मिलान और अनुपात मिलान  
- 17.5 डीनॉइजिंग स्कोर मिलान  
- 17.6 शोर-कंट्रास्टिव अनुमान  
- 17.7 विभाजन फलन का अनुमान  

### 18 अनुमानित अनुमान 579

- 18.1 अनुकूलन के रूप में अनुमान  
- 18.2 एक्सपेक्टेशन मैक्सिमाइजेशन  
- 18.3 MAP अनुमान और स्पार्स कोडिंग  
- 18.4 विविधतापूर्ण अनुमान और लर्निंग  
- 18.5 सीखा हुआ अनुमानित अनुमान  

### 19 डीप जनरेटिव मॉडल 594

- 19.1 बोल्ट्जमैन मशीन  
- 19.2 प्रतिबंधित बोल्ट्जमैन मशीन  
- 19.3 डीप बिलीफ नेटवर्क  
- 19.4 डीप बोल्ट्जमैन मशीन  
- 19.5 वास्तव-मूल्यवान डेटा के लिए बोल्ट्जमैन मशीन  
- 19.6 कन्व्होल्यूशनल बोल्ट्जमैन मशीन  
- 19.7 संरचित या अनुक्रमिक आउटपुट के लिए बोल्ट्जमैन मशीन  
- 19.8 अन्य बोल्ट्जमैन मशीन  
- 19.9 यादृच्छिक संचालन के माध्यम से बैक-प्रोपगेशन  
- 19.10 निर्देशित जनरेटिव नेट  
- 19.11 ऑटोएनकोडर से नमूने खींचना  
- 19.12 जनरेटिव स्टोकैस्टिक नेटवर्क  
- 19.13 अन्य जनरेशन योजनाएँ  
- 19.14 जनरेटिव मॉडल का मूल्यांकन  
- 19.15 निष्कर्ष  

[डीप लर्निंग विषय सूची](https://www.deeplearningbook.org/contents/toc.html)