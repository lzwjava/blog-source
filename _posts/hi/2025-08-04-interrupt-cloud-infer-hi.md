---
audio: false
generated: true
image: false
lang: hi
layout: post
title: बाधाएँ क्लाउड अनुमान को रद्द नहीं करतीं
translated: true
type: note
---

जब आप अपनी Python स्क्रिप्ट को `generate_images()` कॉल पर प्रतीक्षा करते समय इंटरप्ट करते हैं (जैसे Ctrl-C के साथ), तो लगभग यही होता है:

1. **क्लाइंट-साइड व्यवहार**
   – जैसे ही आप Python प्रक्रिया को समाप्त करते हैं, अंतर्निहित HTTP/gRPC कनेक्शन टूट जाता है।
   – GenAI क्लाइंट लाइब्रेरी आमतौर पर टूटे पाइप या कनेक्शन-रीसेट को पकड़ लेगी और एक एक्सेप्शन उठाएगी (जो आपको अपनी स्क्रिप्ट में दिखाई देगी)।

2. **Google की तरफ क्या होता है**
   – जब तक आप कैंसल करते हैं, आपका अनुरोध पहले ही Google की inference सेवा तक पहुँच चुका होता है और कतारबद्ध (या पहले से ही चलना शुरू) हो चुका होता है।
   – अधिकांश क्लाउड inference एंडपॉइंट्स, सिर्फ क्लाइंट के गायब होने पर काम को **स्वचालित रूप से रद्द नहीं** करते हैं। वे आपकी इमेज-जनरेशन जॉब को पूरा होने तक चलाते रहेंगे (GPU/TPU का उपयोग करते हुए और बिलिंग incur करते हुए), भले ही परिणाम वापस भेजने के लिए कोई लाइव कनेक्शन न हो।
   – एक बार जॉब पूरी हो जाने के बाद, जनरेट की गई इमेज को discard कर दिया जाता है—जब तक कि आपने कोई लॉन्ग-रनिंग ऑपरेशन या वेबहुक सेटअप नहीं किया है, आपके पास कोई कॉलबैक नहीं होता।

3. **Nginx (या कोई अन्य प्रॉक्सी) कैसे भूमिका निभाता है**
   – अगर inference सेवा के सामने एक Nginx रिवर्स-प्रॉक्सी है, तो उसका डिफ़ॉल्ट व्यवहार क्लाइंट कनेक्शन को देखना है। जैसे ही क्लाइंट कनेक्शन छोड़ता है, Nginx inference प्रक्रिया से अपना अपस्ट्रीम कनेक्शन बंद कर देता है (एक FIN/RST भेजता है)।
   – अपस्ट्रीम प्रक्रिया को तब एक टूटा हुआ सॉकेट दिखाई देता है जब वह अंततः प्रतिक्रिया लिखने का प्रयास करती है। उस समय, यह एक I/O एरर लॉग कर सकती है, लेकिन—महत्वपूर्ण रूप से—यह आपके द्वारा की गई कम्प्यूटेशन को रिवाइंड और रोकती **नहीं** है; यह बस बाइट्स डिलीवर नहीं कर सकती।
   – आप Nginx के `proxy_ignore_client_abort` डायरेक्टिव को ट्वीक कर सकते हैं—अगर आप इसे `on` पर सेट करते हैं, तो Nginx क्लाइंट के डिस्कनेक्ट होने के बाद भी अपस्ट्रीम कनेक्शन को जीवित रखेगा (जो आपको लॉग या अन्य क्लीनअप लिखने को पूरा करने दे सकता है)।

4. **आपकी स्क्रिप्ट के लिए मुख्य बातें**

   * **इंटरप्ट्स, Google के सर्वर पर मॉडल को "अनडिप्लॉय" या कैंसल नहीं** करते—आपसे पूरी inference की बिलिंग की जाएगी।
   * अगर आपको कैंसल करने योग्य inference की आवश्यकता है, तो आपको एक अलग पैटर्न का उपयोग करना होगा: उदाहरण के लिए,

     1. एक नॉन-ब्लॉकिंग बैच या लॉन्ग-रनिंग ऑपरेशन सबमिट करें,
     2. इसकी स्थिति की पोल करें या एक अलग API कॉल के माध्यम से इसे स्पष्ट रूप से कैंसल करें।

संक्षेप में: 5 सेकंड पर अपनी स्क्रिप्ट को kill करने से आपका लोकल wait रुक जाता है और सॉकेट बंद हो जाता है, लेकिन Google की inference उनके हार्डवेयर पर पूरी होने तक चलती रहती है (और Nginx या इसी तरह का कोई टूल, एक बार तैयार होने पर प्रतिक्रिया को कहीं नहीं भेजकर ड्रॉप कर देगा)।