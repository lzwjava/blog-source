---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: 'वीएलएलएम: कुशल एलएलएम सर्विंग इंजन'
translated: true
type: note
---

### vLLM का आविष्कार

vLLM (जिसका पूरा नाम "वर्चुअल एलएलएम" है) बड़े भाषा मॉडल (एलएलएम) के उच्च-थ्रूपुट और मेमोरी-कुशल अनुमान (इन्फ़रेंस) और सर्विंग के लिए एक ओपन-सोर्स लाइब्रेरी है। इसका आविष्कार 2023 की शुरुआत में यूसी बर्कले के RISELab में स्काई कंप्यूटिंग लैब के शोधकर्ताओं द्वारा किया गया था। यह प्रोजेक्ट एक विशेष अनुमान इंजन (इन्फ़रेंस इंजन) के रूप में शुरू हुआ, जो NVIDIA A100 GPU और मॉडलों के एक सीमित सेट के लिए अनुकूलित था, और इसने एलएलएम सर्विंग में मेमोरी फ़्रैग्मेंटेशन और कम थ्रूपुट जैसी प्रमुख चुनौतियों का समाधान किया।

प्रारंभिक प्रमुख मील के पत्थर:
- **मध्य-अप्रैल 2023**: FastChat के साथ पहला सार्वजनिक एकीकरण, जिसने LMSYS के Vicuna और Chatbot Arena डेमो को शक्ति प्रदान की।
- **जून 2023**: आधिकारिक रिलीज़ और सार्वजनिक GitHub रिपॉजिटरी लॉन्च।
- **12 सितंबर 2023**: आधारभूत शोध पत्र, "Efficient Memory Management for Large Language Model Serving with PagedAttention," arXiv पर प्रकाशित, जिसने मुख्य PagedAttention मैकेनिज्म पेश किया जो निरंतर बैचिंग और लगभग-शून्य KV कैश अपव्यय को सक्षम बनाता है।

GitHub रिपॉजिटरी (vllm-project/vllm) मई-जून 2023 के आसपास बनाई गई, जो प्रारंभिक विकास के धक्के के साथ संरेखित थी।

### लोकप्रियता में वृद्धि

vLLM ने 2024 में महत्वपूर्ण गति प्राप्त करना शुरू किया, और एक विशेष शोध उपकरण से विकसित होकर ओपन-सोर्स एलएलएम सर्विंग के लिए वास्तविक मानक (डी फैक्टो स्टैंडर्ड) बन गया। तेजी से फीचर जोड़ (जैसे क्वांटिज़ेशन, स्पेक्युलेटिव डिकोडिंग, मल्टी-मोडल सपोर्ट), हार्डवेयर विस्तार (NVIDIA, AMD, Google TPUs, आदि), और कंपनियों द्वारा प्रोडक्शन अपनाने (जैसे Amazon द्वारा Prime Day 2024 के दौरान Rufus को पावर देने के लिए) और LinkedIn के कारण इसकी लोकप्रियता में विस्फोट हुआ।

2024 से प्रमुख विकास संकेतक:
- **GitHub Stars**: 14,000 (2024 की शुरुआत) से बढ़कर 32,600 (2024 के अंत) हो गई, यानी 2.3 गुना वृद्धि।
- **मासिक डाउनलोड**: 6,000 से बढ़कर 27,000 हो गए, यानी 4.5 गुना वृद्धि।
- **GPU उपयोग**: 2024 की दूसरी छमाही में लगभग 10 गुना बढ़ गया।
- **कम्युनिटी**: योगदानकर्ता 3.9 गुना बढ़कर 740 हो गए, साथ ही साप्ताहिक ऑफिस आवर्स और साझेदारियाँ (जैसे NVIDIA, IBM, AWS) हुईं।

2024 के मध्य तक, इसके लगभग 20,000 सितारे थे और AI कम्युनिटी में थ्रूपुट में विकल्पों से बेहतर प्रदर्शन के लिए इसकी अक्सर चर्चा होती थी। 2025 में भी गति जारी रही:
- दिसंबर 2024 में PyTorch इकोसिस्टम में शामिल हुआ।
- अक्टूबर 2024 में LF AI & Data इनक्यूबेशन में प्रवेश किया।
- जून 2025 तक 50,000 सितारे प्राप्त कर लिए।

आज (अक्टूबर 2025), इसके 55,000 से अधिक सितारे हैं और यह लगभग 100 मॉडल आर्किटेक्चर का समर्थन करता है, जिससे यह स्केलेबल AI डिप्लॉयमेंट के लिए एक आधारशिला बन गया है।

[PagedAttention पर arXiv पेपर](https://arxiv.org/abs/2309.06180)  
[vLLM GitHub रिपॉजिटरी](https://github.com/vllm-project/vllm)  
[vLLM 2024 रेट्रोस्पेक्टिव ब्लॉग](https://blog.vllm.ai/2025/01/10/vllm-2024-wrapped-2025-vision.html)  
[PyTorch इंटीग्रेशन घोषणा](https://pytorch.org/blog/vllm-joins-pytorch/)