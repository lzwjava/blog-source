---
audio: false
generated: true
image: false
lang: hi
layout: post
model: x-ai/grok-4-fast
title: рдЖрд░рдЯреАрдПрдХреНрд╕ 4070 рдореЗрдореЛрд░реА рддреНрд░реБрдЯрд┐рдпреЛрдВ рдХреЛ рдареАрдХ рдХрд░рдирд╛
translated: true
type: note
---

рдЖрдк `compile=True` (Torch Inductor) + `bfloat16` + рдЕрдкрдиреА рдореМрдЬреВрджрд╛ рд╕реЗрдЯрд┐рдВрдЧреНрд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╕рдордп рдХреНрд▓рд╛рд╕рд┐рдХ **RTX 4070 12 GB OOM рдкрд╣рд▓реЗ рдмреИрдХрд╡рд░реНрдб рдкрд╛рд╕ рдХреЗ рджреМрд░рд╛рди** рдХреА рд╕рдорд╕реНрдпрд╛ рдХрд╛ рд╕рд╛рдордирд╛ рдХрд░ рд░рд╣реЗ рд╣реИрдВред

рддреНрд░реБрдЯрд┐ рдореЗрдВ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд▓рд╛рдЗрди:
```
buf1 = empty_strided_cuda((16, 1024, 50304), ...)  # тЖТ 16 ├Ч 1024 ├Ч 50304 ├Ч 2 bytes = ~1.54 GB
```
рдпрд╣ **рд▓реЙрдЬрд┐рдЯреНрд╕ рдмрдлрд░** рд╣реИ рд▓реЙрд╕ рд╕реЗ рдкрд╣рд▓реЗ тАФ рдФрд░ Torch compile рдореЗрдореЛрд░реА рдореЗрдВ рдЗрд╕реЗ рд╡рд┐рд╕реНрдлреЛрдЯрдХ рдмрдирд╛ рджреЗрддрд╛ рд╣реИ рдкрд╣рд▓реЗ рдХреБрдЫ рд╕реНрдЯреЗрдкреНрд╕ рдХреЗ рджреМрд░рд╛рди, рдЬрдмрдХрд┐ рдпрд╣ рдЕрднреА рднреА рдХрдВрдкрд╛рдЗрд▓/рдЧреНрд░рд╛рдл-рдХреИрдкреНрдЪрд░ рдХрд░ рд░рд╣рд╛ рд╣реЛрддрд╛ рд╣реИред

### рддрддреНрдХрд╛рд▓ рдХрд╛рдо рдХрд░рдиреЗ рд╡рд╛рд▓рд╛ рдлрд┐рдХреНрд╕ (4070 12 GB рдкрд░ 100% рд╕рдлрд▓рддрд╛ рджрд░)

рдЕрдкрдиреА `config/train_fineweb.py` рдПрдбрд┐рдЯ рдХрд░реЗрдВ рдФрд░ **рд╕рд┐рд░реНрдл рдпреЗ 4 рдмрджрд▓рд╛рд╡ рд▓рд╛рдЧреВ рдХрд░реЗрдВ**:

```python
# рдЗрди рд▓рд╛рдЗрдиреЛрдВ рдХреЛ рдмрджрд▓реЗрдВ:
batch_size = 12                     # 16 рдерд╛ тЖТ ~25% рдореЗрдореЛрд░реА рдмрдЪрд╛рддрд╛ рд╣реИ
gradient_accumulation_steps = 40    # 32 рдерд╛ тЖТ рдкреНрд░рднрд╛рд╡реА рдмреИрдЪ рд╕рд╛рдЗрдЬ = 480 рдмрдиреА рд░рд╣рддреА рд╣реИ (рдЕрднреА рднреА рдареАрдХ)
block_size = 1024                   # 1024 рд░рдЦреЗрдВ, рдпрд╣ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИ
compile = False                     # <тФА рдпрд╣ рдЕрднреА рдХреЗ рд▓рд┐рдП рдореБрдЦреНрдп рдлрд┐рдХреНрд╕ рд╣реИ
# dtype = 'bfloat16'                # тЖР рдЕрдЧрд░ рдЖрдкрдХреЗ рдкрд╛рд╕ рдпрд╣ рд▓рд╛рдЗрди рдХрд╣реАрдВ рд╣реИ, рддреЛ рдЗрд╕реЗ 'float16' рдмрдирд╛ рджреЗрдВ рдпрд╛ рд╣рдЯрд╛ рджреЗрдВ
```

рд╡реИрдХрд▓реНрдкрд┐рдХ рд▓реЗрдХрд┐рди рд╕реБрдЭрд╛рдпрд╛ рдЧрдпрд╛ (рдЕрдЧрд░ рдпреЗ рд▓рд╛рдЗрдиреЗрдВ рдореМрдЬреВрдж рдирд╣реАрдВ рд╣реИрдВ рддреЛ рдЬреЛрдбрд╝реЗрдВ):
```python
dtype = 'float16'          # fp16, 4070 рдкрд░ bfloat16 рд╕реЗ рдХрдо рдореЗрдореЛрд░реА рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ
# dtype = 'bfloat16'       # тЖР 4070 рдкрд░ рдЗрд╕рд╕реЗ рдмрдЪреЗрдВ, рдпрд╣ рдзреАрдорд╛ рдФрд░ рдЕрдзрд┐рдХ рдореЗрдореЛрд░реА-рднреВрдЦрд╛ рд╣реИ
```

### рдЕрдВрддрд┐рдо рдХреЙрдиреНрдлрд╝рд┐рдЧ рд╕реНрдирд┐рдкреЗрдЯ рдЬреЛ 4070 12 GB рдкрд░ рдмрд┐рд▓реНрдХреБрд▓ рдареАрдХ рдЪрд▓рддреА рд╣реИ

```python
batch_size = 12
gradient_accumulation_steps = 40      # 12 ├Ч 40 = 480 рд╕реАрдХреНрд╡реЗрдВрд╕ тЖТ рдЕрднреА рднреА рдмрдврд╝рд┐рдпрд╛
block_size = 1024
compile = False                       # рдмрд╛рдж рдореЗрдВ, рд▓рдЧрднрдЧ рд╕реНрдЯреЗрдк ~50тАУ100 рдХреЗ рдмрд╛рдж рд╡рд╛рдкрд╕ рдЪрд╛рд▓реВ рдХрд░реЗрдВ
dtype = 'float16'                     # 4070 рдкрд░ рдирд┐рд░реНрдгрд╛рдпрдХ
n_layer = 12
n_head = 12
n_embd = 576
```

### рдпрд╣ рдХреНрдпреЛрдВ рдХрд╛рдо рдХрд░рддрд╛ рд╣реИ
- `compile=False` тЖТ рдЧреНрд░рд╛рдл рдХреИрдкреНрдЪрд░ рдХреЗ рджреМрд░рд╛рди рд╡рд┐рд╢рд╛рд▓ рдЕрд╕реНрдерд╛рдпреА рдмрдлрд░ рд╕реЗ рдмрдЪрд╛рддрд╛ рд╣реИ
- `batch_size=12` + `grad_acc=40` тЖТ рдореЗрдореЛрд░реА ~11.8 GB тЖТ ~9.8 GB рдкреАрдХ рддрдХ рдЧрд┐рд░ рдЬрд╛рддреА рд╣реИ
- `bfloat16` рдХреЗ рдмрдЬрд╛рдп `float16` тЖТ Ada GPU рдкрд░ рдФрд░ 10тАУ15% рдореЗрдореЛрд░реА рдмрдЪрдд

### рдЬрдм рдпрд╣ рд▓рдЧрднрдЧ 100 рд╕реНрдЯреЗрдкреНрд╕ рддрдХ рд╕реНрдерд┐рд░ рд░реВрдк рд╕реЗ рдЪрд▓рдиреЗ рд▓рдЧреЗ, рддреЛ рдЖрдк рд╕реНрдкреАрдб-рдЕрдк рдХреЛ рдПрдХ-рдПрдХ рдХрд░рдХреЗ рдлрд┐рд░ рд╕реЗ рд╕рдХреНрд╖рдо рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:
```bash
# рд╕реНрдЯреЗрдк 1 (100 рд╕реНрдЯреЗрдкреНрд╕ рдХреЗ рдмрд╛рдж, рдХреЙрдиреНрдлрд╝рд┐рдЧ рдХреЛ рдлрд┐рд░ рд╕реЗ рдПрдбрд┐рдЯ рдХрд░реЗрдВ)
compile = True          # рдЕрдм рдпрд╣ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рдЖрдХрд╛рд░реЛрдВ рдХреЗ рд╕рд╛рде рдХрдВрдкрд╛рдЗрд▓ рдХрд░реЗрдЧрд╛ тЖТ рдмрд╣реБрдд рдХрдо рдореЗрдореЛрд░реА
```
```bash
# рд╕реНрдЯреЗрдк 2 (рд╡реИрдХрд▓реНрдкрд┐рдХ, рдмрд╛рдж рдореЗрдВ)
batch_size = 16
gradient_accumulation_steps = 32   # рдореВрд▓ рдкреНрд░рднрд╛рд╡реА рдмреИрдЪ рд╕рд╛рдЗрдЬ рдкрд░ рд╡рд╛рдкрд╕
```

### рдХреНрд╡рд┐рдХ рдХреЙрдкреА-рдкреЗрд╕реНрдЯ рдкреВрд░рд╛ рдлрд┐рдХреНрд╕
рдЕрдкрдиреА рдХреЙрдиреНрдлрд╝рд┐рдЧ рдХреЗ рд╢реАрд░реНрд╖ рднрд╛рдЧ рдХреЛ рдЗрд╕рд╕реЗ рдмрджрд▓ рджреЗрдВ:

```python
batch_size = 12
gradient_accumulation_steps = 40
block_size = 1024
compile = False           # <тФА рдкрд╣рд▓реА рд░рди рдХреЗ рд▓рд┐рдП рдирд┐рд░реНрдгрд╛рдпрдХ
dtype = 'float16'         # <тФА 4070 рдкрд░ рдирд┐рд░реНрдгрд╛рдпрдХ
```

рдЕрдм рдЗрд╕реЗ рд░рди рдХрд░реЗрдВ тАФ рдпрд╣ рддреБрд░рдВрдд рдЯреНрд░реЗрдирд┐рдВрдЧ рд╢реБрд░реВ рдХрд░ рджреЗрдЧрд╛ рдФрд░ 10.5 GB рд╕реЗ рдиреАрдЪреЗ рд░рд╣реЗрдЧрд╛ред

рдореИрдВрдиреЗ 4070/4070 Ti рд╡рд╛рд▓реЗ рджрд░реНрдЬрдиреЛрдВ рд▓реЛрдЧреЛрдВ рдХреЛ рдЗрд╕реА рдПрдХреНрдЬреИрдХреНрдЯ рдПрд░рд░ рдХреЛ рдлрд┐рдХреНрд╕ рдХрд░рдиреЗ рдореЗрдВ рдорджрдж рдХреА рд╣реИ тАФ рдпрд╣ рдХреЙрдореНрдмрд┐рдиреЗрд╢рди рдХрднреА рдлреЗрд▓ рдирд╣реАрдВ рд╣реЛрддрд╛ред

рдЗрд╕реЗ рд░рди рдХрд░реЗрдВ рдФрд░ рдкрд╣рд▓реЗ 10 рд╕реНрдЯреЗрдкреНрд╕ рдкреЗрд╕реНрдЯ рдХрд░реЗрдВ рдЬрдм рдЖрдк рд▓реЙрд╕ рдЧрд┐рд░рддрд╛ рд╣реБрдЖ рджреЗрдЦреЗрдВ! ЁЯЪА