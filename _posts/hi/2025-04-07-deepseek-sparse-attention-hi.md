---
audio: false
generated: true
image: false
lang: hi
layout: post
model: anthropic/claude-4.5-sonnet
title: डीपसीक स्पार्स अटेंशन समझाया
translated: true
type: note
---

अब मेरे पास DeepSeek-V3.2-Exp में DeepSeek Sparse Attention (DSA) के बारे में व्यापक जानकारी है। मैं एक विस्तृत विवरण प्रदान करता हूँ।

## DeepSeek-V3.2-Exp में DeepSeek Sparse Attention (DSA)

DeepSeek Sparse Attention (DSA) DeepSeek-V3.2-Exp मॉडल में पेश किया गया एक नवीन सूक्ष्म-दानेदार विरल अटेंशन तंत्र है, जो बड़े भाषा मॉडल के लिए कुशल लंबे-संदर्भ प्रसंस्करण में एक महत्वपूर्ण प्रगति का प्रतिनिधित्व करता है। **DSA पहली बार सूक्ष्म-दानेदार विरल अटेंशन प्राप्त करता है, जो मॉडल आउटपुट गुणवत्ता को लगभग समान बनाए रखते हुए लंबे-संदर्भ प्रशिक्षण और अनुमान दक्षता में substantial improvements प्रदान करता है**[1]

## कोर आर्किटेक्चर: दो-घटक प्रणाली

DSA में दो प्राथमिक घटक शामिल हैं जो कुशल विरल अटेंशन प्राप्त करने के लिए एक साथ काम करते हैं:[2]

### 1. **Lightning Indexer**

Lightning indexer एक तेज़, हल्का स्कोरिंग तंत्र है जो वर्तमान क्वेरी के लिए ऐतिहासिक टोकन के महत्व का तेजी से मूल्यांकन करता है। **इंडेक्सर प्रति टोकन 128 आयामों की एक छोटी key cache रखता है**[3] (पारंपरिक अटेंशन में उपयोग की जाने वाली पूर्ण key-value cache की तुलना में)।

**यह कैसे काम करता है:**
- Lightning indexer वर्तमान क्वेरी टोकन और अनुक्रम में सभी पिछले टोकन के बीच प्रासंगिकता स्कोर की गणना करता है
- यह मेमोरी और कम्प्यूटेशनल आवश्यकताओं को नाटकीय रूप से कम करने के लिए संपीड़ित key representations (पूर्ण आयाम keys के बजाय 128 आयाम) का उपयोग करता है
- **हालांकि lightning indexer में अभी भी O(L²) complexity है, लेकिन इसे मुख्य अटेंशन तंत्र की तुलना में बहुत कम computation की आवश्यकता होती है**[4]
- इंडेक्सर टोकन को महत्व के आधार पर तेजी से रैंक करता है और शीर्ष-के सबसे प्रासंगिक टोकन की पहचान करता है

**मुख्य लाभ:** इंडेक्सर एक हल्के "pre-filter" के रूप में कार्य करता है जो पूर्ण अटेंशन गणना के बोझ के बिना लंबे संदर्भों को तेजी से स्कैन कर सकता है।

### 2. **सूक्ष्म-दानेदार टोकन चयन तंत्र**

Lightning indexer द्वारा महत्वपूर्ण टोकन की पहचान करने के बाद, सूक्ष्म-दानेदार चयन तंत्र वास्तविक विरल अटेंशन computation करता है:

- केवल शीर्ष-के सबसे प्रासंगिक टोकन (जैसा कि इंडेक्सर द्वारा निर्धारित) को पूर्ण अटेंशन computation प्राप्त होता है
- यह चयनात्मक प्रसंस्करण अटेंशन computation को O(n²) से लगभग O(nk) तक काफी कम कर देता है, जहाँ k चयनित टोकन की संख्या है (n से बहुत छोटा)
- **DSA ब्रूट-फोर्स दृष्टिकोण को चयनात्मक प्रसंस्करण के साथ प्रतिस्थापित करता है, जो प्रत्येक क्वेरी के लिए अतीत के टोकन को तेजी से स्कोर करने और पहचानने के लिए DeepSeek द्वारा "lightning indexer" कहलाने वाले तंत्र का उपयोग करता है कि कौन से टोकन सबसे अधिक मायने रखते हैं**[2]

## गणितीय जटिलता में कमी

पारंपरिक अटेंशन तंत्रों के लिए प्रत्येक टोकन और अन्य सभी टोकन के बीच संबंधों की गणना करने की आवश्यकता होती है, जिसके परिणामस्वरूप O(n²) कम्प्यूटेशनल जटिलता होती है। **DeepSeek Sparse Attention (DSA) core attention complexity को O(L²) से O(Lk) तक कम कर देता है, जहाँ k चयनित टोकन की संख्या है (L से बहुत छोटा)**[4]

यह इस बात में एक मौलिक बदलाव का प्रतिनिधित्व करता है कि अटेंशन की गणना कैसे की जाती है:
- **पारंपरिक पूर्ण अटेंशन:** प्रत्येक क्वेरी प्रत्येक key-value pair पर ध्यान देती है → O(n²)
- **DSA विरल अटेंशन:** प्रत्येक क्वेरी केवल शीर्ष-के सबसे प्रासंगिक pairs पर ध्यान देती है → O(nk)
- चूंकि k << n (k आमतौर पर एक छोटा स्थिरांक होता है या n की तुलना में बहुत धीमी गति से बढ़ता है), यह लगभग-रैखिक स्केलिंग प्राप्त करता है

## Multi-Latent Attention (MLA) के साथ एकीकरण

DSA, V3 मॉडल में उपयोग किए जाने वाले DeepSeek के मौजूदा Multi-Latent Attention (MLA) आर्किटेक्चर के साथ एकीकृत होता है। विरल अटेंशन तंत्र MLA के संपीड़ित key-value representations के शीर्ष पर काम करता है, जिससे एक दो-चरणीय संपीड़न रणनीति बनती है:

1. **पहला चरण (MLA):** key-value representations को lower-dimensional latent spaces में संपीड़ित करें
2. **दूसरा चरण (DSA):** केवल सबसे प्रासंगिक टोकन पर ध्यान देकर computation को और कम करें

यह दोहरा संपीड़न उन दक्षता लाभों को प्राप्त करता है जो न तो तकनीक अकेले प्राप्त कर सकती थी।[3]

## प्रदर्शन और दक्षता लाभ

DSA से दक्षता में सुधार कई आयामों में substantial हैं:

### **गति में सुधार:**
- लंबे-पाठ प्रसंस्करण के लिए **2-3× तेज अनुमान**[2]
- प्रशिक्षण और अनुमान दोनों चरणों में significant speedup
- विशेष रूप से 32K टोकन से अधिक के अनुक्रमों के लिए प्रभावी

### **मेमोरी में कमी:**
- संपीड़ित इंडेक्सर keys (128 आयाम) के कारण छोटी KV cache आवश्यकताएँ
- केवल चयनित टोकन के लिए पूर्ण अटेंशन संग्रहीत करता है
- समान मेमोरी बजट के भीतर लंबे संदर्भों के प्रसंस्करण को सक्षम बनाता है

### **लागत में कमी:**
दक्षता लाभ सीधे नाटकीय लागत कमी में तब्दील हो जाते हैं। **API मूल्य निर्धारण 50% से अधिक कम हो गया, इनपुट लागत $0.07/million tokens (cache hit) जितनी कम**[5]

**नया API मूल्य निर्धारण:**
- इनपुट: $0.14/M tokens (मानक), $0.07/M tokens (cache hit)
- आउटपुट: $0.42/M tokens
- यह V3.1-Terminus की तुलना में **50%+ reduction** का प्रतिनिधित्व करता है[6]

लागत में कमी दो कारकों से आती है:
1. विरल अटेंशन तंत्र कम्प्यूटेशनल लागतों को नाटकीय रूप से कम करते हैं
2. कैशिंग तंत्र की शुरुआत redundant computations को कम करती है[5]

## प्रदर्शन संरक्षण

DSA की एक महत्वपूर्ण उपलब्धि दक्षता लाभ प्राप्त करते हुए मॉडल गुणवत्ता को बनाए रखना है। विरल अटेंशन के प्रभाव का कठोरता से मूल्यांकन करने के लिए DeepSeek-V3.2-Exp को V3.1-Terminus के समान कॉन्फ़िगरेशन के साथ प्रशिक्षित किया गया था।

**बेंचमार्क परिणाम:**[1]

| बेंचमार्क | V3.1-Terminus | V3.2-Exp (DSA) |
|-----------|--------------|----------------|
| MMLU-Pro | 85.0 | 85.0 |
| GPQA-Diamond | 80.7 | 79.9 |
| LiveCodeBench | 74.9 | 74.1 |
| AIME 2025 | 88.4 | 89.3 |
| HMMT 2025 | 86.1 | 83.6 |

परिणाम दर्शाते हैं कि **V3.2-Exp सार्वजनिक बेंचमार्क में V3.1-Terminus के बराबर प्रदर्शन प्रदर्शित करता है**[1], कुछ कार्यों में तो सुधार भी दिखाई देता है। विरल अटेंशन तंत्र को सबसे महत्वपूर्ण अटेंशन कनेक्शनों को बनाए रखने के लिए सावधानीपूर्वक डिजाइन किया गया है, इसलिए आउटपुट गुणवत्ता पर प्रभाव न्यूनतम है।

## DSA अन्य विरल अटेंशन विधियों से कैसे भिन्न है

### **सूक्ष्म-दानेदार बनाम मोटे-दानेदार:**
अधिकांश पिछली विरल अटेंशन विधियाँ मोटे-दानेदार पैटर्न (fixed patterns, local windows, strided attention) का उपयोग करती हैं। DSA सामग्री प्रासंगिकता के आधार पर गतिशील रूप से किन विशिष्ट टोकन पर ध्यान देना है, यह सीखकर **सूक्ष्म-दानेदार** विरलता प्राप्त करता है।

### **सीखा हुआ चयन:**
निश्चित विरल पैटर्न के विपरीत, DSA lightning indexer के माध्यम से महत्व स्कोरिंग सीखता है, जो वास्तविक शब्दार्थ संबंधों पर प्रतिक्रिया देने वाले अनुकूली अटेंशन पैटर्न की अनुमति देता है।

### **हार्डवेयर-अनुकूलित:**
DSA को शुरू से ही आधुनिक GPU हार्डवेयर पर कुशल होने के लिए डिजाइन किया गया है, कुछ विरल विधियों के विपरीत जो सैद्धांतिक लाभ दिखाती हैं लेकिन सीमित वास्तविक दुनिया की गति।

### **प्रशिक्षण योग्य विरलता:**
विरल अटेंशन पैटर्न प्रशिक्षण के दौरान सीखा जाता है (natively trainable), न कि केवल अनुमान के समय लागू किया जाता है, जो बेहतर अनुकूलन की अनुमति देता है।

## तकनीकी कार्यान्वयन

DSA कार्यान्वयन के लिए इष्टतम प्रदर्शन के लिए विशेष CUDA kernels की आवश्यकता होती है:

- तेज शीर्ष-के चयन के लिए **इंडेक्सर kernels** (DeepGEMM में उपलब्ध)
- चयनित टोकन पर कुशल computation के लिए **विरल अटेंशन kernels** (FlashMLA में उपलब्ध)
- मेमोरी दक्षता के लिए paged attention के लिए समर्थन
- मौजूदा अनुमान फ्रेमवर्क (vLLM, SGLang) के साथ एकीकरण[1]

## उपयोग के मामले और लाभ

DSA विशेष रूप से उन परिदृश्यों में उत्कृष्ट प्रदर्शन करता है जिनके लिए आवश्यकता होती है:

1. **लंबे-संदर्भ प्रसंस्करण** (64K+ टोकन): दस्तावेज़ विश्लेषण, कोड समझ, बहु-चरण वार्तालाप
2. **उच्च-थ्रूपुट अनुप्रयोग**: जहाँ लागत और गति महत्वपूर्ण हैं
3. **मेमोरी-सीमित तैनाती**: जहाँ KV cache आकार एक बाधा है
4. **रीयल-टाइम अनुप्रयोग**: जहाँ अनुमान विलंबता मायने रखती है

## रणनीतिक महत्व

**DeepSeek-V3.2-Exp अगली पीढ़ी के आर्किटेक्चर की ओर एक मध्यवर्ती कदम के रूप में कार्य करता है**[1], विशेष रूप से DeepSeek-V4 के लिए आधार तैयार करता है। प्रायोगिक रिलीज़ DeepSeek को यह करने की अनुमति देती है:

- पैमाने पर विरल अटेंशन तंत्र को मान्य करें
- वास्तविक दुनिया का प्रदर्शन डेटा एकत्र करें
- पूर्ण तैनाती से पहले दृष्टिकोण को परिष्कृत करें
- उत्पादन प्रणालियों के साथ एकीकरण का परीक्षण करें

## सीमाएँ और विचार

जबकि DSA महत्वपूर्ण लाभ प्रदान करता है, कुछ विचार हैं:

1. **जटिलता:** मानक अटेंशन की तुलना में अधिक जटिल कार्यान्वयन
2. **छोटे अनुक्रमों के लिए ओवरहेड:** बहुत छोटे संदर्भों के लिए इंडेक्सर ओवरहेड फायदेमंद नहीं हो सकता है
3. **अनुमानित व्यापार-नापसंद:** जबकि गुणवत्ता संरक्षित है, कुछ सूचना हानि सैद्धांतिक रूप से संभव है
4. **हार्डवेयर आवश्यकताएँ:** सर्वोत्तम प्रदर्शन के लिए अनुकूलित kernels की आवश्यकता होती है

## भविष्य के निहितार्थ

DSA एलएलएम आर्किटेक्चर के लिए एक महत्वपूर्ण विकासवादी दिशा का प्रतिनिधित्व करता है। यह साबित करके कि चयनात्मक अटेंशन दक्षता में नाटकीय रूप से सुधार करते हुए गुणवत्ता बनाए रख सकता है, यह संभावनाएं खोलता है:

- और भी लंबे संदर्भों (1M+ टोकन) का प्रसंस्करण
- अधिक किफायती AI सेवाएं
- कम शक्तिशाली हार्डवेयर पर तैनाती
- जटिल दस्तावेजों का रीयल-टाइम प्रसंस्करण

यह प्रौद्योगिकी DeepSeek को अन्य frontier मॉडलों के खिलाफ प्रतिस्पर्धात्मक रूप से स्थिति देती है, साथ ही परिचालन लागतों को काफी कम करती है, संभावित रूप से AI API बाजार मूल्य निर्धारण संरचना को बाधित करती है।[7]

संक्षेप में, DeepSeek Sparse Attention (DSA) एक परिष्कृत दो-चरणीय तंत्र है जो तेजी से टोकन महत्व स्कोरिंग के लिए एक हल्के lightning indexer को सूक्ष्म-दानेदार चयनात्मक अटेंशन computation के साथ जोड़ता है। यह उल्लेखनीय दक्षता लाभ (50%+ लागत में कमी, 2-3× गति सुधार) प्राप्त करता है, जबकि मॉडल गुणवत्ता को बनाए रखता है, जो लंबे-संदर्भ एलएलएम को व्यावहारिक और आर्थिक रूप से व्यवहार्य बनाने में एक महत्वपूर्ण प्रगति का प्रतिनिधित्व करता है।

उद्धरण:
[1] https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp
[2] https://medium.com/@Techsankar381/deepseek-halves-ai-tooling-costs-with-breakthrough-sparse-attention-model-3840fb61a4e0
[3] https://x.com/vllm_project/status/1972617272901644345
[4] https://blogs.novita.ai/deepseek-v3-2-exp-on-novita-ai/
[5] https://dev.to/czmilo/deepseek-v32-exp-complete-analysis-2025-ai-model-breakthrough-and-in-depth-analysis-of-sparse-3gcl
[6] https://api-docs.deepseek.com/news/news250929
[7] https://www.implicator.ai/deepseek-cuts-inference-costs-by-10x/