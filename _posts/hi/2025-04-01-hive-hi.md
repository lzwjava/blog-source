---
audio: false
generated: true
lang: hi
layout: post
title: अपाचे हाइव
translated: true
type: note
---

Apache Hive एक शक्तिशाली ओपन-सोर्स डेटा वेयरहाउस सिस्टम है जो Hadoop के ऊपर बनाया गया है। यह एक SQL-जैसा इंटरफेस प्रदान करता है, जिसे Hive Query Language (HQL) कहा जाता है, ताकि Hadoop Distributed File System (HDFS) या क्लाउड-आधारित ऑब्जेक्ट स्टोर जैसे वितरित स्टोरेज सिस्टम में रखे बड़े डेटासेट को क्वेरी और विश्लेषित किया जा सके। Hive इन HQL क्वेरीज़ को MapReduce या Tez या Spark जैसे अन्य एक्ज़िक्यूशन फ्रेमवर्क में ट्रांसलेट कर देता है, जिससे स्केलेबल डेटा प्रोसेसिंग संभव होती है।

यहाँ Apache Hive की एक व्यापक गाइड दी गई है:

**1. Hive का परिचय:**

* **उद्देश्य:** Hive एक परिचित SQL-जैसा इंटरफेस प्रदान करके बड़े पैमाने के डेटासेट को क्वेरी और विश्लेषित करने की प्रक्रिया को सरल बनाता है। यह अंतर्निहित वितरित प्रोसेसिंग फ्रेमवर्क की जटिलताओं को छुपा देता है।
* **रीड पर स्कीमा:** पारंपरिक रिलेशनल डेटाबेस के विपरीत, जो राइट पर स्कीमा लागू करते हैं, Hive "रीड पर स्कीमा" सिद्धांत पर काम करता है। इसका मतलब है कि आप अपने डेटा की संरचना तब परिभाषित करते हैं जब आप उसे क्वेरी करते हैं, जो विविध और विकसित हो रहे डेटासेट को हैंडल करने में लचीलापन प्रदान करता है।
* **डेटा वेयरहाउस सिस्टम:** Hive को ऑनलाइन एनालिटिकल प्रोसेसिंग (OLAP) वर्कलोड के लिए डिज़ाइन किया गया है, जो ट्रांजैक्शनल ऑपरेशन्स (OLTP) के बजाय डेटा सारांशीकरण, एकत्रीकरण और विश्लेषण पर केंद्रित है।
* **स्केलेबिलिटी और फॉल्ट टॉलरेंस:** Hadoop पर बना होने के कारण, Hive इसकी स्केलेबिलिटी और फॉल्ट टॉलरेंस क्षमताओं को विरासत में लेता है, जो इसे कमोडिटी हार्डवेयर के बड़े क्लस्टर पर पेटाबाइट्स डेटा प्रोसेस करने की अनुमति देता है।

**2. Hive आर्किटेक्चर और कंपोनेंट्स:**

* **Hive क्लाइंट्स:** ये वे इंटरफेस हैं जिनके माध्यम से उपयोगकर्ता Hive के साथ इंटरैक्ट करते हैं। सामान्य क्लाइंट्स में शामिल हैं:
    * **Beeline:** HQL क्वेरीज़ को एक्ज़िक्यूट करने के लिए एक कमांड-लाइन इंटरफेस (CLI)। यह पुराने Hive CLI के मुकाबले प्राथमिकता दी जाती है, खासकर HiveServer2 के लिए।
    * **HiveServer2:** एक सर्वर जो एक साथ कनेक्ट होने और क्वेरीज़ एक्ज़िक्यूट करने के लिए कई क्लाइंट्स (JDBC, ODBC, Thrift) की अनुमति देता है। यह अपने पूर्ववर्ती, HiveServer1 की तुलना में बेहतर सुरक्षा प्रदान करता है और अधिक उन्नत फीचर्स का समर्थन करता है।
    * **WebHCat:** Hive मेटास्टोर तक पहुंचने और Hive क्वेरीज़ एक्ज़िक्यूट करने के लिए एक REST API।
* **Hive सर्विसेज:** ये मुख्य कंपोनेंट्स हैं जो Hive फंक्शनैलिटी को सक्षम बनाते हैं:
    * **मेटास्टोर:** एक केंद्रीय रिपॉजिटरी जो Hive टेबल्स के बारे में मेटाडेटा स्टोर करती है, जैसे कि उनकी स्कीमा (कॉलम नाम और डेटा टाइप), HDFS में लोकेशन, और अन्य प्रॉपर्टीज। यह आमतौर पर इस मेटाडेटा को संग्रहीत करने के लिए एक रिलेशनल डेटाबेस (जैसे, MySQL, PostgreSQL) का उपयोग करती है।
    * **ड्राइवर:** क्लाइंट्स से HQL क्वेरीज़ प्राप्त करता है, उन्हें पार्स करता है, और कंपाइलेशन और एक्ज़िक्यूशन प्रक्रिया शुरू करता है।
    * **कंपाइलर:** HQL क्वेरी का विश्लेषण करता है, सिमेंटिक चेक करता है, और एक एक्ज़िक्यूशन प्लान (टास्क्स का एक निर्देशित एसाइक्लिक ग्राफ) जनरेट करता है।
    * **ऑप्टिमाइज़र:** विभिन्न ट्रांसफॉर्मेशन लागू करके बेहतर परफॉर्मेंस के लिए एक्ज़िक्यूशन प्लान को ऑप्टिमाइज़ करता है, जैसे जॉइन्स को दोबारा ऑर्डर करना, उपयुक्त जॉइन स्ट्रैटेजी चुनना, और बहुत कुछ। कॉस्ट-बेस्ड ऑप्टिमाइज़ेशन (CBO) डेटा के बारे में स्टैटिस्टिक्स का उपयोग अधिक सूचित ऑप्टिमाइज़ेशन निर्णय लेने के लिए करता है।
    * **एक्ज़िक्यूशन इंजन:** एक्ज़िक्यूशन प्लान में टास्क्स को एक्ज़िक्यूट करता है। डिफ़ॉल्ट रूप से, Hive MapReduce का उपयोग करता है, लेकिन यह Tez या Spark जैसे अन्य इंजन का भी लाभ उठा सकता है, जो अक्सर महत्वपूर्ण परफॉर्मेंस सुधार प्रदान करते हैं।
    * **थ्रिफ्ट सर्वर:** Apache Thrift फ्रेमवर्क का उपयोग करके Hive क्लाइंट्स और Hive सर्वर के बीच कम्युनिकेशन सक्षम करता है।
* **प्रोसेसिंग फ्रेमवर्क और रिसोर्स मैनेजमेंट:** Hive क्लस्टर पर क्वेरीज़ एक्ज़िक्यूट करने के लिए एक वितरित प्रोसेसिंग फ्रेमवर्क (आमतौर पर MapReduce, Tez, या Spark) और एक रिसोर्स मैनेजमेंट सिस्टम (जैसे Hadoop में YARN) पर निर्भर करता है।
* **वितरित स्टोरेज:** Hive मुख्य रूप से टेबल्स के वास्तविक डेटा को स्टोर करने के लिए HDFS का उपयोग करता है। यह Amazon S3, Azure Blob Storage, और Alluxio जैसे अन्य स्टोरेज सिस्टम के साथ भी इंटरैक्ट कर सकता है।

**3. Hive Query Language (HQL):**

* **SQL-जैसी सिंटैक्स:** HQL की सिंटैक्स स्टैंडर्ड SQL से बहुत मिलती-जुलती है, जिससे रिलेशनल डेटाबेस से परिचित उपयोगकर्ताओं के लिए Hive को सीखना और उपयोग करना आसान हो जाता है।
* **डेटा डेफिनिशन लैंग्वेज (DDL):** HQL डेटाबेस ऑब्जेक्ट्स को परिभाषित और प्रबंधित करने के लिए कमांड प्रदान करती है:
    * `CREATE DATABASE`: एक नया डेटाबेस बनाता है (टेबल्स के लिए एक नेमस्पेस)।
    * `DROP DATABASE`: एक डेटाबेस और उसकी सभी टेबल्स को डिलीट करता है।
    * `CREATE TABLE`: एक नई टेबल को परिभाषित करता है, उसकी स्कीमा, स्टोरेज फॉर्मेट और लोकेशन निर्दिष्ट करता है। आप या तो **मैनेज्ड टेबल्स** (जहां Hive डेटा लाइफसाइकल को नियंत्रित करता है) या **एक्सटर्नल टेबल्स** (जहां डेटा बाहरी रूप से प्रबंधित होता है, और Hive केवल मेटाडेटा प्रबंधित करता है) बना सकते हैं।
    * `DROP TABLE`: एक टेबल और उससे जुड़े डेटा को डिलीट करता है (मैनेज्ड टेबल्स के लिए) या केवल मेटाडेटा (एक्सटर्नल टेबल्स के लिए)।
    * `ALTER TABLE`: किसी मौजूदा टेबल की स्कीमा या प्रॉपर्टीज को संशोधित करता है (जैसे, कॉलम जोड़ना/हटाना, टेबल का नाम बदलना, स्टोरेज फॉर्मेट बदलना)।
    * `CREATE VIEW`: किसी क्वेरी के परिणाम के आधार पर एक वर्चुअल टेबल बनाता है।
* **डेटा मैनिपुलेशन लैंग्वेज (DML):** HQL में टेबल्स में डेटा लोड करने और डेटा को क्वेरी करने के लिए कमांड शामिल हैं:
    * `LOAD DATA INPATH`: किसी निर्दिष्ट स्रोत (लोकल फाइल सिस्टम या HDFS) से डेटा को Hive टेबल में कॉपी करता है।
    * `INSERT INTO`: मौजूदा टेबल में नई पंक्तियाँ डालता है (अक्सर `SELECT` क्वेरी का परिणाम)।
    * `SELECT`: निर्दिष्ट शर्तों के आधार पर एक या अधिक टेबल्स से डेटा पुनर्प्राप्त करता है। यह विभिन्न क्लॉज जैसे `WHERE`, `GROUP BY`, `HAVING`, `ORDER BY`, `SORT BY`, `CLUSTER BY`, और `DISTRIBUTE BY` का समर्थन करता है।
    * **जॉइन्स:** Hive कई टेबल्स के डेटा को संयोजित करने के लिए विभिन्न प्रकार के जॉइन्स (INNER JOIN, LEFT OUTER JOIN, RIGHT OUTER JOIN, FULL OUTER JOIN) का समर्थन करता है। छोटी टेबल्स के लिए मैप-साइड जॉइन परफॉर्मेंस में काफी सुधार कर सकते हैं।
* **फंक्शंस:** Hive डेटा मैनिपुलेशन, एग्रीगेशन, और बहुत कुछ के लिए बिल्ट-इन फंक्शंस का एक समृद्ध सेट प्रदान करता है। आप Hive की फंक्शनैलिटी को बढ़ाने के लिए **यूजर-डिफाइंड फंक्शंस (UDFs)**, **यूजर-डिफाइंड एग्रीगेट फंक्शंस (UDAFs)**, और **यूजर-डिफाइंड टेबल-जनरेटिंग फंक्शंस (UDTFs)** भी बना सकते हैं।

**4. Hive डेटा टाइप्स और फॉर्मेट्स:**

* **प्रिमिटिव डेटा टाइप्स:**
    * न्यूमेरिक: `TINYINT`, `SMALLINT`, `INT`, `BIGINT`, `FLOAT`, `DOUBLE`, `DECIMAL`.
    * स्ट्रिंग: `STRING`, `VARCHAR`, `CHAR`.
    * बूलियन: `BOOLEAN`.
    * डेट और टाइम: `TIMESTAMP`, `DATE`, `INTERVAL` (बाद के वर्जन में उपलब्ध)।
    * बाइनरी: `BINARY`.
* **कॉम्प्लेक्स डेटा टाइप्स:**
    * `ARRAY`: एक ही प्रकार के एलिमेंट्स की एक क्रमबद्ध सूची (जैसे, `ARRAY<STRING>`)।
    * `MAP`: की-वैल्यू पेयर्स का एक संग्रह जहां कीज़ एक प्रिमिटिव प्रकार के होते हैं और वैल्यूज़ किसी भी प्रकार की हो सकती हैं (जैसे, `MAP<STRING, INT>`)।
    * `STRUCT`: नामित फील्ड्स के एक निश्चित सेट के साथ एक रिकॉर्ड प्रकार, जिनमें से प्रत्येक का अपना प्रकार होता है (जैसे, `STRUCT<first_name:STRING, last_name:STRING, age:INT>`)।
    * `UNION`: एक प्रकार जो कई निर्दिष्ट डेटा टाइप्स में से एक का मान रख सकता है।
* **डेटा फॉर्मेट्स:** Hive विभिन्न डेटा स्टोरेज फॉर्मेट्स का समर्थन करता है:
    * **टेक्स्ट फाइल्स:** डिलिमिटर्स के साथ प्लेन टेक्स्ट डेटा (जैसे, CSV, TSV)। `ROW FORMAT DELIMITED FIELDS TERMINATED BY ...` का उपयोग करके परिभाषित किया गया।
    * **सीक्वेंस फाइल्स:** एक बाइनरी फाइल फॉर्मेट जो डेटा को की-वैल्यू पेयर्स में स्टोर करता है।
    * **RCFile (रिकॉर्ड कॉलमनर फाइल):** एक कॉलमनर स्टोरेज फॉर्मेट जो रीड-हैवी वर्कलोड के लिए क्वेरी परफॉर्मेंस में सुधार करता है।
    * **ORC (ऑप्टिमाइज़्ड रो कॉलमनर):** एक अत्यधिक ऑप्टिमाइज़्ड कॉलमनर स्टोरेज फॉर्मेट जो RCFile की तुलना में बेहतर कम्प्रेशन और क्वेरी परफॉर्मेंस प्रदान करता है। यह अक्सर अनुशंसित फॉर्मेट होता है।
    * **Parquet:** एक और लोकप्रिय कॉलमनर स्टोरेज फॉर्मेट जो अपने कुशल डेटा कम्प्रेशन और एन्कोडिंग स्कीम्स के लिए जाना जाता है, जो इसे एनालिटिकल क्वेरीज़ के लिए उपयुक्त बनाता है।
    * **Avro:** JSON में परिभाषित स्कीमा के साथ एक रो-बेस्ड स्टोरेज फॉर्मेट, जो स्कीमा इवोल्यूशन क्षमताएं प्रदान करता है।
    * **JSON:** जावास्क्रिप्ट ऑब्जेक्ट नोटेशन फॉर्मेट में संग्रहीत डेटा।

**5. Hive इंस्टालेशन और कॉन्फ़िगरेशन:**

* **पूर्वापेक्षाएँ:** आमतौर पर, आपको एक चल रहे Hadoop क्लस्टर (HDFS और YARN) और Java Development Kit (JDK) इंस्टॉल की आवश्यकता होती है।
* **इंस्टालेशन विधियाँ:**
    * **टारबॉल से:** एक पूर्व-निर्मित बाइनरी पैकेज डाउनलोड करें, इसे एक्सट्रैक्ट करें, और एनवायरनमेंट वेरिएबल्स (`HIVE_HOME`, `PATH`) को कॉन्फ़िगर करें।
    * **सोर्स से:** सोर्स कोड डाउनलोड करें और Apache Maven का उपयोग करके Hive बिल्ड करें।
* **कॉन्फ़िगरेशन:** प्राथमिक कॉन्फ़िगरेशन फाइल `hive-site.xml` है, जो `conf` डायरेक्टरी में स्थित है। मुख्य कॉन्फ़िगरेशन प्रॉपर्टीज में शामिल हैं:
    * `javax.jdo.option.ConnectionURL`, `javax.jdo.option.ConnectionDriverName`, `javax.jdo.option.ConnectionUserName`, `javax.jdo.option.ConnectionPassword`: Hive मेटास्टोर डेटाबेस से कनेक्शन कॉन्फ़िगर करें।
    * `hive.metastore.warehouse.dir`: मैनेज्ड टेबल डेटा के लिए HDFS में डिफ़ॉल्ट लोकेशन निर्दिष्ट करता है।
    * `hive.exec.engine`: उपयोग करने के लिए एक्ज़िक्यूशन इंजन सेट करता है (जैसे, MapReduce के लिए `mr`, `tez`, `spark`)।
    * `hive.server2.thrift.http.port` (HTTP मोड के लिए) या `hive.server2.thrift.port` (बाइनरी मोड के लिए): HiveServer2 के लिए पोर्ट कॉन्फ़िगर करता है।
    * `hive.metastore.uris`: रिमोट मेटास्टोर मोड में चल रहा हो तो मेटास्टोर सर्वर(s) का URI(s) निर्दिष्ट करता है।
* **मेटास्टोर सेटअप:** आपको कॉन्फ़िगर किए गए डेटाबेस में मेटास्टोर स्कीमा को इनिशियलाइज़ करने की आवश्यकता है। यह आमतौर पर Hive के साथ प्रदान किए गए `schematool` कमांड का उपयोग करके किया जाता है।

**6. Hive परफॉर्मेंस ट्यूनिंग और ऑप्टिमाइज़ेशन:**

* **एक्ज़िक्यूशन इंजन चयन:** MapReduce की तुलना में Tez या Spark का उपयोग एक्ज़िक्यूशन इंजन के रूप में करने से परफॉर्मेंस में काफी सुधार हो सकता है, खासकर जटिल क्वेरीज़ के लिए।
* **डेटा फॉर्मेट ऑप्टिमाइज़ेशन:** ORC या Parquet जैसे कॉलमनर फॉर्मेट्स चुनने से बेहतर कम्प्रेशन रेश्यो और कम I/O के कारण तेज़ क्वेरी एक्ज़िक्यूशन हो सकता है।
* **पार्टीशनिंग:** अक्सर क्वेरी किए जाने वाले कॉलम (जैसे, तारीख, क्षेत्र) के आधार पर टेबल्स को छोटे, अधिक प्रबंधनीय भागों में विभाजित करने से Hive क्वेरी एक्ज़िक्यूशन के दौरान अनावश्यक डेटा को छाँट सकता है, जिससे परफॉर्मेंस में सुधार होता है। स्टैटिक और डायनामिक पार्टीशनिंग उपलब्ध हैं।
* **बकेटिंग:** किसी कॉलम के हैश के आधार पर पार्टीशन्स को आगे बकेट्स में विभाजित करने से जॉइन्स और सैंपलिंग की दक्षता में सुधार हो सकता है।
* **इंडेक्सिंग:** अक्सर फ़िल्टर किए जाने वाले कॉलम पर इंडेक्स बनाने से क्वेरी एक्ज़िक्यूशन की गति बढ़ सकती है। Hive कॉम्पैक्ट और बिटमैप इंडेक्स जैसे विभिन्न प्रकार के इंडेक्स का समर्थन करता है।
* **कॉस्ट-बेस्ड ऑप्टिमाइज़ेशन (CBO):** CBO को सक्षम करने से Hive डेटा स्टैटिस्टिक्स के आधार पर अधिक कुशल एक्ज़िक्यूशन प्लान जनरेट कर सकता है। स्टैटिस्टिक्स एकत्र करने के लिए `ANALYZE TABLE` कमांड का उपयोग करें।
* **वेक्टराइज़ेशन:** वेक्टराइज़्ड क्वेरी एक्ज़िक्यूशन को सक्षम करने से डेटा को बैचों में प्रोसेस किया जाता है, जिससे स्कैन, एग्रीगेशन और फ़िल्टर जैसे ऑपरेशन्स की परफॉर्मेंस में सुधार होता है।
* **मैप-साइड जॉइन्स:** छोटी टेबल वाले जॉइन्स के लिए, Hive मैप साइड पर जॉइन कर सकता है, जिससे शफल चरण से बचा जा सकता है और परफॉर्मेंस में सुधार होता है। `hive.auto.convert.join` और संबंधित प्रॉपर्टीज को कॉन्फ़िगर करें।
* **पैरेलल एक्ज़िक्यूशन:** `hive.exec.parallel` को `true` पर सेट करके Hive को स्वतंत्र टास्क्स को समानांतर रूप से एक्ज़िक्यूट करने की अनुमति दें।
* **जॉइन ऑप्टिमाइज़ेशन:** Hive स्वचालित रूप से जॉइन्स के क्रम को ऑप्टिमाइज़ करता है। आप जॉइन स्ट्रैटेजी को प्रभावित करने के लिए हिंट्स भी प्रदान कर सकते हैं।
* **अनावश्यक डेटा रिट्रीवल से बचें:** प्रोसेस किए गए डेटा की मात्रा को कम करने के लिए `SELECT *` के बजाय विशिष्ट कॉलम के साथ `SELECT` का उपयोग करें। सैंपलिंग या टेस्टिंग के लिए लौटाई गई पंक्तियों की संख्या को प्रतिबंधित करने के लिए `LIMIT` का उपयोग करें।
* **स्क्यूड डेटा हैंडलिंग:** यदि जॉइन या एग्रीगेशन कीज़ में डेटा असमान रूप से वितरित (स्क्यूड) है, तो इससे परफॉर्मेंस बॉटलनेक हो सकते हैं। Hive स्क्यूड जॉइन्स और एग्रीगेशन को हैंडल करने के लिए मैकेनिज्म प्रदान करता है।
* **रिसोर्स ट्यूनिंग:** Hive और अंतर्निहित एक्ज़िक्यूशन इंजन (जैसे, कंटेनर्स के लिए मेमोरी) को आवंटित संसाधनों को समायोजित करने से परफॉर्मेंस प्रभावित हो सकती है।

**7. Hive यूज़ केस और उदाहरण:**

* **डेटा वेयरहाउसिंग:** स्ट्रक्चर्ड और सेमी-स्ट्रक्चर्ड डेटा की बड़ी मात्रा को स्टोर और विश्लेषित करने के लिए एक स्केलेबल डेटा वेयरहाउस बनाना।
* **बिजनेस इंटेलिजेंस (BI):** बिजनेस निर्णय लेने के लिए अंतर्दृष्टि प्राप्त करने के लिए डेटा सारांशीकरण, रिपोर्टिंग और विश्लेषण करना। Hive विभिन्न BI टूल्स जैसे Tableau, Power BI, और Looker के साथ इंटीग्रेट होता है।
* **ETL (एक्सट्रैक्ट, ट्रांसफॉर्म, लोड):** डाउनस्ट्रीम विश्लेषण के लिए या अन्य सिस्टम में लोड करने के लिए बड़े डेटासेट को ट्रांसफॉर्म और तैयार करना।
* **लॉग एनालिसिस:** रुझानों, पैटर्न और विसंगतियों की पहचान करने के लिए वेब सर्वर लॉग्स, एप्लिकेशन लॉग्स और अन्य मशीन-जनरेटेड डेटा का विश्लेषण करना।
* **क्लिकस्ट्रीम एनालिसिस:** उपयोगकर्ता व्यवहार को समझने के लिए वेबसाइटों या एप्लिकेशन पर उपयोगकर्ता इंटरैक्शन का विश्लेषण करना।
* **फाइनेंशियल एनालिसिस:** फ्रॉड डिटेक्शन, रिस्क मैनेजमेंट और अन्य उद्देश्यों के लिए बड़े पैमाने के फाइनेंशियल डेटा का विश्लेषण करना।
* **मशीन लर्निंग डेटा प्रीप्रोसेसिंग:** मशीन लर्निंग मॉडल को ट्रेन करने के लिए बड़े डेटासेट को तैयार और ट्रांसफॉर्म करना।

**उदाहरण HQL क्वेरीज़:**

```sql
-- 'mydatabase' नामक एक डेटाबेस बनाएँ
CREATE DATABASE IF NOT EXISTS mydatabase;

-- 'mydatabase' का उपयोग करें
USE mydatabase;

-- 'users' नामक एक एक्सटर्नल टेबल बनाएँ
CREATE EXTERNAL TABLE IF NOT EXISTS users (
    user_id INT,
    username STRING,
    age INT,
    country STRING
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/hdfs/user/hive/warehouse/users';

-- एक HDFS पथ से 'users' टेबल में डेटा लोड करें
LOAD DATA INPATH '/hdfs/raw_data/user_data.csv' INTO TABLE users;

-- एक विशिष्ट देश के उपयोगकर्ताओं को क्वेरी करें
SELECT user_id, username, age
FROM users
WHERE country = 'China';

-- देश द्वारा उपयोगकर्ताओं को ग्रुप करें और प्रत्येक देश में उपयोगकर्ताओं की संख्या गिनें
SELECT country, COUNT(*) AS user_count
FROM users
GROUP BY country
ORDER BY user_count DESC;

-- 'order_date' द्वारा पार्टीशन की गई 'orders' नामक एक पार्टीशन्ड टेबल बनाएँ
CREATE TABLE IF NOT EXISTS orders (
    order_id INT,
    user_id INT,
    product STRING,
    amount DOUBLE
)
PARTITIONED BY (order_date DATE)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';

-- 'orders' टेबल के एक विशिष्ट पार्टीशन में डेटा लोड करें
LOAD DATA INPATH '/hdfs/raw_data/orders_2025-03-31.csv' INTO TABLE orders PARTITION (order_date='2025-03-31');

-- एक विशिष्ट तारीख के लिए ऑर्डर क्वेरी करें
SELECT order_id, user_id, product, amount
FROM orders
WHERE order_date = '2025-03-31';
```

यह गाइड Apache Hive का एक व्यापक अवलोकन प्रदान करती है। इसकी आर्किटेक्चर, क्वेरी लैंग्वेज, डेटा हैंडलिंग क्षमताओं और ऑप्टिमाइज़ेशन तकनीकों को समझकर, आप अपने बिग डेटा प्रोजेक्ट्स में बड़े पैमाने के डेटा विश्लेषण के लिए Hive का प्रभावी ढंग से लाभ उठा सकते हैं। नवीनतम जानकारी और उन्नत फीचर्स के लिए आधिकारिक Apache Hive डॉक्यूमेंटेशन से परामर्श करना याद रखें।