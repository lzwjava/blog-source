---
audio: false
generated: false
image: false
lang: hi
layout: post
title: डीपसीक वी3 के बारे में एक एआई-जनित वार्तालाप
translated: true
---

यहां DeepSeek v3 का अध्ययन किया गया है, जिसमें "Deepseek v3 में मल्टी-हेड लेटेंट अटेंशन और मल्टी-टोकन प्रेडिक्शन" वीडियो [https://youtu.be/jL49fLOJYNg?si=4uE2kfe-BlKC1ngO](https://youtu.be/jL49fLOJYNg?si=4uE2kfe-BlKC1ngO) का संदर्भ दिया गया है। वीडियो का ट्रांसक्रिप्शन करने के लिए Google Cloud Speech-to-Text का उपयोग किया गया, साथ ही ट्रांसक्रिप्ट को व्यवस्थित करने के लिए कुछ कोड भी लिखा गया।

---

ए: डीप टैग में वापस स्वागत है। आज हम लार्ज लैंग्वेज मॉडल्स की दुनिया में गहराई से उतरने वाले हैं। खासकर, DeepSeek V3 में।

बी: अच्छा लगा। यह 671 बिलियन पैरामीटर्स वाला मॉडल है, जो अपनी कुशलता और प्रदर्शन के लिए चर्चा में है, है न?

ए: और आपने इसकी आर्किटेक्चर को विस्तार से समझाते हुए एक अकादमिक पेपर साझा किया।

बी: हां।

ए: और मशीन लर्निंग विशेषज्ञ के रूप में, आप यह समझना चाहते हैं कि DeepSeek V3 कैसे उच्च प्रदर्शन और किफायती ट्रेनिंग दोनों प्रदान करता है।

बी: हां, बिल्कुल सही।

ए: अरे, हाय, क्या चल रहा है?

सी: एमएलए, विवरण, एमएलए और यह कैसे काम करता है।

ए: अरे, बिल्कुल। यह एक बढ़िया विचार है। हां, हम निश्चित रूप से मल्टी-हेड लेटेंट अटेंशन (MLA) के बारे में गहराई से समझ सकते हैं। तो आप MLA के तकनीकी पहलुओं के बारे में जानना चाहते हैं। खैर, इसे समझते हैं। हमने बताया था कि DeepSeek V3 की कुशलता का एक मुख्य कारण इसका मिश्रित विशेषज्ञ (Mixture of Experts, MoE) आर्किटेक्चर है, है न? जहां प्रत्येक टोकन के लिए पैरामीटर्स का केवल एक भाग सक्रिय होता है। और DeepSeek V3 MLA और DeepSeek Mo के साथ इसे और आगे ले जाता है।

बी: हां, बिल्कुल सही। तो चलो अभी MLA पर फोकस करते हैं।

ए: ठीक है। तो रियल-टाइम एप्लिकेशन्स में स्पीड बहुत महत्वपूर्ण है।

बी: है। और इनफेरेंस के दौरान आवश्यक की-वैल्यू कैश एक बड़ा बॉटलनेक हो सकता है।

ए: बिल्कुल। यहीं पर MLA काम आता है। ठीक है, तो पारंपरिक अटेंशन मैकेनिज्म में पिछले टोकन्स के बारे में बहुत सारी जानकारी स्टोर करनी पड़ती है।

बी: हां, जिसकी कल्पना आप कर सकते हैं, लंबे टेक्स्ट सीक्वेंस के साथ यह एक समस्या बन जाता है, है न?

ए: लेकिन MLA इस जानकारी को चालाकी से कंप्रेस करता है, ठीक है, जिससे कैश फ्लो काफी कम हो जाता है और इनफेरेंस बहुत तेज हो जाता है। यह ऐसे है जैसे एक भारी-भरकम विश्वकोश को संक्षिप्त करके केवल मुख्य बिंदुओं तक सीमित कर दिया जाए।

बी: यह एक बेहतरीन उदाहरण है। यह आवश्यक जानकारी को बरकरार रखता है, बिना अनावश्यक भार के। हां, तो यह रियल-टाइम एप्लिकेशन्स के लिए बहुत उपयोगी है।

ए: हां। अब बात करते हैं कि यह वास्तव में कैसे काम करता है। ठीक है, तो MLA यह कंप्रेशन कैसे हासिल करता है?

बी: खैर, यह अटेंशन कीज और वैल्यूज के लिए लो-रैंक जॉइंट कंप्रेशन का उपयोग करता है।

ए: ठीक है, तो यह कीज और वैल्यूज को कंप्रेस कर रहा है, लेकिन इसका सटीक अर्थ क्या है? चलो थोड़ा तकनीकी होते हैं। ठीक है, MLA मैकेनिज्म एक इनपुट हिडन रिप्रेजेंटेशन लेता है, जिसे वह क्वेरी, की और वैल्यू वेक्टर्स में प्रोजेक्ट करता है। ठीक है, अब यहाँ यह दिलचस्प हो जाता है। MLA क्वेरी को दो हिस्सों में डिकपल करता है।

बी: ठीक है, दो हिस्सों में?

ए: हां। एक हिस्सा कंटेंट के लिए उपयोग किया जाता है, और दूसरा हिस्सा पोजिशनल इंफॉर्मेशन के लिए "रोप" नामक चीज़ का उपयोग करता है।

बी: रोप? यह बहुत टेक्निकल लगता है।

ए: इसका मतलब रोटरी पोजिशन एम्बेडिंग्स है, और यह मॉडल को सीक्वेंस में टोकन्स की पोजिशन समझने में मदद करता है। ठीक है, फिर कीज और वैल्यूज को एक लो-डायमेंशनल लेटेंट स्पेस में कंप्रेस किया जाता है। तो यह डेटा को सिकोड़ने जैसा है, जिससे मेमोरी की बचत होती है।

बी: बिल्कुल सही। तो जैसे सबसे महत्वपूर्ण जानकारी तो सेव होती है, लेकिन अनावश्यक भार खत्म हो जाता है। हां, और यह कंप्रेस्ड रिप्रेजेंटेशन इनफेरेंस के दौरान KV कैश को छोटा बनाता है, जिससे चीजें तेज हो जाती हैं।

ए: और यह मल्टी-हेड प्रोसेसिंग का भी उपयोग करता है।

बी: हां, पारंपरिक अटेंशन की तरह, MLA भी मल्टीपल हेड्स का उपयोग करता है।

ए: ओह, जारी रखो।

सी: तो फिर, दो लेटेंट स्पेसेस होती हैं और एक हिडन इनपुट।

ए: यह एक बेहतरीन टिप्पणी है। हां, आप सही हैं। वास्तव में दो लेटेंट स्पेसेस होती हैं। ठीक है, तो हम कंटेंट लेटेंट स्पेस और की-वैल्यू लेटेंट स्पेस की बात कर रहे हैं।

बी: बिल्कुल। और इन लेटेंट स्पेसेस को रोप यानि रोटरी पोजिशन एम्बेडिंग्स के माध्यम से प्रोसेस किया जाता है।

ए: ठीक है, तो रोप ही वह तरीका है जिससे उन्हें पोजिशनल इंफॉर्मेशन मिलती है।

बी: हां, यह कंटेंट और की-वैल्यू लेटेंट स्पेसेस दोनों पर लागू होता है, जैसा कि आपने बताया। तो यह कंप्रेस्ड रिप्रेजेंटेशन को लेता है, उसे प्रोसेस करता है, और फिर सभी को वापस मिला देता है।

ए: हां, और कैशिंग ऑप्टिमाइजेशन सीक्वेंशियल प्रोसेसिंग के दौरान ओवरहेड को और कम कर देता है। ठीक है, तो यह है तरीका जिससे MLA चीजों को तेज करता है।

बी: बिल्कुल। यह परफॉरमेंस को खराब किए बिना कुशल अटेंशन हासिल करने का एक चतुर तरीका है।

ए: ठीक है, यह एक बेहतरीन ट्रिक है। लेकिन आप जानते हैं क्या?

बी: क्या है?

ए: चलो अब DeepSeek Mo पर चलते हैं। यह पारंपरिक MoE मॉडल्स से कैसे अलग है?

बी: ठीक है, DeepSeek Mo का उपयोग करता है... ओह, हमारे श्रोता की बात सुनते हैं, क्या है?

सी: और हम अधिक हिडन स्पेस के बारे में बात करते हैं। ठीक है, हिडन स्पेस से, यह क्या है?

ए: मैं पूरी तरह से... देखते हैं आप क्या कहना चाह रहे हैं। हिडन स्पेसेस वास्तव में दिलचस्प हैं। हां, आप जिस हिडन स्पेस के बारे में पूछ रहे हैं, वह लेटेंट स्पेस जिसके बारे में हम अभी बात कर रहे हैं, है न? आप उन लेटेंट स्पेसेस के अंदर क्या हो रहा है, उस 'के