---
layout: post  
title: "机器学习、深度学习和GPT"  
audio: true  
---

*本篇文章由 ChatGPT 撰写。*

---

1. 机器学习 (ML) 是计算机科学的一个分支，使系统能够从数据中学习并在没有显式编程的情况下提升性能。  

2. 深度学习 (DL) 是机器学习的一个子领域，利用多层神经网络来建模数据中的复杂模式。  

3. 神经网络 是受人脑启发的计算模型，由彼此相连的节点（神经元）组成，通过多层结构来处理信息。  

4. 训练数据 是用于训练机器学习模型的数据集，可以带标签也可以不带标签。  

5. 监督学习 使用带标签的数据进行训练，其中每个样本都包含输入和正确的输出标签。  

6. 无监督学习 使用不带标签的数据，让模型自行发现潜在的模式或分组。  

7. 强化学习 (RL) 通过奖励和惩罚来训练代理，使其学习如何在环境中做出最优决策。  

8. 生成式模型 学习生成与训练数据相似的新数据（例如文本、图像等）。  

9. 判别式模型 关注对输入进行分类或预测具体的输出。  

10. 迁移学习 将在一个任务上训练好的模型迁移或微调到另一个相关任务上。  

11. GPT（Generative Pre-trained Transformer） 是 OpenAI 开发的大型语言模型家族，能够生成类人文本。  

12. ChatGPT 是在 GPT 基础上微调得到的互动式模型，适用于对话和指令处理。  

13. Transformer 架构 首次在论文“Attention Is All You Need”中提出，依赖注意力机制，深刻改变了自然语言处理领域。  

14. 自注意力 (Self-Attention) 机制使模型可以在构造输出表示时，对输入序列的不同部分赋予不同的权重。  

15. 位置编码 (Positional Encoding) 在 Transformer 中帮助模型识别序列中各个 token 的顺序。  

16. 预训练 (Pre-training) 是模型学习的初始阶段，通常在大规模数据上学习通用特征，然后再进行微调。  

17. 微调 (Fine-tuning) 是在预训练模型的基础上，用较小且更具针对性的任务数据来进一步训练模型。  

18. 语言模型 (Language Modeling) 的核心任务是根据前面已知的 token 来预测序列中的下一个 token。  

19. 零样本学习 (Zero-shot Learning) 使模型能够处理没有显式训练样本的新任务，依赖于模型的通用知识。  

20. 少样本学习 (Few-shot Learning) 通过少量的训练样本来引导模型的预测或行为。  

21. RLHF（基于人类反馈的强化学习） 用来让模型在生成结果时更符合人类偏好与价值观。  

22. 人类反馈 可以包括对模型输出的排名或标注，引导模型生成更符合期望的结果。  

23. 提示工程 (Prompt Engineering) 是为大型语言模型设计输入或指令以引导其产生所需输出的技巧。  

24. 上下文窗口 (Context Window) 指模型一次能够处理的文本长度，GPT 类模型都有最大长度限制。  

25. 推理 (Inference) 是模型在训练完成后，根据新输入生成预测或结果的过程。  

26. 参数量 (Parameter Count) 是模型容量的关键指标；更大规模的模型能捕捉更复杂的模式，但也需要更多计算资源。  

27. 模型压缩 (Model Compression)（如剪枝、量化）可在尽量不损失精度的前提下减小模型规模并加快推理速度。  

28. 多头注意力 (Attention Heads) 让 Transformer 能在并行通道中处理不同的输入特征，提升表达能力。  

29. 掩码语言模型 (Masked Language Modeling)（如 BERT）通过预测句子中缺失的 token 来学习上下文。  

30. 因果语言模型 (Causal Language Modeling)（如 GPT）基于先前 token 来预测下一个 token。  

31. 编码器-解码器 (Encoder-Decoder) 架构（如 T5）使用一个网络对输入进行编码，再用另一个网络生成目标序列。  

32. 卷积神经网络 (CNN) 善于处理网格状结构数据（例如图像），通过卷积层提取特征。  

33. 循环神经网络 (RNN) 在时间维度上逐步传递隐藏状态，适用于序列数据，但对长程依赖处理较弱。  

34. 长短期记忆网络 (LSTM) 和 GRU 是 RNN 的变体，更好地捕捉长程依赖。  

35. 批归一化 (Batch Normalization) 通过对中间层输出进行归一化来稳定训练过程。  

36. Dropout 是一种正则化方法，训练时随机“丢弃”部分神经元，防止过拟合。  

37. 优化算法（如随机梯度下降 SGD、Adam、RMSProp）基于梯度信息来更新模型参数。  

38. 学习率 (Learning Rate) 是超参数，决定训练中参数更新的幅度。  

39. 超参数 (Hyperparameters)（如批大小、网络层数）是在训练前设定的，用于控制模型的训练过程。  

40. 模型过拟合 (Overfitting) 表现为模型对训练集学习得过于“死板”，导致在新数据上的泛化性能较差。  

41. 正则化 (Regularization)（如 L2 正则、Dropout）有助于降低过拟合，提高模型泛化能力。  

42. 验证集 (Validation Set) 用于调参，测试集 (Test Set) 用于评估模型在新数据上的最终表现。  

43. 交叉验证 (Cross-validation) 将数据分成多个子集，多次训练和验证，得到更稳定的性能评估结果。  

44. 梯度爆炸和梯度消失 是深层网络中常见问题，会导致训练不稳定或难以进行。  

45. 残差连接 (Residual Connections)（如 ResNet 中）通过跳过部分网络层来缓解梯度消失问题。  

46. 扩展法则 (Scaling Laws) 指随着模型规模和数据规模增大，模型性能通常会提升。  

47. 计算效率 (Compute Efficiency) 至关重要；大型模型的训练需要优化过的硬件（GPU、TPU）和算法。  

48. 伦理考量 (Ethical Considerations) 包括偏见、公平和潜在伤害，需要对模型进行严格的测试和监控。  

49. 数据增广 (Data Augmentation) 人为地扩充数据集，用以提升模型的鲁棒性（尤其在图像、语音任务中常用）。  

50. 数据预处理 (Data Preprocessing)（如分词、归一化）是训练模型前的必要步骤。  

51. 分词 (Tokenization) 将文本拆分为词或子词，是语言模型处理文本的基本单元。  

52. 向量嵌入 (Vector Embeddings) 用数字向量表示词或概念，并保留其语义关系。  

53. 位置嵌入 (Positional Embeddings) 为 Transformer 提供位置信息，以帮助理解序列顺序。  

54. 注意力权重 (Attention Weights) 显示模型在处理输入时对各部分的侧重点分布。  

55. 束搜索 (Beam Search) 是语言模型的一种解码策略，通过在每一步保留多个候选序列来找到最优输出。  

56. 贪心搜索 (Greedy Search) 在每一步都选择概率最高的 token，可能导致整体输出不最优。  

57. 温度 (Temperature) 调整语言生成的“创造力”：温度越高，随机性越大。  

58. Top-k 与 Top-p（Nucleus）采样 仅在每一步保留最可能的 k 个候选或概率总和达到 p 的候选，以平衡多样性和连贯性。  

59. 困惑度 (Perplexity) 测量模型对样本的预测能力；数值越低，模型越擅长预测。  

60. 精确率 (Precision) 和 召回率 (Recall) 是分类任务中的常用指标，分别关注正确预测和覆盖率。  

61. F1 分数 (F1 Score) 是精确率和召回率的调和平均，综合考量二者的表现。  

62. 准确率 (Accuracy) 是正确预测在总预测中的占比，但在不平衡数据集中可能存在误导性。  

63. ROC 曲线下面积 (AUC) 用来衡量分类器在不同阈值下的整体表现。  

64. 混淆矩阵 (Confusion Matrix) 记录真阳性、假阳性、真阴性和假阴性等分类结果。  

65. 不确定性估计 (Uncertainty Estimation)（如蒙特卡洛 Dropout）可以评估模型预测的可信度。  

66. 主动学习 (Active Learning) 会挑选模型最不确定的样本来进行人工标注，从而提高数据利用率。  

67. 在线学习 (Online Learning) 在新数据到来时不断增量更新模型，而不用每次都从头开始训练。  

68. 进化算法 (Evolutionary Algorithms) 和 遗传算法 (Genetic Algorithms) 借鉴生物进化原理来优化模型或超参数。  

69. 贝叶斯方法 (Bayesian Methods) 融合先验知识，并随着新数据到来不断更新对分布的估计，可用于不确定性量化。  

70. 集成方法 (Ensemble Methods)（如随机森林、梯度提升）结合多个模型的结果来提高性能和稳定性。  

71. Bagging（自举聚合） 将训练集随机抽样出不同子集训练多个模型，再对结果进行平均或投票。  

72. Boosting 通过在每次迭代中关注前一轮模型的错误样本，训练新的模型来提升整体性能。  

73. 梯度提升决策树 (GBDT) 对结构化数据通常表现出色，经常比简单的神经网络效果更好。  

74. 自回归模型 (Autoregressive Models) 根据先前的输出来预测序列的下一个值或 token。  

75. 自编码器 (Autoencoder) 是一种神经网络，通过将数据编码到潜在空间并再解码回来，学习数据的压缩表示。  

76. 变分自编码器 (VAE) 加入了概率元素，能生成与训练数据相似的全新数据样本。  

77. 生成对抗网络 (GAN) 由生成器和判别器对抗训练，可生成逼真的图像、文本等内容。  

78. 自监督学习 (Self-Supervised Learning) 在大量未标注的数据上创建人工任务（如预测缺失部分）来学习特征。  

79. 基础模型 (Foundation Models) 是在海量数据上预训练的通用大模型，可适应众多下游任务。  

80. 多模态学习 (Multimodal Learning) 融合来自多种模态（如文本、图像、语音）的信息，以获得更丰富的表示。  

81. 数据标注 (Data Labeling) 通常是机器学习中最耗费时间和资源的环节，需要准确的人工标注。  

82. 边缘计算 (Edge Computing) 将推理部署在靠近数据源的设备上，降低延迟并节省带宽。  

83. 联邦学习 (Federated Learning) 在分散的设备或服务器上训练模型，数据无需集中传输。  

84. 隐私保护型机器学习 (Privacy-Preserving ML) 包括差分隐私、同态加密等技术，用于保护敏感数据。  

85. 可解释人工智能 (XAI) 旨在让复杂模型的决策更具可解释性，方便人类理解。  

86. 偏差与公平性 (Bias and Fairness) 是 ML 模型的重要议题，需要防止放大或固化社会偏见。  

87. 概念漂移 (Concept Drift) 指目标变量的统计性质随时间变化，导致模型的性能下降。  

88. AB 测试 (A/B Testing) 将两个或多个模型版本在真实环境中对比，评估其表现优劣。  

89. GPU 加速 (GPU Acceleration) 通过在图形处理器上并行计算，大幅度提升 ML 训练速度。  

90. TPU（Tensor Processing Unit） 是 Google 专为深度学习工作负载设计的硬件加速器。  

91. 开源框架 (Open-Source Frameworks)（如 TensorFlow、PyTorch）提供构建和训练模型的工具与模块。  

92. 模型服务 (Model Serving) 指将训练好的模型部署，以便实时或批量进行预测。  

93. 可扩展性 (Scalability) 对于大规模数据或高并发请求尤为关键，需要分布式训练与推理。  

94. MLOps 将机器学习开发与运维相结合，关注模型的可重复性、测试和持续集成。  

95. 版本控制 (Version Control) 用于追踪数据和模型的变化，确保实验可复现并便于协作。  

96. 部署策略 (Deployment Strategies)（如容器化、微服务）决定了模型在生产环境中的打包和服务方式。  

97. 监控 (Monitoring) 在模型部署后跟踪性能变化，及时发现并解决异常或退化。  

98. 持续再训练与模型更新 保证模型随着数据和环境的变化能够保持最新、最优的状态。  

99. 时间复杂度 (O-notation) 度量算法随输入规模变化的运行时复杂度；O(1) 代表常数时间。  

100. 机器学习的未来 将出现更先进、更通用的模型，但也必须重视道德、社会和环境影响。  


