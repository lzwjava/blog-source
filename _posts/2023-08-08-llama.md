---
layout: post
title: "Learn LLaMA - Draft"
---

LLaMA (Large Language Model Meta AI) is a family of large language models (LLMs), released by Meta AI starting in February 2023.

After building my computer with NVIDIA GPU, I start to run up the LLaMA project. LLaMa project's GitHub URL is [https://github.com/facebookresearch/llama](https://github.com/facebookresearch/llama). 

When you run the command,

```python
torchrun --nproc_per_node 1 example_text_completion.py \
    --ckpt_dir llama-2-7b/ \
    --tokenizer_path tokenizer.model \
    --max_seq_len 128 --max_batch_size 4
```

It shows the error, "RuntimeError: Distributed package doesn't have NCCL built in". Let's learn about NCCL.

> The NVIDIA Collective Communication Library (NCCL) implements multi-GPU and multi-node communication primitives optimized for NVIDIA GPUs and Networking.


I refer to the below websites to install NVIDIA drivers.

* CUDA Toolkit 12.2 Update 1 Downloads, [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads)
* NVIDIA NCCL, [https://developer.nvidia.com/nccl](https://developer.nvidia.com/nccl)
* NVIDIA Deep Learning NCCL Documentation, [https://docs.nvidia.com/deeplearning/nccl/install-guide/index.html](https://docs.nvidia.com/deeplearning/nccl/install-guide/index.html)
* NVIDIA CUDA Installation Guide for Linux, [https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html)
* After Installing Ubuntu, You Encounter Perform MOK Management, [https://www.cnblogs.com/yutian-blogs/p/13019226.html](https://www.cnblogs.com/yutian-blogs/p/13019226.html)
* Ubuntu 22.04 for Deep Learning, [https://gist.github.com/amir-saniyan/b3d8e06145a8569c0d0e030af6d60bea](https://gist.github.com/amir-saniyan/b3d8e06145a8569c0d0e030af6d60bea)
* Ubuntu 22.04 Notes, [https://github.com/kmcminn/thinkpad/tree/main/extreme3g](https://github.com/kmcminn/thinkpad/tree/main/extreme3g)

