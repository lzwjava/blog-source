---
audio: false
generated: true
image: false
lang: ja
layout: post
title: 軽量ローカルLLMウェブクライアントの選択肢
translated: true
type: note
---

Open WebUIよりも依存関係が少ない、軽量なオープンソースのWebクライアントをローカルでLLMを実行するために探しているなら、以下の強力な代替案があります：

**1. Lobe Chat**
- 軽量で拡張可能なLobe Chatは、ローカルおよびリモートのLLMをサポートしています。プラグインシステムとクリーンなUIを備え、Dockerまたはマシン上で直接実行できます。Ollamaや他のバックエンドとの良好なパフォーマンスと簡単なセットアップで知られています。

**2. LM Studio**
- LM StudioはGGUFモデル（Mistral、Phi 3、Gemmaなど）をサポートするデスクトップアプリで、シンプルでユーザーフレンドリーなインターフェースを提供します。複雑なセットアップや多くの依存関係を必要としない、迅速なローカル推論に最適です。

**3. text-generation-webui (Oobabooga)**
- 機能豊富なGradioベースのWeb UIで、複数のバックエンド（transformers、GPTQ、AWQ、EXL2、llama.cpp）をサポートします。高度にカスタマイズ可能で広く使用されていますが、LM Studioよりもセットアップが少し複雑です。

**4. AnythingLLM**
- ローカルおよびクラウドベースのモデルの両方でうまく機能する、多用途なセルフホスト型チャットUIです。汎用目的で設計されており、デスクトップアプリとして利用可能なため、柔軟で比較的軽量です。

**5. Jan**
- Janはクロスプラットフォームでオフライン対応のチャットUIで、ドラッグ＆ドロップによるカスタマイズと事前構築済みのテンプレートを備えています。パフォーマンスに最適化されており、複数のLLM APIをサポートするため、プライバシーを重視するユーザーに適した選択肢です。

**6. Ollama UI**
- Ollama専用に設計されたこのUIは最小限でデプロイが容易であり、モデルサービングに既にOllamaを使用している場合に適しています。

**7. Open-LLM-WebUI**
- コンパクトなLLMをローカルで実行するためのシンプルなオープンソースWebインターフェースです。使いやすさと最小限のセットアップを目的としており、 straightforwardなものを求めるユーザーにとって良い代替案です。

**まとめテーブル：**

| クライアント               | 主な特徴                              | セットアップの複雑さ | 最適な用途               |
|---------------------------|---------------------------------------|----------------------|--------------------------|
| Lobe Chat                 | プラグイン、Dockerサポート、クリーンなUI | 低い                 | 一般的な使用、Ollama     |
| LM Studio                 | デスクトップアプリ、GGUFサポート、シンプルUI | 非常に低い           | 迅速なローカル推論       |
| text-generation-webui     | マルチバックエンド、高度なカスタマイズ性 | 中程度               | 上級ユーザー             |
| AnythingLLM               | デスクトップアプリ、柔軟性、汎用性     | 低い                 | ローカル/クラウドハイブリッド |
| Jan                       | オフライン、ドラッグ＆ドロップ、テンプレート | 低い                 | プライバシー、カスタマイズ |
| Ollama UI                 | 最小限、Ollama専用                    | 非常に低い           | Ollamaユーザー           |
| Open-LLM-WebUI            | シンプル、軽量                        | 低い                 | コンパクトLLM            |

最も軽量なオプションをお探しなら、**LM Studio**または**Ollama UI**が優れた出発点です。より多くの機能と柔軟性が必要な場合は、**Lobe Chat**または**text-generation-webui**が有力な選択肢です。

これらのセットアップや特定のユースケースについて、より詳細な情報をお求めですか？