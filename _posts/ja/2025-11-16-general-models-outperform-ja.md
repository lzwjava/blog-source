---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4-fast
title: 汎用モデルは特化型AIを凌駕する
translated: true
type: note
---

あなたは非常に良いタイムリーな質問を提起しています。AI業界の振り子は確かに、ほとんどのユースケースにおいて、**汎用基盤モデル**が狭いドメイン特化型モデルよりも合理的（かつ経済的に支配的）である方向に振り戻されています。以下に、「BloombergGPT / Med-PaLM / FinanceGPT / LawGPT」スタイルのアプローチが2024年から2025年にかけて魅力的でなくなった理由を示します：

### 1. データ汚染と重複が甚大である
現代の事前学習コーパス（RefinedWeb, FineWeb, Dolma, RedPajama v2など）には、既に膨大な量の金融、法律、医療、コードテキストが含まれています。例えば：
- Common Crawlだけでも、数十億ものSEC提出書類、裁判書類、GitHubリポジトリ、arXiv論文、金融ニュースなどが含まれています。
- 10–30Tトークンで学習された汎用モデルは、1Tトークンの手作業でキュレーションされたドメインデータで学習された「ドメイン特化型」モデルとほぼ同量の高品質な金融/法律/コードデータを参照します。

結果：100B–400Bの汎用モデルと100Bの「FinanceGPT」との性能差は劇的に縮小しました。BloombergGPT（2023年）は金融タスクで汎用モデルを約10〜20%上回りましたが、今日のLlama 3.1 405BやQwen2.5 72Bは、ドメイン特化型の学習を一切行わなくても、BloombergGPTの数値をしばしば匹敵または凌駕します。

### 2. ドメインの境界が曖昧で流動的である
あなたも完璧に指摘した通りです：金融 + AI、暗号資産 + 法律、バイオテクノロジー + 金融、プログラミング + 数学 + 物理学など、知識は現在強く絡み合っています。
- 純粋な「金融」モデルは、十分なコードを学習していないため、DeFi/スマートコントラクトに関する質問に答えられないでしょう。
- 純粋な「法律」モデルは、トランスフォーマーと学習データの理解を必要とするAI規制関連の事件に対処するのに苦労するでしょう。
- 純粋な「プログラミング」モデルは、市場の微細構造知識を必要とするトレーディングアルゴリズムの記述が苦手でしょう。

汎用モデルは、現実世界と同様に、すべてが混ざり合った状態で学習しているため、これらの複合ドメインを自然に扱います。

### 3. MoEが専門化をほぼ無償化する
Mixture-of-Experts（Mixtral, DeepSeek-V3, Qwen2.5-MoE, Grok-1.5など）は、内部で軽量なドメインルーティングを既に行っています。一部のエキスパートはコードにより強く反応することを学び、別のエキスパートは金融や生物医学テキストに反応することを学びます。これは、誰も明示的にデータを分離する必要なく行われます。余分なエンジニアリングや販売努力を一切かけずに、ドメイン特化型ルーティングの利点の大部分を得ることができます。

### 4. 経済性と流通が変化した
2023年の考え方：「独自データで50BのFinanceGPTを学習 → 銀行にAPIアクセスを100万トークンあたり50〜200ドルで販売。」
2025年の現実：
- 銀行は、Claude 3.5 / GPT-4o / Llama 405Bを自社の内部文書に対してRAGで使用するだけで、性能の95〜98%を1/50のコストで得ることができます。
- オープンソースのフロンティアモデル（Llama 3.1 405B, Qwen2.5 72B, DeepSeek-V3）は現在十分に高性能であり、ほとんどの企業は、閉鎖的なドメインモデルに大きなプレミアムを支払うよりも、ファインチューニングやコンテキスト注入を好みます。
- 専用の70B–400Bドメインモデルのホスティングと推論コストは、顧客基盤が小さい場合、非常に高くなります。

### 5. 事後学習（SFT + RL）が残りのギャップのほとんどを埋める
事前学習後の純粋なドメイン知識において汎用モデルがわずかに遅れをとっていたとしても、教師ありファインチューニングとそのドメインに調整されたDPO/RLHFにおいて、500〜5000の高品質な合成または人手で書かれた例を使用すれば、それを最先端の水準に押し上げることができます。これは、テラバイト級のドメイン事前学習データを収集しクリーニングするよりも、100倍安く、高速です。

### ドメイン特化型モデルが依然として意味を持つ場合（残りわずかのケース）
- 文字通りデータをOpenAI/Anthropic/Metaに送信できない、非常に規制が厳しい、またはセキュリティセンシティブな環境（一部の防衛、中央銀行、医療システム）。
- 公共のインターネット上に本当に存在しない大規模な独自データ（例：何兆もの非公開取引記録、数十年分の内部法務メモ）を持ち、汎用モデルがその情報を見逃していることを証明できる場合。
- オンデバイスまたはエアギャップシステムで動作する小さなモデル（例：7Bパラメータ未満で法律事務所のファイアウォール内で完全に動作する法律コパイロット）。

しかし、2025年における商業ユースケースの95%以上に対して、答えは次の通りです：
汎用フロンティアモデル（オープンまたはクローズド） + ドメイン特化的事後学習 / RAG / ツール利用 >> 専用のドメイン事前学習モデル

ですから、はい — あなたの指摘はまさに正しいです：トランスフォーマーの本質は、ドメインに関係なくテキストを予測することであり、データ混合の問題 + スケーリング則 + MoE + 低コストな事後学習により、純粋なドメイン特化型モデルは主に2022年から2023年の現象となったのです。