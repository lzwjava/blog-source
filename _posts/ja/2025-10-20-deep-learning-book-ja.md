---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4-fast
title: グッドフェロー、ベンジオ、クールビルによる深層学習
translated: true
type: note
---

**Ian Goodfellow**  
**Yoshua Bengio**  
**Aaron Courville**

## 目次

- ウェブサイト viii  
- 謝辞 ix  
- 表記法 xiii  

### 1 はじめに 1

- 1.1 本書の対象読者 8  
- 1.2 深層学習の歴史的変遷 12  

## I 応用数学と機械学習の基礎 27

### 2 線形代数 29

- 2.1 スカラー、ベクトル、行列、テンソル 29  
- 2.2 行列とベクトルの乗算 32  
- 2.3 単位行列と逆行列 34  
- 2.4 線形従属とスパン 35  
- 2.5 ノルム 37  
- 2.6 特殊な種類の行列とベクトル 38  
- 2.7 固有分解 40  
- 2.8 特異値分解 42  
- 2.9 ムーア・ペンローズ擬似逆行列 43  
- 2.10 トレース演算子 44  
- 2.11 行列式 45  
- 2.12 例：主成分分析 45  

### 3 確率と情報理論 51

- 3.1 なぜ確率なのか？ 52  
- 3.2 確率変数 54  
- 3.3 確率分布 54  
- 3.4 周辺確率 56  
- 3.5 条件付き確率 57  
- 3.6 条件付き確率の連鎖律 57  
- 3.7 独立性と条件付き独立性 58  
- 3.8 期待値、分散、共分散 58  
- 3.9 一般的な確率分布 60  
- 3.10 一般的な関数の有用な性質 65  
- 3.11 ベイズの規則 68  
- 3.12 連続変数の技術的詳細 69  
- 3.13 情報理論 71  
- 3.14 構造化確率モデル 73  

### 4 数値計算 78

- 4.1 オーバーフローとアンダーフロー 78  
- 4.2 条件付けの悪さ 80  
- 4.3 勾配ベース最適化 80  
- 4.4 制約付き最適化 91  
- 4.5 例：線形最小二乗法 94  

### 5 機械学習の基礎 96

- 5.1 学習アルゴリズム 97  
- 5.2 容量、過学習、未学習 108  
- 5.3 ハイパーパラメータと検証セット 118  
- 5.4 推定量、バイアス、分散 120  
- 5.5 最尤推定 129  
- 5.6 ベイズ統計学 133  
- 5.7 教師あり学習アルゴリズム 137  
- 5.8 教師なし学習アルゴリズム 142  
- 5.9 確率的勾配降下法 149  
- 5.10 機械学習アルゴリズムの構築 151  
- 5.11 深層学習を動機づける課題 152  

## II 深層ネットワーク：現代的な実践 162

### 6 深層順伝播ネットワーク 164

- 6.1 例：XORの学習 167  
- 6.2 勾配ベース学習 172  
- 6.3 隠れユニット 187  
- 6.4 アーキテクチャ設計 193  
- 6.5 誤差逆伝播法とその他の微分アルゴリズム 200  
- 6.6 歴史的注記 220  

### 7 深層学習のための正則化 224

- 7.1 パラメータノルムペナルティ 226  
- 7.2 制約付き最適化としてのノルムペナルティ 233  
- 7.3 正則化と未確定問題 235  
- 7.4 データセット拡張 236  
- 7.5 ノイズに対する頑健性 238  
- 7.6 半教師あり学習 240  
- 7.7 マルチタスク学習 241  
- 7.8 早期打ち切り 241  
- 7.9 パラメータ共有とパラメータタイイング 249  
- 7.10 スパース表現 251  
- 7.11 バギングとその他のアンサンブル手法 253  
- 7.12 ドロップアウト 255  
- 7.13 敵対的訓練 265  
- 7.14 接距離、接線伝播、多様体接線分類器 267  

### 8 深層モデルの訓練のための最適化 271

- 8.1 学習が純粋な最適化と異なる点 272  
- 8.2 ニューラルネットワーク最適化の課題 279  
- 8.3 基本的なアルゴリズム 290  
- 8.4 パラメータ初期化戦略 296  
- 8.5 適応的学習率アルゴリズム 302  
- 8.6 近似二階法 307  
- 8.7 最適化戦略とメタアルゴリズム 313  

### 9 畳み込みネットワーク 326

- 9.1 畳み込み演算 327  
- 9.2 動機 329  
- 9.3 プーリング 335  
- 9.4 無限に強い事前分布としての畳み込みとプーリング 339  
- 9.5 基本的な畳み込み関数の変種 342  
- 9.6 構造化出力 352  
- 9.7 データ型 354  
- 9.8 効率的な畳み込みアルゴリズム 356  
- 9.9 ランダムまたは教師なし特徴 356  
- 9.10 畳み込みネットワークの神経科学的基礎 358  
- 9.11 畳み込みネットワークと深層学習の歴史 365  

### 10 系列モデリング：回帰結合型と再帰的ネットワーク 367

- 10.1 計算グラフの展開 369  
- 10.2 回帰結合型ニューラルネットワーク 372  
- 10.3 双方向RNN 388  
- 10.4 エンコーダ・デコーダ系列間アーキテクチャ 390  
- 10.5 深層回帰結合型ネットワーク 392  
- 10.6 再帰的ニューラルネットワーク 394  
- 10.7 長期的依存関係の課題 396  
- 10.8 エコー状態ネットワーク 399  
- 10.9 漏洩ユニットと複数時間スケールのためのその他の戦略 402  
- 10.10 Long Short-Term Memoryとその他のゲート付きRNN 404  
- 10.11 長期的依存関係のための最適化 408  
- 10.12 明示的メモリ 412  

### 11 実践的方法論 416

- 11.1 性能指標  
- 11.2 デフォルトのベースラインモデル  
- 11.3 さらにデータを収集すべきかの判断  
- 11.4 ハイパーパラメータの選択  
- 11.5 デバッグ戦略  
- 11.6 例：複数桁数字認識  

## III 深層学習の研究 482

### 12 線形因子モデル 485

- 12.1 確率的PCAと因子分析  
- 12.2 独立成分分析 (ICA)  
- 12.3 遅延特徴分析  
- 12.4 スパースコーディング  
- 12.5 PCAの多様体解釈  

### 13 オートエンコーダ 500

- 13.1 不完全オートエンコーダ  
- 13.2 正則化オートエンコーダ  
- 13.3 表現力、層のサイズと深さ  
- 13.4 確率的エンコーダとデコーダ  
- 13.5 デノイジングオートエンコーダ  
- 13.6 オートエンコーダによる多様体学習  
- 13.7 収縮オートエンコーダ  
- 13.8 予測的スパース分解  
- 13.9 オートエンコーダの応用  

### 14 表現学習 525

- 14.1 貪欲な層ごとの教師なし事前訓練  
- 14.2 転移学習とドメイン適応  
- 14.3 因果因子の半教師あり分離  
- 14.4 分散表現  
- 14.5 深さによる指数的な利得  
- 14.6 根本原因発見のための手がかりの提供  

### 15 深層学習のための構造化確率モデル 540

- 15.1 非構造化モデリングの課題  
- 15.2 モデル構造を記述するグラフの利用  
- 15.3 グラフィカルモデルからのサンプリング  
- 15.4 構造化モデリングの利点  
- 15.5 依存関係の学習  
- 15.6 推論と近似推論  
- 15.7 構造化確率モデルへの深層学習のアプローチ  

### 16 モンテカルロ法 557

- 16.1 サンプリングとモンテカルロ法  
- 16.2 重点サンプリング  
- 16.3 マルコフ連鎖モンテカルロ法  
- 16.4 ギブスサンプリング  
- 16.5 分離されたモード間の混合の課題  

### 17 分配関数への対処 567

- 17.1 対数尤度勾配  
- 17.2 確率的最尤法とコントラスティブ・ダイバージェンス  
- 17.3 擬似尤度  
- 17.4 スコアマッチングと比率マッチング  
- 17.5 デノイジングスコアマッチング  
- 17.6 ノイズ対照推定  
- 17.7 分配関数の推定  

### 18 近似推論 579

- 18.1 最適化としての推論  
- 18.2 期待値最大化法  
- 18.3 MAP推論とスパースコーディング  
- 18.4 変分推論と学習  
- 18.5 学習された近似推論  

### 19 深層生成モデル 594

- 19.1 ボルツマンマシン  
- 19.2 制限ボルツマンマシン  
- 19.3 深層信念ネットワーク  
- 19.4 深層ボルツマンマシン  
- 19.5 実数値データのためのボルツマンマシン  
- 19.6 畳み込みボルツマンマシン  
- 19.7 構造化または系列出力のためのボルツマンマシン  
- 19.8 その他のボルツマンマシン  
- 19.9 ランダム演算を通した誤差逆伝播法  
- 19.10 有向生成ネット  
- 19.11 オートエンコーダからのサンプル抽出  
- 19.12 生成的確率的ネットワーク  
- 19.13 その他の生成手法  
- 19.14 生成モデルの評価  
- 19.15 結論  

[Deep Learning 目次](https://www.deeplearningbook.org/contents/toc.html)