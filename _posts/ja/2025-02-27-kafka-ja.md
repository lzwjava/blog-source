---
audio: false
generated: true
lang: ja
layout: post
title: JavaでのApache Kafkaの使用
translated: true
type: note
---

JavaでApache Kafkaを使用するには、Javaアプリケーション内でKafkaクライアントを設定してメッセージをプロデュースおよびコンシュームする必要があります。Kafkaは分散型ストリーミングプラットフォームであり、そのJavaクライアントライブラリにより統合が容易になります。以下では、基本的な手順を説明します。

まず、環境を設定する必要があります。Kafkaがシステムまたはサーバー上にインストールされ、実行されていることを確認してください。公式Apache Kafkaウェブサイトからダウンロードし、提供されているスクリプトを使用してZooKeeperとKafkaサーバーを起動できます。簡単のため、デフォルト設定（例: `localhost:9092` をブートストラップサーバーとして）でKafkaをローカルで実行していると仮定します。

次に、Kafkaクライアントの依存関係をJavaプロジェクトに追加します。Mavenを使用している場合は、`pom.xml` に以下を含めます：

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>3.6.0</version> <!-- 最新バージョンを使用 -->
</dependency>
```

では、コードを書いてみましょう。シンプルなプロデューサーとコンシューマーの作成方法を示します。

### Kafkaプロデューサーの例
プロデューサーはメッセージをKafkaトピックに送信します。基本的な例を以下に示します：

```java
import org.apache.kafka.clients.producer.*;
import java.util.Properties;

public class SimpleProducer {
    public static void main(String[] args) {
        // プロデューサープロパティを設定
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092"); // Kafkaサーバーアドレス
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // プロデューサーインスタンスを作成
        try (Producer<String, String> producer = new KafkaProducer<>(props)) {
            // "test-topic"というトピックにメッセージを送信
            String topic = "test-topic";
            for (int i = 0; i < 10; i++) {
                String key = "key" + i;
                String value = "Hello, Kafka " + i;
                ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);

                producer.send(record, (metadata, exception) -> {
                    if (exception == null) {
                        System.out.println("Sent message: " + value + " to partition " + metadata.partition());
                    } else {
                        exception.printStackTrace();
                    }
                });
            }
        }
    }
}
```

このコードでは：
- `bootstrap.servers` はKafkaが実行されている場所を指定します。
- シリアライザーはキーと値（ここでは両方とも文字列）をバイトに変換する方法を定義します。
- `ProducerRecord` はメッセージを表し、`send()` はコールバックを使用して非同期にメッセージを送信し、成功または失敗を処理します。

### Kafkaコンシューマーの例
コンシューマーはトピックをサブスクライブしてメッセージを読み取ります。例を以下に示します：

```java
import org.apache.kafka.clients.consumer.*;
import java.util.Collections;
import java.util.Properties;

public class SimpleConsumer {
    public static void main(String[] args) {
        // コンシューマープロパティを設定
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "test-group"); // コンシューマーグループID
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("auto.offset.reset", "earliest"); // トピックの最初から開始

        // コンシューマーインスタンスを作成
        try (KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {
            // トピックをサブスクライブ
            consumer.subscribe(Collections.singletonList("test-topic"));

            // メッセージをポーリング
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(1000); // タイムアウト（ミリ秒）
                for (ConsumerRecord<String, String> record : records) {
                    System.out.printf("Received: key=%s, value=%s, partition=%d, offset=%d%n",
                            record.key(), record.value(), record.partition(), record.offset());
                }
            }
        }
    }
}
```

ここでは：
- `group.id` はコンシューマーグループを識別し、調整を行います。
- デシリアライザーはバイトデータを文字列に変換します。
- `poll()` はループ内でメッセージを取得し、`auto.offset.reset` はオフセットがコミットされていない場合に最初のメッセージから開始することを保証します。

### コードの実行
1. **Kafkaを起動**: ZooKeeperとKafkaが実行されていることを確認します（例: Unix系システムでは `bin/zookeeper-server-start.sh config/zookeeper.properties` と `bin/kafka-server-start.sh config/server.properties`）。
2. **トピックを作成**: 存在しない場合はKafkaコマンドラインツールを使用して `test-topic` を作成します：`bin/kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1`。
3. **プロデューサーを実行**: `SimpleProducer` クラスを実行してメッセージを送信します。
4. **コンシューマーを実行**: `SimpleConsumer` クラスを実行してメッセージがコンシュームされるのを確認します。

### ヒント
- **エラーハンドリング**: 本番コードではtry-catchブロックやロギングを追加します。
- **設定**: 信頼性のための `acks`（プロデューサー）やバッチサイズのための `max.poll.records`（コンシューマー）などのプロパティをニーズに基づいて調整します。
- **ライブラリ**: より複雑なアプリケーションでは、設定と使用を簡素化するSpring Kafkaの使用を検討してください。

これは基本的なセットアップです。パーティショニング、エラーハンドリング、または大規模なアプリケーションとの統合などの特定の機能についてさらに詳しく知りたい場合は、お知らせください！