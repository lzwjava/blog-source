---
audio: false
generated: true
lang: ja
layout: post
title: Apache KafkaをJavaで使用する
translated: true
---

Apache KafkaをJavaで使用するには、JavaアプリケーションにKafkaクライアントを設定してメッセージを生成および消費する必要があります。Kafkaは分散ストリーミングプラットフォームであり、そのJavaクライアントライブラリは統合が簡単です。以下に、基本的な手順を説明します。

まず、環境を設定します。Kafkaがシステムまたはサーバーにインストールされ、実行されていることを確認してください。公式のApache Kafkaウェブサイトからダウンロードし、提供されるスクリプトを使用してZooKeeperとKafkaサーバーを開始できます。簡単のために、ローカルでデフォルト設定（例：`localhost:9092`がブートストラップサーバー）でKafkaを実行していると仮定します。

次に、Kafkaクライアントの依存関係をJavaプロジェクトに追加します。Mavenを使用している場合、`pom.xml`に以下を含めます：

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>3.6.0</version> <!-- 最新バージョンを使用 -->
</dependency>
```

次に、コードを書きます。簡単なプロデューサとコンシューマを作成する方法を示します。

### Kafkaプロデューサの例
プロデューサはメッセージをKafkaトピックに送信します。以下は基本的な例です：

```java
import org.apache.kafka.clients.producer.*;
import java.util.Properties;

public class SimpleProducer {
    public static void main(String[] args) {
        // プロデューサのプロパティを設定
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092"); // Kafkaサーバーのアドレス
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // プロデューサのインスタンスを作成
        try (Producer<String, String> producer = new KafkaProducer<>(props)) {
            // トピック「test-topic」にメッセージを送信
            String topic = "test-topic";
            for (int i = 0; i < 10; i++) {
                String key = "key" + i;
                String value = "Hello, Kafka " + i;
                ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);

                producer.send(record, (metadata, exception) -> {
                    if (exception == null) {
                        System.out.println("Sent message: " + value + " to partition " + metadata.partition());
                    } else {
                        exception.printStackTrace();
                    }
                });
            }
        }
    }
}
```

このコードでは：
- `bootstrap.servers`はKafkaが実行されている場所を指定します。
- シリアライザはキーと値（ここでは両方とも文字列）をバイトに変換する方法を定義します。
- `ProducerRecord`はメッセージを表し、`send()`は非同期でコールバックを使用して成功または失敗を処理します。

### Kafkaコンシューマの例
コンシューマはトピックを購読し、メッセージを読み取ります。以下は例です：

```java
import org.apache.kafka.clients.consumer.*;
import java.util.Collections;
import java.util.Properties;

public class SimpleConsumer {
    public static void main(String[] args) {
        // コンシューマのプロパティを設定
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "test-group"); // コンシューマグループID
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("auto.offset.reset", "earliest"); // トピックの最初から開始

        // コンシューマのインスタンスを作成
        try (KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {
            // トピックを購読
            consumer.subscribe(Collections.singletonList("test-topic"));

            // メッセージをポーリング
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(1000); // タイムアウト（ms）
                for (ConsumerRecord<String, String> record : records) {
                    System.out.printf("Received: key=%s, value=%s, partition=%d, offset=%d%n",
                            record.key(), record.value(), record.partition(), record.offset());
                }
            }
        }
    }
}
```

ここでは：
- `group.id`はコーディネーションのためのコンシューマグループを識別します。
- デシリアライザはバイトデータを文字列に戻します。
- `poll()`はループでメッセージをフェッチし、`auto.offset.reset`はオフセットがコミットされていない場合に最初のメッセージから開始することを保証します。

### コードの実行
1. **Kafkaの開始**: ZooKeeperとKafkaが実行されていることを確認します（例：Unix系システムで`bin/zookeeper-server-start.sh config/zookeeper.properties`と`bin/kafka-server-start.sh config/server.properties`）。
2. **トピックの作成**: Kafkaのコマンドラインツールを使用して`test-topic`が存在しない場合は作成します：`bin/kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1`。
3. **プロデューサの実行**: `SimpleProducer`クラスを実行してメッセージを送信します。
4. **コンシューマの実行**: `SimpleConsumer`クラスを実行してメッセージが消費されるのを確認します。

### Tips
- **エラーハンドリング**: 生産コードにはtry-catchブロックまたはログを追加します。
- **設定**: `acks`（プロデューサの信頼性）や`max.poll.records`（コンシューマのバッチサイズ）などのプロパティを必要に応じて調整します。
- **ライブラリ**: より複雑なアプリケーションには、Spring Kafkaを検討してください。これは設定と使用を簡素化します。

これは基本的な設定です。特定の機能（例：パーティショニング、エラーハンドリング、より大きなアプリケーションとの統合）に深く掘り下げたい場合はお知らせください！