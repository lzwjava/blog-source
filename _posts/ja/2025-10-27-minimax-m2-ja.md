---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4-fast
title: MiniMax M2オープンソースAIモデル
translated: true
type: note
---

### MiniMax M2とは？

MiniMax M2は、中国のAI企業MiniMax AI（テキスト、音声、画像、動画の基盤モデルに焦点を当てた企業）がリリースしたばかりのオープンソース大規模言語モデル（LLM）です。2025年10月27日現在、わずか数時間前に公開されたばかりのこのモデルは、Mixture of Experts（MoE）モデルであり、コーディングとエージェント型ワークフロー（自律型AIエージェントが計画を立て、ツールを実行し、フルスタック開発、データ分析、多段階の研究などの複雑なタスクを処理する）に最適化されています。GPTやClaudeのような汎用モデルではありませんが、エンドツーエンドのプログラミングとエージェントアプリケーションにおいて優れており、Claude Code、Cursor、ブラウザ/シェルインタープリターなどのツールとシームレスに統合します。

主な仕様：
- **パラメータ数**：総計2300億、ただしアクティブは100億のみ（効率性のため）。
- **コンテキスト長**：最大128Kトークン。
- **デプロイ**：Hugging FaceでMITライセンスの下利用可能。SGLangやvLLMなどのフレームワークをサポートし、セルフホスティング可能。
- **アクセス**：2025年11月7日までMiniMax Agent（agent.minimax.io）経由で無料APIトライアルを提供。有料APIは入力100万トークンあたり0.30ドル、出力100万トークンあたり1.20ドル—Claude 3.5 Sonnetの約8%のコスト。

このモデルは「インターリーブ思考」アプローチ（推論に`