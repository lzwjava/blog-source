---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4-fast
title: ニューラル言語モデルのスケーリング則
translated: true
type: note
---

### 概要
2020年にOpenAIのJared Kaplanら（Sam McCandlish、Tom Henighan、Tom B. Brown、Benjamin Mann、Prafulla Dhariwal、Andrew Radford、Ilya Sutskeverを含む）によって発表された論文「Scaling Laws for Neural Language Models」は、大規模ニューラル言語モデルの性能—交差エントロピー損失で測定—が、主要な学習リソースとともにどのようにスケールするかを探求しています。Transformerベースのモデルを用いた広範な実験を通じて、彼らはモデルサイズ、データセットサイズ、計算予算（7桁以上にわたる範囲）において、予測可能なべき乗則が成り立つことを明らかにしました。これらの「スケーリング則」は、試行錯誤なしで性能を予測し、学習効率を最適化するための枠組みを提供します。

### スケーリング則に関する主な発見
中核となる洞察は、損失 \\( L \\) が以下の3つの変数に対してべき乗則に従って減少するということです：
- **モデルサイズ (\\( N \\), パラメータ数)**: \\( L(N) \propto N^{-\alpha} \\)、ここで \\( \alpha \approx 0.076 \\)（言語モデリングの場合）。より大きなモデルは初期学習が速いが、全体としての学習は遅くなる。
- **データセットサイズ (\\( D \\), トークン数)**: \\( L(D) \propto D^{-\beta} \\)、ここで \\( \beta \approx 0.103 \\)。より多くのデータは一貫して損失を減少させるが、\\( D \\) が増加するにつれて利得は逓減する。
- **計算量 (\\( C \\), 浮動小数点演算数)**: \\( L(C) \propto C^{-\gamma} \\)、ここで \\( \gamma \approx 0.050 \\)。これは \\( N \\) と \\( D \\) の効果を組み合わせたもので、典型的な学習では \\( C \approx 6ND \\) となる。

これらの法則は経験的なものですが、アーキテクチャ（例えば、幅と深さの影響は小さい）やタスクを超えて顕著に一貫しています。その他の観察事項は以下の通りです：
- **サンプル効率**: より大きなモデルははるかにデータ効率が良い—例えば、100倍大きなモデルは同じ損失を達成するのに約10分の1のデータしか必要としない。
- **過学習**: \\( N/D \\) 比に基づいて予測可能。\\( N \\) が \\( D \\) をある係数で超えるときに発生し、\\( L_{\text{test}} - L_{\text{train}} \propto (N/D)^\kappa \\) に従う。
- **最適配分**: 固定された計算予算に対して、最良の戦略は、*非常に大きな*モデルを*適度な量*のデータで学習し、逓減収益を避けるために早期に（完全な収束前に）停止することである。

### 理論的および実践的意義
本論文は、これらの法則がノイズや還元不可能なパープレキシティに起因する還元不可能な損失下限といった、ニューラルネットワークの基本的な性質に由来することを示唆しています。これは「データは常に多ければ多いほど良い」という直感に挑戦し、限られた計算資源からより多くの性能を引き出すために巨大なモデルを支持します。これは、スケールアップが予測可能な方法でブレークスルーをもたらすことを予測することで、GPT-3のような巨大モデルへの投資を正当化し、現代のAI開発に深く影響を与えました。

要するに、本論文は「計算最適」な道筋、すなわちモデルサイズを優先し、高品質なデータを必要十分量使い、効率的に学習することを主張しており、LLMにおけるスケーリング時代への道を開いたのでした。

[Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)