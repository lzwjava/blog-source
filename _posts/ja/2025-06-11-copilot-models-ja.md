---
audio: false
generated: true
lang: ja
layout: post
title: GPT-4oとGPT-4.1の比較
translated: true
type: note
---

### **エグゼクティブサマリー**

本レポートは、OpenAIのGPT-4oおよびGPT-4.1モデルについて、特にその能力、パフォーマンス、そしてGitHub Copilot for Visual Studio Code (VS Code) および JetBrains IDEA環境内での統合に焦点を当てた包括的な分析を提供します。分析の結果、GPT-4.1は前身であるGPT-4oを凌駕する、アーキテクチャおよびパフォーマンスにおける大幅な進化を遂げており、GitHub CopilotにおけるAI支援開発の新たな標準として確立されつつあることが明らかになりました。その優れたコーディング能力、強化された指示追従性、そして大幅に拡張されたコンテキストウィンドウは、開発者の生産性向上と、より信頼性の高いAIエージェントワークフローの実現に直接寄与します。
重要な差異は、GPT-4.1が重要なベンチマークにおいて顕著な改善を示している点です。例えば、SWE-bench Verifiedにおいて54.6%の成功率を達成し、GPT-4oの33.2%から21.4%の絶対的改善を示しています。さらに、GPT-4.1はAiderのポリグロット差分ベンチマークにおいてGPT-4oのスコアを2倍以上上回り、コード変更生成における優れた正確性を示しています。また、モデルは100万トークンという巨大なコンテキストウィンドウを備え、GPT-4oの128Kトークンからの大幅なアップグレードにより、コードベース全体の理解を劇的に拡大しています。同時に、その指示追従の信頼性も顕著に強化されています。
GitHub Copilotは、Copilot Chat、Edits、およびAgentモードにおける新たなデフォルトモデルとしてGPT-4.1への戦略的移行を進めており、これらの機能におけるGPT-4oの提供を90日以内に終了する明確な計画があります。一方、GPT-4o Copilot（ファインチューニングされたGPT-4o mini）は現在、コード補完のデフォルトモデルとして残っていますが、全体的な傾向はCopilotの全機能セットにおいてGPT-4.1が間もなく支配的となることを示しています。両モデルは、Copilot拡張機能を通じてVS CodeおよびJetBrains IDE内で利用可能です。しかし、機能の同等性や新モデルの展開速度はIDE間で若干異なる可能性があり、VS Codeの方がJetBrains IDEよりも早くアップデートやプレビュー機能を受け取ることが多いことが観察されています。

### **1. GitHub CopilotのAIモデル概要**

GitHub Copilotは、先進的なAIペアプログラマーとして機能し、現代のソフトウェア開発ワークフローにシームレスに統合されています。その主な機能は、統合開発環境（IDE）であるVisual Studio CodeやJetBrains IDEA内で、リアルタイムのコード提案を提供し、Copilot Chatを通じて会話型の支援を提供し、コードリファクタリング、デバッグ、プロジェクトのスキャフォールディングといった高度な機能をサポートすることで、開発者の生産性を向上させることにあります。このツールの中核的価値は、開発サイクルの加速、反復的なコーディングタスクの自動化、複雑な問題解決の支援を通じて、開発者の効率を大幅に高める能力にあります。
GitHub Copilotの有効性と能力は、それが活用する基盤となる大規模言語モデル（LLM）のパフォーマンスと特性に本質的に結びついています。これらの基盤モデルは、コード生成の品質と関連性、文脈理解の深さ、応答速度、および関連する運用コストを決定します。GitHub Copilotはユーザーに、これらの基盤となるAIモデルから選択する柔軟性を提供しており、開発者が特定のタスクや個人の好みに合わせてAI支援を最適化することを可能にします。この適応性は、迅速なプロトタイピングから複雑なマルチファイルリファクタリング操作まで、多様な開発ニーズにAIの動作を適合させる上で極めて重要です。
AIモデルの状況は、継続的かつ急速な革新によって特徴づけられます。OpenAIによるGPTシリーズの一貫した進歩は、GitHub Copilotのようなツールの進化に直接影響を与えます。各新世代のモデルは、実質的なパフォーマンス向上、効率性の向上、および拡張された能力を導入し、開発者環境内でAIが達成できる境界を一貫して押し広げ続けています。この動的かつ反復的な改善は、Copilotの全潜在能力を効果的に活用し、ソフトウェア開発における競争力を維持するために、連続するモデル間の差異についての徹底的かつ継続的な理解を必要とします。

### **2. GPT-4o: ベースライン能力と初期の役割**

GPT-4o（「o」は「omni」を意味する）は、画期的なマルチモーダルAIモデルとして導入され、主要なアーキテクチャの変化を示しました。このモデルは、単一のニューラルネットワーク内で、テキスト、画像、音声、ビデオといった様々なモダリティにわたってコンテンツをシームレスに処理し生成するネイティブな能力を有していました。この統一されたマルチモーダルサポートは、リアルタイム音声会話や直接的な視覚的質問応答などの機能に例示される、より直感的な人間とコンピュータの相互作用を可能にする、重要な技術的飛躍を表していました。GPT-4oの導入は、OpenAIにとって、マルチモーダル能力、リアルタイムパフォーマンス、およびコスト削減のバランスを重視する、顕著な戦略的転換を示すものでした。これは単なる知能の漸進的改善ではなく、より汎用的で効率的なAIツールに対する業界の成長する需要を反映した、AI設計の根本的な変化でした。
GPT-4oの主な利点の一つは、その報告されている速度にあり、前身であるGPT-4 Turboの2倍の速さでトークンを生成する能力を示しました。さらに、GPT-4と比較して約50%低い運用コストの削減を提供しました。音声入力に対してわずか320ミリ秒で応答するその驚くべき能力は、会話型AIにおけるリアルタイムレイテンシの大幅な改善を示すものでした。この「稲妻のように高速」な速度と「瞬時の応答」への重点は、Copilotのような対話型ツールにおけるAIモデルの採用において、知覚される応答性が重要な要素であることを強調しています。リアルタイムの提案とチャットを提供するツールにとって、即時の応答性は、開発者のフローと生産性を維持するために最も重要です。技術的に優れていても顕著な遅延をもたらすモデルは、採用とユーザー満足度を妨げるため、OpenAIとGitHubによるユーザー体験指標の優先順位付けを浮き彫りにしています。
知的能力の点では、GPT-4oは改善された推論能力を示し、高度なメモリとコンテキスト処理と相まって、複雑な問題解決を促進しました。コードの自動生成、デバッグ、ドキュメント作成などのタスクに熟達しており、多言語コンテキストおよび視覚的コンテンツの解釈において強化されたパフォーマンスを示しました。このモデルは128Kトークンのコンテキストウィンドウを特徴としており、そのリリース時点では、以前のモデルと比較してかなりの改善でした。
GitHub Copilot内では、GPT-4oはそのリリース後に顕著な役割を果たしました。特に「GPT-4o Copilot」（GPT-4o miniを基にしたファインチューニング版）と呼ばれる変種が、すべてのCopilotユーザーにおけるコード補完のデフォルトモデルとして確立され、以前のGPT-3.5 Turboベースのモデルに取って代わりました。この専門化されたモデルは、高品質な公開GitHubリポジトリの大規模なデータセットに対する広範なトレーニングの恩恵を受けており、30以上のプログラミング言語にわたる包括的なカバレッジを提供します。Copilotへのコード補完デフォルトモデルとしてのこの統合は、GitHubの当初の優先事項が、一般的なシナリオにおける広範で効率的かつ手頃なコード生成であったことを示唆し、IDE内でのパフォーマンスとユーザー体験に対する強力なベースラインを設定しました。さらに、GPT-4oはCopilot Chat内での選択肢として利用可能であり、軽量な開発タスクおよび一般的な会話型プロンプトに対して効果的であることが証明されました。GPT-4o、GPT-4o mini、GPT-4o nanoの同時リリースはまた、OpenAIによる多様なパフォーマンスとコスト要件に対応する意図的な戦略を強調し、高需要のリアルタイムシステムからコストに敏感なシナリオまで、様々なアプリケーションへの広範なアクセシビリティと統合を可能にしました。

### **3. GPT-4.1: アーキテクチャの進歩と現在の状況**

GPT-4.1は、2025年4月14日にリリースされ、「最新のフラグシップ」モデルおよび「OpenAIのGPT-4oモデルの刷新版」として称賛されています。これはGPT-4oの基盤の上に、「構造的改善」を伴って構築されており、AIモデル開発における継続的かつ急速な反復を示しています。Copilot向けのGPT-4oの一般提供に続くGPT-4.1というこの迅速な進展は、最先端の能力を提供するというOpenAIのコミットメントと、開発者第一の戦略を示しています。「直接的な開発者からのフィードバック」に基づく明示的な最適化は、開発者の痛点と、より正確で信頼性の高いAI支援の必要性に対する深い理解を強調しています。
GPT-4.1の中核的なアーキテクチャの改善は、主にソフトウェア開発タスクにおけるその有用性を高めることに焦点を当てています。

*   **比類なきコーディング能力:** この領域はGPT-4.1の開発において主要な焦点となりました。このモデルはSWE-bench Verifiedにおいて印象的な54.6%を達成し、GPT-4oの33.2%からの顕著な21.4%の絶対的改善を示しています。このベンチマークは、コードベース内で現実世界のソフトウェアエンジニアリングタスクをエンドツーエンドで解決するモデルの能力を測定します。さらに、GPT-4.1はAiderのポリグロット差分ベンチマーク（52.9%の精度）においてGPT-4oのスコアを2倍以上上回り、様々なプログラミング言語にわたるコード差分と的を絞った正確な変更を生成する上でかなり信頼性が高まっています。質的な改善として注目すべきは、「無関係な編集」の劇的な減少であり、GPT-4oでの9%からGPT-4.1ではわずか2%に低下しています。フロントエンドコーディングでは、人間の評価者がGPT-4oの生成したウェブアプリケーションよりも80%の頻度でGPT-4.1の生成物を好み、より機能性が高く美的に優れた結果であると挙げています。これらの進歩は、単なるコードスニペットを提案するAIから、より信頼性が高く、正確で、信頼できる「コーディング協働者」へと戦略的に移行していることを示しています。
*   **強化された指示追従性と操縦性:** GPT-4.1は、指示を正確に追従する能力において主要な進歩を示しています。MultiChallengeでは38.3%を記録し、GPT-4oのパフォーマンスから10.5%の絶対的増加を表し、IFEvalでは87.4%を達成し、GPT-4oの81%から向上しました。このトレーニングにより、モデルは「より操縦可能」になり、指示を「より文字通りに」追従できるようになり、信頼性の高い自動化ワークフローとAIエージェントを構築するための重要な要素となります。これは、多くのLLMに共通する課題、つまり幻覚を発生させたり明示的な多段階の指示から逸脱したりする傾向に直接対応し、与えられたタスクを正確に実行するAIの能力に対するより大きな信頼を育みます。
*   **拡張されたコンテキストウィンドウと長文コンテキスト理解:** すべてのGPT-4.1モデル（標準、mini、nano）は、巨大な100万トークンのコンテキストウィンドウを誇ります。これはGPT-4oの128Kトークンからの8倍の増加を表し、モデルが「75万語以上のテキスト—約3,000ページ」を処理し理解することを可能にします。これは単なる量的な増加ではなく、「コードベース全体、長文ドキュメント、または複数のファイルを一度に処理」することを可能にする質的飛躍を表します。また、長文コンテキストからの検索も改善され、Video-MME 'long, no subtitles'タスクで72.0%の精度を達成し、GPT-4oの65.3%から6.7%の絶対的改善を示しています。長文コンテキスト内でのマルチホップ推論のベンチマークであるGraphwalksでは、GPT-4.1はGPT-4oの41.7%に対して61.7%を記録しました。
*   **最適化された速度とコスト効率:** GPT-4.1は「その前身であるGPT-4oおよびGPT-4.5よりも最大40%高速」と説明されていますが、OpenAIはまた、GPT-4oと「ほぼ同じ範囲」のレイテンシを維持しつつ「より賢く（そしてより安価）」であることも示しています。miniおよびnanoバージョンの導入は、特にさらに低いレイテンシとコストを対象としており、先進的なAI能力を多様なアプリケーションにとってよりアクセスしやすく効率的にしています。この効率性への焦点は、より強力なモデルを高ボリュームのリアルタイム開発者ワークフローに対して経済的に実行可能にし、先進的なAI能力へのアクセスを民主化します。
*   **洗練されたマルチモーダル能力:** GPT-4.1は、GPT-4oと同様に、その完全なマルチモーダルサポートを維持し、複雑なマルチモーダルデータの優れた処理のために「高度な埋め込み技術」を統合しています。Video-MMEで72.0%、MMMUで74.8%を記録するなど、マルチモーダルベンチマークにおける継続的な進歩を示しています。これは、開発者がコードとテキストのみを通じてではなく、視覚的にもAIアシスタントと対話する未来を示唆しており、UI/UXや視覚的要素のデバッグなどのタスクにおける新しい相互作用のパラダイムを可能にします。

**GitHub Copilotにおける現在の状況と戦略的転換:**
GPT-4.1はGitHub Copilot内で急速に新標準となりつつあり、重要な戦略的転換を示しています。2025年5月8日現在、GPT-4.1はCopilot Chat、Edits、およびAgentモードの新たなデフォルトモデルとして展開されています。この移行は、GPT-4oからの直接的なアップグレードとして明示的に位置づけられています。GitHubは、GPT-4.1がデフォルトとして展開された後90日間はモデル選択肢としてGPT-4oを利用可能にしておくことを発表しており、その後これらの役割からは廃止される予定です。これは、Copilotのほとんどの機能にわたって、GitHubがGPT-4.1を主要かつ優先されるモデルとして戦略的に枢軸を回していることを示すものです。「コーディングと指示追従」のために明示的に設計されたGPT-4.1は、開発者の痛点と、より正確で信頼性の高いAI支援の必要性に対する深い理解を示し、ソフトウェアエンジニアリングタスク向けに特別に構築されたモデルへと向かう動きです。
コード補完に関しては、2025年3月27日現在、デフォルトモデルは「GPT-4o Copilot」（ファインチューニングされたGPT-4o mini）でした。しかし、GPT-4.1はすでに最新のVS CodeおよびJetBrains IDE内でコード補完のために手動で選択可能です。その優れたコーディングベンチマークを考慮すると、GPT-4.1が間もなくコード補完の普遍的なデフォルトとなることが強く期待されます。GPT-4.1はCopilot Freeティアを含むすべてのGitHub Copilotプランでアクセス可能であり、その強化された能力への広範なアクセスを保証しています。この急速な革新のペースは、開発者が最新のモデル能力を活用するために、ワークフローを継続的に適応させ、敏捷性を保つ必要があることを意味します。
「指示追従」と「長文コンテキスト理解」における顕著な進歩は、GPT-4.1が「エージェントを駆動する」または「エージェント的ワークフロー」において効果的であることと明示的に結びつけられています。多段階の指示に従い、長い会話で一貫性を保ち、コードベース全体を処理する能力は、複雑なタスクを独立して達成できるAIエージェントにとって基本的なものです。これは、単純なコード補完やチャットを超えて、多面的なソフトウェアエンジニアリングの問題に取り組むことができる、より自律的なAIアシスタントへの移行を示しており、機能がどのように構築され、バグが修正されるかを革命的に変える可能性があります。

### **4. 総合的なパフォーマンス比較: GPT-4o vs. GPT-4.1**

このセクションでは、利用可能なベンチマークと質的観察を活用し、主要な指標にわたるGPT-4.1の優れたパフォーマンスを強調する、GPT-4oとGPT-4.1の詳細なデータ駆動型比較を提供します。
**表 1: GPT-4o vs. GPT-4.1 中核的能力 & ベンチマーク**
この表は重要な参考資料として機能し、最も重要なパフォーマンス指標の簡潔な一覧比較を提供します。開発者が散在するベンチマークデータを容易に消化可能な形式に統合することで、GPT-4.1がGPT-4oに対して提供する改善の大きさを迅速に把握することを可能にします。この直接比較は、モデル選択に関する情報に基づいた意思決定に不可欠です。

| 機能/指標 | GPT-4o | GPT-4.1 | 重要性 |
| :---- | :---- | :---- | :---- |
| **リリース日** | 2024年5月13日 (概算) | 2025年4月14日 5 | GPT-4.1はより新しく、より先進的な反復版。 |
| **SWE-bench Verified スコア (コーディング)** | 33.2% 1 | 54.6% 1 | 21.4%の絶対的改善。現実世界のソフトウェアエンジニアリングスキルを測定。 |
| **Aider Polyglot Diff スコア (コーディング精度)** | \~25% (推定) 1 | 52.9% 1 | GPT-4oのスコアを2倍以上上回る。正確なコード差分生成における優れた信頼性を示す。 |
| **無関係なコード編集** | 9% 1 | 2% 1 | 不要な変更の劇的減少。よりクリーンなコードと迅速なレビューにつながる。 |
| **MultiChallenge スコア (指示追従)** | 27.8% 1 | 38.3% 1 | 10.5%の絶対的改善。マルチターン指示への追従能力を測定。 |
| **IFEval スコア (指示追従)** | 81.0% 1 | 87.4% 1 | 検証可能な指示とフォーマット規則への適合性が改善。 |
| **コンテキストウィンドウ** | 128K トークン 3 | 100万 トークン 1 | 8倍の増加。コードベース全体の理解を可能にする (約3,000ページ)。 |
| **相対的コスト (API)** | GPT-4 Turboより手頃 24, GPT-4より約50%低い 9 | 「低コスト」 1, 「GPT-4oより安価」 2, 「初期モデルと比較して80%低い入力コスト」 8 | 運用費を削減しつつパフォーマンスを最適化。 |
| **相対的速度/レイテンシ** | GPT-4 Turboの2倍の速さ 24, 「稲妻のように高速」 9, 「瞬時の応答」 9 | 「GPT-4oより最大40%高速」 4, 「最速」 11, GPT-4oと「同様の速度」 3 | 知能を高めつつ応答性を維持または改善。 |
| **マルチモーダリティ** | テキスト、画像、音声、ビデオ 9 | 高度なテキスト、画像、音声、ビデオ 3 | 両者ともマルチモーダル。GPT-4.1は複雑な視覚データの理解が強化。 |
| **ナレッジカットオフ** | 明示されず、GPT-4.1より前と推定 | 2024年6月 2 | GPT-4.1はより最新のトレーニングデータを保持。 |

*注: GPT-4oのAider Polyglot Diffスコアは、GPT-4.1のスコアと「GPT-4oのスコアを2倍以上上回る」という記述から推定。*

#### **4.1. コーディングパフォーマンス**

GPT-4.1は、コーディング特有のベンチマークにおいて一貫して顕著なリードを示し、開発者にとって優れたツールとしての位置づけを確立しています。現実世界のソフトウェアエンジニアリングスキルを測定するベンチマークであるSWE-bench Verifiedにおいて、GPT-4.1は54.6%の成功率を達成し、GPT-4oの33.2%からの実質的な21.4%の絶対的改善を表しています。これは、GPT-4.1のコードリポジトリの探索、タスクの完了、実行可能でテストに合格するコードの生成能力が強化されていることを示します。コード差分生成において、GPT-4.1はAiderのポリグロット差分ベンチマークで52.9%を記録し、GPT-4oの推定パフォーマンスの2倍以上です。この指標は、様々なプログラミング言語とフォーマットにわたる正確なコード変更を生成するその信頼性にとって極めて重要であり、開発者がコストとレイテンシを節約し、変更された行のみを出力することを可能にします。
生のスコアを超えて、GPT-4.1はコード生成において重要な質的改善を示します。それは「無関係な編集をより少ない頻度で」行い、その割合はGPT-4oでの9%からわずか2%に大幅に低下しています。この不要な変更の減少は、よりクリーンで保守性の高いコード、そして迅速なレビューサイクルに直接つながります。GPT-4.1はまた、フォーマット全体で「コード差分においてはるかに信頼性が高い」です。フロントエンドコーディングでは、人間の評価者がGPT-4oの生成したウェブアプリケーションよりも80%の頻度でGPT-4.1の生成物を好み、より機能性が高く美的に優れた結果であると挙げています。開発者による内部評価では、GPT-4.1は内部コーディングベンチマークにおいてGPT-4oよりも「60%優れている」と報告され、これはコード変更が最初のレビューで受け入れられる頻度と強く相関しています。ユーザーフィードバックはこれをさらに裏付けており、GPT-4.1がエージェントモードで「1000から1200行のReactコンポーネント」をモジュラー構造にリファクタリングすることに成功したという報告があります。これはGPT-4oが以前は苦戦していたタスクです。この信頼性と精度の高さは、開発者がAI生成コードの修正または改良に費やす時間が大幅に短縮されることを意味し、真のかつ実質的な生産性向上につながります。これにより、開発者はより複雑で、マルチファイルにまたがり、アーキテクチャ的なタスクをAIに自信を持って委任できるようになり、それによって人間の開発者はより高レベルのアーキテクチャ設計、複雑な問題解決、そして創造的革新に解放されます。

#### **4.2. 指示追従性と操縦性**

GPT-4.1は、AIアシスタントにとって重要な能力である指示追従において、顕著な向上を示しています。このモデルはMultiChallengeベンチマークで38.3%を記録し、GPT-4oの27.8%から10.5%の絶対的増加を表しています。このベンチマークは、モデルがマルチターンの指示に従い、会話の深部まで一貫性を維持し、過去のメッセージから情報を拾い出す能力を測定します。IFEvalでは、コンテンツの長さの指定や特定の用語やフォーマットの回避など、検証可能な指示への適合性を評価しますが、GPT-4.1は87.4%を達成し、GPT-4oの81%から向上しました。
OpenAIは明示的にGPT-4.1を「指示をより文字通りに追従するようにトレーニングし、モデルをより操縦可能にした」と述べています。初期のテスターはこれが「より文字通りになり得る」ことを確認し、ユーザーフィードバックはその指示を正確に追従する能力を称賛し、「私が依頼した以上のことをしない」と述べています。この強化された文字通りの遵守は、信頼性が高く予測可能なAIエージェントと自動化ワークフローを構築するために極めて重要です。「文字通り」の指示追従への明示的な重点と、IFEvalのようなベンチマークでの改善されたスコアは、多くのLLMに共通する課題、つまり幻覚を発生させたり明示的な多段階の指示から逸脱したりする傾向に直接対応します。自動化ワークフロー、AIエージェント、または正確なルールベースのタスクにAIを依存する開発者にとって、与えられた指示通りに正確に従うAIの能力への信頼は最も重要です。GPT-4.1の強化された操縦性はこの信頼を育み、ソフトウェアエンジニアリングにおける真に効果的なエージェント的能力のための必須の前提条件である、より堅牢で予測可能かつ信頼できるAI駆動プロセスの創造を可能にします。

#### **4.3. コンテキストウィンドウと長文コンテキスト理解**

GPT-4.1は業界をリードする100万トークンのコンテキストウィンドウを特徴としています。これはGPT-4oの128Kトークンからの8倍の増加を表し、「75万語以上のテキスト—約3,000ページ」に相当する処理を可能にします。これは単なる量的な増加ではなく、大規模な情報を理解するAIの能力における質的飛躍を表し、モデルが「コードベース全体、長文ドキュメント、または複数のファイルを一度に処理」することを可能にします。これは、コンテキスト認識が多くの場合、アクティブなファイルまたは最近のコードの小さなウィンドウに集中していたという、AIアシスタントの伝統的な制限に直接対応します。
このモデルは「これらの長文コンテキストから情報を正しく見つけて検索するためのより優れた注意メカニズム」を組み込んでいます。長文コンテキストベンチマークにおけるそのパフォーマンスはこれを反映しており、Video-MME (long, no subtitles) はGPT-4oの65.3%からGPT-4.1では72.0%に改善しています。長文コンテキスト内でのマルチホップ推論のベンチマークであるGraphwalksでは、GPT-4.1はGPT-4oの41.7%に対して61.7%を達成しています。この劇的に拡張されたコンテキストは、AIアシスタントがソフトウェアプロジェクト全体または大規模なサブシステムの広範なアーキテクチャ、相互依存関係、コーディング規約、および暗黙の知識を理解することを可能にします。これは、大規模なリファクタリング、レガシープロジェクトの移行、包括的なテストスイートの生成、または複数のファイルとモジュールにまたがるセキュリティ分析の実行などの複雑なタスクにとって深く重要であり、Copilotを「スニペットジェネレーター」から、全体的な問題解決が可能な「プロジェクトを意識したアーキテクト」へと効果的に変革します。

#### **4.4. 速度、レイテンシ、コスト効率**

GPT-4.1は、GPT-4oと比較して「同様の速度で、より賢く（そしてより安価な）モデル」として戦略的に位置づけられています。GPT-4oはその速度で称賛され、GPT-4 Turboの2倍の速さでトークンを生成し、「稲妻のように高速」な瞬時の応答を提供しましたが、GPT-4.1はまた「その前身であるGPT-4oおよびGPT-4.5よりも最大40%高速」であるとも言及されています。これは、応答性を犠牲にすることなく知能を高めるという、パフォーマンス最適化への継続的な推進力を示しています。
コストの点では、GPT-4.1は「低コストで卓越したパフォーマンス」を提供するように設計され、「初期モデルと比較して80%低い入力コスト」を達成しています。GPT-4.1 miniおよびnanoバリアントの導入は、さらにこの焦点を強調するものであり、それらは特にさらに低いレイテンシとコストのために設計され、先進的なAI能力をより広範なアプリケーションにとって経済的に実行可能にします。この効率性への執拗な焦点は、より強力で能力の高いAIモデルを高ボリュームのリアルタイム開発者ワークフローに対して経済的に実行可能にします。それは事実上、それらをより手頃にすることによって最先端のAI能力へのアクセスを民主化し、それによって以前はコストがかかりすぎた新しいアプリケーションを可能にし、より広範なユーザーベースのための日常的な開発実践への先進的なAIの統合を加速します。

#### **4.5. マルチモーダル能力**

GPT-4.1は、その完全なマルチモーダルサポートをGPT-4oと同様に維持し、テキスト、画像、その他のモダリティを処理し統合する能力を有し、改善された処理のための「高度な埋め込み技術」の恩恵を受けています。GPT-4oが音声とビデオをネイティブに処理したのに対し、GPT-4.1はマルチモーダルベンチマークにおける継続的な進歩を示し、Video-MMEで72.0%、MMMUで74.8%を記録しています。
視覚的入力能力を備えたモデル、GPT-4バリアントを含む、は、コンテキスト理解のためのスクリーンショットのような画像を処理するのに価値があります。これは、モックアップからのデザイン変更の適用やユーザーインターフェースの視覚的不一致のデバッグなどのタスクに特に有用です。GPT-4.1における堅牢なマルチモーダル能力への継続的な重点は、開発者がコードとテキストプロンプトのみを通じてではなく、視覚的にもAIアシスタントと対話する未来を示唆しています。これは開発者にとっての新しいより直感的な相互作用のパラダイムを開き、フロントエンド開発、UI/UXデザイン、または視覚的バグのデバッグに関連するタスク、特にAIとのより自然で効率的なコミュニケーションを可能にします。これは、従来のコードと並んで視覚的および概念的な入力を包含する、ソフトウェア開発プロセス全体のより全体的な理解に向かってCopilotを動かします。

### **5. IDE間での統合とユーザー体験 (VS Code & JetBrains IDEA)**

GitHub Copilotは、人気のある統合開発環境全体での広範な互換性を念頭に設計されており、VS CodeとJetBrains IDEAに対する特定の統合のニュアンスがあります。

#### **5.1. Copilot Chatにおけるモデル選択**

GitHub Copilot Chatのユーザーは、それらの相互作用を駆動するために異なる基盤となるAIモデルを選択する柔軟性を持っています。VS CodeおよびGitHub.com上の没入型ビューのCopilot Chat内では、開発者はGPT-4o、GPT-4.1、GPT-4.5 (プレビュー)、様々なClaude Sonnetモデル (3.5, 3.7, 3.7 Thinking, 4 プレビュー, Opus 4 プレビュー)、およびGeminiモデル (2.0 Flash, 2.5 Pro プレビュー) など、