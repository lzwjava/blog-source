---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4-fast
title: MIT教授がAI安全性を推進
translated: true
type: note
---

アレクサンダー・マドリーは、著名な計算機科学者でありMITの教授である。MITでは電気工学・計算機科学科（EECS）においてCadence Design Systems Professorshipを保持している。また、計算機科学・人工知能研究所（CSAIL）のメンバーであり、MIT Center for Deployable Machine Learningのディレクターも務めている。マドリーは2011年にMITで博士号を取得し、その後マイクロソフトリサーチニューイングランドで博士研究員を務め、EPFLで教職に就いた後、2015年にMITに戻った。

彼の研究は主に機械学習、最適化、アルゴリズム的グラフ理論に焦点を当てており、特に実世界での展開に向けた、堅牢で信頼性が高く責任ある機械学習システムの開発を重視している。彼はMITのMadry Labを率いており、敵対的頑健性や安全な意思決定など、AIモデルのリスクを軽減するためのツールや技術を探求している。代表的な貢献としては、証明可能に頑健なニューラルネットワークに関する基礎研究や、大規模モデルのためのデータ帰属手法などが挙げられる。

2023年5月以降、マドリーはMITを休職してOpenAIにTechnical Staffの一員として参加している。この役職では、AI Preparedness and Reasoningチームを率いており、フロンティアAIモデルの潜在的リスク（壊滅的な悪用など）を評価し、システムをより有能で信頼性が高く、人間の価値観に沿ったものとするために推論能力を進歩させることに取り組んでいる。以前は、OpenAIのPreparednessチームを率いて安全評価に焦点を当てていたが、2024年の組織再編により、その重点は推論プロジェクトへと移行した。最近のインタビューで、マドリーは人工汎用知能（AGI）が2026年末までに出現する可能性があると予測し、AIが金融や製薬などの分野で目に見える影響を与える転換点となると述べた。

彼はX（旧Twitter）で@aleks_madryとして活動しており、大規模AIシステムにおけるトレーニングデータの影響を分析するための小さな「プロキシ」モデルの使用に関する最近の研究など、自身の研究に関する更新情報を共有している。

### 参考文献
- [Aleksander Mądry Homepage](http://madry.mit.edu/)
- [Madry Lab](https://madrylab.mit.edu/)
- [Aleksander Mądry LinkedIn](https://www.linkedin.com/in/aleksander-madry-61115b233)
- [OpenAI Reassigns Madry to AI Reasoning Role (CNBC, 2024)](https://www.cnbc.com/2024/07/23/openai-removes-ai-safety-executive-aleksander-madry-from-role.html)
- [Mądry on AGI Timeline (Reddit Interview Summary, 2025)](https://www.reddit.com/r/accelerate/comments/1ocgxdl/openais_aleksander_m%C4%85dry_by_the_end_of_2026_well/)
- [Mądry X Profile](https://x.com/aleks_madry)