---
audio: false
generated: true
lang: ja
layout: post
title: 大規模言語モデルが私のCFA洞察を裏付ける
translated: true
type: note
---

https://weibo.com/6347862377/5183994120372979

https://substack.com/inbox/post/167355695

---

以前の微博でも述べたように、私は自分がやりたくなかったり読む気が起きない複雑で退屈なことをLLMに処理させるのが好きです。多くの学術論文もこれに含まれます。

2009-2010年にPySonar2（Pythonの型推論と静的解析ツール）を作ってから10年以上経った今、ChatGPTと制御フロー解析（CFA）について議論していて、10年前にある「CFA学生」と議論したことを思い出しました。

https://www.yinwang.org/blog-cn/2016/04/07/cfa

（当時ウェブサイトにアップロードしたスクリーンショットは今は消えてしまいました。残っているものだけで我慢してください。）

とても興味深いことです——10年以上前に私がはっきりと見えていたことが、今ChatGPTによって「確認」されました。

15年前、PySonar2が最初に作られた時点で、それは当時のすべての学術的なCFA研究（最新のCFA2を含む）をすでに凌駕していました。lambdaクロージャを持つPythonのような準関数型言語において、これほど精密な型推論を実現したのは初めてのことでした。精度が非常に高いだけでなく、そのパフォーマンスもGitHub上のすべての大規模Pythonプロジェクトを分析するのに十分なほどでした。

PySonar2の最大のユーザーであったSourcegraphの創業者は当時、PySonar2の解析が驚くほど精密だと私に話していました。当時、私はあまり気に留めませんでした。なぜなら、私のアプローチは非常に単純で、誰でも思いつき得るものだと思っていたからです。他に誰もそれを成し遂げていなかったことに気づくまで、その価値を強調すべきだとは思いませんでした。

今でさえ、JetBrainsのPyCharm IDEでさえ、これほど精密な解析や「定義の検索」機能を実現できていません。例えば、Noneで初期化されたグローバル変数を定義し、後で何らかの「初期化関数」内で構造体を代入する場合、その構造体のメンバーを見つけることはできません。そんな悪いコードを書くべきだと言っているのではありません。これは一例です。

私がインディアナ大学で成し遂げたことを知っていれば、PySonar2は私にとって本当に大したことではなかったと理解できるでしょう——それは私の努力のほんの一部に過ぎませんでした。当時、私はPython言語自体にはあまり関心がありませんでした。そしてそれらのCFA論文は難解で、深く掘り下げる気も起きませんでした。私はそれらにざっと目を通しただけで、ほとんどがナンセンスだとわかりました。だから、私は数ヶ月でPySonar2を構築し、他の人に自由に使わせ、論文を書くことさえしませんでした。その原理はほんの数文で説明できました。

私は謙虚すぎました。CFA、k-CFA、CFA2の論文の山を見てください——大量にあるのに、現実の問題を解決できず、実際に使われることもありませんでした。k-CFAには「呼び出しと戻り値が一致しない」という基本的な問題さえありました。これは私が起こり得るとは思わなかったことです。PySonar2にはこの問題は一度もありませんでした。どうして誰かがそんな愚かな設計をし、それについて論文を書き、後継者たちがそれを「改良」し続けることができるのでしょうか？

Matt MightのCFA2は何らかの「プッシュダウンオートマトン」を導入しましたが、それは初期の欠陥のある設計から関数呼び出しスタックを回復する方法に過ぎませんでした。PySonar2には常に「プッシュダウンオートマトン」がありました。関数呼び出しを解釈する際には自然にスタックが生じるからです。

Matt Mightはブログを持っていて、「自動CPS変換」がどのようにして生まれたかを得意げに説明していました。まるで彼だけが理解しているかのように。しかし、彼のアイデアは明らかに過度に複雑なCPS論文から進化したもので、独立した思考の結果ではなく、多くの歴史的な負債を抱えていました。彼の文章はしばしば深遠に聞こえますが、理解するのが難しい——実際に理解できますか？彼のアイデアは私の「40行のコード」アプローチとは比較になりません。彼のブログを読んだ時、私は笑っていましたが、礼儀と「謙虚さ」のために黙っていました。Matt Mightには本質が欠けていると思います。そしてあのグループの人々はただでたらめを言っていただけです。これが真実で、長い時を経て今明かすことができます。

これらの論文はただの意味不明なものを生み出しているのではありませんか？はい、私は10年以上前にこれを知っていました。しかし、当時誰に理解できたでしょうか？今ではChatGPTで確認できます :)

実際、ChatGPTは別のことも確認しました。Olin Shiversの基礎的なCFA論文におけるCPSの使用が、すべてのトラブルの根源でした。

PySonar2は完全に独立して構築され、いかなる学術的な仕事も参照していません。それは学術的な負債なしに、直接根本的な問題に対処しました。これが単純な思考の価値です。これは私がこのような鋭い結果で学界と産業界の両方を独立して凌駕した最初の経験ではありませんでした。

私がPySonar2を作った後、Googleのチームは2年以上を費やしてより優れたものを作ろうとしましたが、彼らは何も成し遂げられず、Googleは私が改良したオープンソースのコードを使い続けなければなりませんでした。なぜですか？彼らの戦略が最初から間違っていたからです。彼らはPythonの型推論にPrologのような論理プログラミング言語を使いたがりました。そして私はそれが失敗する運命にあるとすぐにわかりました。どうしてわかったのか？私はすでにこれらの方法を実装しており、Hindley-MilnerシステムとPrologの限界を理解していたからです。どうしてそれを知っていたのか？IUで論理プログラミング言語を実装し改良していたからです。

私が見た事実をChatGPTが明確に説明してくれたことに感謝しなければなりません。それによって、あの難解な論文を読む必要がなくなりました。私のアイデアの価値を検証してくれたことに感謝しています。LLMが人類の進歩に大きく貢献するだろうと感じています。

今、私はCFAについてChatGPTと交わした会話を共有します。この分野の研究者の助けになればと思います：

https://chatgpt.com/share/6864e9a1-66c8-8002-b9f5-55e845fde7ae