---
audio: false
generated: true
lang: ja
layout: post
title: ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨Vision Transformerã‚’ç”¨ã„ãŸç”»åƒå‡¦ç†
translated: true
type: note
---

ä»¥ä¸‹ã¯ã€**ç•³è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆCNNï¼‰** ã¨ **Vision Transformerï¼ˆViTï¼‰** ã‚’ Python ã® **PyTorch** ã§ä½¿ç”¨ã—ã¦ç”»åƒã‚’å‡¦ç†ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã‚³ãƒ¼ãƒ‰ä¾‹ã§ã™ã€‚

---

## **1. CNNï¼ˆç•³è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã«ã‚ˆã‚‹ç”»åƒå‡¦ç†**
CNNã¯ã€ç”»åƒåˆ†é¡ã€ç‰©ä½“æ¤œå‡ºã€ç‰¹å¾´é‡æŠ½å‡ºã«åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

### **ä¾‹ï¼šäº‹å‰å­¦ç¿’æ¸ˆã¿CNNï¼ˆResNetï¼‰ã®ä½¿ç”¨**
```python
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image

# äº‹å‰å­¦ç¿’æ¸ˆã¿ResNetãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
model = models.resnet18(pretrained=True)
model.eval()  # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š

# ç”»åƒå‰å‡¦ç†ã®å®šç¾©
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# ç”»åƒã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
image = Image.open("example.jpg")  # ç”»åƒãƒ‘ã‚¹ã«ç½®ãæ›ãˆã¦ãã ã•ã„
input_tensor = preprocess(image)
input_batch = input_tensor.unsqueeze(0)  # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 

# GPUãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯GPUã«ç§»å‹•
if torch.cuda.is_available():
    input_batch = input_batch.to('cuda')
    model.to('cuda')

# ç‰¹å¾´é‡ã®æŠ½å‡ºï¼ˆæœ€çµ‚åˆ†é¡å±¤ã®å‰ï¼‰
with torch.no_grad():
    features = model(input_batch)

print("ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã®å½¢çŠ¶:", features.shape)  # ä¾‹: torch.Size([1, 1000])
```
**èª¬æ˜**:
1. **ResNet18** ã¯ã€ImageNetã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸCNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚
2. ç”»åƒã¯å‰å‡¦ç†ï¼ˆãƒªã‚µã‚¤ã‚ºã€æ­£è¦åŒ–ï¼‰ã•ã‚Œã¾ã™ã€‚
3. ãƒ¢ãƒ‡ãƒ«ã¯ç”»åƒã‚’**ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«**ï¼ˆä¾‹: ResNet18ã®å ´åˆã¯1000æ¬¡å…ƒï¼‰ã«å¤‰æ›ã—ã¾ã™ã€‚

---

## **2. Vision Transformer (ViT) ã«ã‚ˆã‚‹ç”»åƒå‡¦ç†**
ViTã¯ã€ç”»åƒã‚’ãƒ‘ãƒƒãƒã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¨ã—ã¦æ‰±ã„ã€ï¼ˆNLPã®ã‚ˆã†ãªï¼‰Self-Attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

### **ä¾‹ï¼šäº‹å‰å­¦ç¿’æ¸ˆã¿ViTï¼ˆHugging Faceï¼‰ã®ä½¿ç”¨**
```python
from transformers import ViTFeatureExtractor, ViTModel
from PIL import Image
import torch

# äº‹å‰å­¦ç¿’æ¸ˆã¿Vision Transformer (ViT)ã®èª­ã¿è¾¼ã¿
model_name = "google/vit-base-patch16-224-in21k"
feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)
model = ViTModel.from_pretrained(model_name)

# ç”»åƒã®èª­ã¿è¾¼ã¿
image = Image.open("example.jpg")  # ç”»åƒãƒ‘ã‚¹ã«ç½®ãæ›ãˆã¦ãã ã•ã„

# ç”»åƒã®å‰å‡¦ç†ï¼ˆãƒ‘ãƒƒãƒã¸ã®å¤‰æ›ï¼‰
inputs = feature_extractor(images=image, return_tensors="pt")

# ç‰¹å¾´é‡ã®æŠ½å‡ºï¼ˆCLSãƒˆãƒ¼ã‚¯ãƒ³ã¾ãŸã¯ãƒ‘ãƒƒãƒåŸ‹ã‚è¾¼ã¿ï¼‰
with torch.no_grad():
    outputs = model(**inputs)

# ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã®å–å¾—ï¼ˆCLSãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
features = outputs.last_hidden_state[:, 0, :]  # å½¢çŠ¶: [1, 768]

print("ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã®å½¢çŠ¶:", features.shape)  # ä¾‹: torch.Size([1, 768])
```
**èª¬æ˜**:
1. **ViT** ã¯ç”»åƒã‚’ **16x16ãƒ‘ãƒƒãƒ** ã«åˆ†å‰²ã—ã€NLPã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚ˆã†ã«å‡¦ç†ã—ã¾ã™ã€‚
2. `CLSãƒˆãƒ¼ã‚¯ãƒ³`ï¼ˆæœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã¯ã€ç”»åƒå…¨ä½“ã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¡¨ã—ã¾ã™ã€‚
3. å‡ºåŠ›ã¯ **768æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«**ï¼ˆ`vit-base`ã®å ´åˆï¼‰ã§ã™ã€‚

---

## **3. CNNã¨ViTã®ç‰¹å¾´æŠ½å‡ºã®æ¯”è¼ƒ**

| ãƒ¢ãƒ‡ãƒ« | ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ | ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚µã‚¤ã‚º | ãƒ©ã‚¤ãƒ–ãƒ©ãƒª |
|-------|----------|---------------------|-----------|
| **CNN (ResNet18)** | ç•³è¾¼ã¿å±¤ + ãƒ—ãƒ¼ãƒªãƒ³ã‚° | 1000 (ImageNet ã‚¯ãƒ©ã‚¹æ•°) | `torchvision` |
| **ViT (Google ViT-Base)** | ãƒ‘ãƒƒãƒåŸ‹ã‚è¾¼ã¿ + Transformer | 768 (éš ã‚Œæ¬¡å…ƒæ•°) | `transformers` |

---

## **4. ç”»åƒç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã®å¿œç”¨ä¾‹**
- **ç”»åƒæ¤œç´¢**: ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ¯”è¼ƒï¼ˆä¾‹: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰ã€‚
- **è»¢ç§»å­¦ç¿’**: äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ç‰¹å¾´é‡ã‚’ã‚«ã‚¹ã‚¿ãƒ ã‚¿ã‚¹ã‚¯ã«ä½¿ç”¨ã€‚
- **ç‰©ä½“æ¤œå‡º**: ç‰¹å¾´é‡ã‹ã‚‰é–¢å¿ƒé ˜åŸŸï¼ˆROIï¼‰ã‚’æŠ½å‡ºã€‚

```python
# ä¾‹ï¼š2æšã®ç”»åƒé–“ã®é¡ä¼¼åº¦è¨ˆç®—
from sklearn.metrics.pairwise import cosine_similarity

# features1 ã¨ features2 ãŒæŠ½å‡ºã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã¨ä»®å®š
similarity = cosine_similarity(features1, features2)
print("é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢:", similarity[0][0])
```

---

## **ä¸»ãªãƒã‚¤ãƒ³ãƒˆ**
1. **CNN**ï¼ˆä¾‹: ResNetï¼‰ã¯ã€**ç•³è¾¼ã¿å±¤**ã‚’ä½¿ç”¨ã—ã¦éšå±¤çš„ãªç‰¹å¾´ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
2. **ViT**ï¼ˆä¾‹: Googleã®ViTï¼‰ã¯ã€ç”»åƒã‚’**ãƒ‘ãƒƒãƒã‚·ãƒ¼ã‚±ãƒ³ã‚¹**ã¨ã—ã¦æ‰±ã„ã€**Self-Attention**ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
3. ä¸¡æ–¹ã¨ã‚‚ã€ç”»åƒã‚’ä¸‹æµã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®**ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«**ã«å¤‰æ›ã—ã¾ã™ã€‚

**ã‚«ã‚¹ã‚¿ãƒ CNN/ViTã‚’ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ä¾‹**ã«ã¤ã„ã¦ã‚‚ã”å¸Œæœ›ã§ã™ã‹ï¼ŸãŠçŸ¥ã‚‰ã›ãã ã•ã„ï¼ ğŸš€