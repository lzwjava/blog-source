---
audio: false
generated: true
image: false
lang: ja
layout: post
title: ミストラル・ミディアムのトークン制限を超えて
translated: true
type: note
---

あなたが使用しているモデル **Mistral Medium 3.1** のトークンコンテキスト制限に達しています。このモデルの上限は **32kトークン**（プロンプト＋出力）です。ログでは、あなたはすでに約9kトークンのプロンプトを送信し、約1kトークンの出力を得ているので、まだ制限内ではありますが、この上限を自分で「引き上げる」ことはできません。

実際に取れるオプションは以下の通りです：

### 1. より大きなコンテキストウィンドウを持つモデルに切り替える

* **Claude Sonnet 4** → 最大 **1Mトークン**
* **Claude Opus 4** → 最大 **200kトークン**
* **GPT-4.1 / GPT-5** → 最大 **128kトークン**（プロバイダー設定による）
* **Gemini 1.5 Pro** → 最大 **2Mトークン**（Google Vertex/AI Studio経由）

32kトークンを超える入力が必要な場合、Mistral Mediumでは対応できません。別のモデルを選択する必要があります。

### 2. チャンキングまたは検索を利用する

コストや速度の理由でMistral Mediumを使い続けたい場合は、入力を小さな部分に分割する必要があります：

* トランスクリプトやドキュメントを約20k-25kトークンのチャンクに分割する。
* バッチ処理を実行する。
* オプションで**検索パイプライン**を使用する：長いドキュメントをベクトルDBに保存し、最も関連性の高い部分のみを渡す。

### 3. プロバイダー設定を確認する

一部のAPIゲートウェイ（OpenRouter、Vertexなど）では、モデルのバリアント（`mistral-large`、`mistral-medium`など）を指定できます。より高い制限が必要で、かつMistralを優先したい場合は、**Mistral Large**（約128kトークンをサポート）に切り替える必要があります。

---

👉 もしあなたの目標が単に「ログがより多くのトークンを受け入れられるようにする」ことであるなら、唯一の方法は**より高いコンテキスト長を持つモデルを選ぶ**ことです。

現在ルーティングしているすべてのモデル（Claude、Gemini、GPT-5、DeepSeek、Mistralなど）の**最大トークンコンテキスト**をリストアップして、どれを使用するか決める手伝いをしましょうか？