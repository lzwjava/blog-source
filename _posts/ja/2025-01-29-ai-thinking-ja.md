---
audio: true
lang: ja
layout: post
title: AI思考
translated: true
---

- Satya Nadellaはジェボンズパラドックスについて言及しました。学びに価値があるでしょう。

- 殷 王：人工知能には「知能」がありません、ニューラルネットワークには「神経」がありません、機械学習には「学習」がありません、ディープラーニングには「深さ」がありません。ディープラーニングには「深さ」がありません。本当に効果的なものは「微分」と呼ばれます。そこでこの分野を「微分可能コンピューティング」と呼び、モデルを構築するプロセスを「微分可能プログラミング」と呼ぶのが好みです。

- 殷 王：機械学習は非常に有用で、きっと美しい理論でもあります。単に化粧をした微分学です！それはニュートンやライブニッツの古いさらなる大きな理論ですが、より簡潔で美しく力強い形です。機械学習は主に微分学を用いて関数を導出し、適合させることであり、ディープラーニングはより複雑な関数を適合させることです。

- 現在、大規模言語モデルはYAMLやPythonのようなファイル言語でフィルタリングできません。しかし、実際の世界の情報の大部分はこのように整理されています。これは、大規模言語モデルをファイルでトレーニングすることができるということを意味します。

- 大規模言語モデルをトレーニングするためには、正確な一致を見つけるシステムを開発することができます。もしかすると、KMP（ナッソー・モリス・プラット）検索アルゴリズムをトランスフォーマーアーキテクチャと組み合わせて検索機能を向上させることができるかもしれません。