---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4-fast
title: 計算力は人間の創意を凌駕する
translated: true
type: note
---

### リチャード・サットンの「苦い教訓」

強化学習の研究で知られる先駆的なAI研究者、リチャード・サットンは、2019年に「苦い教訓」と題する短いエッセイを書きました。これは70年以上にわたるAIの歴史を振り返り、AIの進歩への最も効果的な道筋は、人間の知能を模倣したり、専門知識を詰め込んだりするものではないと論じたものです。その代わりに、「苦い」真実とは、**長期的には、検索アルゴリズムや機械学習のような、生の計算力でスケールする汎用的な手法が、人間にインスパイアされた巧妙な設計を常に凌駕する**ということです。

#### 核心的な考え
サットンは繰り返し現れるパターンを観察しています。初期のAIの成功は、しばしば人間の専門知識（例：ルール、ヒューリスティクス、ドメイン固有の知識）をシステムに注入することからもたらされます。これは最初は直感的で効率的に感じられますが、計算コストが安くなり豊富になるにつれて、それらの知識重視のアプローチは壁にぶつかります。それらは脆くなり、スケールが難しく、試行錯誤を通じてコンピュータに力任せに解決策を見つけさせる、より単純な「メタ手法」によって追い抜かれてしまうのです。

「苦い」部分とは？私たち人間は、この教訓が自らの創意工夫や直感を脇に追いやるため、これを嫌います。私たちは「人間のように考える」システムを構築したくなりますが、証拠はそれが大きな進歩にとって行き止まりであることを示しています。サットンは次のように要約します：「苦い教訓は、私たちが開発した最も強力な手法…は計算を活用するものであるという観察に基づいている」。

#### 歴史的な事例
サットンは説明のためにAIのマイルストーンから例を引いています：
- **チェス**: 1990年代、人間の専門家は、序盤、戦術、戦略をコード化した知識ベースのプログラムで支配的でした。しかし、ディープ・ブルー（1997年）は、その「知恵」の多くを無視し、大規模な探索木と計算を使ってカスパロフを打ち負かしました。
- **囲碁**: 同様の話—AlphaGo（2016年）は、プロの棋譜を深く研究するのではなく、自己対戦とニューラルネットワークを通じて学習しました。それは計算力でスケールし、直感ベースのライバルを打ち負かしました。
- **音声認識**: 手作りの言語モデルが支配的でしたが、統計的学習（データと計算の活用）が2010年代にそれを引き継ぎ、今日の音声アシスタントにつながりました。
- **コンピュータビジョン**: 初期のシステムはエッジ検出や形状ルールに依存していましたが、現在ではディープラーニングがGPUでピクセルデータを大量に処理します。

それぞれの事例において、知識ベースのアプローチは短期的な戦いには勝ちましたが、計算を貪る汎用性との戦争には負けたのです。

#### なぜ重要なのか
この教訓はAIを「スケーラブルな監視」—あらゆる洞察を一から教え込む必要なく、膨大なデータから学習するシステムを構築すること—へと押し進めます。これが、今日のブレークスルー（大規模言語モデルのような）が、規則集ではなくインターネット規模のデータによるトレーニングから生まれている理由です。しかし、これが「苦い」のは、進歩を続けるためにはさらに多くの計算（とエネルギー）が必要となり、「エレガントな」解決策を工夫することの重要性が薄れることを暗示しているからです。

サットンはこれを警告として書きました。この潮流と戦うのではなく、より速い進歩のためにそれを受け入れよ、と。

#### 参考文献
- [The Bitter Lesson (Original Essay)](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
- [Bitter Lesson (Wikipedia Summary)](https://en.wikipedia.org/wiki/Bitter_lesson)
- [ELI5 Explanation on Reddit](https://www.reddit.com/r/explainlikeimfive/comments/1nug43e/eli5_what_is_richard_suttons_bitter_lesson_in_ai/)