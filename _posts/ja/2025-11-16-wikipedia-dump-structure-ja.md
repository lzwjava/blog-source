---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4-fast
title: ウィキペディアダンプファイル構造の相違
translated: true
type: note
---

主な違いは、完全なWikipedia記事テキストが複数のファイルに分割される方法にあります。具体的には、1つの`.xml.bz2`ファイルが単一のリビジョンストリームのみを含むか（非マルチストリーム）、または多くの圧縮ストリームがバンドルされているか（マルチストリーム）です。

### 1. 非マルチストリームダンプ（旧形式、またはデフォルトの「pages-articles」ファイル）
ファイル名の例：  
`enwiki-20251101-pages-articles1.xml-p1p41242.bz2`

- 各`.xml.bz2`ファイルには、ページID順にページの一部（例：ページ1〜41242）が含まれます。
- ファイル内には、正確に1つの連続した`<page>` … `<page>` … シーケンスがあります。
- 単一ページのすべてのリビジョンは、その1つのページタグ内にまとめられています（最新リビジョンと、過去のリビジョンも「最新＋履歴」を要求した場合）。
- 単一の記事を抽出するには、任意のXML/BZ2ツールで大きなXMLを通常通り解凍して解析するだけです。
- `wget -c`は、ファイルが単一のbzip2ストリームであるため、単純な方法で完全に動作します：停止した場所から正確に再開します。

### 2. マルチストリームダンプ（ファイル名に「multistream」を含むもの）
ファイル名の例（リンク先のもの）：  
`enwiki-20251101-pages-articles-multistream1.xml-p1p41242.bz2`

- 同じページ範囲（p1p41242）がカバーされていますが、すべてのリビジョンの完全なテキストはもはやメインのXMLファイル内に保存されていません。
- 代わりに：
  - メインのXMLファイルにはメタデータ（タイトル、ID、制限、最新リビジョンのタイムスタンプなど）と、実際のリビジョンテキストが存在する場所へのポインタ（バイトオフセットと長さ）のみが含まれます。
  - 実際のリビジョンテキストは、同じ`.bz2`ファイル内の多くの小さな圧縮ストリームに別々に保存されます（したがって「マルチストリーム」）。
- 通常、コンパニオンとなる`...-multistream-index1.txt.bz2`ファイルがあり、各ページ/リビジョンの正確なバイトオフセットが含まれているため、ツールは正しい圧縮ストリームに直接ジャンプし、10〜30 GBのファイル全体を解凍することなくそのテキストのみを抽出できます。

### これが `wget -c` にとって重要な理由は？

実際には、両方のコマンド：

```bash
wget -c https://.../enwiki-20251101-pages-articles1.xml-p1p41242.bz2
wget -c https://.../enwiki-20251101-pages-articles-multistream1.xml-p1p41242.bz2
```

は、wgetの観点からはまったく同じように動作します：両方とも通常の単一のbzip2ファイルであるため、`-c`オプションによる再開可能なダウンロードはどちらの場合も完全に機能します。

違いは、ダウンロードしたファイルの処理を開始したときにのみ現れます。

### サマリーテーブル

| 特徴                              | 非マルチストリーム（通常）                      | マルチストリーム                                      |
|--------------------------------------|-------------------------------------------------|--------------------------------------------------|
| ファイル名に含まれるもの            | `-pages-articlesN.xml-...bz2`                  | `-pages-articles-multistreamN.xml-...bz2`        |
| 記事テキストの場所                  | XML `<page><revision><text>...</text></revision></page>` 内 | XMLの外部、別々の圧縮ストリーム内 |
| ファイルサイズ（同じページ範囲の場合）| はるかに大きい（多くの場合2〜3倍）              | はるかに小さい                                    |
| ランダムアクセス / 単一ページ抽出    | 非常に遅い（ファイル全体を解凍する必要がある）    | （インデックスファイルを使用すれば）非常に高速      |
| 直接理解するツール                  | 任意のXMLパーサー（SAX, xmltodictなど）         | wikimediaのdump-generatorツール, pywiki, mwxmlなど |
| コンパニオンインデックスファイルが必要？ | いいえ                                          | はい (`-multistream-index....txt.bz2`)            |
| `wget -c` の再開可能性              | 完璧                                            | 完璧（依然として1つのbzip2ファイル）               |

### では、どちらをダウンロードすべきか？

- 完全なシーケンシャルパスを一度だけ実行したい場合（例：言語モデルのトレーニング）、非マルチストリームファイルの方がシンプルです。
- 個々のページを素早く検索したい場合、またはディスク容量と抽出速度を気にする場合は、常にマルチストリームとインデックスのペアを優先してください。現在、ほとんどすべての本格的なWikimedia処理ツール（WikiExtractor、gensimのWikiCorpus、jawikiスクリプトなど）は、マルチストリームバージョンを期待しているか、強く推奨しています。

どちらのファイルも、`wget -c`で問題なく再開できます。「マルチストリーム」の部分は、ファイルの内部の内容を変更するだけで、HTTP/wgetが認識する方法は変更しません。