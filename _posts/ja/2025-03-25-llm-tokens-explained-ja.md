---
audio: false
generated: true
image: false
lang: ja
layout: post
title: LLMトークンの簡単な解説
translated: true
type: note
---

素晴らしい質問です — LLM APIにおけるトークンは最初少し混乱することがあります。明確に説明しますね。

---

## トークンとは何か

* **トークン** は、モデルが処理するテキストの最小単位です。
* トークンは**単語そのものではありません**。トークンは通常、言語とトークナイザに応じて、単語の一部、完全な単語、句読点、あるいはスペースまでも含みます。
* LLM（OpenAIのGPTモデルなど）は、事前に定義された**トークナイザ**を使用してテキストをトークンに分割します。

例:

* `"cat"` → 1トークン
* `"cats"` → `"cat"` + `"s"` に分割される可能性があります → 2トークン
* `"You're handsome."` → `"You"`, `"'re"`, `" handsome"`, `"."` のように分割されます → **4トークン**

このように、トークンは**サブワード単位**であり、モデルが多くの言語や珍しい単語を効率的に処理できるように最適化されています。

---

## APIにおいてトークンが重要な理由

1. **課金** – ほとんどのLLM APIはトークン数（入力 + 出力）に基づいて課金します。
2. **制限** – モデルには最大トークン制限があります（例: GPT-4 Turbo 128k は、入力と出力を合わせて最大128,000トークンまでを意味します）。
3. **効率性** – コストを削減し、制限内に収めるために、プロンプト送信時のトークン数を最小化したいと考えます。

---

## 実際のトークン処理

* **トークンの概算**: おおまかな目安として、英語では1トークンあたり約4文字です。したがって、1,000語の英語のエッセイ（約5,000文字）は、約1,200～1,300トークンになります。
* **トークンの正確な確認**: ほとんどのSDK（OpenAI向けのPythonの `tiktoken` など）では、送信前にトークンをカウントできます。
* **プロンプトの最適化**:

  * 不要な空白や単語を削除する。
  * 簡潔な指示を使用する。
  * 生のテキストをそのまま投入するのではなく、コンテキストを要約する。

---

## 例

```python
import tiktoken

enc = tiktoken.get_encoding("cl100k_base")
text = "You're handsome."
tokens = enc.encode(text)
print(tokens)        # トークンIDのリスト
print(len(tokens))   # トークン数
```

これは、おおよそ `[9125, 3938, 13]` → 3トークンのような結果を出力します（正確なトークナイザのバージョンによります）。

---

✅ つまり: **トークン ≠ 単語** です。トークンはLLMが認識する構成要素です。`"You're handsome."` は2単語ではなく、約3～4トークンです。

---

**ご自身のテキスト（例：トランスクリプト、エッセイ、コード）でトークンをカウントする方法**をお見せして、APIを呼び出す前にコストや制限を確認できるようにしましょうか？