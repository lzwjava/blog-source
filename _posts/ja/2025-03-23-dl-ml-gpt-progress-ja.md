---
audio: false
generated: true
lang: ja
layout: post
title: 深層学習、機械学習、GPTの進歩 (2010-2025)
translated: true
type: note
---

以下は、2010年から私の知識がカットオフとなる2024年10月までの、ディープラーニング、機械学習、GPTにおける主要なブレークスルーの詳細なタイムラインです。

## 2010年代前半：基礎の確立

- **2012年: AlexNet** - Krizhevsky、Sutskever、HintonによるCNNアーキテクチャがImageNetコンペティションで優勝し、エラーレートを26%から15.3%に減少させ、コンピュータビジョンにおけるディープラーニング革命の引き金となった。

- **2013年: Word2Vec** - Mikolovが、文脈に基づいて単語をベクトルとして表現する単語埋め込み技術を導入し、意味理解を可能にした。

- **2014年: GAN (敵対的生成ネットワーク)** - Goodfellowが、生成器と識別器ネットワークが競い合うフレームワークを導入し、写実的な画像生成を可能にした。

- **2014年: Sequence-to-Sequence モデル** - Sutskever、Vinyals、Le が、入力シーケンスを出力シーケンスにマッピングできる機械翻訳モデルを開発した。

## 2010年代中盤：基盤モデルの出現

- **2015年: ResNet** - He らが残差接続を導入し、はるかに深いネットワーク（152層以上）の学習を可能にし、3.57%のエラーレートでImageNetで優勝した。

- **2015年: バッチ正規化** - Ioffe と Szegedy が、ニューラルネットワークの学習を安定化・加速する技術を開発した。

- **2015年: アテンション機構** - Bahdanau がニューラル機械翻訳にアテンションを導入し、モデルが入力シーケンスの関連部分に注目できるようにした。

- **2016年: AlphaGo** - DeepMindのシステムが、ディープ強化学習とモンテカルロ木探索を組み合わせ、囲碁で世界チャンピオン李世乭を破った。

## 2010年代後半：トランスフォーマー革命

- **2017年: トランスフォーマーアーキテクチャ** - Vaswani らが「Attention Is All You Need」論文を発表し、RNNをセルフアテンション機構で置き換えた。

- **2018年: BERT** - Googleの Bidirectional Encoder Representations from Transformers が、自然言語理解において最先端の結果を達成した。

- **2018年: GPT-1** - OpenAIが、BookCorpusで学習された1億1700万パラメータの最初の Generative Pre-trained Transformer をリリースした。

- **2019年: GPT-2** - OpenAIが15億パラメータにスケールアップし、驚くべきゼロショット能力を示したが、悪用の懸念から当初は完全公開を差し控えた。

## 2020年代前半：スケーリングとマルチモーダル化

- **2020年: GPT-3** - OpenAIが1750億パラメータのモデルをリリースし、ファインチューニングなしで様々なタスクにわたる驚異的な数ショット学習能力を示した。

- **2021年: DALL-E** - OpenAIが、トランスフォーマーがテキスト記述から画像を生成できることを実証した。

- **2021年: Codex** - OpenAIのコード生成モデルで、GitHub Copilot に動力をもたらし、プログラミング能力を示した。

- **2021年: 拡散モデル** - GLIDE、DALL-E 2、Stable Diffusion が、優れた画像生成品質を導入した。

- **2022年: ChatGPT** - OpenAIのGPTモデルへの対話型インターフェースが、前例のない一般普及を達成した（2ヶ月で1億ユーザー）。

- **2022年: PaLM** - Googleの5400億パラメータモデルが、推論能力を示した。

- **2022年: Chinchilla** - DeepMindが、より多くのデータを用いた小さなモデルが大きなモデルを性能で上回りうることを示す最適なスケーリング則を示した。

## 2023-2024年：マルチモーダルLLMと推論

- **2023年: GPT-4** - OpenAIのマルチモーダルモデルで、推論、安全性、画像理解能力が向上した。

- **2023年: Claude** - Anthropicが、有益性、無害性、誠実性に焦点を当てた Constitutional AI をリリースした。

- **2023年: LLaMA** - Metaがオープンウェイトの大規模言語モデルをリリースし、オープンソースのイノベーションを促進した。

- **2023年: Mixture-of-Experts (MoE)** - Mixtral 8x7B のようなモデルが、各入力に対してネットワークの関連部分のみを活性化することで効率性の向上を示した。

- **2023-2024年: マルチモーダルモデル** - GPT-4V、Gemini、Claude 3 などが、視覚、音声、言語にわたる能力を獲得した。

- **2024年: Sora** - OpenAIのテキストからビデオへのモデルが、複雑なシーンの写実的なビデオを生成した。

- **2024年: 推論の強化** - モデルは Chain-of-Thought 能力が向上し、数学、コーディング、科学的推論のための専門モデルが登場した。

- **2024年: エージェントフレームワーク** - 計画、ツール利用、メモリを組み込んだシステムにより、モデルが複雑な多段階タスクを完了できるようになった。

## この期間を通した主要なトレンド：

1.  **スケーリング則**: モデルサイズ、データセットサイズ、計算量の増加による一貫した性能向上。
2.  **創発能力**: 特定のスケールの閾値で予期せず現れる、文脈学習などの能力。
3.  **マルチモーダル化**: テキスト、画像、音声、ビデオの統一モデルへの統合。
4.  **人間のフィードバックからの強化学習 (RLHF)**: モデルを人間の選好に合わせる。
5.  **民主化**: オープンソースモデルとアクセス可能なフレームワークの成長による、ML開発への参入障壁の低下。

この期間は、おそらく人類史上どの分野よりも速い技術的進歩を表しており、MLを専門的な学問分野から、地球規模の影響力を持つ汎用技術へと変貌させました。