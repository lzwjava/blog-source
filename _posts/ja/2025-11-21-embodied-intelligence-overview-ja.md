---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4.1-fast
title: 具現化知能の概要
translated: true
type: note
---

### エンボディード・インテリジェンス：概要

エンボディード・インテリジェンス（Embodied Intelligence）、またはエンボディードAIは、身体（例えばロボット）を通じて物理的に世界に存在し、環境との直接的な相互作用を通じて学習、推論、行動する人工知能システムを指します。GPTのような言語モデルなど、抽象化されたデータを隔離されて処理する従来のAIとは異なり、エンボディードAIは、真の知性が感覚運動ループ（世界を知覚し、それに作用し、フィードバックに基づいて適応する）から生じることを強調します。このパラダイムは、認知が純粋な計算ではなく物理的具現化に根ざしていると見なす認知科学に由来しています。

主な原則は以下の通りです：
- **マルチモーダル知覚**：視覚、触覚、自己受容感覚、そして時には言語や音声を統合する。
- **相互作用駆動型学習**：エージェントは実世界または高精度なシミュレーション（Sim-to-Real Transfer）における試行錯誤を通じて改善する。
- **汎化と適応**：構造化されていない動的環境、長期にわたるタスク、マルチモダリティ（例：視覚と言語の組み合わせ）、外乱への頑健性に対処する。

2025年現在、エンボディードAIは、ファウンデーションモデル（大規模事前学習済み視覚言語モデル）、拡散技術、Open X-Embodimentのような大規模データセットにより、爆発的に発展しています。これはヒューマノイドロボット、マニピュレーション、ナビゲーション、人間-ロボットインタラクションの進歩を支えています。リアルタイム性能、安全性、Sim-to-Realのギャップ、オープンワールドタスクへのスケーリングにおいて課題は残っています。主な取り組みには、GoogleのRTシリーズ、OpenVLA、拡散ベースのポリシーなどがあり、汎用ロボットを目指しています。

### 主要テクノロジー：Diffusion Policy、RT-2、ACT

これら3つは、明示的な報酬なしで人間やエキスパートのデモンストレーションに基づいて学習する模倣学習による、ロボットポリシー（観測から行動への写像）を学習するための最先端のアプローチを代表しています。

#### ACT (Action Chunking with Transformer)
- **起源**：2023年にTony Zhaoら（Covariant.ai、元UC Berkeley）によって、低コストの両手マニピュレーションのためのALOHAシステムの一部として導入。
- **核心となる考え方**：将来の行動の**チャンク**（例えば、一度に100ステップ）を予測するTransformerベースのポリシー。これにより、時間的誤差（長期にわたる誤差の累積）が減少し、滑らかで高周波数の制御（例：50Hz）が可能になる。
- **アーキテクチャ**：Variational Autoencoder (VAE) またはTransformerバックボーンを使用。入力：マルチビューRGB画像 + 自己受容感覚（関節状態）。出力：チャンク化された関節位置/速度。
- **長所**：
  - 極めてサンプル効率が高い（複雑なタスクを約50回のデモンストレーションから学習）。
  - コンシューマーハードウェアでリアルタイム実行可能。
  - 低コストロボットによる精密で器用なタスク（針に糸を通す、洗濯物を畳むなど）に優れる。
- **限界**：主に模倣ベース。拡張なしでは言語指示やWebスケールの汎化に対する本質的なサポートが少ない。
- **実世界への影響**：ALOHA（移動マニピュレータ）などのシステムを支え、両手タスクに広く採用されている。

#### Diffusion Policy
- **起源**：2023年のCheng Chiら（コロンビア大学、Toyota Research Institute、MIT）による論文。3D Diffusion PolicyやScaleDP（2025年には10億パラメータまで拡大）などの研究で拡張。
- **核心となる考え方**：ロボットの行動を、拡散モデル（Stable Diffusionなどの画像生成器に触発）からの生成的サンプルとして扱う。ノイズの多い行動から始め、観測に条件付けして反復的にノイズ除去し、高品質でマルチモーダルな行動系列を生成する。
- **アーキテクチャ**：条件付きノイズ除去拡散モデル（多くの場合Transformerを使用）。「スコア関数」（行動分布の勾配）を学習。推論にはリceding-horizon制御を使用：系列を計画し、最初の行動を実行し、再計画する。
- **長所**：
  - **マルチモーダル**な振る舞いを自然に扱える（例：オブジェクトを把持する複数の有効な方法—拡散は平均化せずに一貫性のある方法を一つサンプリング）。
  - 高次元の行動とノイズの多いデモンストレーションに対して頑健。
  - ベンチマークで最先端（2023年時点で従来手法比46%以上の改善；2025年現在も競争力あり）。
  - 3D Diffusion Policyなどの拡張は、3D理解を向上させるために点群を使用。
- **限界**：推論が遅い（10–100のノイズ除去ステップ）、ただし最適化（ステップ数削減、蒸留など）によりリアルタイム実行が可能に。
- **実世界への影響**：視覚運動マニピュレーションに広く使用。PoCo (Policy Composition) などのシステムやスケーリングモデルに統合。

#### RT-2 (Robotics Transformer 2)
- **起源**：2023年、Google DeepMind（RT-1を基盤）。Vision-Language-Action (VLA) ファミリーの一部。
- **核心となる考え方**：大規模事前学習済み視覚言語モデル（例：PaLM-E または PaLI-X、最大550億パラメータ）をロボット軌道データで共同ファインチューニング。行動はテキスト文字列としてトークン化され、モデルはWebスケールの知識（画像＋テキスト）を活用しながら直接行動を出力できる。
- **アーキテクチャ**：画像＋言語指示→トークン化された行動を出力するTransformer。Web事前学習からの創発スキル（例：記号についての推論、連鎖思考）。
- **長所**：
  - **意味的汎化**：ロボット固有の訓練なしで新しいコマンドを理解（例：「絶滅した動物を拾って」→恐竜のおもちゃをつかむ）。
  - Webの知識をロボティクスに転送（例：インターネット画像からゴミを認識）。
  - 従来のロボットモデルと比較して、創発スキルで最大3倍優れる。
- **限界**：大規模モデル→計算資源が多い。ACT/Diffusionと比較して低レベルな器用な制御の精度が低い（高レベルの推論に優れる）。
- **実世界への影響**：Googleのロボットフリートデータ収集 (AutoRT) を支え、RT-Xへ進化し、後のシステムと統合。

### 比較表

| 観点                      | ACT                                      | Diffusion Policy                          | RT-2                                      |
|---------------------------|------------------------------------------|-------------------------------------------|-------------------------------------------|
| **主要手法**              | Transformer + 行動チャンキング (決定的/回帰的) | ノイズ除去拡散 (生成的)                   | VLA (LLM/VLM内でのトークン化された行動)   |
| **入力**                  | マルチビュー画像 + 自己受容感覚          | 画像/点群 + 自己受容感覚                  | 画像 + 言語指示                           |
| **出力**                  | チャンク化された関節行動                  | ノイズ除去された行動系列                  | トークン化された行動文字列                |
| **主な強み**              | サンプル効率、精度、リアルタイム性        | マルチモーダリティ、頑健性、表現力        | 意味的推論、Webデータからの汎化           |
| **推論速度**              | 高速 (単一パス)                          | 遅い (反復的ノイズ除去)                   | 中程度 (Transformerの自己回帰)            |
| **データ効率**            | 非常に高い (~50 デモ/タスク)             | 高い                                      | 中程度 (Web事前学習の恩恵)                |
| **最適な用途**            | 精密で器用なマニピュレーション            | 複雑でマルチモーダルなタスク              | 言語誘導型、新しい/創発的なタスク         |
| **典型的な成功率向上 (ベースライン比)** | 実ロボットベンチマークで強力              | +46% (2023年ベンチマーク)                 | 創発スキルで2–3倍                         |
| **2025年時点の状況**      | 低コストハードウェアのベースライン        | 数十億パラメータにスケーリング            | OpenVLA/RT-X後継モデルの基盤              |

### エンボディード・インテリジェンスにおける位置付け

- **ACT と Diffusion Policy**：純粋な視覚運動ポリシー—低レベルの感覚運動スキル、エンボディードAIの「身体」を得意とする。生のピクセルから物理世界で流暢に行動することをロボットに可能にする。
- **RT-2 (および VLA モデル)**：高次認知への架け橋—人間のようなインタラクションと推論のために言語を追加し、汎用エンボディードエージェントに向けて推進する。
- **ハイブリッドが未来**：2025年のトレンドはこれらを組み合わせる（例：OpenVLA = RT-2ライク + 拡散ヘッド；OCTO = 拡散要素を持つ小型効率的モデル）。最終目標：マルチモーダルに知覚し、LLM/世界モデルで推論し、拡散/チャンキングを通じて精密に行動するロボット。

これらの方法は器用なロボティクスを民主化しました：かつては何年ものエンジニアリングを必要としたタスクが、数十回の人間のデモンストレーションで成功するようになりました。データセット（例：Open X-Embodiment）が成長し、ハードウェア（Figure 01、Tesla Optimusなどのヒューマノイド）が改善されるにつれて、エンボディードAIは汎用性の高い、実世界で役立つロボットに急速に近づいています。

[Diffusion Policy プロジェクトページ](https://diffusion-policy.cs.columbia.edu/)
[RT-2 アナウンスメント](https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/)
[ALOHA / ACT 論文](https://tonyzhaozh.github.io/aloha/)
[Open X-Embodiment データセット](https://robotics-transformer-x.github.io/)