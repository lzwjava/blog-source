---
audio: false
generated: true
image: false
lang: ja
layout: post
model: anthropic/claude-sonnet-4
title: TikTokenトークン化ガイドと例
translated: true
type: note
---

このコードは、**TikToken** ライブラリの使用方法を示しています。TikToken は OpenAI が提供するトークナイザーで、GPT-3.5 や GPT-4 などの言語モデルに送信するテキスト内のトークンをカウントおよび処理するために使用されます。

## TikToken の役割

TikToken はテキストを**トークン**（言語モデルが処理する基本単位）に変換します。各トークンは、おおよそ単語または単語の一部に対応します。トークン化を理解することは以下の理由から重要です：

- API コストはトークン数に基づく
- モデルには入力/出力のトークン制限がある
- トークン数は処理速度に影響する

## コードの詳細

### 1. 基本的なエンコード (`basic_encoding()`)
```python
enc = tiktoken.encoding_for_model("gpt-3.5-turbo")
tokens = enc.encode("Hello, how are you doing today?")
```
- GPT-3.5-turbo 用のトークナイザーを作成
- テキストをトークン ID のリストに変換: `[9906, 11, 1268, 527, 499, 3815, 3432, 30]`
- "Hello, how are you doing today?" が 8 トークンであることを示す
- トークンを元のテキストにデコード可能

### 2. モデル比較 (`different_models()`)
同じテキストを異なるモデルがどのようにトークン化するかを比較：
- **GPT-4**: "The quick brown fox jumps over the lazy dog." = 10 トークン
- **GPT-3.5-turbo**: 10 トークン（同じエンコーディング）
- **text-davinci-003**: 10 トークン（同じエンコーディング）

異なるモデルは異なるトークナイザーを使用する可能性があるため、トークン数は変動することがあります。

### 3. バッチ処理 (`batch_processing()`)
複数のテキストを効率的に処理する方法を示す：
- 異なる長さの 3 つのメッセージを処理
- 全メッセージの合計トークンを計算（合計 15 トークン）
- 複数のメッセージを送信する際のコスト見積もりに有用

### 4. 特殊トークン (`special_tokens()`)
`<|endoftext|>` のような特殊な制御トークンを扱う：
- モデルで利用可能な特殊トークンを表示
- 特殊トークンを含むテキストのエンコードを実演
- 特殊トークンを処理するために `allowed_special="all"` を使用

### 5. 効率的なカウント (`count_tokens_efficiently()`)
トークンをカウントする 2 つの方法：
- **方法 1**: トークンを保存してからカウント (`len(enc.encode(text))`)
- **方法 2**: 直接カウント（大規模なテキストに対してメモリ効率が良い）
- トークン対単語の比率を計算（この例では 1.29）

## 実用的な応用例

1. **コスト見積もり**: リクエストを行う前に API コストを計算
2. **入力検証**: テキストがモデルのトークン制限内に収まることを確認
3. **バッチ最適化**: API コールのためにメッセージを効率的にグループ化
4. **パフォーマンス監視**: アプリケーション内でのトークン使用量を追跡

## 出力から得られる主な知見

- 単純なフレーズは予想よりも少ないトークンを使用する
- トークン数は必ずしも単語数と一致しない
- 異なるモデルは異なる方法でトークン化する可能性がある
- 特殊トークンは注意深い取り扱いが必要

このライブラリは、OpenAI の API を使用してアプリケーションを構築するすべての人にとって不可欠です。なぜなら、API が実際に課金するものと一致する正確なトークンカウントを提供するからです。