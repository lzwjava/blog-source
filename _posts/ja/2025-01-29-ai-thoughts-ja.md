---
audio: false
generated: false
image: false
lang: ja
layout: post
title: AIワークフロー、コードエディター、プラットフォームの破壊
translated: true
type: post
---

### 目次

1. [AIに関する所感](#ai-thoughts)
   - AIには真の知性や深みが欠けている
   - 機械学習は高度な応用微積分である
   - LLMは構造化ファイル形式に苦戦する
   - オープンソースが技術の秘密を無くす
   - テキストベースのツールが最初にAIの影響を受ける

2. [AIワークフローで強化される新プラットフォーム](#new-platforms-powered-by-ai-workflows)
   - AIワークフローによる多言語コンテンツ自動生成
   - ユーザーがプロンプトで形式変換を依頼
   - コンテンツの改善や要約を可能にするプラットフォーム
   - キーワード設定でカスタマイズ可能なAIワークフロー
   - AIによるエンドツーエンドのコンテンツ変換

3. [AIコードエディタの次の方向性](#the-next-direction-of-ai-code-editors)
   - CI/CDワークフローにはクラウド連携が不可欠
   - A/BテストでAI生成コンテンツを強化
   - RLHFが実環境のフィードックに拡張
   - 人間のフィードバックで不完全なAI出力を改善
   - 出力修正よりもプロンプト最適化が重要

## AIに関する所感

*最終更新: 2025年8月*

- サティア・ナデラがジェボンズのパラドックスに言及。学ぶ価値あり。

- 王寅: 人工知能には「知能」はなく、ニューラルネットワークには「ニューラル」はなく、機械学習には「学習」はなく、ディープラーニングには「深み」はない。この分野で実際に機能しているのは「微積分」だ。したがって、この分野を「微分可能計算」と呼び、モデル構築のプロセスを「微分可能プログラミング」と呼ぶことを好む。

- 王寅: 機械学習は実際に有用で、美しい理論と言える，なぜならそれは微積分の改装版に過ぎないからだ。ニュートンやライプニッツの古くて偉大な理論が、よりシンプルで優雅で強力な形で現れたもの。機械学習は基本的に微積分を使って関数を導出・fittingすることで，ディープラーニングはより複雑な関数のfittingだ。

- 現在の大規模言語モデルはYAMLやPythonのようなファイル言語でフィルタリングできない。しかし現実世界の情報の多くはこの形式で編成されている。つまり、ファイルを使って大規模言語モデルを訓練できる可能性がある。

- 大規模言語モデルの訓練のために、完全一致検索システムを開発できるかもしれない。KMP（Knuth-Morris-Pratt）検索アルゴリズムとTransformerアーキテクチャを組み合わせて検索能力を強化できる可能性がある。

- 技術的な秘密は存在しない。オープンソースがすべての秘密を明らかにする。

- AIは多くのツールに影響を与える、間接的なものも含めて。人々はFigmaでプロトタイプを描く必要がなくなり、直接コードを書くようになるだろうと言う。Postmanも同様で、Pythonや他のスクリプトを直接使ってAPIを呼び出したりテストしたりするようになると思う。

- AI時代にPostmanやFigmaを使わない理由の一つは、それらの機能がテキストから生成できないからだ。また、コンポーネント置換をトリガーするcommand + Kショートカットも欠けている。

- ユーザーインターフェースはAI時代の障壁になりつつある。なぜPostmanをAI対応にアップグレードしてアプリケーションをテストする必要があるのか？Pythonのrequestsライブラリや他のプログラミング言語でコードをテストすれば、それがAIによって強化されるからだ。

- なぜFigmaをAI対応にアップグレードしてUIを作成する必要があるのか？コードベースのUI生成はAIによって強化され、より直接的で強力なアプローチを提供できる。

- LLMは最初にテキスト関連のアプリケーションを変えるだろう。Google、検索エンジン、テキストエディタやライティングツール、Quizlet、Zendesk、DeepL、Medium、WordPress、Trello、Asana、Gmail、GitHub、Goodreads、Duolingo、Feedlyなど。

- 逆に、LLMはGit、Linux、ffmpeg、携帯電話、ハードウェア、ブラウザ、OS、音声やビデオ通話のような技術を革新する可能性は低い。これらの技術はコード中心であり、PostmanのようなAPIテストツールとは異なり、AIによって簡単に生成されるコードではない。

- コードの多い技術はAIによって革新されにくい。OpenOffice、MySQL、Mozilla Firefox、Chromium、VLCメディアプレイヤー、Qtフレームワーク、LLVM/Clang、GNOMEなど。AIがこれらの技術を作れるなら、置き換えられることはない。AIはより良い技術を作るのに役立つべきで、そのためにはAIは同じ量のコードを生成するためにより多くの計算資源が必要になる。

- LLMが変化をもたらす方法は2つある。1つ目は、TikTokのようなアプリのコンテンツ翻訳など、プラットフォームやソフトウェア内のコンテンツやデータを変更すること。2つ目は、PostmanやGoogle検索、Google翻訳など、特定のソフトウェアやプラットフォームを直接置き換えること。

- AI音声ツールが変化をもたらす方法も2つある。1つ目は、Audibleのためのオーディオブック生成など、プラットフォームやソフトウェア内のコンテンツやデータを変更すること。2つ目は、Sing songsアプリのように、特定のソフトウェアやプラットフォームを直接置き換えること。AIが人間と同じタスクを実行できるため、人々が趣味で歌を歌うことが容易になる。

- AIが現在のソフトウェアやプラットフォームに与える影響を測る方法はいくつかある。1つは、AIによって生成または改善されるデータやコンテンツの量を測定すること。もう1つは、AIによって書かれるまたは改善されるコードの量を測定すること。つまり、AIが生成するものを現在のプラットフォームを改善するために使う。さらに、AIは新しいソフトウェアやプラットフォームの発明を助けることができる。

- 製品には3つのタイプがある。生成AI製品、生成AI製品のAPIを使う製品、その他の製品。

- 1つの製品アイデアは、AIを使ってReddit、GitHub Trending、Twitterトレンド、Quoraトレンド、Zhihuトレンドなどのソーシャルプラットフォームからリアルタイムの情報、ニュース、アップデートを蓄積すること。ユーザーはプロンプトを使ってフィードをカスタマイズしたり、特定のソーシャルアカウントを追加したりできる。

- 重要なデータの種類は5つある。テキスト、画像、音声、動画、コード。

- その他の重要なデータの種類には、数値、地理空間、生体認証、センサー、トランザクション、メタデータ、時系列、構造化、非構造化、半構造化、健康、環境、ログ、ネットワーク、行動データなどがある。

- Googleは依然としてウェブサイトのインデックス作成に優れており、特に特定のサイトからソフトウェアやドキュメントをダウンロードしたい場合に有用。ドメイン検索のように機能する。情報を見つけるためではなく、他のサイトに移動してタスクを実行するために使う。LLMは最新のダウンロードリンクを持っていない可能性がある。

- Googleはドメイン検索のように機能する。Mavenリポジトリのサイトに行って最新バージョンを確認したい場合に使える。

- Googleは画像検索で依然として有用だが、LLMはテキスト生成に優れている。それでも人々はハードウェアの詳細、寸法、物体の形状、人の外見を確認するために実在する画像を好む。

- AIチャットボットが人気なのは、テキストは画像よりも処理が難しいからだ。人々はAI生成画像よりも実在する画像を好む，なぜなら画像は一目で理解しやすいから。しかしAI画像生成には未開拓の可能性がある - ユーザーはAIに異なる角度を見せたり、顔をズームしたり、基板の詳細を拡大したりするよう依頼できる。人々が主にテキストではなく画像を扱うため，AI画像ツールには大きな成長の余地がある。

- AIは概念を説明し理解を助けることに優れている。さらにユーザーは特定の詳細について質問できる。これがおそらくAIツールの最も重要な用途だ。

- 私はAIを使って大規模言語モデルについて学んだ。K、Q、Vを理解するのを助けてくれた瞬間は素晴らしかった。

- LLMがリリースされて以来Ubuntuを使うことを好む理由は、macOSの豊かでカラフルなアプリが私にとって魅力を失ったからだ。私はターミナルとテキストを通じてすべてを行うことを好む。

- AIは、pom.xmlやrequirements.txtファイルを最新バージョンに更新し、ライブラリを更新し、チェックを実行する能力で評価できる。このプロセスには多くの作業が含まれ、時に複雑になることがある。

- AI時代には、パフォーマンスと堅牢性に優れたプログラミング言語がより重要で人気が高まる，一方で構文は重要ではなくなる。LLMがコードを生成するため，プログラムがうまく実行される限り問題にならないからだ。

- 人々はAIチャットボットからすべてを読みたがる，なぜなら学びやすく、あらゆる側面について質問でき、形式が一貫しており、品質がインターネットで見つかる最高のものの一つであるからだ。

- しかし情報はテキストだけではない，AIチャットボットからほとんどのテキスト情報を読めるが、元のウェブサイトとそのレイアウトや形式、説明画像やウェブデザインが失われる。

- インタラクションの多いウェブサイトはAIによって大きく変わる可能性が低い。ウェブゲーム、Googleドキュメント、Googleスプレッドシート、ZoomやSlackのようなコラボレーションツールなど。これらはコード中心で、テキストだけに焦点を当てていない。

- AIチャットボットではタイプミスをしやすく、プロンプトを作成するのに手間がかかる。そのため、完全にAI駆動のデジタルバンク、デジタル取引アプリ、またはシンプルなチャットボックスを持つAIソーシャルメディアはうまく機能しないことが多い。モバイルアプリの従来のクリックボタン、ページナビゲーション、レイアウトの方が便利だ。

- [AIとブロックチェーン時代をどう生きるか](./ai-blockchain-en)

---

## AIワークフローで強化される新プラットフォーム

*2025.01.08*

- ワークフローとは、大規模言語モデル(LLM)とツールが事前定義されたコードパスで連携するシステムだ。[^1]

- TikTokやQuora、X、Threads、Instagram、WhatsApp、Facebook、LinkedIn、Reddit、YouTubeのような新プラットフォームを想像してほしい，完全にAI翻訳によって強化されている。

- ユーザーが作成するすべての投稿や回答は単一の言語で保存される。プラットフォームは自動的にコンテンツを20言語に翻訳し、ユーザーは自分の好みの言語で閲覧できる。

- 翻訳以外にも、要約、音声生成、動画生成などのAI機能が重要な役割を果たす。基本的にユーザーはプロンプトコンテキストを提出し，プラットフォームが残りを処理する。

- ユーザーはテキスト、画像、音声、動画をアップロードでき，プラットフォームは自動的にコンテンツを他の形式に変換する。ユーザーはそのコンテンツをどの形式で受け取りたいか（例: テキスト、画像、音声、動画）を決められる。

- プラットフォームは自動的に要約を生成でき，複数の言語で異なる種類の要約が提供される。

- プラットフォーム上のあらゆるテキスト、画像、音声、動画で，AIがコンテンツの生成、改善、強化、修正、要約、拡張、他の形式への変換、新しい形式の想像を支援できる。

- ユーザーは「英語」や「面白い」のようなキーワードを使ってTikTokのようなプラットフォームのAIワークフロースタイルを調整できる。設定するとAIはそれに合わせてコンテンツを調整する。


---

[^1]: 効果的なエージェントの構築, [Anthropic](https://www.anthropic.com/research/building-effective-agents)

---

## AIコードエディタの次の方向性

*2025.01.08*

最近、GitHub Actionsに`xelatex`パイプラインを追加する作業をしていた。

GitHubフローで`fontawesome5`パッケージに問題が発生した。4o-miniが提案した解決策（TeX Live 2021をインストールして`tlmgr install fontawesome5`を使う）は私の環境では機能しなかった。しかし4oはより良いアプローチを提案した：TeX Live 2023にアップグレードし、やはり`tlmgr`で`fontawesome5`をインストールすること。これで完全には解決しなかったが、TeX Live 2023に切り替えると状況は大幅に改善した。

私はChatGPTを使って問題を理解するのを助けてもらった。詳細は[ChatGPT O1ができて4o-miniができないこと](./o1-en)を参照。

この時点でCursorやWindsurfのようなエディタは使わなかったが、別のプロジェクトで試したことはある。これらのコードエディタの問題は、ローカルのテスト出力しかキャプチャしないため、クラウド環境では機能が制限されることだ。

GitHub Actions、Jenkinsジョブ、コードデプロイやテストフローのようなワークフローでは、コードエディタはより良く統合される必要がある。クラウドやCI/CDプロセスとシームレスに連携するべきだ。

この統合は他のコンテンツ作成ツールにも当てはまる - テキスト、画像、音声、動画のいずれであろうと。これらのツールはA/Bテストシステムと統合されるべきだ。AIツールがコンテンツを生成し，A/Bテストツールがフィードバックを提供できる。これはReinforcement Learning from Human Feedback (RLHF)に似たダイナミクスで，AIモデルは時間の経過とともに実環境のフィードバックに基づいて改善される。

RLHFを単なるモデル出力から実環境のテストやデプロイ環境に拡張するこのコンセプトは、コードエディタとAI駆動のコンテンツ作成ツールの両方で改善の有望な方向性のように思える。

テストは瞬時に行われることも長期間にわたることもあり、自動化されることも人間の支援を受けることもある。テストが自動化されている場合、例えばAIツールのユーザーA/Bテストでは、依然として人間のフィードバックが関わるがプロセスが自動化される。例えば毎日または毎時、A/Bテストの結果に基づいてコンピュータに結果をチェックさせ、作成プロセスを改善させる。同様にJenkinsやGitHub Actionsジョブでは、タスク完了後にコンピュータにチェックさせることができる。

人間の支援が関わる場合、フィードバックは機械には完全に理解できず、しばしば曖昧だ。例えばAIツールが画像や動画を作成する場合、人間はコンテンツが十分に面白くないとか、特定の詳細を改善すべきだと指摘するかもしれない。機械がすべてを完璧にするにはまだ長い道のりがあり、「完璧」かどうかはしばしば個人の嗜好に依存する。人間のフィードバックが物事をより良くする。

理論的には、すべての人間が定義したルールはプロンプトとして書ける。ユーザープロンプトとシステムプロンプトがある。毎回出力を修正するのではなく、プロンプトを改善することに焦点を当てるべきだ。