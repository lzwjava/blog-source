---
audio: true
lang: ja
layout: post
title: 人工知能の思考
translated: true
---

- Satya Nadellaはジェボンズのパラドックスを言及しました。学ぶ価値はあります。

- 尹 王：「人工知能」には「知能」がありません、「ニューラル」は「ニューラルネットワーク」にはありません、「学習」は「機械学習」にもありません、「深さ」は「ディープラーニング」にもありません。この分野で本当に働いているのは「微分」と呼ばれます。したがって、この分野を「微分可能なコンピューティング」と呼び、モデルを構築するプロセスを「微分可能なプログラミング」と呼ぶのが好みです。

- 尹 王：機械学習は非常に有用で、さらに美しい理論でもあります。純粋に言うと、これはリフェイション後の「微分」です！古代と非常に偉大なニュートン、ライブニッツの理論が、より簡潔で優雅でかつ強力な形になっています。機械学習は基本的に微分を用いて関数を導出し、適合させることですが、ディープラーニングはより複雑な関数を適合させることです。

- 現在の大規模言語モデルは、YAMLやPythonのようなファイル言語でフィルタリングできません。しかし、実世界での情報の大部分はこのように整理されています。これは、大きな言語モデルをトレーニングするためにファイルを使用することができるということです。

- 大規模言語モデルをトレーニングするためには、完全一致を見つけるシステムを開発できます。例えば、KMP（ナッス・モリス・プラット）検索アルゴリズムをトランスフォーマーアーキテクチャと組み合わせることで、検索能力を向上させることができるかもしれません。

- 技術的な秘密はありません。オープンソースがすべての密かに守られている秘密を明かすでしょう。