---
audio: true
lang: ja
layout: post
title: AIの考え
translated: true
---

- サッチャ・ナデラはジェヴンズのパラドックスを触れました。学ぶ価値があります。

- 尹・ワン：アーティフィシャル・インテリジェンスには「知」がありません。ニューラル・ネットワークには「ニューラル」もありません。マシン・ラーニングには「学習」もありません。ディープ・ラーニングには「深み」もありません。この分野で本当に働くのは「微分」と呼ばれます。したがってこの分野を「微分可能な計算」と呼び、モデルを構築するプロセスを「微分可能なプログラミング」と呼びます。

- 尹・ワン：マシン・ラーニングは非常に有用であり、まさに美しい理論です。単に化粧をした微分学です。それはニュートン、ライブニッツの古いと大きな理論の、よりただしい、優雅でかつ強力な形です。マシン・ラーニングは基本的に微分学を用いて関数を導出し、適合させることです。ディープ・ラーニングはそれよりも複雑な関数を適合させることです。

- 現在の大規模言語モデルは、YAMLやPythonのようなファイル言語でフィルタリングすることはできません。しかし、現実世界の情報の大部分はこのように整理されています。これは、ファイルを使って大規模言語モデルをトレーニングすることができることを意味します。

- 大規模言語モデルをトレーニングするためには、正確な一致を見つけるシステムを開発することができます。KMP（ナッソー・モリス・プラット）検索アルゴリズムをトランスフォーマー構造と組み合わせることで、検索能力を向上させることができるかもしれません。

- 技術的な秘密はありません。オープンソースは密かに守られているすべての秘密を明かします。

- [AIワークフローによる新しいプラットフォーム](./ai-workflow-en)

- [AIコードエディタの次の方向性](./ai-code-en)

- [AIとブロックチェーン時代における私の生活方法](./ai-blockchain-en)