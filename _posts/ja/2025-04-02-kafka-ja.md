---
audio: false
generated: true
lang: ja
layout: post
title: Apache Kafka
translated: true
type: note
---

あなたのリクエストに誤解があるかもしれません。前回のRedisに関する質問とこの質問の文脈から判断して、作家のフランツ・カフカではなく、分散型イベントストリーミングプラットフォームである **Apache Kafka** について包括的なガイドを求めていると推測します。もし私の理解が間違っていて、別のことを意味していた場合は、明確にしてください！今のところ、Apache Kafkaに関する詳細なガイドを以下に示します。

---

### Apache Kafkaとは？
Apache Kafkaは、高スループットでフォールトトレラント、スケーラブルなリアルタイムデータ処理のために設計された、オープンソースの分散型イベントストリーミングプラットフォームです。2010年にLinkedInによって開発され、後に2011年にApache Software Foundationに寄贈されました。KafkaはJavaとScalaで書かれており、リアルタイムデータパイプライン、ストリーミングアプリケーション、イベント駆動型アーキテクチャの構築に広く使用されています。

主な特性：
- **分散型**: 複数のサーバーにまたがるクラスタとして実行されます。
- **イベント駆動型**: イベントのストリームをリアルタイムで処理します。
- **永続性**: 設定可能な保持期間でデータをディスクに永続的に保存します。
- **スケーラブル**: 1日あたり数兆のイベントを処理します。

---

### Kafkaを使用する理由
Kafkaは、リアルタイムデータ処理と高いスケーラビリティを必要とするシナリオで優れています。一般的なユースケースは次のとおりです：
1. **メッセージング**: 従来のメッセージブローカー（例：RabbitMQ）を、より優れたスループットとフォールトトレランスで置き換えます。
2. **アクティビティ追跡**: ユーザーのアクション（例：クリック、ログイン）をリアルタイムで追跡します。
3. **ログ集約**: 集中処理のために複数のソースからログを収集します。
4. **ストリーム処理**: リアルタイム分析または変換を支えます。
5. **イベントソーシング**: アプリケーションの状態変化を記録します。
6. **メトリクス収集**: システムまたはIoTデバイスを監視します。

---

### 主な機能
1. **コアコンポーネント**:
   - **トピック**: メッセージ（イベント）が公開されるカテゴリ。
   - **パーティション**: 並列処理とスケーラビリティのためのトピックの細分化。
   - **プロデューサー**: トピックにメッセージを送信するアプリケーション。
   - **コンシューマー**: トピックからメッセージを読み取るアプリケーション。
   - **ブローカー**: Kafkaクラスタ内でデータを保存および管理するサーバー。

2. **レプリケーション**: ブローカー間でデータを複製することでフォールトトレランスを確保します。
3. **保持期間**: 設定可能なデータ保持期間（時間ベースまたはサイズベース）。
4. **Kafka Connect**: 外部システム（例：データベース、ファイル）と統合します。
5. **Kafka Streams**: リアルタイムストリーム処理のためのライブラリ。
6. **高スループット**: 低遅延（例：2ms）で1秒あたり数百万のメッセージを処理します。

---

### アーキテクチャ
Kafkaのアーキテクチャは、分散コミットログを中心に構築されています：
- **クラスタ**: 連携して動作するブローカーのグループ。
- **トピックとパーティション**: メッセージはトピックに書き込まれ、負荷分散とスケーラビリティのためにパーティションに分割されます。各パーティションは順序付けられた不変のログです。
- **レプリケーション**: 各パーティションにはリーダーとレプリカがあります。リーダーに障害が発生すると、レプリカが引き継ぎます。
- **オフセット**: パーティション内のメッセージに対する一意の識別子。コンシューマーが自身の位置を追跡することを可能にします。
- **ZooKeeper（またはKRaft）**: 従来、ZooKeeperがクラスタのメタデータと調整を管理していました。Kafka 3.3以降、KRaft（Kafka Raft）モードではZooKeeperへの依存を排除し、メタデータを自己管理できます。

---

### インストール
LinuxシステムにKafkaをインストールする方法（Java 8+がインストールされていることを前提）：

1. **Kafkaをダウンロード**:
   ```bash
   wget https://downloads.apache.org/kafka/3.7.0/kafka_2.13-3.7.0.tgz
   tar -xzf kafka_2.13-3.7.0.tgz
   cd kafka_2.13-3.7.0
   ```

2. **ZooKeeperを起動**（KRaftを使用しない場合）:
   ```bash
   bin/zookeeper-server-start.sh config/zookeeper.properties
   ```

3. **Kafkaサーバーを起動**:
   ```bash
   bin/kafka-server-start.sh config/server.properties
   ```

4. **トピックを作成**:
   ```bash
   bin/kafka-topics.sh --create --topic mytopic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
   ```

5. **確認**:
   ```bash
   bin/kafka-topics.sh --list --bootstrap-server localhost:9092
   ```

KRaftモード（ZooKeeper不要）の場合、クラスタIDを生成し、`config/kraft/server.properties`を調整します：
```bash
bin/kafka-storage.sh random-uuid
bin/kafka-storage.sh format -t <UUID> -c config/kraft/server.properties
bin/kafka-server-start.sh config/kraft/server.properties
```

---

### 基本操作
Kafkaはコマンドラインインターフェースまたはクライアントライブラリを使用します。`kafka-console-*`ツールを使用した例：

#### メッセージの生成
```bash
bin/kafka-console-producer.sh --topic mytopic --bootstrap-server localhost:9092
> Hello, Kafka!
> Another message
```

#### メッセージの消費
```bash
bin/kafka-console-consumer.sh --topic mytopic --from-beginning --bootstrap-server localhost:9092
```
出力: `Hello, Kafka!` `Another message`

#### 主要コマンド
- トピック一覧表示: `bin/kafka-topics.sh --list --bootstrap-server localhost:9092`
- トピックの詳細表示: `bin/kafka-topics.sh --describe --topic mytopic --bootstrap-server localhost:9092`

---

### Kafkaを使ったプログラミング
Kafkaはクライアントライブラリを介して多くの言語をサポートしています。以下は`kafka-python`を使用したPythonの例です：

1. **ライブラリをインストール**:
   ```bash
   pip install kafka-python
   ```

2. **プロデューサーの例**:
   ```python
   from kafka import KafkaProducer

   producer = KafkaProducer(bootstrap_servers='localhost:9092')
   producer.send('mytopic', b'Hello, Kafka!')
   producer.flush()
   ```

3. **コンシューマーの例**:
   ```python
   from kafka import KafkaConsumer

   consumer = KafkaConsumer('mytopic', bootstrap_servers='localhost:9092', auto_offset_reset='earliest')
   for message in consumer:
       print(message.value.decode('utf-8'))
   ```

---

### 高度な概念
1. **コンシューマーグループ**:
   - グループ内の複数のコンシューマーがパーティションを共有します。各メッセージはグループごとに1回処理されます。
   - 例: コンシューマー設定での`group.id=mygroup`。

2. **レプリケーションとフォールトトレランス**:
   - `replication-factor`を1より大きく設定して、ブローカー障害時にデータが失われないようにします。
   - 例: `--replication-factor 3`。

3. **Kafka Streams**:
   - データをリアルタイムで処理します（例：集約、結合）。
   - Javaでの例:
     ```java
     StreamsBuilder builder = new StreamsBuilder();
     KStream<String, String> stream = builder.stream("mytopic");
     stream.foreach((key, value) -> System.out.println(value));
     ```

4. **Kafka Connect**:
   - データをインポート/エクスポートします（例：MySQLからKafkaへ）。
   - 例: JDBCソースコネクタを使用。

5. **保持期間とコンパクション**:
   - `log.retention.hours=168`（デフォルト7日）。
   - ログコンパクションはキーごとの最新の値を保持します。

---

### パフォーマンスのヒント
1. **パーティショニング**: 並列処理のためにパーティション数を増やしますが、過剰なパーティショニングは避けます（例：トピックあたり10〜100）。
2. **バッチ処理**: スループット向上のために`batch.size`と`linger.ms`を調整します。
3. **圧縮**: `compression.type=gzip`で有効にします。
4. **監視**: Kafka ManagerやPrometheus + Grafanaなどのツールを使用します。

---

### セキュリティ
- **認証**: SASLを有効にします（例: `sasl.mechanism=PLAIN`）。
- **認可**: `kafka-acls.sh`を使用してACLを設定します。
- **暗号化**: SSLを設定します（`security.protocol=SSL`）。
- **アクセス制限**: `server.properties`で特定のIPにバインドします。

---

### Kafka vs. その他
- **Kafka vs. RabbitMQ**: Kafkaはより高いスループットと永続性を提供します。RabbitMQは従来のメッセージングにはよりシンプルです。
- **Kafka vs. Redis**: Kafkaはイベントストリーミング用、Redisはインメモリキャッシング/キーバリューストレージ用です。
- **Kafka vs. AWS Kinesis**: Kafkaは自己管理でよりカスタマイズ可能、Kinesisは完全管理型です。

---

### 制限事項
- **複雑さ**: クラスタリングとチューニングには学習曲線が急です。
- **リソース集約的**: 大量のメモリとディスク容量を必要とします。
- **ネイティブなクエリ機能なし**: 処理には外部ツール（例：Kafka Streams）に依存します。

---

### リソース
- **公式サイト**: [kafka.apache.org](https://kafka.apache.org)
- **ドキュメント**: [kafka.apache.org/documentation](https://kafka.apache.org/documentation)
- **Confluent**: [confluent.io](https://www.confluent.io)（チュートリアル、マネージドKafka）

---

このガイドはKafkaの基本とそれ以上をカバーしています。特定の領域（例：クラスタリング、Streams、ユースケース）をさらに深く探求したい場合は、お知らせください！