---
audio: false
generated: true
lang: ja
layout: post
title: コンピュータビジョンは人間に及ばない
translated: true
type: note
---

Yin Wangのブログ記事では、2019年時点の先進的なコンピュータビジョンシステムでさえ、人間レベルの性能には程遠いと論じられている。これらのシステムは基本的な物体認識（例：車の識別）に苦戦し、敵対的サンプルやわずかな画像変更で簡単に騙されてしまうという。一方、人間は物体を容易に認識できる。Wangは、この分野の進歩が過大評価されており、画像処理と理解の根本的な限界により、真の人間レベルのコンピュータビジョンは未だ実現されていないと示唆している。

### 真実か？
投稿が公開された2019年10月時点では、Wangの主張は当時のコンピュータビジョンの状況に基づき妥当性があった：

- **限定的な一般化**: 畳み込みニューラルネットワーク（CNN）のようなコンピュータビジョンモデルは、トレーニングデータ内のパターンマッチングに強く依存していた。Wangが述べるように、新しい文脈への一般化やエッジケースの扱いによく失敗した。例えば、照明、角度、背景が大きく変化すると、モデルは物体を誤分類することがあった。

- **敵対的攻撃への脆弱性**: モデルを誤った分類に導くために微妙に変更された画像である敵対的サンプルについてのWangの指摘は正確だった。Goodfellow et al. (2014) などの研究は、わずかで知覚できない摂動がモデルに高い確信度で画像を誤分類させることを示し、人間と機械の視覚の間の隔たりを浮き彫りにした。

- **過大宣伝された主張**: この記事はコンピュータビジョン周辺の誇大宣伝を批判している。2019年時点で、ResNet、YOLO、初期のトランスフォーマーなどのモデルはベンチマーク（例：ImageNet）で印象的な結果を示したが、これらは制御されたデータセットだった。現実世界のアプリケーションでは、自動運転や顔認識システムにおける誤認識などの弱点がしばしば明らかになった。

しかし、記事のトーンは絶対的であり、「人間レベルのコンピュータビジョンは存在しない」と主張している。これは特定のタスクにおける進歩を見落としている。例えば：
- **タスク特化の成功**: 2019年までに、コンピュータビジョンシステムは、特定の医療画像の分類（糖尿病性網膜症の検出など）や制御された環境での特定の物体認識といった限定的なタスクにおいて人間を凌駕していた。
- **2019年以降の進歩**: 2025年までに、Vision Transformer（ViT、CLIPなど）や大規模マルチモーダルモデル（GPT-4o、DALL·E 3など）のような進歩により、隔たりは縮まっている。これらのモデルはより多様な入力を扱い、文脈を越えてより良く一般化し、言語と視覚を統合して推論を改善している。それでも、人間の視覚の頑健性、文脈認識、直感的理解を完全に再現するわけではない。

### 批判的評価
Wangの核心的な主張—2019年時点のコンピュータビジョンが人間レベルではなかったこと—はほぼ真実である。モデルは人間の視覚の一般化能力、頑健性、直感的理解を欠いていた。しかし、進歩を否定する彼の見方は過度に悲観的かもしれない。なぜなら、その後大きな飛躍が達成されているからである。2025年現在でも、コンピュータビジョンは特定の領域で優れているが、以下のような問題により、現実世界のシナリオにおける人間レベルの知覚には依然及ばない：
- **文脈的推論**: 人間は感覚データと世界の知識を容易に統合するが、機械はこれに苦戦する。
- **エッジケース**: モデルは、人間が素早く適応する稀な状況や新しい状況で失敗することがある。
- **エネルギー効率**: 人間の視覚は計算モデルよりもはるかにエネルギー効率が良い。

この記事はAI能力の過大宣伝への批判として関連性を保っているが、この分野の急速な進歩を考慮していない。2025年現在、「人間レベル」の視覚が達成されたことを確認する単一の情報源は存在しないが、隔たりは大きく狭まっている。[](https://yinwang0.wordpress.com/2019/10/20/human-level-computer-vision/)