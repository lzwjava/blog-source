---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4-fast
title: RTX 4070トレーニング時間の目安
translated: true
type: note
---

以下は、あなたのログとハードウェア（RTX 4070, 12 GB VRAM）に基づいた実用的な予測です。

---

## **1. 最初のイテレーションが27秒かかった理由**

* 最初のイテレーションは、以下の理由で*常に*誤解を招くほど遅くなります：

  * PyTorchの`compile=True`が*事前グラフコンパイル*をトリガーするため。
  * Inductorがオートチューニング、カーネル特殊化、グラフloweringを実行するため。
  * CUDAコンテキストの作成、メモリ割り当てが行われるため。
  * データセットの初回読み込みとパイプラインのウォームアップが行われるため。

最初のステップに20～30秒かかるのは正常です。

ウォームアップ後、トレーニング速度は劇的に向上します。

**ステップ0は完全に無視すべき**です。

---

## **2. ウォームアップ後の予想速度**

あなたのモデルサイズ（～40M パラメータ）、ブロックサイズ1024、バッチ16 × 勾配累積32 = **512 シーケンス/イテレーション**、RTX 4070の場合、通常以下の値を達成します：

**～1.5～2.5 million tokens/sec MFUは初期は低いが改善する**
ウォームアップ後の実スループットは通常：

**80～120 ms / イテレーション**

これは以下の条件での値です：

* 40M パラメータモデル（軽量）
* fp16、融合AdamW
* シーケンス長 1024
* 実効バッチサイズ 512

---

## **3. max_iters = 6000 であること**

したがって、総時間はおよそ：

**6000 × ～0.1 s = 600 秒 ≈ 10 分**

スループットが遅かったとしても：

* **150 ms/iter → 15 分**
* **200 ms/iter → 20 分**

これが正しいオーダーです。

---

## **4. ログを確認 — MFUは正常化する**

MFUが「-100%」と表示されるのは、単に最初のイテレーション時間が無効なためです。

10～20イテレーション後、以下の値が見えるはずです：

* MFU ～ 25–40% (4070での40Mモデルでは正常)
* イテレーション時間が <200 ms に低下

---

## **5. まとめ：どれだけ待つ必要があるか**

**合計で約10～20分です。**
数時間ではありません。

ログのイテレーション時間が**100～200 ms**前後で表示され始めれば、安定していると判断できます。

---

必要であれば、次の～10イテレーションのログを貼り付けてください。あなたの実行から正確なスループットを計算できます。