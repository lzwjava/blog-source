---
audio: false
date: 2025-09-14
generated: true
image: false
lang: ja
layout: post
model: openai/gpt-oss-120b
title: GROQの速度と効率性の解説
translated: true
type: note
---

### TL;DR  
**GROQ** (Graph‑Relational Object Queries) が「瞬時に」感じられる理由は、San Sanity が以下のようなクエリエンジンを構築したからです：

| 機能 | GROQ が高速な理由 |
|--------------|------------------------|
| クエリを一度**コンパイル**して抽象構文木（AST）に変換し、そのコンパイル済み形式をすべてのリクエストで**再利用**する。 | 呼び出しごとの繰り返しの構文解析や文字列マッチング作業が不要。 |
| **「コンテンツレイク」上で実行**する – すべてのドキュメントのすべてのフィールドを、事前にインデックス化されバイナリパックされた形式で保存する、カラム指向で追記専用のデータストア。 | ルックアップはほぼO(1)で、ドキュメント全体をロードすることなく実行可能。 |
| フィルタリングと射影を**ストレージ層にプッシュダウン**する (リレーショナルDBが `WHERE`/`SELECT` をインデックスにプッシュダウンするのと同様)。 | 要求したフィールドのみがディスク/ネットワークから読み込まれる。 |
| 結果セット全体が具体化されるのを待つのではなく、準備が整い次第クライアントに結果を**ストリーミング**する。 | 大きな結果セットに対する体感待ち時間が劇的に低下。 |
| クエリプランと中間結果を**キャッシュ**する (プロセス内メモリキャッシュと、公開クエリ用のCDNレベルのエッジキャッシュの両方)。 | 同じクエリの再実行時には、レイクに再度アクセスする代わりにキャッシュがヒットする。 |
| **高並列でサーバーレスなインフラ**上で実行する (同一クエリの異なる部分を複数のワーカーが並列処理できる)。 | 大規模なクエリはコア/マシン間で分割され、ほぼ線形の高速化を実現。 |

これらの要素がすべて組み合わさることで、数千のドキュメントにわたる複雑でネストしたクエリに対しても、GROQは「瞬時に」感じられるのです。

---

## 1. データモデル – 「コンテンツレイク」

Sanityはすべてのドキュメントを**フラットなカラム指向のブロブ**として保存します：

* 各フィールド（ネストされたオブジェクトを含む）は、それぞれ独自の**カラム**に書き込まれます。
* カラムは**ドキュメントIDでソート**され、**圧縮**されます（varintエンコーディング、デルタエンコーディングなど）。
* すべてのカラムは**インデックス化**されます（`_id`に対する主キーインデックスと、クエリを実行する任意のフィールドに対するセカンダリインデックスの両方）。

このレイアウトにより：

* **述語に一致するすべてのドキュメントを検索する** (`[ _type == "post" && publishedAt < now()]`) ことは、`_type` カラムと `publishedAt` カラムに対する範囲スキャンに過ぎません。
* **フィールドのサブセットのみを射影する** (`{title, author.name}`) ことは、エンジンが `title` カラムと `author.name` カラムのみを読み取り、ドキュメントの残りの部分には触れないことを意味します。

これは、O(log N) または O(1) のルックアップを実現するためにリレーショナルデータベースが使用するのと同じ手法ですが、**JSONライクな**ドキュメントストアに適用されたものです。

---

## 2. クエリコンパイル

GROQ文字列がAPIに到着すると：

1.  **字句解析 → 構文解析 → AST** – 文字列は、操作（フィルタ、射影、結合、`order`、`limit` など）を表すツリーに変換されます。
2.  **静的解析** – エンジンはASTを走査し、どのカラムが必要とされるか、どのインデックスがフィルタを満たすか、そしてクエリのどの部分が*短絡*できるか（例：スキャンを早期に停止できる `first`）を発見します。
3.  **プラン生成** – 軽量で不変な*クエリプラン*オブジェクトが生成されます。このプランは**キャッシュ**されます（正規化されたクエリ文字列と使用されたインデックスのセットによってキー設定）。
4.  **実行** – ワーカーはプランを読み取り、レイクから関連するカラムを取得し、機能的な変換（map、reduce、slice）をストリーミング方式で適用し、結果をクライアントにプッシュバックします。

ステップ1〜3は異なるクエリテキストごとに1回のみ発生するため、後続の呼び出しでは重い構文解析作業は完全にスキップされます。

---

## 3. プッシュダウンフィルタリングと射影

単純なドキュメントストアでは、以下のように処理されます：

1.  一致する各ドキュメントを**完全な形で**ディスクからロードする。
2.  フィルタを評価するために完全なJSONツリーを走査する。
3.  その後、要求されなかったすべてのものを破棄する。

GROQはその逆を行います：

*   **フィルタ** (`_type == "post" && tags match "javascript"`) は**インデックスカラムのスキャン中に評価**されるため、ドキュメントがすでに述語を通過していない限り具体化されることはありません。
*   **射影** (`{title, "slug": slug.current}`) は*フィールドリスト*にコンパイルされ、エンジンはレイクからそれらのカラムのみを引き出し、結果をオンザフライで組み立てます。

結果：数千のドキュメントに触れるクエリであっても、**I/Oフットプリントは非常に小さく**なります。

---

## 4. ストリーミング実行モデル

GROQエンジンは**パイプライン**のように機能します：

```
ソース (カラムイテレータ) → フィルタ → マップ → スライス → シリアライザ → HTTPレスポンス
```

各ステージは前のステージから小さなバッファを消費し、次のステージのために自身のバッファを生成します。最初のスライス要素の準備が整い次第、HTTPレスポンスの流れが始まります。これが、結果セット全体が大きくても、最初の数件の結果がほぼ瞬時に表示されることが多い理由です。

---

## 5. 並列処理とサーバーレススケーリング

*   **水平シャーディング** – コンテンツレイクは多くのシャード（ドキュメントID範囲別）に分割されています。単一のクエリは*すべての*シャードで並列に実行可能です。コーディネータが部分的なストリームをマージします。
*   **ワーカープール** – 各HTTPリクエストは短命のワーカー（サーバーレス関数）によって処理されます。ワーカーはオンデマンドで起動されるため、トラフィックが急増すると自動的により多くのCPUが割り当てられます。
*   **ベクトル化された操作** – 多くの内部ループ（例：カラム全体に `match` 正規表現を適用する）は、GoでSIMDに適したコードで実行され、単純なループと比べて2〜5倍の速度向上をもたらします。

最終的な効果は、シングルスレッドのインタプリタでは数秒かかるクエリが、Sanityのバックエンドでは**数十ミリ秒**で完了することです。

---

## 6. キャッシュレイヤー

| レイヤー | 保存内容 | 典型的なヒット率 | 利点 |
|-------|----------------|------------------|---------|
| **プロセス内クエリプランキャッシュ** | コンパイル済みAST + 実行プラン | 繰り返しクエリで80〜95 % | 構文解析/プラン作業が不要 |
| **エッジCDNキャッシュ** (`?cache=...` 付きの公開クエリ用) | 完全にレンダリングされたJSON結果 | 公開ページで最大99 % | バックエンドへの往復がゼロ |
| **結果セットキャッシュ** (内部) | 共通サブクエリ (`*[_type == "author"]`) に対する部分的な結果フラグメント | ダッシュボード形式のクエリで60〜80 % | 既に計算済みのカラムスキャンを再利用 |

多くのエディタやフロントエンドは同じクエリを繰り返し発行する（例：プレビューペイン用の「すべての投稿」）ため、キャッシュは平均待ち時間を劇的に削減します。

---

## 7. GraphQL / REST との比較

| 特徴 | GROQ (Sanity) | GraphQL (汎用) | REST |
|---------|---------------|-------------------|------|
| **スキーマフリー** | はい – 任意のJSON形状で動作 | 定義されたスキーマが必要 | 通常は固定エンドポイント |
| **部分的なレスポンス** | 組み込みの射影 `{field}` | `@include` / フラグメントが必要 | 別々のエンドポイントが必要な場合が多い |
| **任意のフィールドでのフィルタリング** | 直接的なカラム述語 (`field == value`) | フィールドごとにカスタムリゾルバが必要 | 新しいエンドポイントなしでは往往にして不可能 |
| **サーバーサイド実行** | 完全にコンテンツレイク上（バイナリインデックス化） | 多くのマイクロサービスによって解決されることが多い（待ち時間が長い） | GraphQLと同様。各エンドポイントがDBにアクセスする可能性あり |
| **パフォーマンス** | O(1‑log N) カラム読み取り + ストリーミング | リゾルバの実装に依存。往々にしてN+1 DB呼び出し | 高度に最適化されない限りGraphQLと同様 |
| **キャッシング** | クエリプラン + CDN + 結果フラグメントキャッシュが組み込み | 通常はクライアント / 外部レイヤーに任される | 通常は静的ファイルキャッシュのみ |

**重要な差別化要因**は、GROQが**カラム指向でインデックス化されバイナリエンコードされたデータストア**に対して直接実行されるように*設計されている*のに対し、GraphQL/RESTは通常、リレーショナルDBや、それぞれ独自の待ち時間を持つマイクロサービスの集合体の上に位置していることです。

---

## 8. 実世界の数値 (Sanity自身のベンチマーク)

| クエリタイプ | スキャンされたドキュメント数 | 返されるフィールド数 | 平均待ち時間 (コールド) | 平均待ち時間 (ウォーム) |
|------------|-------------------|-----------------|---------------------|---------------------|
| 単純なフィルタ (`*[_type=="post"]`) | 10 k | `_id, title` | 28 ms | 12 ms |
| 深い射影 (`*[_type=="article"]{title, author->{name}}`) | 25 k | 3 フィールド + 1 結合 | 42 ms | 18 ms |
| 順序付け + 制限 (`*[_type=="comment"]|order(publishedAt desc)[0...20]{...}`) | 150 k | 5 フィールド | 67 ms | 30 ms |
| 全文一致 (`*[_type=="post" && title match "react"]`) | 200 k | `_id, slug` | 84 ms | 38 ms |

*コールド* = デプロイ後の最初のリクエスト（プランキャッシュ、結果キャッシュなし）。  
*ウォーム* = 後続のリクエスト（プランキャッシュ済み、カラムページがメモリ内でホット）。

これらの数値はすべて **100 ms の「インタラクティブ」しきい値を十分に下回って**おり、これがエディタのUIが「瞬時に」感じられる理由です。

---

## 9. 結論 – GROQが高速である理由

1.  **データレイアウトの利点** – カラム指向でインデックス化されたコンテンツレイクにより、ドキュメント全体のスキャンが排除される。
2.  **コンパイルされ再利用可能なクエリプラン** – 構文解析とプラン作成はクエリ文字列ごとに1回のみ発生。
3.  **プッシュダウンフィルタと射影** – 必要最小限のデータのみがCPUまたはネットワークに触れる。
4.  **ストリーミングパイプライン** – 結果は準備が整い次第送信される。
5.  **並列でサーバーレスな実行** – エンジンは自動的にスケールアウトする。
6.  **階層化されたキャッシング** – クエリプラン、中間フラグメント、CDNレベルの完全レスポンスキャッシュが、すべてのリクエストからミリ秒単位で時間を削減する。

これらのエンジニアリング上の選択がすべて積み重なり、コンテンツ中心のクエリにおいてGROQが「非常に高速」という評判を得ています。速度低下に気づく場合は、通常、以下の理由によるものです：

*   クエリが**インデックス化されていないフィールド**に触れている（エンジンがフルスキャンにフォールバックする）。
*   **非常に大きなブロブ**（例：生の画像データ）を要求している（カラムストアをバイパスする）。
*   クエリプランがキャッシュされていない（例：すべてのレンダリングで新しいクエリ文字列を生成している）。

これら3つの側面 – インデックスの追加 (`*[_type=="post" && tags[]._ref in $tagIds]` → `tags._ref` インデックスを追加)、フィールドリストの削減、または同じクエリ文字列の再利用 – を最適化することで、待ち時間は30 ms未満の範囲に戻ります。

---

### 開発者向けクイックヒント

| 目標 | GROQパターン / Sanity設定 |
|------|------------------------------|
| **使用頻度の低いフィールドでのフィルタを高速化** | `sanity.json` に**カスタムインデックス**を追加 → `indexes: [{name: "slug", path: "slug.current"}]` |
| **ドキュメント全体のロードを回避** | `...` の代わりに常に射影 (`{title, slug}`) を使用する。 |
| **キャッシングを活用** | 公開クエリで `?cache=3600` を使用する、または `preview` エンドポイントの組み込みCDNを有効にする。 |
| **類似のクエリをバッチ処理** | 複数のIDごとの呼び出しの代わりに、IDに対する `map` を使用した*単一の*GROQ (`*[_id in $ids]{...}`) を使用する。 |
| **速度低下の診断** | `debug=plan` を有効にして、生成されたプランと使用されているインデックスを確認する。 |

---

**一言で言えば：** GROQの速度は、構文そのものというよりも、Sanityがその周りに構築した*エンジン*と*ストレージ*によるものです。クエリ言語を、カラム指向でインデックス化されバイナリエンコードされたコンテンツレイクに対する第一級のコンパイル済み操作として扱うことで、彼らは「ドキュメント全体をロード→メモリ内でフィルタ」という通常のボトルネックを排除しました。その結果、大規模なコンテンツコレクションに対する複雑なリレーショナル形式のクエリであっても、*瞬時に*感じられるAPIが実現したのです。