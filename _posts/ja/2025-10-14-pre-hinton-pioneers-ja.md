---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4-fast
title: ヒントン以前のディープラーニング先駆者たち
translated: true
type: note
---

### アレクセイ・イワフネンコの業績

ウクライナ・ソビエトのサイバネティクス研究者であるアレクセイ・グリゴーリエヴィチ・イワフネンコは、1960年代から1970年代にかけての先駆的な取り組みから、しばしば「ディープラーニングの生みの親」と呼ばれています。現在よりも計算リソースが数百万倍も限られていた冷戦時代に、彼はデータの階層的表現を自動的に学習できる多層ニューラルネットワークに焦点を当てました。

- **1965年: データ処理のグループ手法 (GMDH)**: ヴァレンティン・ラパと共に、イワフネンコは教師あり深層順伝播型多層パーセプトロン (MLP) に対する、最初の汎用的で実用的な学習アルゴリズムを発表しました。この手法は、入出力データペアに対する回帰分析を用いて、ネットワークを層ごとに学習させました。層を段階的に増やし、順次学習させ、検証セットを用いて不要な隠れユニットを剪定することを含んでいました。決定的に重要なのは、特徴量エンジニアリングを人手で行うことなく、ネットワークが入力データの分散的な内部表現を学習できるようにした点です。これは現代のディープラーニングの中核的な概念であり、西洋のAIにおける同様の概念を数十年先取りしていました。この手法は、パターン認識や予測といった実世界の問題に応用されました。

- **1971年: 深層ネットワークの実装**: イワフネンコはGMDHの原理を用いた8層の深層ニューラルネットワークを実証し、複雑なタスクに対するスケーラブルな深さを示しました。彼のアプローチは、深層ネットワークを多項式近似の一形態として扱い、自動的なモデル選択を可能にし、高層アーキテクチャにおける「次元の呪い」を回避しました。

イワフネンコのGMDHは、より広範な帰納的モデリングの枠組みへと進化し、制御システムや経済学などの分野に影響を与えました。その影響力にもかかわらず、彼の業績の多くはロシア語で発表され、英語圏のAIコミュニティでは見過ごされていました。

### 甘利俊一の業績

日本の数学者・神経科学者である甘利俊一は、1960年代から1970年代にかけて、適応的学習と情報処理の幾何学的視点を重視した、ニューラルネットワーク理論への基礎的貢献を行いました。彼の研究は神経科学と計算理論を橋渡しし、自己組織化システムの基盤を築きました。

- **1967-1968年: 適応的パターン分類と確率的勾配降下法 (SGD)**: 甘利は、SGD（1951年にさかのぼる最適化技法ですが、多層ネットワークに新たに適用されました）を用いて、深層MLPをエンドツーエンドで学習させる最初の手法を提案しました。5層ネットワーク（2つの調整可能な層）を用いたシミュレーションにおいて、彼のシステムは非線形分離可能なパターンを分類することを、層を跨いで直接重みを調整することで学習しました。これにより、勾配ベースの更新を通じて内部表現が出現することが可能になり、バックプロパゲーションに似た手法の直接の先駆けとなりました。これらはすべて、現代の基準よりも数十億倍厳しい計算制約下で行われました。

- **1972年: 適応的連想記憶ネットワーク**: 1925年のレンツ・イジングモデル（物理学に基づくリカレントアーキテクチャ）に基づいて、甘利は、相関に基づいて結合重みを調整することでパターンを記憶し想起することを学習する適応版を導入しました。これは系列処理を扱い、ノイズの多い部分的な入力から記憶したパターンを神経ダイナミクスを介して検索しました。1969年にまず日本語で発表されたこの業績は、連想記憶のための「ホップフィールドネットワーク」の起源と見なされています。

甘利はまた、統計モデルと神経ダイナミクスを解析するために微分幾何学を用いる情報幾何学という分野を創始し、これは現代の確率的ニューラルネットワークの基礎を支えています。

### 2024年ノーベル賞への反論における文脈

ユルゲン・シュミッドフーバーは、2024年の報告書「盗用に対するノーベル賞」において、ヒントンとホップフィールドのノーベル賞受賞アイデア—例えば、表現を学習するボルツマンマシン (1985) や、連想記憶のためのホップフィールドネットワーク (1982) —が、イワフネンコの層ごとの深層学習や甘利のSGD/適応的リカレントモデルを出典明示せずに流用したと主張しています。例えば、ボルツマンマシンは、イワフネンコの1965年の内部表現学習や甘利の1967年のSGDへの言及を省略しており、ホップフィールドのネットワークは甘利の1972年の適応的イジングモデルを無視していたとされます。シュミッドフーバーは、この省略が後の調査報告やノーベル賞の科学的背景文書においても続いており、AIの歴史における西洋中心のバイアスを浮き彫りにしていると主張しています。

[Alexey Ivakhnenko - Wikipedia](https://en.wikipedia.org/wiki/Alexey_Ivakhnenko)  
[Deep Learning in a Nutshell: History and Training - NVIDIA Developer](https://developer.nvidia.com/blog/deep-learning-nutshell-history-training/)  
[Shun-ichi Amari | Kyoto Prize](https://www.kyotoprize.org/en/laureates/shun-ichi_amari/)  
[Japanese scientists were pioneers of AI, yet they're being written out of history](https://modernsciences.org/japanese-ai-pioneers-history-shuninchi-amari-kunihiko-fukushima-december-2024/)  
[A Nobel Prize for Plagiarism - Technical Report IDSIA-24-24](https://people.idsia.ch/~juergen/physics-nobel-2024-plagiarism.pdf)  
[Machine Learning Stirs Controversy in Nobel Prize in Physics - Harvard Technology Review](https://harvardtechnologyreview.com/2024/11/18/machine-learning-stirs-controversy-in-nobel-prize-in-physics/)