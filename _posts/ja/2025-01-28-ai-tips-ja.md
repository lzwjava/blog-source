---
audio: false
lang: ja
layout: post
title: AI Tools Tips
translated: true
---

* カーソルにサンプルコードをコピーし、コメントでコンテキストを記述してください。

* 香港地域では、DeepSeekまたはMistralサービスの使用は許容されますが、ChatGPT、Claude、Geminiの使用は許容されません。

* ある地域のAPIポリシーはそのアプリポリシーとほぼ同じです。

* Visual Studio Codeの代わりにCursorを使用してください。

* git mergeエディタのシナリオなど、Visual Studio Codeを使用する必要があるケースはまだあります。その場合、私はまだ`git config --global core.editor "code --wait"`を使用しています。

* Deepseek V3リリースの日から、AIツールのサブスクリプションは不要になりました。

* 「幸せな旧正月（蛇年）の画像を、名前のテキストを含めて生成してください」などのプロンプトで、GeminiまたはGrokを使用して祭りの祝賀画像を生成してください。

* AIモデルに元のテキストを提供して表を作成する場合でも、出力の一部が入力と異なる場合があります。たとえば、CursorでDeepseek V3モデルを使用してpip listの表を生成すると、「1.极狐0」のようなバージョンが含まれる場合があります。「极狐」は中国のGitLabプラットフォームを指します。

* DeepSeekまたはMistral APIを使用して「あなたはプロの翻訳者です。Jekyllブログ投稿のMarkdownファイルを英語から中国語に翻訳しています。{テキスト}」のようなプロンプトでタイトルを翻訳すると、誤訳につながる可能性があります。提供したテキストに加えて、出力には過剰な翻訳が含まれることがよくあります。

* カーソルのAIモデルが部分的に正しいテキストを与える場合でも、AIモデルに正しい部分を再生成させるフォローアップ指示を追加できるので、受け入れることができます。

* 役に立たない可能性が高い場合は、大規模言語モデルに過剰なコンテキストを提供しないでください。たとえば、会話の対話行を生成する際に、トピックに関する100個のポイントを提供しないでください。大規模言語モデルには既に膨大なデータが含まれています。

* 翻訳や対話歌詞の生成などのタスクに十分なコンテキストを提供する場合は、思考連鎖機能を使用しないでください。処理速度が遅くなり、冗長で役に立たない応答につながる可能性があります。

* チャットボットがユーザーの指示に従えるかどうかをテストする1つの方法は、英語で何かを説明するように依頼し、次に中国語で入力を続け、チャットボットが英語での出力を維持するかどうかを確認することです。

* AI時代においてPostmanやFigmaを使用しない理由の1つは、それらの機能がテキストから生成できないことです。また、コンポーネントの置き換えをトリガーするcommand + Kショートカットもありません。

* ユーザーインターフェースはAI時代において障壁になりつつあります。Pythonのリクエストライブラリやその他のプログラミング言語を使用してコードを直接テストできるのに、なぜアプリケーションのテストのためにPostmanをAI化してアップグレードする必要があるのでしょうか？後者の方がAIによって強化されるからです。

* コードベースのUI生成はAIによって強化され、より直接的で強力なアプローチを提供するのに、なぜUI作成のためにFigmaをAI化してアップグレードする必要があるのでしょうか？

* LLMは、テキスト関連のアプリケーションを最初に変更します。


* [AI搭載Gitコミットメッセージ](./gitmessageai-en)

* [会話音声生成](./conversation-style-en)

* [Google Cloud音声認識](./speech-to-text-en)

* [llama.cppを試す](./llama-cpp-en)

* [ChatGPTでの検索の事例](./ai-search-en)

* [Deepseek、Mistral、Anthropic](./dma-en)
