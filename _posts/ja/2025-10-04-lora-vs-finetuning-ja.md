---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4-fast
title: LoRAとフルファインチューニングの性能比較
translated: true
type: note
---

### LoRAと完全ファインチューニングのパフォーマンス比較概要

Thinking Machines Labの実証分析に基づくと、LoRA（Low-Rank Adaptation）はパラメータ効率の良いファインチューニング手法であり、小規模データセットや強化学習（RL）のような容量制約のあるシナリオでは完全ファインチューニング（FullFT）と同等の性能を発揮することが多いですが、大規模データセットでは本来のトレーニングダイナミクスの制限により性能が低下します。[1] 本項では各知見について、メカニズム、証拠、モデル開発者への実践的意義を解説します。

### 中小規模の指示チューニングと推論データセットにおける同等性

指示追従（Alpacaスタイルのデータセットなど）や推論タスク（GSM8K数学問題など）に使用される中規模までのデータセットでファインチューニングする場合、LoRAはFullFTと同等の性能を達成します。この同等性は、これらのデータセットが通常10,000～100,000例を含み、LoRAの低ランクパラメータ化容量とよく一致するために生じます。LoRAは重み更新を低ランク行列分解（ΔW = B A、BとAは低ランク行列）として近似しますが、これは全てのパラメータを更新する完全な表現性を必要とせず、このようなタスクに必要な限定的な振る舞いの変化を捉えるのに十分です。

実際には、開発者はLoRAを使用して大規模モデル（例：70B+ パラメータ）をコンシューマハードウェアやメモリが限られたクラウドインスタンスでファインチューニングし、精度やパープレキシティなどの下流指標においてFullFTと同じ結果を得ることができます。例えば、指示タスク用のDolly-15kのようなデータセットでは、ランク8～16のLoRAは見分けがつかない結果をもたらし、トレーニング可能なパラメータとトレーニング時間を最大99%節約します。[1] ただし、これはデータセットがトレーニング分布を超えた広範な一般化を要求しない場合にのみ成り立ち、過学習のリスクはFullFTと同様に残ります。

### LoRAの容量を超える大規模データセットにおける性能低下

データセットがLoRAの実効容量を超えて大きくなると（例えば、The Stackでのコード生成のようなドメイン特化適応における数百万の例）、LoRAはFullFTに遅れを取ります。重要な問題は、損失が急激に頭打ちになるような厳密な「容量限界」ではなく、LoRAが低ランクボトルネックとデータセット規模のミスマッチに起因して、損失収束が遅くなるというトレーニング効率の低下を示すことです。

これはLoRAの帰納的バイアスに起因します。行列積の形式（W' = W + γ B A）は更新を部分空間に制限します。これは疎で低次元の変化には有効ですが、大規模データセットの高分散な信号には対処が困難です。経験的には、損失曲線はLoRAがFullFTレベルに近づくために2～5倍多くのステップを必要とすることを示しており、たとえ到達したとしても、コーディングのHumanEvalのようなベンチマークでは最終性能が5～10%劣る可能性があります。[1] この関係はパラメトリックです。データセットサイズがLoRAのランク（r）よりも速くスケールするにつれて効率が低下し、rを増やすことはわずかに役立つものの、低データ領域での過学習リスクを伴わずに完全に補償するわけではないことを示唆しています。

これが意味するところは、大規模コーパスにはFullFT（またはQLoRAのようなハイブリッド手法）を優先し、LoRAは反復的なプロトタイピングで輝くということです。これはまた、手法を選択する前にデータセットサイズを見積もる必要性を強調しており、トークンカウントのようなツールがこれを導くのに役立ちます。

### 大規模バッチサイズとパラメータ化効果への感受性

LoRAはFullFTと比較して大規模バッチサイズに対する耐性が低く、最適点を超える（例：バッチサイズ > 512）と損失ペナルティが急激に現れます。FullFTの勾配ノイズがより優雅にスケールするのに対し、LoRAの行列積の設定は低ランク更新における分散を増幅し、不安定な最適化を引き起こします。このペナルティは、ランクを増やした場合でも持続します。なぜなら、それは直接的な重み最適化に対する双線形形式の異なるヘッセ行列特性に根ざしているからです。

例えば、推論データセットでの実験では、バッチサイズが1kを超えるとLoRAの損失は20～30%速く上昇しますが、FullFTはより広範なパラメータ平均化によって安定します。[1] 軽減策には、効果的なバッチを小さくシミュレートするための勾配累積や、注意深い学習率スケジューリングを伴うAdamWのような技術の使用が含まれます。このダイナミクスはLoRAのトレードオフを浮き彫りにします。メモリ効率は良いが、計算並列性のスケーリングでは脆弱性があり、高スループットのトレーニングクラスターにはあまり理想的ではありません。

### 全層、特にMLPとMoEへのLoRA適用の利点

小規模データセットであっても、LoRAを普遍的に（Attention、MLP、Mixture-of-Experts層すべてに）適用することは、Attentionのみのバリアントを凌駕し、特にパラメータ数がより高いランクによって一致させられる場合に顕著です。初期の実装で一般的だったAttentionのみのLoRAは、マルチホップ推論のようなタスクで3～7%性能が劣ります。これは、ほとんどの非線形変換とドメイン固有の知識統合を扱うフィードフォワード層（MLP/MoE）を無視するためです。

全層LoRAはモデルのアーキテクチャをより全体的に活用します。MLPはパラメータの約70%を占め、タスク固有の計算を捕捉し、MoE（Mixtralのようなモデル）はルート固有の適応から恩恵を受けます。Attentionのランクだけを上げてパラメータを一致させようとしても、Attentionヘッドの冗長性により非効率な部分空間が生じ、失敗します。ベストプラクティス：小規模データでは、すべての層でランク16～64を使用し、追加の計算コストなしで効率と評価指標の向上をもたらします。[1] この知見は、PEFTのようなライブラリでの広範な採用を促進し、特殊なアーキテクチャにおける「LoRA税」を減らします。

### 低ランクでの強化学習における同等性

LoRAは、強化学習のファインチューニング（例えば、選好データセットに対するRLHFやDPO）において、非常に低いランク（r=4～8）であってもFullFTと同等の性能を発揮します。これは、RLの本来の低容量要求によるものです。情報理論的には、RLの更新は疎な軌道上での報酬モデリングと方策勾配に焦点を当て、教師あり学習（SL）の密なトークン予測を超える表現力を低ランクデルタが持つことは稀です。

理論から予想されるように、これはRLの損失（例：PPOクリップ）が行動の方向性の変化を強調し、LoRAの部分空間が完全なパラメータ化を必要とせずにこれを効率的に符号化するために成り立ちます。実験では、AnthropicのHH-RLHFのようなベンチマークで同等性が確認され、LoRAはより速く収束し、10倍少ないメモリを使用します。[1] 実践者にとって、これはLoRAをRLパイプラインのデフォルトとし、控えめなハードウェアで兆パラメータモデルのスケーラブルなアライメントを可能にします。

### 広範な意義と推奨事項

これらの洞察は、LoRAが特にリソース制約のある環境におけるほとんどのポストトレーニングニーズに対する実用的なツールである一方、広大なデータに対するFullFTの普遍的な代替品ではないことを明らかにしています。将来の研究では、ギャップを埋めるための適応的ランクや層別スケーリングの探求が行われるかもしれません。開発者は自身のデータセット規模でベンチマークを行い、バッチ効果を早期に監視すべきです。[1] 全体として、LoRAは対象を絞ったシナリオにおいて後悔のない形でファインチューニングを民主化し、効率的なAI開発への移行と一致しています。

引用:
[1] https://tinker-docs.thinkingmachines.ai/lora-primer