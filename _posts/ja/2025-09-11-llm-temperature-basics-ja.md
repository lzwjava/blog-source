---
audio: false
date: 2025-09-11
generated: true
image: false
lang: ja
layout: post
model: openai/gpt-5
title: LLM温度パラメータの基礎理解
translated: true
type: note
---

LLM API（OpenAI、Copilot API、Anthropicなど）において、**temperature**（温度）はモデルの出力をどの程度*ランダム*または*確定的*にするかを制御するパラメータです。

---

### Temperatureの役割

* **低い温度（0に近い値）:**
  モデルは確定的になり、常に最も確率の高い次のトークンを選択します。
  例: 定義を尋ねた場合、毎回最も標準的/期待される回答が得られます。

* **高い温度（1以上に近い値）:**
  モデルはより自由にサンプリングし、確率の低いトークンも探索します。これにより多様性、創造性、予測不可能性が増します。
  例: ブレインストーミング、ストーリーテリング、コードのバリエーション生成には、高い温度が適している場合があります。

---

### 「0.7」が意味するもの

* `temperature = 0.7` は**中程度のバランス**です。

  * ある程度のランダム性と多様性を許容します。
  * `0` ほど硬直的ではなく、`1.2` ほど「野生的」でもありません。
  * これが**多くのAPI、Copilotのようなシステムでデフォルト値としてよく使われる**理由です。創造的でありながら、信頼性の高い結果をもたらします。

---

### 使用方法

ほとんどのAPIでは、リクエストのパラメータとして渡します。例:

**OpenAI API (チャット補完):**

```json
{
  "model": "gpt-4.1",
  "messages": [
    {"role": "user", "content": "ドラゴンとロボットに関する短いストーリーを書いてください。"}
  ],
  "temperature": 0.7
}
```

**GitHub Copilot API:**
このパラメータも同様に機能します。Copilotは内部的にtemperatureを使用して、より文字通りの補完とより探索的な提案の間で決定します。ほとんどのIDE統合では `0.7` 前後に設定されていますが、コンテキスト（コード補完など）によっては安定性のために低い値が使用される場合があります。

---

✅ **経験則:**

* **0–0.3** → 確定的、事実に基づく、予測可能。数学、APIドキュメント、設定、単体テストに適しています。
* **0.4–0.7** → バランスの取れた、自然な文章、標準的なコーディング。ほとんどの場合の適切なデフォルト値です。
* **0.8–1.2** → 創造的、探索的、リスクを冒す。ブレインストーミング、ストーリー、詩に適しています。

---

Copilot/LLM APIでよく利用可能な **temperature と `top_p`（核サンプリング）の相互作用**についても説明しましょうか？