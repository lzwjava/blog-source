---
audio: false
generated: true
image: false
lang: ja
layout: post
model: x-ai/grok-4-fast
title: 理論的性能と実際の性能のギャップ
translated: true
type: note
---

この不一致は、**理論上のピークFLOPS**（1秒あたりの浮動小数点演算回数）が理想的な条件下での生の演算スループットを測定するためです。つまり、すべての実行ユニットの完全な利用、メモリボトルネックの不在、無限の帯域幅を仮定しています。実際のワークロード（特にAI/トレーニング/推論）では、パフォーマンスは演算能力だけでなく、**メモリサブシステムの非効率性**によって制限されます。2010年のFermi GPU（例: GTX 480）はこれが特に悪く、RTX 4090のような現代のカードと比較した際に「予想される」差を誇張していました。

### Fermiが理論上のFLOPSを十分に活用できなかった主な理由
1. **貧弱なキャッシュ階層とメモリコアレシング**
   - FermiのSMあたりのL1キャッシュは64KBのみ（レジスタと共有）、L2キャッシュは小さな768KB（チップ全体）。
   - 適切なキャッシュ一貫性がなく、グローバルメモリアクセスは非コアレシング → 実際のカーネルでは**実効帯域幅は約10〜30%**。
   - 現代のGPU（Ampere/Ada）は**大容量L1（192KB/SM）**、**専用テクスチャキャッシュ**、**積極的なプリフェッチ**を備え、理論帯域幅の70〜90%を達成。

2. **高レイテンシ、低帯域幅のECC DDR5/GDDR5**
   - Fermi: ~170 GB/s GDDR5、**384ビットバスだがECCのオーバーヘッド** → 実効 ~130 GB/s。
   - RTX 4090: **1 TB/s GDDR6X**、384ビットバスだが**コンシューマーモードではECCによるペナルティなし**、さらに**優れた圧縮技術**。
   - 実際のAIカーネルは**メモリバウンド**（例: 大規模行列のGEMM）。データ供給が滞ればFLOPSは意味をなさない。

3. **非効率なレジスタファイルとワープスケジューリング**
   - Fermi: 32k 32ビットレジスタ/SM → **最大1536スレッド**だが、レジスタスピリングのため実際の**占有率は約50%**。
   - Ada: 256 KB レジスタファイル → **2048スレッド/SM**、ほぼ100%の占有率。
   - 分岐の減少、優れた命令レベル並列性の抽出。

4. **電力/熱スロットリング**
   - GTX 480: 250W TDP、**持続的な負荷下で激しくスロットリング**（クロック速度が10〜20%低下）。
   - RTX 4090: 450Wだが、4nmプロセス、DLSS、ダイナミックブーストにより**性能/ワット比が約3倍向上**。

### 実測された実世界での向上（AIワークロード）

| 指標 | GTX 480 (Fermi, 2010) | RTX 4090 (Ada, 2022) | 高速化倍率 |
|--------|------------------------|----------------------|---------|
| FP32 TFLOPS (ピーク) | 1.35 | 82.6 | **61倍** |
| FP16 TFLOPS (ピーク) | ~0.7 (エミュレート) | 330 (Tensor) | **400倍以上** |
| **ResNet-50 トレーニング (img/s)** | ~60 | ~1,050 | **約17倍** |
| **GPT-2 推論 (tokens/s)** | ~8 | ~140 | **約17倍** |
| **Stable Diffusion (it/s)** | <0.1 | ~1.6 | **16倍以上** |

*出典: NVIDIA論文、MLPerfベンチマーク、AnandTech。*

### 結論
理論上のFLOPSは、Fermiが約70%の利用率を維持できると仮定していましたが、実際には維持できませんでした（実際は約15〜25%）。現代のアーキテクチャはこの差を**約70〜90%**にまで縮めているため、**実効的な演算能力のスケーリングは、ムーアの法則＋アーキテクチャの改善に近いもの**（12年間で約10〜17倍）であり、ピークFLOPSが示唆する60倍以上にはなりません。残りは「紙上の性能」です。