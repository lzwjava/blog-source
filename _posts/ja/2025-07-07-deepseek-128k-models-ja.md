---
audio: false
generated: true
lang: ja
layout: post
title: DeepSeekの2025年128Kトークンモデル
translated: true
type: note
---

2025年6月現在、DeepSeekは印象的なコンテキスト長を備えた一連のモデルを有しており、効率性のためにMixture-of-Experts（MoE）アーキテクチャを活用しています。以下が詳細です：

* **DeepSeek-R1:** 2025年1月にリリースされたこのモデルは、**128,000トークン**（一部のベンチマークでは131,072トークン）のコンテキスト長をサポートすることで注目されています。強化学習（RL）による事後学習により、数学、コーディング、構造化思考において特に優れた性能を発揮します。
* **DeepSeek-V3:** 2024年12月にリリースされたDeepSeek-V3（ベースモデルを含む）も**128,000トークン**のコンテキスト長をサポートしています。これは6710億の総パラメータ（クエリごとに370億がアクティブ）を有する強力なMoEモデルです。
* **DeepSeek-Coder-V2:** 2024年7月にリリースされたこのコード特化型MoEモデルは、**128,000トークン**という大きなコンテキストウィンドウを備えています。幅広いプログラミング言語（338種類）をサポートしています。
* **DeepSeek-V2:** 2024年5月に発表されたDeepSeek-V2は、**128,000トークン**のコンテキスト長を誇ります。このMoEモデルは、経済的なトレーニングと効率的な推論を目指しています。
* **DeepSeek-V2.5:** 2024年9月にリリースされたこのモデルは、汎用能力とコーディング能力を組み合わせており、**128,000トークン**のコンテキストウィンドウもサポートしています。

**重要な考慮事項：**

* **ネイティブコンテキスト長とAPI制限:** DeepSeekモデルの一部は最大163,840トークンのネイティブコンテキスト長を有していますが、DeepSeek APIは特定のモデルで利用可能なコンテキストウィンドウを制限する場合があります（例：「deepseek-chat」と「deepseek-reasoner」は現在、APIを通じて64Kのコンテキスト制限があります）。完全なコンテキストが必要な場合は、モデルをローカルで実行するか、より長いコンテキストを許可するAPIプロバイダーを使用する必要があるかもしれません。
* **パフォーマンスの低下:** 他の大規模言語モデルと同様に、モデルが非常に長いコンテキストウィンドウを宣伝していても、絶対的な最大長まで押し込まれた場合、パフォーマンス（精度、推論能力）が低下することがあります。例えば、DeepSeek R2は、R1で観測された128,000トークンの最大コンテキストウィンドウにおける15%のパフォーマンス低下に対処することが期待されています。

要約すると、DeepSeekは長いコンテキストLLM分野における強力なプレイヤーであり、2025年6月時点で複数のモデルが128Kトークンのコンテキストウィンドウを提供しており、大規模な入力と複雑なタスクの処理に適しています。