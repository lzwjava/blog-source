---
audio: false
generated: true
image: false
lang: de
layout: post
model: x-ai/grok-4-fast
title: Rechnerische Macht übertrumpft menschlichen Einfallsreichtum
translated: true
type: note
---

### Die bittere Lektion von Richard Sutton

Richard Sutton, ein bahnbrechender KI-Forscher, bekannt für seine Arbeit im Bereich Reinforcement Learning, schrieb 2019 einen kurzen Essay mit dem Titel "The Bitter Lesson". Es ist eine Reflexion über mehr als 70 Jahre KI-Geschichte, in der er argumentiert, dass die effektivsten Wege für KI-Fortschritt nicht diejenigen sind, die menschliche Intelligenz nachahmen oder spezialisiertes Wissen einbauen. Stattdessen ist die "bittere" Wahrheit, dass **allgemeine Methoden, die mit reiner Rechenleistung skalieren – Dinge wie Suchalgorithmen und maschinelles Lernen – auf lange Sicht konsequent kluge, menscheninspirierte Designs übertreffen**.

#### Kernaussage
Sutton beobachtet ein wiederkehrendes Muster: Frühe KI-Erfolge stammen oft davon, menschliches Expertenwissen (z.B. Regeln, Heuristiken oder domänenspezifisches Wissen) in Systeme einzubringen. Das fühlt sich zunächst intuitiv und effizient an, aber wenn Rechenleistung günstiger und reichlicher verfügbar wird, stoßen diese wissensbasierten Ansätze an ihre Grenzen. Sie werden spröde, schwer zu skalieren und werden von einfacheren "Meta-Methoden" überholt, die es Computern ermöglichen, Lösungen durch Trial-and-Error zu erarbeiten.

Der "bittere" Teil? Wir Menschen hassen diese Lektion, weil sie unsere Ingenieurskunst und Intuition an den Rand drängt. Wir würden lieber Systeme bauen, die "wie wir denken", aber die Beweise zeigen, dass das für große Fortschritte eine Sackgasse ist. Sutton fasst es zusammen: "Die bittere Lektion basiert auf der Beobachtung, dass die leistungsstärksten Methoden, die wir entwickelt haben... jene sind, die Rechenleistung nutzbar machen."

#### Historische Beispiele
Sutton zieht aus KI-Meilensteinen Beispiele heran:
- **Schach**: In den 1990ern dominierten menschliche Experten mit wissensbasierten Programmen, die Eröffnungen, Taktiken und Strategien kodierten. Aber Deep Blue (1997) besiegte Kasparov, indem es massive Suchbäume und Rechenleistung nutzte und viel von dieser "Weisheit" ignorierte.
- **Go**: Ähnliche Geschichte – AlphaGo (2016) lernte durch Selbstspiel und neuronale Netze, nicht durch das tiefgehende Studium von Profi-Spielen. Es skalierte mit Rechenleistung und besiegte intuitionsbasierte Rivalen.
- **Spracherkennung**: Handgefertigte linguistische Modelle herrschten vor, bis statistisches Lernen (das Daten und Rechenleistung nutzt) in den 2010ern übernahm und zu den heutigen Sprachassistenten führte.
- **Computer Vision**: Frühe Systeme verließen sich auf Kantenerkennung und Formregeln; heute verarbeitet Deep Learning Pixel mit GPUs.

In jedem Fall gewann der wissensbasierte Ansatz die kurzfristigen Schlachten, verlor aber den Krieg gegen die rechenhungrige Allgemeingültigkeit.

#### Warum es wichtig ist
Diese Lektion drängt die KI in Richtung "skalierbarer Überwachung" – dem Bau von Systemen, die aus riesigen Datenmengen lernen, ohne dass wir jede Erkenntnis eingeben müssen. Deshalb stammen die heutigen Durchbrüche (wie große Sprachmodelle) vom Training mit internetgroßen Datenmengen und nicht aus Regelbüchern. Aber es ist "bitter", weil es impliziert, dass wir noch mehr Rechenleistung (und Energie) benötigen werden, um weiter voranzukommen, und es betont weniger die Erstellung "eleganter" Lösungen.

Sutton schrieb dies als Warnung: Bekämpft diesen Trend nicht; nehmt ihn an, um schneller Fortschritte zu erzielen.

#### Referenzen
- [The Bitter Lesson (Original Essay)](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
- [Bitter Lesson (Wikipedia Summary)](https://en.wikipedia.org/wiki/Bitter_lesson)
- [ELI5 Explanation on Reddit](https://www.reddit.com/r/explainlikeimfive/comments/1nug43e/eli5_what_is_richard_suttons_bitter_lesson_in_ai/)