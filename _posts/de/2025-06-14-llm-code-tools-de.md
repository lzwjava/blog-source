---
audio: false
generated: true
image: false
lang: de
layout: post
model: openai/gpt-5
title: Gro√üsprachmodelle, Codeverst√§ndnis und Werkzeugnutzung
translated: true
type: note
---

Gute Frage! Du fragst im Grunde, wie etwas wie **Anthropic's Claude (und √§hnliche LLMs)** intern folgendes handhabt:

1.  **Code-Ausf√ºhrung oder codebezogene Schlussfolgerungen**
2.  **JSON-Schema-Pr√ºfung/Validierung strukturierter Ausgaben**
3.  **Tool-Nutzung und Routing zwischen Tools**

Lass mich das im Detail aufschl√ºsseln.

---

### 1. Code-Schlussfolgerungen & Ausf√ºhrung
Claude (und andere fortschrittliche LLMs) f√ºhren Code nicht direkt im Modell aus ‚Äì sie **simulieren Code-Schlussfolgerungen**, indem sie Token f√ºr Code oder logische Schritte vorhersagen.

- Im **normalen Textmodus** kann Claude Code "schreiben", indem es ein Muster fortsetzt, f√ºhrt ihn aber nicht intern aus.
- Wenn es mit einem **Backend (wie Anthropic's Workbench oder OpenAI's Code Interpreter)** verwendet wird, kann das System diese Code-Schnipsel abfangen und sie dann tats√§chlich in einer sandboxed Umgebung *ausf√ºhren*.
- Die Ergebnisse k√∂nnen dann dem Modell als Kontext zur√ºckgegeben werden, sodass es Schlussfolgerungen wie folgt verketten kann:
  ‚Üí Code generieren ‚Üí Extern ausf√ºhren ‚Üí Ausgabe erhalten ‚Üí N√§chsten Schritt entscheiden.

Die Intelligenz liegt also in der Schleife: LLM generiert ‚Üí externer Runner f√ºhrt aus ‚Üí LLM interpretiert Ergebnisse.

---

### 2. JSON-Schema-Pr√ºfung
Viele APIs (Claude, OpenAI, etc.) unterst√ºtzen nun den **strukturierten Ausgabemodus**, bei dem man ein JSON-Schema anh√§ngen kann. So funktioniert das intern:

- Man √ºbergibt eine **JSON-Schema-Definition** mit der Anfrage.
- Das LLM wird angeleitet, **ausschlie√ülich g√ºltiges JSON** auszugeben, das konform ist.
- Wenn es versucht, ung√ºltiges JSON auszugeben, erkennt das System dies (mit einem Validator wie [jsonschema](https://pypi.org/project/jsonschema/)) und fordert das Modell auf, die Ausgabe zu "reparieren".
- Hinter den Kulissen ist dies oft ein **Constrained Decoding** oder **Grammar-Based Decoding** Mechanismus ‚Äì im Grunde wird die Token-Generierung so eingeschr√§nkt, dass nur `"g√ºltige n√§chste Token im Schema"` erlaubt sind.

Dies stellt sicher, dass die Ausgabe syntaktisch und semantisch korrektes JSON ist, was f√ºr die Automatisierung der Tool-Nutzung entscheidend ist.

---

### 3. Tool-Nutzung & Routing
Die Tool-Nutzung wird √ºber eine Art **Router-Ebene** zwischen dem LLM und einer Tool-Ausf√ºhrungsumgebung abgewickelt:

- **Routing-Logik**: Das Modell wird aufgefordert zu *entscheiden, welches Tool aufgerufen werden soll* (oder direkt zu antworten).
- **Schema-Durchsetzung**: Jedes Tool hat ein Eingabeschema. Das LLM muss g√ºltiges JSON f√ºr dieses Tool erzeugen.
- **Ausf√ºhrungs-Adapter**: Die Orchestrierungsebene (au√üerhalb des Modells) nimmt das JSON des LLM, validiert es gegen das Schema, f√ºhrt das Tool aus und speist die Ergebnisse dann als Kontext zur√ºck.
- **Verkettete Schlussfolgerungen (ReAct-Stil)**: Das LLM "denkt laut" (k√∂nnte dem Benutzer verborgene Denkschritte produzieren), gibt dann bei Bedarf Tool-Aufrufe aus und gelangt schrittweise zu einer endg√ºltigen Antwort.

Zum Beispiel:
```json
{
  "tool": "web_search",
  "query": "neueste Forschung zu Quantenfehlerkorrektur"
}
```
‚Üí Der Router sieht `"tool": "web_search"`, validiert das Schema, f√ºhrt die Websuche aus, f√ºgt die Ergebnisse zur√ºck in den Kontext des Modells ein, und das Modell setzt seine Schlussfolgerungen fort.

Anthropic's Claude, OpenAI's GPTs, LangChain und andere unterst√ºtzen alle dieses Muster.

---

### üîë Zusammenfassung
- **Claude Code**: F√ºhrt Code nicht intern aus; generiert Code ‚Üí Sandbox f√ºhrt aus ‚Üí Ergebnisse werden zur√ºckgegeben ‚Üí Iteratives Schlie√üen.
- **JSON-Schema-Pr√ºfung**: Verwendet Constrained Decoding / Schema-Validierung, um eine g√ºltige strukturierte Ausgabe zu gew√§hrleisten.
- **Tool-Use-Routing**: LLM w√§hlt Tool-Aufrufe in JSON aus, die Orchestrierungs-Engine validiert & f√ºhrt sie aus, speist Ergebnisse in einer Schleife zur√ºck.

---

üëâ M√∂chtest du, dass ich **ein Diagramm zeichne**, das den Ablauf (LLM ‚Üî Tool-Router ‚Üî Schema-Validator ‚Üî Ausf√ºhrungs-Engine) zeigt, damit es visuell klarer wird?