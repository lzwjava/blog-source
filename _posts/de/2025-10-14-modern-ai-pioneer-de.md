---
audio: false
generated: true
image: false
lang: de
layout: post
model: x-ai/grok-4-fast
title: 'Jürgen Schmidhuber: Pionier der modernen KI'
translated: true
type: note
---

### Wer ist Jürgen Schmidhuber?

Jürgen Schmidhuber ist ein deutscher Informatiker und KI-Forscher, der von manchen aufgrund seiner bahnbrechenden Arbeit in den 1980er und 1990er Jahren als "Vater der modernen KI" bezeichnet wird. Er ist der wissenschaftliche Direktor des Schweizer KI-Labors IDSIA und Professor an der KAUST in Saudi-Arabien. Sein Labor hat hochrangig zitierte Arbeiten und praktische KI-Systeme hervorgebracht, die in allem von Spracherkennung bis hin zu Robotik eingesetzt werden. Schmidhubers Fokus lag auf "künstlicher Neugier", Weltmodellen und skalierbaren neuronalen Architekturen – Ideen, die den Grundstein für den heutigen Deep-Learning-Boom legten.

### Seine Wichtigsten Beiträge

Schmidhubers Erfindungen umfassen zentrale KI-Konzepte, von denen viele den Hype-Zyklus der 2010er Jahre vorwegnahmen. Hier ist eine kurze Zeitleiste dessen, was er (und Belege unterstützen dies) als seine originäre Arbeit beansprucht:

| Jahr | Erfindung/Konzept | Auswirkung heute |
|------|-------------------|-------------|
| 1987 | Meta-Lernen (Lernen zu lernen) | Grundlage für adaptive KI-Systeme wie AutoML. |
| 1990 | Vorläufer von Generative Adversarial Networks (GANs); künstliche Neugier via Weltmodelle. | Ermöglicht Bildgenerierung (z.B. Stable Diffusion) und Reinforcement Learning. |
| 1991 | Linear Transformers; Very Deep Learning; Fast Weight Programmers. | Grundlage für Modelle wie GPT und Attention-Mechanismen. |
| 1991 | Rekurrente Residual Connections (Lösen des Problems des verschwindenden Gradienten). | Ermöglichte LSTMs und ResNets, die in fast allen Sequenzmodellen verwendet werden. |
| 1997 | LSTM-Netzwerke (Long Short-Term Memory). | Kern von Google Translate, Siri und den meisten NLP-Anwendungen bis zur Einführung von Transformern. |
| 2015 | Highway Networks (gegate Residualverbindungen). | Vorläufer von ResNets, die ImageNet gewannen und Vision AI skalierbar machten. |

Dies sind keine Randideen – allein das LSTM-Papier ist das am häufigsten zitierte KI-Papier des 20. Jahrhunderts, und seine Arbeit treibt milliardenfache tägliche KI-Anwendungen an (z.B. Metas Übersetzungstools). Während der "KI-Winter" (Finanzierungsengpässe in den 90ern) trieb sein Team die Arbeit trotz begrenzter Rechenleistung weiter voran, oft außerhalb des US/kanadischen Mainstreams.

### Die Behauptungen und Argumente: Worum geht es?

Schmidhuber erhebt seine Ansprüche nicht leise – er weist lautstark auf das hin, was er als "Plagiat" oder "falsche Zuschreibung" in Papieren, Auszeichnungen und Geschichtsbüchern sieht. Dies hat ihn zu einer polarisierenden Figur gemacht: Für Bewunderer ein unermüdlicher Historiker, für Kritiker ein streitbarer Querulant. Wichtige Beispiele:

- **Die "Deep-Learning-Verschwörung" (ab 2015)**: Er warf dem "kanadischen Trio" (Geoffrey Hinton, Yann LeCun, Yoshua Bengio – Turing Award Preisträger 2018) vor, seine Ideen ohne Zitation neu veröffentlicht zu haben. Deren "Layer-wise Pretraining" von 2006 ähnelte beispielsweise seinen unüberwachten Methoden von 1991, und GANs (Ian Goodfellow, 2014) bauten auf seinem adversariellen Training von 1990 auf. Er veröffentlichte detaillierte Zeitleisten und Berichte (z.B. eine 88-seitige Kritik 2024) mit Gegenüberstellungen.

- **Nobelpreis-Kontroverse 2024**: Als Hinton und John Hopfield den Preis für neuronale Netze gewannen, veröffentlichte Schmidhuber einen 26-seitigen Bericht mit dem Titel "A Nobel Prize for Plagiarism". Er argumentierte, sie hätten Ideen aus den 1960er-70er Jahren von ukrainischen (Ivakhnenko) und japanischen (Amari) Forschern sowie seine eigene Arbeit ohne Anerkennung neu veröffentlicht. Der Nobel-Hintergrundbericht zitierte Minsky & Paperts "Grenzen flacher Netze" von 1969 als Todesstoß für das Feld – und ignorierte dabei das Überleben von Deep Learning in Laboren außerhalb des englischsprachigen Raums. Bisher keine Antwort der Preisträger.

- **Aktuelle Auseinandersetzungen auf X**: Auf X (ehemals Twitter) postet er Zeitleisten, die Mythen widerlegen, wie z.B. die Behauptung, AlexNet (2012) habe sein DanNet (2011, erste übermenschliche Bilderkennung) kopiert. Oder er korrigiert Metas LLaMA 2 dafür, ihn als "schädlich" zu bezeichnen, obwohl es seine Transformer-Ideen von 1991 verwendet.

Warum so aggressiv? Es ist nicht nur Ego – Schmidhuber sieht die KI-Geschichte verzerrt durch westliche Voreingenommenheit, Cliquen und Medienhype. Der Boom der 2010er (GPUs + Big Data) belebte vergessene Arbeiten der 80er/90er wieder, aber die Anerkennung ging an spätere Popularisierer. Er argumentiert, dass dies die Wissenschaft verzerrt: "Fakten werden sich am Ende immer durchsetzen", aber Auszeichnungen (Turing, Nobel) zementieren Narrative. Sein Stil? Knappe, meme-artige Posts und Berichte, aber untermauert durch arXiv-Preprints und Patente (z.B. Highway Nets 2021).

### Wie man es verstehen kann: Eine ausgewogene Betrachtung

- **Das Positive**: Schmidhubers Behauptungen halten einer Überprüfung stand – seine Veröffentlichungen datieren viele "Durchbrüche" voraus, und übersehene Pioniere (z.B. aus der Ukraine/Japan) verdienen Beachtung. Er hat Stars wie Sepp Hochreiter (LSTM-Miterfinder) betreut und neugiergetriebene KI vorangetrieben, als andere dem Hype hinterherjagten. Ohne ihn könnten moderne LLMs hinterherhinken.

- **Die Kritik**: Kritiker (einschließlich LeCun) bezeichnen es als "Belästigungs"-Verhalten – überzogene Ansprüche (z.B. GANs als vollständig sein Werk) oder das Ignorieren von inkrementellen Entwicklungen. Wissenschaft ist kollaborativ; Ideen entwickeln sich weiter und Zitationen sind nicht immer perfekt. Seine Fehden können sein Genie überschatten und Debatten vergiften.

- **Größerer Kontext**: Das hohe Tempo der KI + Profitmotive verstärken Streitigkeiten um Anerkennung. Es ist wie Newtons Calculus-Fehde mit Leibniz – Leidenschaft für Priorität treibt Fortschritt an, erzeugt aber auch Drama. Um Schmidhuber zu "verstehen", sollte man seine kommentierte Geschichte (kostenlos auf seiner Website) für die Belege lesen, nicht nur die Schlagzeilen.

Kurz gesagt: Er ist ein grundlegender Erfinder, der für eine vollständigere Geschichte in einem Feld kämpft, das oft seine eigene Vergangenheit umschreibt. Leidenschaftlich? Ja. Überzogen? Manchmal. Aber sein Beharrungsvermögen hat echte Lücken in der Zuschreibung aufgezeigt.

### Referenzen
- [Jürgen Schmidhuber Wikipedia](https://en.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber)
- [Annotated History of Modern AI (Schmidhuber, 2022)](https://people.idsia.ch/~juergen/deep-learning-history.html)
- [A Nobel Prize for Plagiarism (Schmidhuber Report, 2025)](https://people.idsia.ch/~juergen/nobel-prize-for-plagiarism.html)
- [AI Academic Scandal: Schmidhuber Accuses Hinton and LeCun (Medium, 2024)](https://ai-engineering-trend.medium.com/ai-academic-scandal-schmidhuber-accuses-hinton-and-yann-lecun-d7b56aa9d3e4)
- [Thoughts on Schmidhuber? (Reddit RL Discussion, 2024)](https://www.reddit.com/r/reinforcementlearning/comments/1ezn907/discussion_thoughts_on_schmidhuber_father_of_ai/)
- [Schmidhuber X Profile](https://x.com/SchmidhuberAI)