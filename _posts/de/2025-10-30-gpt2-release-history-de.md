---
audio: false
generated: true
image: false
lang: de
layout: post
model: x-ai/grok-4-fast
title: Freigabe von GPT-2 und Open-Source-Chronik
translated: true
type: note
---

### GPT-2-Paper
Das GPT-2-Paper mit dem Titel "Language Models are Unsupervised Multitask Learners" wurde am 14. Februar 2019 veröffentlicht, zusammen mit dem ersten Blogbeitrag von OpenAI, der das Modell ankündigte.

### Open-Source-Veröffentlichung
GPT-2 hatte eine gestaffelte Veröffentlichung aufgrund von Bedenken hinsichtlich möglichen Missbrauchs:
- **Kleines Modell (124M Parameter)**: Veröffentlicht am 14. Februar 2019.
- **Mittleres Modell (355M Parameter)**: Veröffentlicht im Juli 2019.
- **Großes Modell (774M Parameter)**: Veröffentlicht am 20. August 2019.
- **Vollständiges Modell (1.5B Parameter) und Open-Source-Code**: Veröffentlicht am 5. November 2019, wodurch die vollständigen Gewichte und die Implementierung öffentlich auf GitHub verfügbar gemacht wurden.

Referenzen:  
[Better language models and their implications](https://openai.com/index/better-language-models/)  
[GPT-2: 1.5B release](https://openai.com/index/gpt-2-1-5b-release/)