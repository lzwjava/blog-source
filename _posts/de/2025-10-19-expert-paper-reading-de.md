---
audio: false
generated: true
image: false
lang: de
layout: post
model: x-ai/grok-4-fast
title: Übermenschliche Lesefertigkeiten von Experten für wissenschaftliche Arbeiten
translated: true
type: note
---

Absolut, Leute wie Richard Sutton (der RL-Pionier, den Sie mit "shutton" meinten), Yann LeCun (Deep-Learning-Godfather, wobei die LSTM-Urheberschaft eher bei Schmidhuber und Hochreiter liegt) und Jürgen Schmidhuber (der "jurlgen suff" LSTM-Miterfinder) befinden sich auf dem absoluten Gipfel der ML/DL-Expertise. Ihre Lesefähigkeit für technische Papiere ist nicht nur hoch – sie ist im Vergleich zu den meisten von uns Sterblichen übermenschlich. Sie "lesen" Papiere nicht nur; sie sezieren sie mit Warp-Geschwindigkeit, um Kerninnovationen zu extrahieren, Fehler aufzuspüren und ihre eigenen Ideen anzuregen.

Hier ist der Grund, warum das ein Volltreffer ist:

-   **Jahrelanges Eintauchen**: Diese Leute haben Jahrzehnte in den Schützengräben verbracht – Sutton prägt RL seit den 80ern, LeCun war in den 90ern ein Pionier von Conv Nets, und Schmidhuber hat 400+ Papiere zu allem von LSTMs bis zu Transformers-Vorläufern veröffentlicht. Um vorne mitzuhalten, haben sie sich trainiert, dichte Mathematik, neuartige Architekturen und empirische Ergebnisse zu verarbeiten, als wäre es ein Thriller. LeCun hat sogar getwittert, wie Profis Jahre damit verbringen, "Papiere zu lesen, Forschung zu betreiben und zu publizieren", um diese Intuition aufzubauen – es ist keine Option, es ist Überlebensnotwendigkeit.

-   **Meisterhaftes Überfliegen**: Top-Forscher wie sie befolgen eine bewährte Strategie (von Andrew Ng in Vorträgen bekräftigt): Erster Durchgang ist Titel/Abstract/Figuren/Schlussfolgerungen für das große Bild (5-10 Min.). Überspringen Sie zunächst die Beweise/Mathematik, es sei denn, es ist bahnbrechend. Der zweite Durchgang taucht in Methoden/Ergebnisse zur Validierung ein. Der dritte? Gnadenlose Kritik. Dies ermöglicht es ihnen, "Kernideen" aus 10-20 Papieren pro Tag zu erfassen, ohne auszubrennen, und sich auf Neuartigkeit statt auf Kleinigkeiten zu konzentrieren.

-   **Prolifique Leistung als Beweis**: Schmidhumbers wahnsinnige Publikationsrate (333+ peer-reviewed) bedeutet, dass er nicht nur liest – er synthetisiert Hunderte pro Jahr. Suttons "Bitter Lesson"-Essay spielt auf 70 Jahre KI-Geschichte an und zieht Fäden aus unzähligen Werken. LeCun weist routinemäßig überhypte Behauptungen auf X nach schnellen Durchsichten von arXiv-Dumps zurück.

Kurz gesagt, ja, sie lesen schnell *und* tief, weil das Feld ein Feuerwehrschlauch ist – verpassen Sie eine Schlüsselidee, und Sie sind von gestern. Wenn Sie darauf abzielen, sich zu verbessern, beginnen Sie mit dieser Multi-Pass-Methode; sie bringt Sie zu 80 % ans Ziel.

[How to Read Research Papers (Andrew Ng)](https://forums.fast.ai/t/how-to-read-research-papers-andrew-ng/66892)
[Yann LeCun on X about reading/publishing](https://x.com/ylecun/status/1845792947389755474)
[The Bitter Lesson by Richard Sutton](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)