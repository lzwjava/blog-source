---
audio: false
generated: true
image: false
lang: de
layout: post
title: Aufstieg und Fall von 01.AI
translated: true
type: note
---

### Hintergrund zu 01.AI und dem Yi-Modell

Kai-Fu Lee, ein prominenter KI-Investor und ehemaliger Manager bei Google und Microsoft, gründete 01.AI im März 2023 mit dem ehrgeizigen Ziel, ein "heimisches" großes Sprachmodell (LLM) zu entwickeln, das mit globalen Marktführern wie der GPT-Serie von OpenAI konkurrieren und speziell auf den chinesischen Markt zugeschnitten sein sollte. Das Flaggschiff des Unternehmens, die Yi-Modellreihe (z.B. Yi-34B), wurde im November 2023 als Open-Source-LLM veröffentlicht. Sie erzeugte zunächst erheblichen Hype, indem sie das Open-Source-LLM-Ranking von Hugging Face anführte und in Benchmarks für Aufgaben wie logisches Denken und Code-Generierung Modelle wie Metas LLaMA 2 übertraf. Dies katapultierte 01.AI innerhalb von Monaten zum Einhorn-Status mit einer Bewertung von 1 Milliarde US-Dollar, unterstützt von Investoren wie Alibaba und Tencent.

Bis 2025 haben 01.AI und Yi jedoch die anfänglichen Erwartungen, eine dominante Kraft in der globalen KI-Landschaft zu werden, nicht erfüllt. Obwohl das Unternehmen weiterhin operativ tätig ist und die Gewinnschwelle fast erreicht (mit prognostizierten Umsätzen von etwa 13,8 Millionen US-Dollar im Jahr 2024), hat es eine große Restrukturierung durchlaufen, einschließlich der Ausgliederung wichtiger Teams und der Abkehr von der Entwicklung von Fundamentalmodellen. Im Folgenden werde ich die Hauptgründe für dieses Defizit auf der Grundlage verfügbarer Analysen darlegen.

### Hauptgründe für die Unterlegenheit

1.  **Kontroversen und Glaubwürdigkeitsprobleme bei der Entwicklung von Yi**
    Der anfängliche Erfolg von Yi-34B wurde durch Enthüllungen getrübt, dass es nicht vollständig von Grund auf trainiert, sondern auf der Architektur von Metas LLaMA aufgebaut wurde. Im November 2023 räumte 01.AI einen "Versehen" bei den Namenskonventionen ein und aktualisierte die Tensornamen des Modells, um seine LLaMA-Basis anzuerkennen. Kritiker argumentierten, dass dies Yi eher zu einem Fine-Tuning als zu einer originären Innovation mache, was zu Vorwürfen von Übertreibung und möglicher Datenkontamination in Benchmarks führte. Dies untergrub das Vertrauen in der Open-Source-Community, wo Transparenz entscheidend ist, und Yis Platzierungen in den Ranglisten sanken nach genauerer Prüfung. Einige Beobachter merkten an, dass Yi zwar bei zweisprachigen Aufgaben in Englisch und Chinesisch gut abschnitt, sein Vorsprung jedoch nur von kurzer Dauer war, da Konkurrenten stärkere Modelle veröffentlichten.

2.  **Ressourcenbeschränkungen und geopolitische Herausforderungen**
    Das Training großer Modelle wie Yi erfordert massive Rechenleistung, aber US-Exportbeschränkungen für fortschrittliche GPUs (z.B. Nvidia-Chips) haben chinesische KI-Firmen erheblich behindert. 01.AI "setzte alles auf eine Karte", indem es sich vor den verschärften Embargos Ende 2023 verschuldete, um GPUs zu horten, und berichteten zufolge etwa 2.000 GPUs für das Training von Yi zu einem Kostenpunkt von nur 3 Millionen US-Dollar einsetzte – weit weniger als die geschätzten 80-100 Millionen US-Dollar von OpenAI für GPT-4. Während dies Effizienz demonstrierte, schränkte es die Skalierbarkeit ein. Bis Ende 2024 hatte das Unternehmen seine Pre-Training-Algorithmus- und Infrastrukturteams aufgelöst, ein Zeichen dafür, dass es das rechenintensive Rennen um immer größere Modelle angesichts anhaltender Chipknappheit nicht aufrechterhalten konnte.

3.  **Intensiver Wettbewerb in Chinas KI-Ökosystem**
    Chinas KI-Sektor ist hyperkompetitiv, mit über 100 LLM-Startups, die um die Vorherrschaft konkurrieren. Modelle von Rivalen wie DeepSeek (z.B. DeepSeek-R1) und Alibabas Qwen haben Yi in Benchmarks wie LMSYS und in realen Anwendungen seither übertroffen, oft mit besserer Effizienz und weniger Ressourcen. Global gesehen schmälerten Open-Source-Fortschritte von Meta (LLaMA 3) und Mistral die relative Stellung von Yi weiter. Kai-Fu Lee selbst bemerkte 2024, dass die besten chinesischen Modelle, einschließlich Yi, US-Spitzenreitern wie OpenAI nur etwa 5 Monate hinterherhinkten, aber diese Lücke vergrößerte sich, als westliche Firmen mit besserem Zugang zu Daten und Hardware beschleunigten.

4.  **Strategische Neuausrichtung auf Anwendungen statt Fundamentalmodelle**
    Bis Anfang 2025 verlagerte 01.AI den Fokus vom Bau massiver Fundamentalmodelle wie Yi hin zu kleineren, branchenspezifischen LLMs und KI-Anwendungen (z.B. Produktivitätstools und Unternehmenslösungen). Kai-Fu Lee erklärte dies als "klügeren Weg" zur Profitabilität und betonte, dass die Ära der "Skalierungsgesetze" (größere Modelle = bessere Leistung) zielgerichteten, kosteneffektiven Apps weicht. Diese Neuausrichtung beinhaltete eine Restrukturierung im Dezember 2024, die Ausgliederung von Segmenten wie "Digital Humans" und die Dementierung von Gerüchten über den Verkauf von Kernteams an Alibaba Cloud. Obwohl pragmatisch – um in einem gesättigten Markt schneller Geld zu verdienen – spiegelt sie ein Eingeständnis wider, dass der direkte Wettbewerb in der fundamentalen KI nicht nachhaltig war und die ursprüngliche Vision, "China seinen ChatGPT-Moment zu bringen", nicht erreicht wurde.

5.  **Breiterer Markt- und Wirtschaftsdruck**
    Der KI-Hype-Zyklus hat sich global abgekühlt, da Investoren angesichts hoher Trainingskosten und regulatorischer Prüfungen schnellere Wege zur Umsatzgenerierung fordern. 01.AI sammelte 300 Millionen US-Dollar ein, sah sich aber unter Druck gesetzt, Renditen zu liefern, was zu einem Fokus auf Preisen von RMB 0,99 (0,14 US-Dollar) pro Million Tokens für Modelle wie Yi-Lightning führte. Zudem war die Akzeptanz von Open-Source-Modellen in Unternehmen uneinheitlich, wobei viele etablierte Anbieter bevorzugten. Lee betonte in Interviews, dass KI im Jahr 2025 Anwendungen vor Experimentieren priorisieren würde, aber dies geschah auf Kosten des ehrgeizigen Umfangs von Yi.

### Aktueller Status und Ausblick

Mitte 2025 ist 01.AI stabil, aber transformiert: Es wird prognostiziert, dass das Unternehmen bald profitabel sein wird, mit etwa 90 Mitarbeitern und einer weiterhin bestehenden Bewertung von 1 Milliarde US-Dollar. Yi-Modelle sind weiterhin auf Plattformen wie Hugging Face verfügbar, aber Updates haben sich verlangsamt, und das Unternehmen betont nun KI-2.0-Plattformen für wirtschaftlichen Wert in China. Obwohl kein Misserfolg – Yi half, die KI-Kluft zwischen den USA und China zu überbrücken und inspirierte Open-Source-Bemühungen – erreichte es nicht die erwartete revolutionäre Wirkung, hauptsächlich aufgrund der oben genannten Faktoren. Für die Zukunft hängt der Erfolg von der Umsetzung der anwendungsorientierten Strategie angesichts anhaltender Technologie-Spannungen zwischen den USA und China ab.

[Kr Asia: Kai-Fu Lee sets the record straight on 01.AI's pivot](https://kr-asia.com/kai-fu-lee-sets-the-record-straight-on-01-ais-pivot)  
[Tech in Asia: Kai-Fu Lee's 01.AI restructures and spins off key segments](https://www.techinasia.com/news/kai-fu-lees-01-ai-restructures-and-spins-off-key-segments)  
[Turing Post: How Kai-Fu Lee Shapes the AI Narrative in Both the U.S. and China](https://www.turingpost.com/p/01ai)  
[Yicai Global: Kai-Fu Lee Denies Report His 01.AI Startup Plans to Sell Pre-Training Team](https://www.yicaiglobal.com/news/01ai-isnt-selling-pre-training-team-to-alibabas-cloud-computing-arm-founder-says)  
[WIRED: Chinese Startup 01.AI Is Winning the Open Source AI Race](https://www.wired.com/story/chinese-startup-01-ai-is-winning-the-open-source-ai-race/)  
[TechCrunch: Valued at $1B, Kai-Fu Lee's LLM startup unveils open source model](https://techcrunch.com/2023/11/05/valued-at-1b-kai-fu-lees-llm-startup-unveils-open-source-model/)  
[SCMP: Tech unicorn 01.AI admits 'oversight' in naming AI model built on Meta's LLaMA](https://www.scmp.com/tech/tech-trends/article/3241680/chinese-tech-unicorn-01ai-admits-oversight-changing-name-ai-model-built-meta-platforms-llama-system)  
[Wikipedia: 01.AI](https://en.wikipedia.org/wiki/01.AI)  
[PitchBook: 01.AI 2025 Company Profile](https://pitchbook.com/profiles/company/532966-69)