---
audio: false
generated: true
lang: de
layout: post
title: Mistral AIs Modell-Kontextlängen von 2025
translated: true
type: note
---

Stand Juni 2025 hat Mistral AI mehrere Modelle mit unterschiedlichen Kontextlängen veröffentlicht. Hier ist eine Zusammenfassung einiger wichtiger Modelle und ihrer Kontextfenster:

*   **Magistral Small (magistral-small-2506):** Dieses Open-Weight-Modell hat ein Kontextfenster von 128k, die Leistung kann jedoch über 40k hinaus nachlassen, daher beträgt die empfohlene Maximallänge 40k Tokens.
*   **Magistral Medium (magistral-medium-2506):** Dieses nur über die API verfügbare Reasoning-Modell hat ebenfalls ein empfohlenes Kontextfenster von 40k.
*   **Mistral Small 3.1 (mistral-small-2503) / Mistral Small 3.2 (mistral-small-2506):** Diese Modelle verfügen über ein Kontextfenster von bis zu 128.000 Tokens.
*   **Codestral (codestral-2501):** Dieses auf Code spezialisierte Modell bietet ein bedeutendes Kontextfenster von 256.000 Tokens.
*   **Mistral Large 2 (mistral-large-2407 / mistral-large-2411):** Mistrals Flaggschiff-Modell für große Aufgaben hat ein 128k Kontextfenster.
*   **Mistral NeMo (open-mistral-nemo-2407):** Dieses 12B-Modell, entwickelt in Zusammenarbeit mit NVIDIA, bietet ein großes Kontextfenster von bis zu 128.000 Tokens.
*   **Mistral Medium 3 (mistral-medium-2505):** Dieses multimodale Modell unterstützt ebenfalls ein 128k Kontextfenster.

Es ist wichtig zu beachten, dass einige Modelle zwar sehr große Kontextfenster (z.B. 128k) angeben, die praktische Leistung jedoch für einen etwas kleineren Bereich (z.B. 40k für die Magistral-Modelle) optimiert sein könnte.