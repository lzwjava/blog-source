---
audio: false
generated: true
lang: de
layout: post
title: Stable Diffusion Proxy Problem
translated: true
type: note
---

Basierend auf dem Fehler und Ihrer Umgebung finden Sie hier die L√∂sung f√ºr das Problem "Unknown scheme for proxy URL":

### L√∂sung:
Der Fehler tritt auf, weil **`httpx` standardm√§√üig keine `socks://` Proxys unterst√ºtzt**. Sie haben zwei M√∂glichkeiten:

#### Option 1: SOCKS-Proxy-Referenz entfernen
1. √úberpr√ºfen Sie Ihre Umgebungsvariablen auf verirrte Proxy-Einstellungen:
   ```bash
   env | grep -i proxy
   ```
   Suchen Sie nach `socks://`-Referenzen (insbesondere `ALL_PROXY` oder `http_proxy`).

2. Setzen Sie die problematische Variable zur√ºck (ersetzen Sie `VAR_NAME` mit dem tats√§chlichen Namen, den Sie oben gefunden haben):
   ```bash
   unset VAR_NAME  # z.B., unset ALL_PROXY
   ```

#### Option 2: SOCKS-Unterst√ºtzung zu `httpx` hinzuf√ºgen
1. Aktivieren Sie Ihre Python-Virtual-Umgebung:
   ```bash
   source /home/lzw/Projects/stable-diffusion-webui/venv/bin/activate
   ```

2. Installieren Sie die erforderlichen Abh√§ngigkeiten:
   ```bash
   pip install -U "httpx[socks]"
   ```

3. Deaktivieren Sie die Umgebung:
   ```bash
   deactivate
   ```

### Warum das passiert:
- Ihre Haupt-Proxys (`HTTP_PROXY/HTTPS_PROXY`) verwenden `http://` (unterst√ºtzt), aber etwas (wahrscheinlich eine andere App/ein anderes Skript) setzt einen `socks://` Proxy, den `httpx` ohne zus√§tzliche Pakete nicht verarbeiten kann.
- Der Stack-Trace zeigt, dass Gradio/`httpx` versucht, `socks://127.0.0.1:7891` zu verwenden, der nicht in Ihrer `checkproxy`-Ausgabe enthalten ist.

### √úberpr√ºfung:
F√ºhren Sie nach der Fehlerbehebung aus:
```bash
./webui.sh
```
Der SOCKS-Proxy-Fehler sollte verschwinden.

> üí° **Hinweis**: Wenn Sie keinen SOCKS-Proxy absichtlich eingerichtet haben, untersuchen Sie Anwendungen, die Proxys automatisch konfigurieren k√∂nnten (z.B. VPNs, Netzwerk-Manager oder Shell-Konfigurationsdateien wie `~/.bashrc`).

---

Der Fehler `Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check` zeigt an, dass PyTorch, das von Stable Diffusion WebUI verwendet wird, keine kompatible GPU erkennen oder darauf zugreifen kann. Dies liegt wahrscheinlich an fehlenden CUDA-Bibliotheken, einer inkompatiblen GPU, Treiberproblemen oder einem Konfigurationsproblem. Im Folgenden finden Sie Schritte zur Behebung dieses Problems, angepasst an Ihre Umgebung (glibc 2.35, Python 3.10.12, GCC 11.4.0, wahrscheinlich Ubuntu 22.04 basierend auf der glibc-Version).

### Schritte zur Problembehebung

#### 1. **GPU- und CUDA-Kompatibilit√§t √ºberpr√ºfen**
   - **√úberpr√ºfen Sie, ob Sie eine NVIDIA-GPU haben**:
     F√ºhren Sie aus:
     ```bash
     lspci | grep -i nvidia
     ```
     Dies listet NVIDIA-Hardware auf. Wenn keine Ausgabe erscheint, hat Ihr System m√∂glicherweise keine NVIDIA-GPU, und PyTorch ben√∂tigt eine NVIDIA-GPU f√ºr die CUDA-Unterst√ºtzung.
   - **√úberpr√ºfen Sie die NVIDIA-Treiberinstallation**:
     F√ºhren Sie aus:
     ```bash
     nvidia-smi
     ```
     Wenn installiert, wird eine Tabelle mit GPU-Details angezeigt (z.B. Treiberversion, CUDA-Version). Wenn nicht, installieren Sie den NVIDIA-Treiber:
     ```bash
     sudo apt-get update
     sudo apt-get install nvidia-driver-<version> nvidia-utils-<version> -y
     ```
     Ersetzen Sie `<version>` durch den neuesten stabilen Treiber (z.B. `535` oder `550`). Finden Sie die passende Treiberversion mit:
     ```bash
     ubuntu-drivers devices
     sudo ubuntu-drivers autoinstall
     ```
   - **CUDA-Version √ºberpr√ºfen**:
     PyTorch ben√∂tigt CUDA-Bibliotheken. √úberpr√ºfen Sie die installierte CUDA-Version:
     ```bash
     nvcc --version
     ```
     Wenn nicht installiert, installieren Sie das CUDA Toolkit:
     ```bash
     sudo apt-get install nvidia-cuda-toolkit -y
     ```
     Alternativ laden Sie das neueste CUDA Toolkit von der NVIDIA-Website herunter (z.B. CUDA 11.8 oder 12.1) und folgen Sie deren Installationsanleitung.

#### 2. **PyTorch-Installation √ºberpr√ºfen**
   Der Fehler deutet darauf hin, dass PyTorch installiert ist, aber die GPU nicht verwenden kann. Stellen Sie sicher, dass Sie die korrekte PyTorch-Version mit CUDA-Unterst√ºtzung haben.
   - **PyTorch-Installation √ºberpr√ºfen**:
     F√ºhren Sie aus:
     ```bash
     python3 -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"
     ```
     Die erwartete Ausgabe sollte eine PyTorch-Version (z.B. `2.0.1`) und `True` f√ºr `torch.cuda.is_available()` enthalten. Wenn `False` ausgegeben wird, erkennt PyTorch die GPU nicht.
   - **PyTorch mit CUDA-Unterst√ºtzung neu installieren**:
     F√ºr Python 3.10 und CUDA (z.B. 11.8) installieren Sie PyTorch in Ihrer Stable-Diffusion-Umgebung:
     ```bash
     cd /home/lzw/Projects/stable-diffusion-webui
     source venv/bin/activate
     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
     ```
     Ersetzen Sie `cu118` durch Ihre CUDA-Version (z.B. `cu121` f√ºr CUDA 12.1). √úberpr√ºfen Sie die unterst√ºtzten Versionen auf der offiziellen PyTorch-Website.
   - **Nach der Neuinstallation √ºberpr√ºfen**:
     F√ºhren Sie die √úberpr√ºfung erneut aus:
     ```bash
     python3 -c "import torch; print(torch.cuda.is_available()); print(torch.cuda.get_device_name(0))"
     ```

#### 3. **CUDA-Check umgehen (Vor√ºbergehende Problemumgehung)**
   Wenn Sie Stable Diffusion ohne GPU-Unterst√ºtzung ausf√ºhren m√∂chten (z.B. zum Testen auf der CPU), umgehen Sie den CUDA-Check, indem Sie `--skip-torch-cuda-test` zu den Befehlszeilenargumenten hinzuf√ºgen.
   - Bearbeiten Sie `webui-user.sh` (oder erstellen Sie sie, falls sie nicht existiert):
     ```bash
     nano /home/lzw/Projects/stable-diffusion-webui/webui-user.sh
     ```
     F√ºgen Sie die Zeile `COMMANDLINE_ARGS` hinzu oder modifizieren Sie sie:
     ```bash
     export COMMANDLINE_ARGS="--skip-torch-cuda-test"
     ```
     Speichern Sie und beenden Sie.
   - F√ºhren Sie das Skript aus:
     ```bash
     ./webui.sh
     ```
     Dies erm√∂glicht es Stable Diffusion, auf der CPU zu laufen, aber die Leistung wird deutlich langsamer sein.

#### 4. **Sicherstellen, dass TCMalloc korrekt konfiguriert ist**
   Ihre Ausgabe zeigt, dass TCMalloc (`libtcmalloc_minimal.so.4`) erkannt und mit `LD_PRELOAD` verlinkt wird. Best√§tigen Sie, dass es funktioniert:
   ```bash
   echo $LD_PRELOAD
   ```
   Wenn es `/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4` ausgibt, ist alles in Ordnung. Wenn nicht, setzen Sie es manuell:
   ```bash
   export LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
   ```
   Oder f√ºgen Sie es zu `webui-user.sh` hinzu:
   ```bash
   export LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4
   ```

#### 5. **Umgebungsvariablen und Pfade √ºberpr√ºfen**
   Stellen Sie sicher, dass Ihre Umgebung korrekt eingerichtet ist:
   - **LD_LIBRARY_PATH √ºberpr√ºfen**:
     CUDA-Bibliotheken m√ºssen zug√§nglich sein. F√ºgen Sie sie bei Bedarf hinzu:
     ```bash
     export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
     ```
     F√ºgen Sie dies zu `~/.bashrc` oder `webui-user.sh` f√ºr Persistenz hinzu.
   - **Virtuelle Umgebung aktivieren**:
     Aktivieren Sie immer die Stable-Diffusion-Virtual-Umgebung vor der Ausf√ºhrung:
     ```bash
     cd /home/lzw/Projects/stable-diffusion-webui
     source venv/bin/activate
     ```

#### 6. **Stable Diffusion WebUI aktualisieren**
   Ihre Version (`v1.10.1`, Commit `82a973c`) k√∂nnte Kompatibilit√§tsprobleme haben. Aktualisieren Sie auf die neueste Version:
   ```bash
   cd /home/lzw/Projects/stable-diffusion-webui
   git pull
   ```
   Installieren Sie dann die Abh√§ngigkeiten neu:
   ```bash
   ./webui.sh
   ```

#### 7. **Fehlerbehebung**
   - **Wenn `nvidia-smi` fehlschl√§gt**: Installieren Sie den NVIDIA-Treiber neu oder √ºberpr√ºfen Sie auf GPU-Hardwareprobleme.
   - **Wenn PyTorch die GPU immer noch nicht erkennt**:
     - Stellen Sie sicher, dass CUDA und cuDNN korrekt installiert sind. Installieren Sie cuDNN, falls es fehlt:
       ```bash
       sudo apt-get install libcudnn8
       ```
     - √úberpr√ºfen Sie die Kompatibilit√§t der CUDA-Version mit Ihrer GPU und PyTorch. √Ñltere GPUs (z.B. Kepler-Serie) unterst√ºtzen beispielsweise m√∂glicherweise CUDA 12 nicht.
   - **Wenn Fehler bestehen bleiben**: √úberpr√ºfen Sie die Stable-Diffusion-Logs auf detaillierte Fehler:
     ```bash
     cat /home/lzw/Projects/stable-diffusion-webui/log/webui.log
     ```
     Teilen Sie spezifische Fehler f√ºr weitere Unterst√ºtzung mit.
   - **Hardware-Einschr√§nkungen**: Wenn Ihre GPU zu alt ist (z.B. NVIDIA-GPUs vor 2016), unterst√ºtzt sie m√∂glicherweise keine modernen CUDA-Versionen. Verwenden Sie in diesem Fall `--skip-torch-cuda-test` oder upgraden Sie Ihre GPU.

#### 8. **Anwendung ausf√ºhren**
   Nachdem Sie die Korrekturen angewendet haben, f√ºhren Sie die WebUI aus:
   ```bash
   cd /home/lzw/Projects/stable-diffusion-webui
   ./webui.sh
   ```
   Wenn Sie das GPU-Problem behoben haben, sollte der Fehler verschwinden. Wenn Sie `--skip-torch-cuda-test` verwenden, wird es auf der CPU laufen.

### Hinweise
- **Systeminfo**: Ihr Setup (glibc 2.35, Python 3.10.12, GCC 11.4.0) deutet auf Ubuntu 22.04 hin, das mit CUDA 11.8 oder 12.1 und aktuellen PyTorch-Versionen kompatibel ist.
- **Leistung**: Das Ausf√ºhren auf der CPU (mit `--skip-torch-cuda-test`) ist ein Fallback, wird aber langsam sein. Das Beheben der GPU-Unterst√ºtzung wird f√ºr Stable Diffusion empfohlen.
- **TCMalloc**: Das TCMalloc-Problem scheint basierend auf Ihrer Ausgabe behoben zu sein. Stellen Sie sicher, dass `LD_PRELOAD` gesetzt bleibt, wenn Sie speicherbezogene Probleme feststellen.

Wenn Sie immer noch Probleme haben oder Hilfe mit spezifischen Fehlermeldungen ben√∂tigen, geben Sie bitte zus√§tzliche Details an (z.B. GPU-Modell, CUDA-Version oder vollst√§ndige Logs), und ich kann die L√∂sung verfeinern!