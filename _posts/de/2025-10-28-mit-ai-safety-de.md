---
audio: false
generated: true
image: false
lang: de
layout: post
model: x-ai/grok-4-fast
title: MIT-Professor schreitet bei KI-Sicherheit voran
translated: true
type: note
---

Aleksander Mądry ist ein bedeutender Informatiker und Professor am MIT, wo er die Cadence Design Systems Professur in der Abteilung für Elektrotechnik und Informatik (EECS) innehat. Er ist außerdem Mitglied des Computer Science and Artificial Intelligence Laboratory (CSAIL) und Direktor des MIT Center for Deployable Machine Learning. Mądry promovierte 2011 am MIT, gefolgt von einer Postdoc-Tätigkeit bei Microsoft Research New England und einer Professur an der EPFL, bevor er 2015 zum MIT zurückkehrte.

Seine Forschung konzentriert sich primär auf Machine Learning, Optimierung und algorithmische Graphentheorie, mit einem besonderen Schwerpunkt auf der Entwicklung robuster, zuverlässiger und verantwortungsvoller Machine-Learning-Systeme für den Einsatz in der realen Welt. Er leitet das Madry Lab am MIT, das Werkzeuge und Techniken erforscht, um Risiken in KI-Modellen zu mindern, wie z. B. adversariale Robustheit und sicheres Entscheidungsfinden. Zu seinen bedeutenden Beiträgen gehören grundlegende Arbeiten zu nachweislich robusten neuronalen Netzen und Data-Attribution-Methoden für große Modelle.

Seit Mai 2023 ist Mądry vom MIT beurlaubt und arbeitet bei OpenAI als Member of Technical Staff. In dieser Rolle leitet er das AI Preparedness and Reasoning Team, das potenzielle Risiken von Frontier-AI-Modellen (wie katastrophalen Missbrauch) bewertet und Reasoning-Fähigkeiten vorantreibt, um Systeme leistungsfähiger, zuverlässiger und besser mit menschlichen Werten in Einklang zu bringen. Zuvor leitete er das Preparedness-Team von OpenAI, das sich auf Safety-Evaluierungen konzentrierte, bevor eine Reorganisation im Jahr 2024 seinen Schwerpunkt auf Reasoning-Projekte verlagerte. In einem kürzlichen Interview sagte Mądry voraus, dass eine künstliche allgemeine Intelligenz (AGI) bis Ende 2026 entstehen könnte, was einen Übergang markieren würde, bei dem KI sichtbare Auswirkungen auf Bereiche wie Finanzen und Pharmazie hat.

Er ist aktiv auf X (ehemals Twitter) unter @aleks_madry, wo er Updates zu seiner Forschung teilt, einschließlich aktueller Arbeiten zur Verwendung kleinerer "Proxy"-Modelle zur Analyse der Auswirkungen von Trainingsdaten auf große KI-Systeme.

### Referenzen
- [Aleksander Mądry Homepage](http://madry.mit.edu/)
- [Madry Lab](https://madrylab.mit.edu/)
- [Aleksander Mądry LinkedIn](https://www.linkedin.com/in/aleksander-madry-61115b233)
- [OpenAI versetzt Madry in AI-Reasoning-Rolle (CNBC, 2024)](https://www.cnbc.com/2024/07/23/openai-removes-ai-safety-executive-aleksander-madry-from-role.html)
- [Mądry zum AGI-Zeitplan (Reddit Interview-Zusammenfassung, 2025)](https://www.reddit.com/r/accelerate/comments/1ocgxdl/openais_aleksander_m%C4%85dry_by_the_end_of_2026_well/)
- [Mądry X-Profil](https://x.com/aleks_madry)