---
audio: false
lang: de
layout: post
title: Tipps für KI-Tools
translated: true
---

* Beispielcode in Cursor kopieren und mit Kommentaren kontextualisieren.

* In der Region Hongkong ist die Verwendung von DeepSeek oder Mistral-Diensten akzeptabel, während die Verwendung von ChatGPT, Claude oder Gemini nicht akzeptabel ist.

* Die API-Richtlinie einer Region entspricht in etwa ihrer App-Richtlinie.

* Anstelle von Visual Studio Code Cursor verwenden.

* Es gibt immer noch Fälle, in denen Visual Studio Code verwendet werden muss, z. B. bei Git-Merge-Editor-Szenarien, wo ich immer noch `git config --global core.editor "code --wait"` verwende.

* Ab der Veröffentlichung von Deepseek V3 müssen wir keine KI-Tools mehr abonnieren.

* Verwenden Sie Gemini oder Grok, um Bilder für Festlichkeiten mit Eingabeaufforderungen wie „Generieren Sie ein fröhliches Bild zum Mondneujahrsfest des Schlangenjahres mit einbegriffenen Textnamen“ zu generieren.

* In einigen Fällen können sich selbst bei der Bereitstellung von Originaltext an KI-Modelle zur Erstellung einer Tabelle einige Stellen in der Ausgabe vom Input unterscheiden. Wenn beispielsweise das Deepseek V3-Modell in Cursor verwendet wird, um eine Tabelle der pip-Liste zu generieren, können Versionen wie `1.极狐0` enthalten sein. Hier bezieht sich `极狐` auf die chinesische GitLab-Plattform.

* Bei Verwendung der DeepSeek- oder Mistral-API zum Übersetzen von Titeln mit Eingabeaufforderungen wie `Sie sind ein professioneller Übersetzer. Sie übersetzen eine Markdown-Datei für einen Jekyll-Blogbeitrag von Englisch nach Chinesisch. {Text}` kann dies zu falschen Übersetzungen führen. Neben dem von Ihnen angegebenen Text enthält die Ausgabe häufig übermäßige Übersetzungen.

* Obwohl KI-Modelle in Cursor manchmal teilweise korrekte Texte liefern, können wir diese akzeptieren, da wir Folgeaufforderungen hinzufügen können, die die KI-Modelle dazu bringen, die korrekten Teile neu zu generieren.

* Vermeiden Sie es, großen Sprachmodellen übermäßigen Kontext zu liefern, wenn dies wahrscheinlich nicht hilfreich ist. Vermeiden Sie beispielsweise bei der Generierung von Dialogzeilen die Angabe von 100 Punkten zu einem Thema. Große Sprachmodelle enthalten bereits riesige Datenmengen.

* Vermeiden Sie bei der Bereitstellung von ausreichendem Kontext für Aufgaben wie Übersetzung oder die Generierung von Dialogtexten die Verwendung von Chain-of-Thought-Funktionen, da dies langsam sein und zu ausführlichen oder nicht hilfreichen Antworten führen kann.

* Eine Möglichkeit zu testen, ob ein Chatbot den Anweisungen eines Benutzers folgen kann, besteht darin, ihn zu bitten, etwas auf Englisch zu erklären und dann die Eingabe auf Chinesisch fortzusetzen, wobei beobachtet wird, ob der Chatbot seine Ausgabe auf Englisch beibehält.

* Ein Grund, warum wir Postman oder Figma im KI-Zeitalter nicht verwenden, ist, dass ihre Funktionalitäten nicht durch Text generiert werden können. Ihnen fehlt auch eine Befehl + K-Tastaturkürzel zum Auslösen des Komponentenersatzes.

* Benutzeroberflächen werden im KI-Zeitalter zu einer Barriere. Warum Postman für das Testen von Anwendungen auf KI-Basis aktualisieren, wenn wir die Requests-Bibliothek von Python oder andere Programmiersprachen direkt zum Testen von Code verwenden können, da letztere von KI unterstützt werden?

* Warum Figma für die KI-gestützte UI-Erstellung aktualisieren, wenn die codebasierte UI-Generierung, die durch KI verbessert wird, einen direkteren und potenziell leistungsstärkeren Ansatz bietet?

* LLMs werden zuerst textbezogene Anwendungen verändern.


* [KI-gestützte Git-Commit-Nachrichten](./gitmessageai-en)

* [Generierung von Gesprächsaudio](./conversation-style-en)

* [Google Cloud-Transkription](./speech-to-text-en)

* [Ausprobieren von llama.cpp](./llama-cpp-en)

* [Ein Fall mit der Suche in ChatGPT](./ai-search-en)

* [Deepseek, Mistral und Anthropic](./dma-en)
