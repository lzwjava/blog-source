---
audio: false
lang: de
layout: post
title: Tipps für KI-Tools
translated: true
---

* Beispielcode in Cursor kopieren und mit Kommentaren kontextualisieren.

* In der Region Hongkong ist die Verwendung von DeepSeek oder Mistral Services akzeptabel, während ChatGPT, Claude oder Gemini nicht akzeptabel sind.

* Die API-Richtlinie einer Region entspricht ungefähr der App-Richtlinie.

* Cursor anstelle von Visual Studio Code verwenden.

* Es gibt immer noch Fälle, in denen Visual Studio Code verwendet werden muss, z. B. bei Git-Merge-Editor-Szenarien, wo ich immer noch `git config --global core.editor "code --wait"` verwende.

* Seit der Veröffentlichung von Deepseek V3 müssen wir keine AI-Tools mehr abonnieren.

* Gemini oder Grok verwenden, um Bilder für Festlichkeiten zu generieren, mit Prompts wie „Generiere ein fröhliches Bild zum Mondneujahrsfest des Schlangenjahres mit Namensangaben“.

* In einigen Fällen können sich selbst bei der Bereitstellung von Originaltext an KI-Modelle zur Erstellung einer Tabelle einige Stellen in der Ausgabe vom Input unterscheiden. Wenn beispielsweise das Deepseek V3-Modell in Cursor verwendet wird, um eine Tabelle der Pip-Liste zu generieren, können Versionen wie `1.极狐0` enthalten sein. Hier bezieht sich `极狐` auf die chinesische GitLab-Plattform.

* Bei der Verwendung der DeepSeek- oder Mistral-API zum Übersetzen von Titeln mit Prompts wie `Du bist ein professioneller Übersetzer. Du übersetzt eine Markdown-Datei für einen Jekyll-Blogbeitrag von Englisch ins Chinesische. {text}` kann es zu falschen Übersetzungen kommen. Neben dem von Ihnen angegebenen Text enthält die Ausgabe oft übermäßige Übersetzungen.

* Obwohl KI-Modelle in Cursor manchmal teilweise korrekte Texte liefern, können wir diese akzeptieren, da wir Folgeanweisungen hinzufügen können, die die KI-Modelle dazu bringen, die korrekten Teile neu zu generieren.

* Vermeiden Sie es, großen Sprachmodellen übermäßigen Kontext zu liefern, wenn dies wahrscheinlich nicht hilfreich ist. Vermeiden Sie beispielsweise bei der Generierung von Dialogzeilen die Angabe von 100 Punkten zu einem Thema. Große Sprachmodelle enthalten bereits riesige Datenmengen.

* Vermeiden Sie bei der Bereitstellung ausreichendem Kontext für Aufgaben wie Übersetzung oder die Generierung von Dialogtexten die Verwendung von Chain-of-Thought-Funktionen, da dies langsam sein und zu ausführlichen oder unhilfreichen Antworten führen kann.

* Eine Möglichkeit, zu testen, ob ein Chatbot den Anweisungen eines Benutzers folgen kann, besteht darin, ihn zu bitten, etwas auf Englisch zu erklären und dann die Eingabe auf Chinesisch fortzusetzen, wobei beobachtet wird, ob der Chatbot seine Ausgabe auf Englisch beibehält.

* Ein Grund, warum wir Postman oder Figma im KI-Zeitalter nicht verwenden, ist, dass ihre Funktionalitäten nicht über Text generiert werden können. Ihnen fehlt auch eine Befehl + K-Verknüpfung zum Auslösen des Komponentenersatzes.

* Benutzeroberflächen werden im KI-Zeitalter zu einer Barriere. Warum Postman für das Testen von Anwendungen auf KI-Basis aktualisieren, wenn wir die Requests-Bibliothek von Python oder andere Programmiersprachen direkt zum Testen von Code verwenden können, da letztere von KI unterstützt werden?

* Warum Figma für die KI-gestützte UI-Erstellung aktualisieren, wenn die codebasierte UI-Generierung, erweitert durch KI, einen direkteren und potenziell leistungsstärkeren Ansatz bietet?

* LLMs werden zuerst textbezogene Anwendungen verändern.


* [KI-gestützte Git-Commit-Nachrichten](./gitmessageai-en)

* [Generierung von Konversationsaudio](./conversation-style-en)

* [Google Cloud Transkription](./speech-to-text-en)

* [Ausprobieren von llama.cpp](./llama-cpp-en)

* [Ein Anwendungsfall mit Suche in ChatGPT](./ai-search-en)

* [Deepseek, Mistral und Anthropic](./dma-en)
