---
audio: false
lang: de
layout: post
title: Tipps für KI-Tools
translated: true
---

* Kopieren Sie Beispielcode in Cursor und verwenden Sie Kommentare, um Kontext bereitzustellen.

* In der Region Hongkong ist die Verwendung von DeepSeek- oder Mistral-Diensten akzeptabel, während die Verwendung von ChatGPT, Claude oder Gemini nicht akzeptabel ist.

* Die API-Richtlinie einer Region entspricht ungefähr der App-Richtlinie.

* Verwenden Sie Cursor anstelle von Visual Studio Code.

* Es gibt immer noch Fälle, in denen Sie Visual Studio Code verwenden müssen, z. B. für Git-Merge-Editor-Szenarien, wo ich immer noch `git config --global core.editor "code --wait"` verwende.

* Ab der Veröffentlichung von Deepseek V3 müssen wir keine AI-Tools mehr abonnieren.

* Verwenden Sie Gemini oder Grok, um Bilder für Festlichkeiten zu generieren, mit Aufforderungen wie "Generieren Sie ein fröhliches Bild zum Mondschlangen-Neujahr mit einbezogenen Textnamen".

* In einigen Fällen können sich, selbst wenn Sie Originaltext an KI-Modelle zur Erstellung einer Tabelle liefern, einige Stellen in der Ausgabe vom Input unterscheiden. Wenn Sie beispielsweise das Deepseek V3-Modell in Cursor verwenden, um eine Tabelle der Pip-Liste zu generieren, kann es Versionen wie `1.极狐0` enthalten. Hier bezieht sich `极狐` auf die chinesische GitLab-Plattform.

* Wenn Sie die DeepSeek- oder Mistral-API verwenden, um Titel mit Aufforderungen wie `Sie sind ein professioneller Übersetzer. Sie übersetzen eine Markdown-Datei für einen Jekyll-Blogbeitrag von Englisch ins Chinesische. {Text}` zu übersetzen, kann dies zu falschen Übersetzungen führen. Neben dem von Ihnen bereitgestellten Text enthält die Ausgabe oft übermäßige Übersetzungen.

* Obwohl KI-Modelle in Cursor manchmal teilweise korrekte Texte liefern, können wir diese akzeptieren, da wir Folgeanweisungen hinzufügen können, die die KI-Modelle dazu bringen, die korrekten Teile neu zu generieren.

* Vermeiden Sie es, großen Sprachmodellen übermäßigen Kontext zu liefern, wenn dies wahrscheinlich nicht hilfreich ist. Vermeiden Sie beispielsweise bei der Generierung von Dialogzeilen, 100 Punkte zu einem Thema anzugeben. Große Sprachmodelle enthalten bereits riesige Datenmengen.

* Vermeiden Sie bei der Bereitstellung von ausreichendem Kontext für Aufgaben wie Übersetzung oder die Generierung von Dialogtexten die Verwendung von Chain-of-Thought-Funktionen, da dies langsam sein und zu ausführlichen oder unbrauchbaren Antworten führen kann.

* Eine Möglichkeit, zu testen, ob ein Chatbot den Anweisungen eines Benutzers folgen kann, besteht darin, ihn zu bitten, etwas auf Englisch zu erklären und dann die Eingabe auf Chinesisch fortzusetzen, wobei beobachtet wird, ob der Chatbot seine Ausgabe auf Englisch beibehält.

* Ein Grund, warum wir Postman oder Figma im KI-Zeitalter nicht verwenden, ist, dass ihre Funktionen nicht über Text generiert werden können. Ihnen fehlt auch eine Befehl + K-Verknüpfung zum Auslösen des Komponentenersatzes.

* Benutzeroberflächen werden im KI-Zeitalter zu einer Barriere. Warum Postman für das Testen von Anwendungen auf KI-Basis aktualisieren, wenn wir die Requests-Bibliothek von Python oder andere Programmiersprachen direkt zum Testen von Code verwenden können, da letztere von KI unterstützt werden?

* Warum Figma für die KI-gestützte UI-Erstellung aktualisieren, wenn die codebasierte UI-Generierung, die durch KI verbessert wird, einen direkteren und potenziell leistungsstärkeren Ansatz bietet?


* [KI-gestützte Git-Commit-Nachrichten](./gitmessageai-en)

* [Generierung von Gesprächsaudio](./conversation-style-en)

* [Google Cloud-Transkription](./speech-to-text-en)

* [Ausprobieren von llama.cpp](./llama-cpp-en)

* [Ein Fall mit der Suche in ChatGPT](./ai-search-en)

* [Deepseek, Mistral und Anthropic](./dma-en)
