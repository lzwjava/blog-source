---
audio: false
generated: true
lang: de
layout: post
title: KI kann Programmierfähigkeiten nicht ersetzen
translated: true
type: note
---

https://weibo.com/6347862377/5183583601819943

---

Heutzutage gibt es so viele Fehlinformationen im Internet, die behaupten, dass KI (LLM) unglaublich gut im Programmieren sei und in der Lage ist, Projekte ohne eine einzige Codezeile abzuschließen. Basierend auf meiner umfangreichen praktischen Erfahrung mit ChatGPT, Claude, Copilot und kürzlich Cursor, ist es fast eine Fantasievorstellung, dass jemand, der nicht programmieren kann, ein Projekt mit KI erfolgreich abschließen kann.

Selbst diejenigen, die programmieren können, aber kein tiefes Verständnis der Informatik und keine Fähigkeit besitzen, extrem einfache, logisch präzise Programme zu schreiben, werden wahrscheinlich mit KI keinen "Wang Yin-level" Code produzieren. Einige sind überrascht, dass Wang Yin auch KI benutzt? Natürlich, warum sollte ich nicht? Ich benutze sie quite a bit und effektiver als die meisten Leute. Während der späteren Phasen der fünften Sektion des Computer Science Basics Kurses letztes Jahr, demonstrierte ich den Studenten die Verwendung von Copilot zum Vervollständigen von Code. Ich empfehle den Studenten im Kurs jedoch nicht, diese Tools zu benutzen, weil ihnen die Fähigkeit fehlt, die Qualität des generierten Codes zu beurteilen, und die Nutzung von KI ihr Denken und ihren Fortschritt offensichtlich behindern würde. Aber ich kann es kontrollieren, also kann ich es benutzen.

Im letzten Monat hat Cursor über 60.000 Codezeilen für mich generiert. Ratet mal, wie viele Zeilen ich akzeptiert habe? Weniger als 5.000. Es geht oft in die falsche Richtung, wiederholt die gleiche Logik, ohne Abstraktion zu verstehen, und korrigiert sogar Teile, die ich manuell angepasst habe, und macht zuvor korrigierte Fehler wieder rückgängig. Es schreibt viele komplexe Tests, die es selbst nicht verstehen kann, und scheitert letztendlich daran, zu verstehen, warum die Tests "nicht bestehen..."

Vor ein paar Tagen habe ich ein neues Projekt erstellt, das über 20 Stunden meiner "Erklärungen" an es verschlungen hat, was zur Generierung von über 20.000 Codezeilen führte. Schließlich wurde es so komplex, dass es nicht mehr reparierbar war, und ich musste mich entscheiden, komplett von vorne anzufangen. Es jubelte sogar: "Erfolg!" und listete Punkt für Punkt die "Errungenschaften" auf, völlig ignorierend die fundamentalen Fehler, die keinen Sinn ergaben. Ich wies wiederholt auf die Probleme hin, aber es antwortete ständig mit "Oh, ich verstehe!" und "Dieses Mal habe ich die Wurzel des Problems gefunden!", aber das war alles leeres Gerede... Weil es nicht korrigiert werden konnte, konnte es sich nur selbst täuschen?

Das von mir verwendete Modell war der neueste Claude 4 Sonnet. GPT 4.1 ist sogar schlechter und für Codeänderungen fast unbrauchbar. Claude Opus ist zu teuer und langsam, und soweit ich es ausprobiert habe, scheint es nicht viel besser als Sonnet zu sein. Einige Leute bieten Cursor Konfigurations-"Richtlinien" an und sagen, man müsse diese nur in .cursorrules schreiben. Natürlich habe ich es versucht, aber es ist nutzlos. Es erfüllt nicht, was auch immer man verlangt; sogar die von mir gerade vorgeschlagenen Anforderungen können manchmal ignoriert werden. Die Leute denken, KI könne eine große Menge komplexen Codes verstehen, aber immer wieder hat mich die Erfahrung gelehrt, dass sie es nicht kann.

Niemand kann chaotischen Code verstehen, nicht einmal Wang Yin. Wenn man der KI ein paar Mal Anweisungen gibt und der generierte Code kombiniert wird, fängt er an, sich zu wiederholen und chaotisch zu werden. KI kann die Muster und Ähnlichkeiten in diesem Code nicht verstehen; sie hat sich vielleicht sogar einige Teile des Codes gar nicht angesehen. Daher kann sie solchen Code nicht vereinfachen oder sogar erkennen, wo er vereinfacht werden kann. Ein paar Mal habe ich explizit die Zeilennummern markiert und darauf hingewiesen: "Dieser Teil kann vereinfacht werden." Es antwortete: "Ja! Ich helfe dir, es zu vereinfachen!" Aber am Ende war sein Verständnis völlig anders; es ging hin und korrigierte Teile, die ursprünglich korrekt waren, und der Code wurde überhaupt nicht vereinfacht.

Versteht mich nicht falsch, die Verwendung von KI für Aufgaben ist nicht immer ein Misserfolg; tatsächlich ist sie oft in kleinem Maßstab erfolgreich. Manchmal kann sie wirklich Dinge erledigen, aber man muss wissen, wie man sie kontrolliert. Ich gebe dieses Beispiel nur, um zu zeigen, dass selbst Wang Yin oft scheitert, wenn er KI zum Schreiben von Code verwendet. Es ist eindeutig nicht so, wie beworben, wo man ihm einfach sagt, was es tun soll. Ich habe es sehr detailliert beschrieben, und es funktioniert immer noch nicht gut. Wie detailliert können Wang Yins Beschreibungen sein? Schaut euch einfach Wang Yins Artikel an, und ihr werdet es wissen.

Einige sagen, man solle die Ziele nicht zu hoch oder zu schnell setzen und eine Strategie haben. Natürlich weiß ich das; ich bin sehr strategisch. Glaubt ihr, meine vorherigen erfolgreichen Projekte hätten ohne Weisheit und Strategie erreicht werden können? Die sogenannte Strategie besteht darin, zu wissen, was zuerst zu tun ist, was später zu tun ist, was getan werden sollte, was nicht getan werden sollte und was vorerst nicht getan werden sollte. Ich kann sagen, dass ich ein Meister dieser Art von Strategie bin. Sehr wenige Leute wissen, wie ich Dinge mache; sie kennen nur das Endergebnis.

Nachdem ich PySonar gemacht hatte, verbrachte ein Team bei Google zwei Jahre damit, zu versuchen, ein Projekt zu schaffen, das PySonar übertrifft, aber am Ende erreichten sie nichts. Warum? Weil ihre Strategie von Anfang an falsch war. Sie wollten eine logische Programmiersprache wie Prolog verwenden, um Typinferenz zu implementieren. Sobald ich das hörte, wusste ich, dass es zum Scheitern verurteilt war. Woher wusste ich das? Weil ich es bereits versucht hatte und ich die Grenzen des Hindley-Milner-Systems und von Prolog kannte. Zu wissen, was man nicht tun sollte und was zum Scheitern verurteilt ist, ist tatsächlich eine sehr wichtige Weisheit und Strategie. Vielen Menschen fehlt diese Weisheit.

Ich schweife ab. Kurz gesagt, ich fand später heraus, dass meine üblichen Programmierstrategien verwendet werden können, um KI beim Schreiben von Code anzuleiten, wie z.B. von den grundlegendsten kleinen Funktionen auszugehen und allmählich fortzuschreiten. Kann es es richtig machen, wenn es so angeleitet wird? Ich stellte fest, dass es nicht einmal kleine Code-Stücke gut schreiben kann. Einige kleine Funktionen von nur wenigen Zeilen erfordern, dass ich sie mehrmals korrigiere, bevor es sie richtig hinbekommt. Und dann, wer weiß, wann es sie wieder falsch korrigieren könnte, also muss man jede Stelle überprüfen, die es geändert hat. Man muss wissen, wie guter Code aussieht und was Müll ist. Mit anderen Worten, man muss fast jede Codezeile, die es schreibt, überprüfen, sonst ist es leicht, die Kontrolle zu verlieren.

Wenn man keinen Code schreiben kann, wie kann man dann den Code von jemand anderem überprüfen? Zu wissen, wie guter und korrekter Code aussieht, ist das Schwierigste. Ohne gründliche Forschung und viel Erfahrung ist es unmöglich, dies zu erkennen. Ja, KI ist jetzt ein Coder geworden, und ich bin ein VP geworden. Aber was kann ein VP, der Informatik nicht versteht und eine Gruppe von Codern anführt, die Spaghetti-Code schreiben, Gutes produzieren? Hehe, ich verstehe ähnliche Phänomene in vielen Unternehmen. Sie wissen nicht, was ihre Untergebenen tun, wer recht hat oder was der nächste Schritt sein sollte. Ich weiß, wie viele VPs im Dunkeln tappen, täuschen und betrügen.

Also, Leute ohne Fähigkeiten können mit KI immer noch nichts anfangen, weil sie sie nicht kontrollieren können. Sie sind nicht qualifiziert, VPs zu sein. Weil der größte Teil des Codes auf der Welt von mittelmäßigen Spaghetti-Code-Programmierern geschrieben wird und die Trainingsdaten so sind, ist es zu erwarten, dass KI kaum "Wang Yin-level" Code schreiben kann. Ich stellte fest, dass KI, wenn ich ihr meinen gut geschriebenen Code gebe, tatsächlich einige nützliche Analysen und Verbesserungen durchführen kann. Aber wenn sie von Grund auf neu schreibt, kämpft KI wirklich. Fast jede kleine Funktion erfordert, dass ich sie mehrmals korrigiere, um die Einfachheit und Verständlichkeit zu erreichen, die ich erwarte.

Der Code in meinem Informatikkurs ist alles extrem tiefgründig, völlig anders als Unternehmenscode und Open-Source-Projekte. Daher haben Studenten, die meinen Kurs besuchen, wenig Hoffnung, KI zu benutzen, um ihre Übungen zu vervollständigen. Weil das Datenvolumen zu gering ist, es keine Trainingsdaten gibt, daher wird KI vielleicht niemals dieses Niveau an Tiefgründigkeit erreichen. Natürlich, nach dem Abschluss ist das Niveau der Studenten weit über dem von KI und diesen mittelmäßigen Programmierern, die die Quelle der KI-Trainingsdaten sind. Deshalb heißt mein Kurs "Informatik" und nicht "Programmieren". Es gibt einen riesigen Unterschied zwischen Informatikern und Programmierern/Softwareingenieuren.

KI mag gewöhnliche Programmierer ersetzen können, aber sie kann Informatiker niemals ersetzen. Sie kann nur von Informatikern als Werkzeug benutzt werden. Versteht mich nicht falsch, ich halte KI tatsächlich für eine großartige Sache und eine wirklich großartige Erfindung. Ich fand heraus, dass LLM menschliche Sprache wirklich verstehen kann und eine tiefe Ebene des "Denkens" zu haben scheint, was bereits eine bemerkenswerte Leistung ist. Meine vorherigen Bewertungen von KI waren meistens richtig, wie die Vorhersage, dass "selbstfahrende Autos" zum Scheitern verurteilt sind. Es ist nur so, dass die Fähigkeiten von LLM meine Erwartungen etwas übertroffen haben.

Allerdings ist das derzeitige Programmierniveau von LLM eindeutig weit unter meinem. Bei der Verwendung von KI stellte ich fest, dass die Geschwindigkeit der Problemlösung stark zugenommen hat, weil viele mühsame Aufgaben nicht meine persönliche Aufmerksamkeit erfordern, was es mir ermöglicht, mich mehr auf die Kernbereiche zu konzentrieren. Kurz gesagt, ich benutze es, um die "Drecksarbeit" zu erledigen, die ich nicht machen möchte, und es beschwert sich nicht. Das ist der Grund, warum ich sie nach so vielen Misserfolgen weiterhin benutze und sogar dafür bezahle. Weil es auf dieser Welt zu viel Drecksarbeit gibt, zu viele komplexe und schlecht gestaltete Dokumente, und ich brauche ein solches Werkzeug, um mir zu helfen, damit umzugehen. Aber die Kernideen müssen immer noch von mir kommen; KI ist in dieser Hinsicht machtlos.